# Ollama Model Library

![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.github.com%2Frepos%2Fyuma-shintani%2Follama-model-library%2Factions%2Fworkflows%2F144521343%2Fruns%3Fstatus%3Dcompleted%26per_page%3D1&query=%24.workflow_runs%5B0%5D.run_started_at&style=flat-square&label=Last%20update%20Ollama%20models)

Get Ollama models from the Ollama library website (https://ollama.com/library) in JSON format.

# Features

## Get Models JSON Format

Access the following link to obtain a list of Ollama models in JSON format.  
https://yuma-shintani.github.io/ollama-model-library/model.json

````json:model.json
[
  {
    "name": "deepseek-r1",
    "link": "https://ollama.com/library/deepseek-r1",
    "description": "DeepSeek's first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.",
    "pullCount": "17M",
    "updated": "10 days ago",
    "size": [
      "1.5b",
      "7b",
      "8b",
      "14b",
      "32b",
      "70b",
      "671b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a)\n\nDeepSeekâ€™s first-generation reasoning models, achieving performance comparable to OpenAI-o1 across math, code, and reasoning tasks.\n\n## Models\n\n**DeepSeek-R1**\n\n```\nollama run deepseek-r1:671b\n\n```\n\n### Distilled models\n\nDeepSeek team has demonstrated that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models.\n\nBelow are the models created via fine-tuning against several dense models widely used in the research community using reasoning data generated by DeepSeek-R1\\. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks.\n\n**DeepSeek-R1-Distill-Qwen-1.5B**\n\n```\nollama run deepseek-r1:1.5b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-7B**\n\n```\nollama run deepseek-r1:7b\n\n```\n\n**DeepSeek-R1-Distill-Llama-8B**\n\n```\nollama run deepseek-r1:8b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-14B**\n\n```\nollama run deepseek-r1:14b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-32B**\n\n```\nollama run deepseek-r1:32b\n\n```\n\n**DeepSeek-R1-Distill-Llama-70B**\n\n```\nollama run deepseek-r1:70b\n\n```\n\n![deepseek](/assets/library/deepseek-r1/e44d096e-fa46-4cae-b2f2-53991e8c8da0)\n\n### License\n\nThe model weights are licensed under the MIT License. DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that:\n\nThe Qwen distilled models are derived from Qwen-2.5 series, which are originally licensed under Apache 2.0 License, and now finetuned with 800k samples curated with DeepSeek-R1.\n\nThe Llama 8B distilled model is derived from Llama3.1-8B-Base and is originally licensed under llama3.1 license.\n\nThe Llama 70B distilled model is derived from Llama3.3-70B-Instruct and is originally licensed under llama3.3 license.\n\nWrite Preview \n\n<img src=\"/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a\" width=\"320\" /> DeepSeek's first-generation reasoning models, achieving performance comparable to OpenAI-o1 across math, code, and reasoning tasks. ## Models \\*\\*DeepSeek-R1\\*\\* \\`\\`\\` ollama run deepseek-r1:671b \\`\\`\\` ### Distilled models DeepSeek team has demonstrated that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models. Below are the models created via fine-tuning against several dense models widely used in the research community using reasoning data generated by DeepSeek-R1\\. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. \\*\\*DeepSeek-R1-Distill-Qwen-1.5B\\*\\* \\`\\`\\` ollama run deepseek-r1:1.5b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-7B\\*\\* \\`\\`\\` ollama run deepseek-r1:7b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Llama-8B\\*\\* \\`\\`\\` ollama run deepseek-r1:8b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-14B\\*\\* \\`\\`\\` ollama run deepseek-r1:14b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-32B\\*\\* \\`\\`\\` ollama run deepseek-r1:32b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Llama-70B\\*\\* \\`\\`\\` ollama run deepseek-r1:70b \\`\\`\\` !\\[deepseek\\](/assets/library/deepseek-r1/e44d096e-fa46-4cae-b2f2-53991e8c8da0) ### License The model weights are licensed under the MIT License. DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that: The Qwen distilled models are derived from Qwen-2.5 series, which are originally licensed under Apache 2.0 License, and now finetuned with 800k samples curated with DeepSeek-R1\\. The Llama 8B distilled model is derived from Llama3.1-8B-Base and is originally licensed under llama3.1 license. The Llama 70B distilled model is derived from Llama3.3-70B-Instruct and is originally licensed under llama3.3 license. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-r1:latest",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:1.5b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:7b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:8b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:14b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:32b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:70b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:671b",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:1.5b-qwen-distill-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:1.5b-qwen-distill-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:1.5b-qwen-distill-q8_0",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:14b-qwen-distill-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:14b-qwen-distill-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:14b-qwen-distill-q8_0",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:32b-qwen-distill-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:32b-qwen-distill-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:32b-qwen-distill-q8_0",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:671b-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:671b-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:671b-q8_0",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:70b-llama-distill-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:70b-llama-distill-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:70b-llama-distill-q8_0",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:7b-qwen-distill-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:7b-qwen-distill-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:7b-qwen-distill-q8_0",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:8b-llama-distill-fp16",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:8b-llama-distill-q4_K_M",
        "size": "",
        "updated": ""
      },
      {
        "name": "deepseek-r1:8b-llama-distill-q8_0",
        "size": "",
        "updated": ""
      }
    ]
  }
]
````

You can incorporate the Ollama Library into your own applications.
![own app](/public/image.png)

## Models Update

Models are updated daily at midnight on Github Actions.

# License

This project is licensed under the MIT License. See the [LICENSE](LICENSE.md) file for more details.

# Contact

For any inquiries or support, please open an issue on GitHub.
