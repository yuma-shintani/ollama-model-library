[
  {
    "name": "gpt-oss",
    "link": "https://ollama.com/library/gpt-oss",
    "description": "OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.",
    "pullCount": "1.9M",
    "updated": "3 weeks ago",
    "size": [
      "20b",
      "120b"
    ],
    "capabilities": "toolsthinking",
    "readme": "## Readme\n\n![OpenAI gpt-oss banner](/assets/library/gpt-oss/e9da5025-e172-441d-9f06-8dfa797da9b0)\n\n### Welcome OpenAI’s gpt-oss!\n\nOllama partners with OpenAI to bring its latest state-of-the-art open weight models to Ollama. The two models, 20B and 120B, bring a whole new local chat experience, and are designed for powerful reasoning, agentic tasks, and versatile developer use cases.\n\n### Get started\n\nYou can get started by [downloading the latest Ollama version](https://ollama.com/download).\n\nThe model can be downloaded directly in Ollama’s new app or via the terminal:\n\n**ollama run gpt-oss:20b**\n\n**ollama run gpt-oss:120b**\n\n### Feature highlights\n\n* **Agentic capabilities:** Use the models’ native capabilities for function calling, web browsing (Ollama is introducing built-in web search that can be optionally enabled), python tool calls, and structured outputs.\n* **Full chain-of-thought:** Gain complete access to the model’s reasoning process, facilitating easier debugging and increased trust in outputs.\n* **Configurable reasoning effort:** Easily adjust the reasoning effort (low, medium, high) based on your specific use case and latency needs.\n* **Fine-tunable:** Fully customize models to your specific use case through parameter fine-tuning.\n* **Permissive Apache 2.0 license:** Build freely without copyleft restrictions or patent risk—ideal for experimentation, customization, and commercial deployment.\n\n![benchmark](/assets/library/gpt-oss/d29a500d-303f-4d24-b557-a8247d17ed4c)\n\n### Quantization - MXFP4 format\n\nOpenAI utilizes quantization to reduce the memory footprint of the gpt-oss models. The models are post-trained with quantization of the mixture-of-experts (MoE) weights to MXFP4 format, where the weights are quantized to 4.25 bits per parameter. The MoE weights are responsible for 90+% of the total parameter count, and quantizing these to MXFP4 enables the smaller model to run on systems with as little as 16GB memory, and the larger model to fit on a single 80GB GPU.\n\nOllama is supporting the MXFP4 format natively without additional quantizations or conversions. New kernels are developed for Ollama’s new engine to support the MXFP4 format.\n\nOllama collaborated with OpenAI to benchmark against their reference implementations to ensure Ollama’s implementations have the same quality.\n\n### 20B parameter model\n\n![gpt-oss 20B](/assets/library/gpt-oss/343d558d-a3bc-472e-9956-37fdc3cc4f6c)\n\ngpt-oss-20b model is designed for lower latency, local, or specialized use-cases.\n\n### 120B parameter model\n\n![gpt-oss 120B](/assets/library/gpt-oss/51b69d33-c747-4117-ba76-a6efa1b0a986)\n\n### Reference\n\n* [OpenAI launch blog](https://openai.com/index/introducing-gpt-oss)\n* [OpenAI model card](https://openai.com/index/gpt-oss-model-card/)\n* [NVIDIA RTX blog](https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss)\n* [NVIDIA cloud to edge](https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge/)\n\nWrite Preview \n\n!\\[OpenAI gpt-oss banner\\](/assets/library/gpt-oss/e9da5025-e172-441d-9f06-8dfa797da9b0) ### Welcome OpenAI's gpt-oss! Ollama partners with OpenAI to bring its latest state-of-the-art open weight models to Ollama. The two models, 20B and 120B, bring a whole new local chat experience, and are designed for powerful reasoning, agentic tasks, and versatile developer use cases. ### Get started You can get started by \\[downloading the latest Ollama version\\](https://ollama.com/download). The model can be downloaded directly in Ollama’s new app or via the terminal: \\*\\*ollama run gpt-oss:20b\\*\\* \\*\\*ollama run gpt-oss:120b\\*\\* ### Feature highlights - \\*\\*Agentic capabilities:\\*\\* Use the models’ native capabilities for function calling, web browsing (Ollama is introducing built-in web search that can be optionally enabled), python tool calls, and structured outputs. - \\*\\*Full chain-of-thought:\\*\\* Gain complete access to the model's reasoning process, facilitating easier debugging and increased trust in outputs. - \\*\\*Configurable reasoning effort:\\*\\* Easily adjust the reasoning effort (low, medium, high) based on your specific use case and latency needs. - \\*\\*Fine-tunable:\\*\\* Fully customize models to your specific use case through parameter fine-tuning. - \\*\\*Permissive Apache 2.0 license:\\*\\* Build freely without copyleft restrictions or patent risk—ideal for experimentation, customization, and commercial deployment. !\\[benchmark\\](/assets/library/gpt-oss/d29a500d-303f-4d24-b557-a8247d17ed4c) ### Quantization - MXFP4 format OpenAI utilizes quantization to reduce the memory footprint of the gpt-oss models. The models are post-trained with quantization of the mixture-of-experts (MoE) weights to MXFP4 format, where the weights are quantized to 4.25 bits per parameter. The MoE weights are responsible for 90+% of the total parameter count, and quantizing these to MXFP4 enables the smaller model to run on systems with as little as 16GB memory, and the larger model to fit on a single 80GB GPU. Ollama is supporting the MXFP4 format natively without additional quantizations or conversions. New kernels are developed for Ollama’s new engine to support the MXFP4 format. Ollama collaborated with OpenAI to benchmark against their reference implementations to ensure Ollama’s implementations have the same quality. ### 20B parameter model !\\[gpt-oss 20B\\](/assets/library/gpt-oss/343d558d-a3bc-472e-9956-37fdc3cc4f6c) gpt-oss-20b model is designed for lower latency, local, or specialized use-cases. ### 120B parameter model !\\[gpt-oss 120B\\](/assets/library/gpt-oss/51b69d33-c747-4117-ba76-a6efa1b0a986) ### Reference - \\[OpenAI launch blog\\](https://openai.com/index/introducing-gpt-oss) - \\[OpenAI model card\\](https://openai.com/index/gpt-oss-model-card/) - \\[NVIDIA RTX blog\\](https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss) - \\[NVIDIA cloud to edge\\](https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "gpt-oss:latest",
        "size": "gpt-oss:latest",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gpt-oss:20b",
        "size": "gpt-oss:20b",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gpt-oss:120b",
        "size": "gpt-oss:120b",
        "updated": "Text input • \n                    3 weeks ago"
      }
    ]
  },
  {
    "name": "deepseek-r1",
    "link": "https://ollama.com/library/deepseek-r1",
    "description": "DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.",
    "pullCount": "60.7M",
    "updated": "2 months ago",
    "size": [
      "1.5b",
      "7b",
      "8b",
      "14b",
      "32b",
      "70b",
      "671b"
    ],
    "capabilities": "toolsthinking",
    "readme": "## Readme\n\n![](/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a)\n\nDeepSeek-R1 has received a minor version upgrade to DeepSeek-R1-0528 for the 8 billion parameter distilled model and the full 671 billion parameter model. In this update, DeepSeek R1 has significantly improved its reasoning and inference capabilities. The model has demonstrated outstanding performance across various benchmark evaluations, including mathematics, programming, and general logic. Its overall performance is now approaching that of leading models, such as O3 and Gemini 2.5 Pro.\n\n![image.png](/assets/library/deepseek-r1/ba9ac535-ac57-4d42-9f36-20067c8eaa50)\n\n## Models\n\n**DeepSeek-R1-0528-Qwen3-8B**\n\n```\nollama run deepseek-r1\n\n```\n\n**DeepSeek-R1**\n\n```\nollama run deepseek-r1:671b\n\n```\n\n> Note: to update the model from an older version, run `ollama pull deepseek-r1`\n\n### Distilled models\n\nDeepSeek team has demonstrated that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models.\n\nBelow are the models created via fine-tuning against several dense models widely used in the research community using reasoning data generated by DeepSeek-R1\\. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks.\n\n**DeepSeek-R1-0528-Qwen3-8B**\n\n```\nollama run deepseek-r1:8b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-1.5B**\n\n```\nollama run deepseek-r1:1.5b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-7B**\n\n```\nollama run deepseek-r1:7b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-14B**\n\n```\nollama run deepseek-r1:14b\n\n```\n\n**DeepSeek-R1-Distill-Qwen-32B**\n\n```\nollama run deepseek-r1:32b\n\n```\n\n**DeepSeek-R1-Distill-Llama-70B**\n\n```\nollama run deepseek-r1:70b\n\n```\n\n### License\n\nThe model weights are licensed under the MIT License. DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that:\n\nThe Qwen distilled models are derived from Qwen-2.5 series, which are originally licensed under Apache 2.0 License, and now finetuned with 800k samples curated with DeepSeek-R1.\n\nThe Llama 8B distilled model is derived from Llama3.1-8B-Base and is originally licensed under llama3.1 license.\n\nThe Llama 70B distilled model is derived from Llama3.3-70B-Instruct and is originally licensed under llama3.3 license.\n\nWrite Preview \n\n<img src=\"/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a\" width=\"320\" /> DeepSeek-R1 has received a minor version upgrade to DeepSeek-R1-0528 for the 8 billion parameter distilled model and the full 671 billion parameter model. In this update, DeepSeek R1 has significantly improved its reasoning and inference capabilities. The model has demonstrated outstanding performance across various benchmark evaluations, including mathematics, programming, and general logic. Its overall performance is now approaching that of leading models, such as O3 and Gemini 2.5 Pro. !\\[image.png\\](/assets/library/deepseek-r1/ba9ac535-ac57-4d42-9f36-20067c8eaa50) ## Models \\*\\*DeepSeek-R1-0528-Qwen3-8B\\*\\* \\`\\`\\` ollama run deepseek-r1 \\`\\`\\` \\*\\*DeepSeek-R1\\*\\* \\`\\`\\` ollama run deepseek-r1:671b \\`\\`\\` > Note: to update the model from an older version, run \\`ollama pull deepseek-r1\\` ### Distilled models DeepSeek team has demonstrated that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models. Below are the models created via fine-tuning against several dense models widely used in the research community using reasoning data generated by DeepSeek-R1\\. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. \\*\\*DeepSeek-R1-0528-Qwen3-8B\\*\\* \\`\\`\\` ollama run deepseek-r1:8b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-1.5B\\*\\* \\`\\`\\` ollama run deepseek-r1:1.5b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-7B\\*\\* \\`\\`\\` ollama run deepseek-r1:7b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-14B\\*\\* \\`\\`\\` ollama run deepseek-r1:14b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Qwen-32B\\*\\* \\`\\`\\` ollama run deepseek-r1:32b \\`\\`\\` \\*\\*DeepSeek-R1-Distill-Llama-70B\\*\\* \\`\\`\\` ollama run deepseek-r1:70b \\`\\`\\` ### License The model weights are licensed under the MIT License. DeepSeek-R1 series support commercial use, allow for any modifications and derivative works, including, but not limited to, distillation for training other LLMs. Please note that: The Qwen distilled models are derived from Qwen-2.5 series, which are originally licensed under Apache 2.0 License, and now finetuned with 800k samples curated with DeepSeek-R1\\. The Llama 8B distilled model is derived from Llama3.1-8B-Base and is originally licensed under llama3.1 license. The Llama 70B distilled model is derived from Llama3.3-70B-Instruct and is originally licensed under llama3.3 license. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-r1:latest",
        "size": "deepseek-r1:latest",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:1.5b",
        "size": "deepseek-r1:1.5b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:7b",
        "size": "deepseek-r1:7b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b",
        "size": "deepseek-r1:8b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:14b",
        "size": "deepseek-r1:14b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:32b",
        "size": "deepseek-r1:32b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:70b",
        "size": "deepseek-r1:70b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:671b",
        "size": "deepseek-r1:671b",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "deepseek-r1:1.5b-qwen-distill-q4_K_M",
        "size": "deepseek-r1:1.5b-qwen-distill-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:1.5b-qwen-distill-q8_0",
        "size": "deepseek-r1:1.5b-qwen-distill-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:1.5b-qwen-distill-fp16",
        "size": "deepseek-r1:1.5b-qwen-distill-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:7b-qwen-distill-q4_K_M",
        "size": "deepseek-r1:7b-qwen-distill-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:7b-qwen-distill-q8_0",
        "size": "deepseek-r1:7b-qwen-distill-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:7b-qwen-distill-fp16",
        "size": "deepseek-r1:7b-qwen-distill-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b-0528-qwen3-q4_K_M",
        "size": "deepseek-r1:8b-0528-qwen3-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b-0528-qwen3-q8_0",
        "size": "deepseek-r1:8b-0528-qwen3-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b-0528-qwen3-fp16",
        "size": "deepseek-r1:8b-0528-qwen3-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b-llama-distill-q4_K_M",
        "size": "deepseek-r1:8b-llama-distill-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b-llama-distill-q8_0",
        "size": "deepseek-r1:8b-llama-distill-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:8b-llama-distill-fp16",
        "size": "deepseek-r1:8b-llama-distill-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:14b-qwen-distill-q4_K_M",
        "size": "deepseek-r1:14b-qwen-distill-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:14b-qwen-distill-q8_0",
        "size": "deepseek-r1:14b-qwen-distill-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:14b-qwen-distill-fp16",
        "size": "deepseek-r1:14b-qwen-distill-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:32b-qwen-distill-q4_K_M",
        "size": "deepseek-r1:32b-qwen-distill-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:32b-qwen-distill-q8_0",
        "size": "deepseek-r1:32b-qwen-distill-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:32b-qwen-distill-fp16",
        "size": "deepseek-r1:32b-qwen-distill-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:70b-llama-distill-q4_K_M",
        "size": "deepseek-r1:70b-llama-distill-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:70b-llama-distill-q8_0",
        "size": "deepseek-r1:70b-llama-distill-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:70b-llama-distill-fp16",
        "size": "deepseek-r1:70b-llama-distill-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:671b-0528-q4_K_M",
        "size": "deepseek-r1:671b-0528-q4_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "deepseek-r1:671b-0528-q8_0",
        "size": "deepseek-r1:671b-0528-q8_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "deepseek-r1:671b-0528-fp16",
        "size": "deepseek-r1:671b-0528-fp16",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "deepseek-r1:671b-q4_K_M",
        "size": "deepseek-r1:671b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:671b-q8_0",
        "size": "deepseek-r1:671b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "deepseek-r1:671b-fp16",
        "size": "deepseek-r1:671b-fp16",
        "updated": "Text input • \n                    3 months ago"
      }
    ]
  },
  {
    "name": "gemma3",
    "link": "https://ollama.com/library/gemma3",
    "description": "The current, most capable model that runs on a single GPU.",
    "pullCount": "14.7M",
    "updated": "3 weeks ago",
    "size": [
      "270m1b",
      "4b",
      "12b",
      "27b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n![Google Gemma 3 logo](/assets/library/gemma3/b54bf767-f9c5-4284-b551-a49aebe3a3c2)\n\n> This model requires Ollama 0.6 or later. [Download Ollama](https://ollama.com/download)\n\nGemma is a lightweight, family of models from Google built on Gemini technology. The Gemma 3 models are multimodal—processing text and images—and feature a 128K context window with support for over 140 languages. Available in 270M, 1B, 4B, 12B, and 27B parameter sizes, they excel in tasks like question answering, summarization, and reasoning, while their compact design allows deployment on resource-limited devices.\n\n## Models\n\n### Text\n\n**270M parameter model** (32k context window)\n\n```\nollama run gemma3:270m\n\n```\n\n**1B parameter model** (32k context window)\n\n```\nollama run gemma3:1b \n\n```\n\n### Multimodal (Vision)\n\n**4B parameter model** (128k context window)\n\n```\nollama run gemma3:4b\n\n```\n\n**12B parameter model** (128k context window)\n\n```\nollama run gemma3:12b\n\n```\n\n**27B parameter model** (128k context window)\n\n```\nollama run gemma3:27b\n\n```\n\n### Quantization aware trained models (QAT)\n\nThe quantization aware trained Gemma 3 models preserves similar quality as half precision models (BF16) while maintaining a lower memory footprint (3x less compared to non-quantized models).\n\n**1B parameter model**\n\n```\nollama run gemma3:1b-it-qat\n\n```\n\n**4B parameter model**\n\n```\nollama run gemma3:4b-it-qat\n\n```\n\n**12B parameter model**\n\n```\nollama run gemma3:12b-it-qat\n\n```\n\n**27B parameter model**\n\n```\nollama run gemma3:27b-it-qat\n\n```\n\n## Evaluation\n\n![Chatbot Arena ELO Score](/assets/library/gemma3/89dc5a19-179e-4dd3-8e5d-12ad54973148)\n\n### Benchmark Results\n\n**Gemma 3 270M**\n\n| **Benchmark**                                            | **n-shot** | **Gemma 3 270m instruction tuned** |\n| -------------------------------------------------------- | ---------- | ---------------------------------- |\n| [HellaSwag](https://arxiv.org/abs/1905.07830)            | 0-shot     | 37.7                               |\n| [PIQA](https://arxiv.org/abs/1911.11641)                 | 0-shot     | 66.2                               |\n| [ARC-c](https://arxiv.org/abs/1911.01547)                | 0-shot     | 28.2                               |\n| [WinoGrande](https://arxiv.org/abs/1907.10641)           | 0-shot     | 52.3                               |\n| [BIG-Bench Hard](https://paperswithcode.com/dataset/bbh) | few-shot   | 26.7                               |\n| [IF Eval](https://arxiv.org/abs/2311.07911)              | 0-shot     | 51.2                               |\n\nThese models were evaluated against a large collection of different datasets and metrics to cover different aspects of text generation:\n\n#### Reasoning, logic and code capabilities\n\n| Benchmark                                                                          | Metric        | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ---------------------------------------------------------------------------------- | ------------- | ------------- | ------------- | -------------- | -------------- |\n| [HellaSwag](https://arxiv.org/abs/1905.07830)                                      | 10-shot       | 62.3          | 77.2          | 84.2           | 85.6           |\n| [BoolQ](https://arxiv.org/abs/1905.10044)                                          | 0-shot        | 63.2          | 72.3          | 78.8           | 82.4           |\n| [PIQA](https://arxiv.org/abs/1911.11641)                                           | 0-shot        | 73.8          | 79.6          | 81.8           | 83.3           |\n| [SocialIQA](https://arxiv.org/abs/1904.09728)                                      | 0-shot        | 48.9          | 51.9          | 53.4           | 54.9           |\n| [TriviaQA](https://arxiv.org/abs/1705.03551)                                       | 5-shot        | 39.8          | 65.8          | 78.2           | 85.5           |\n| [Natural Questions](https://github.com/google-research-datasets/natural-questions) | 5-shot        | 9.48          | 20.0          | 31.4           | 36.1           |\n| [ARC-c](https://arxiv.org/abs/1911.01547)                                          | 25-shot       | 38.4          | 56.2          | 68.9           | 70.6           |\n| [ARC-e](https://arxiv.org/abs/1911.01547)                                          | 0-shot        | 73.0          | 82.4          | 88.3           | 89.0           |\n| [WinoGrande](https://arxiv.org/abs/1907.10641)                                     | 5-shot        | 58.2          | 64.7          | 74.3           | 78.8           |\n| [BIG-Bench Hard](https://paperswithcode.com/dataset/bbh)                           | 28.4          | 50.9          | 72.6          | 77.7           |                |\n| [DROP](https://arxiv.org/abs/1903.00161)                                           | 3-shot, F1    | 42.4          | 60.1          | 72.2           | 77.2           |\n| [AGIEval](https://arxiv.org/abs/2304.06364)                                        | 3-5-shot      | 22.2          | 42.1          | 57.4           | 66.2           |\n| [MMLU](https://arxiv.org/abs/2009.03300)                                           | 5-shot, top-1 | 26.5          | 59.6          | 74.5           | 78.6           |\n| [MATH](https://arxiv.org/abs/2103.03874)                                           | 4-shot        | –             | 24.2          | 43.3           | 50.0           |\n| [GSM8K](https://arxiv.org/abs/2110.14168)                                          | 5-shot, maj@1 | 1.36          | 38.4          | 71.0           | 82.6           |\n| [GPQA](https://arxiv.org/abs/2311.12022)                                           | 9.38          | 15.0          | 25.4          | 24.3           |                |\n| [MMLU](https://arxiv.org/abs/2009.03300) (Pro)                                     | 5-shot        | 11.2          | 23.7          | 40.8           | 43.9           |\n| [MBPP](https://arxiv.org/abs/2108.07732)                                           | 3-shot        | 9.80          | 46.0          | 60.4           | 65.6           |\n| [HumanEval](https://arxiv.org/abs/2107.03374)                                      | pass@1        | 6.10          | 36.0          | 45.7           | 48.8           |\n| [MMLU](https://arxiv.org/abs/2009.03300) (Pro COT)                                 | 5-shot        | 9.7           | NaN           | NaN            | NaN            |\n\n#### Multilingual capabilities\n\n| Benchmark                                                                        | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| -------------------------------------------------------------------------------- | ------------- | ------------- | -------------- | -------------- |\n| [MGSM](https://arxiv.org/abs/2210.03057)                                         | 2.04          | 34.7          | 64.3           | 74.3           |\n| [Global-MMLU-Lite](https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite) | 24.9          | 57.0          | 69.4           | 75.7           |\n| [Belebele](https://arxiv.org/abs/2308.16884)                                     | 26.6          | 59.4          | 78.0           | –              |\n| [WMT24++](https://arxiv.org/abs/2502.12404v1) (ChrF)                             | 36.7          | 48.4          | 53.9           | 55.7           |\n| [FloRes](https://arxiv.org/abs/2106.03193)                                       | 29.5          | 39.2          | 46.0           | 48.8           |\n| [XL-Sum](https://arxiv.org/abs/2106.13822)                                       | 4.82          | 8.55          | 12.2           | 14.9           |\n| [XQuAD](https://arxiv.org/abs/1910.11856v3) (all)                                | 43.9          | 68.0          | 74.5           | 76.8           |\n\n#### Multimodal capabilities\n\n| Benchmark                                                                                                     | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B |\n| ------------------------------------------------------------------------------------------------------------- | ------------- | -------------- | -------------- |\n| [COCOcap](https://cocodataset.org/#home)                                                                      | 102           | 111            | 116            |\n| [DocVQA](https://www.docvqa.org/) (val)                                                                       | 72.8          | 82.3           | 85.6           |\n| [InfoVQA](https://arxiv.org/abs/2104.12756) (val)                                                             | 44.1          | 54.8           | 59.4           |\n| [MMMU](https://arxiv.org/abs/2311.16502) (pt)                                                                 | 39.2          | 50.3           | 56.1           |\n| [TextVQA](https://textvqa.org/) (val)                                                                         | 58.9          | 66.5           | 68.6           |\n| [RealWorldQA](https://paperswithcode.com/dataset/realworldqa)                                                 | 45.5          | 52.2           | 53.9           |\n| [ReMI](https://arxiv.org/html/2406.09175v1)                                                                   | 27.3          | 38.5           | 44.8           |\n| [AI2D](https://allenai.org/data/diagrams)                                                                     | 63.2          | 75.2           | 79.0           |\n| [ChartQA](https://arxiv.org/abs/2203.10244)                                                                   | 45.4          | 60.9           | 63.8           |\n| [ChartQA](https://arxiv.org/abs/2203.10244) (augmented)                                                       | 81.8          | 88.5           | 88.7           |\n| [VQAv2](https://visualqa.org/index.html)                                                                      | –             | –              | –              |\n| [BLINK](https://arxiv.org/abs/2404.12390)                                                                     | 38.0          | 35.9           | 39.6           |\n| [OKVQA](https://okvqa.allenai.org/)                                                                           | 51.0          | 58.7           | 60.2           |\n| [TallyQA](https://arxiv.org/abs/1810.12440)                                                                   | 42.5          | 51.8           | 54.3           |\n| [SpatialSense VQA](https://arxiv.org/abs/1908.02660)                                                          | 50.9          | 60.0           | 59.4           |\n| [CountBenchQA](https://github.com/google-research/big%5Fvision/blob/main/big%5Fvision/datasets/countbenchqa/) | 26.1          | 17.8           | 68.0           |\n\n## Reference\n\n[Gemma Terms of Use](https://ai.google.dev/gemma/terms)\n\nWrite Preview \n\n!\\[Google Gemma 3 logo\\](/assets/library/gemma3/b54bf767-f9c5-4284-b551-a49aebe3a3c2) > This model requires Ollama 0.6 or later. \\[Download Ollama\\](https://ollama.com/download) Gemma is a lightweight, family of models from Google built on Gemini technology. The Gemma 3 models are multimodal—processing text and images—and feature a 128K context window with support for over 140 languages. Available in 270M, 1B, 4B, 12B, and 27B parameter sizes, they excel in tasks like question answering, summarization, and reasoning, while their compact design allows deployment on resource-limited devices. ## Models ### Text \\*\\*270M parameter model\\*\\* (32k context window) \\`\\`\\` ollama run gemma3:270m \\`\\`\\` \\*\\*1B parameter model\\*\\* (32k context window) \\`\\`\\` ollama run gemma3:1b \\`\\`\\` ### Multimodal (Vision) \\*\\*4B parameter model\\*\\* (128k context window) \\`\\`\\` ollama run gemma3:4b \\`\\`\\` \\*\\*12B parameter model\\*\\* (128k context window) \\`\\`\\` ollama run gemma3:12b \\`\\`\\` \\*\\*27B parameter model\\*\\* (128k context window) \\`\\`\\` ollama run gemma3:27b \\`\\`\\` ### Quantization aware trained models (QAT) The quantization aware trained Gemma 3 models preserves similar quality as half precision models (BF16) while maintaining a lower memory footprint (3x less compared to non-quantized models). \\*\\*1B parameter model\\*\\* \\`\\`\\` ollama run gemma3:1b-it-qat \\`\\`\\` \\*\\*4B parameter model\\*\\* \\`\\`\\` ollama run gemma3:4b-it-qat \\`\\`\\` \\*\\*12B parameter model\\*\\* \\`\\`\\` ollama run gemma3:12b-it-qat \\`\\`\\` \\*\\*27B parameter model\\*\\* \\`\\`\\` ollama run gemma3:27b-it-qat \\`\\`\\` ## Evaluation !\\[Chatbot Arena ELO Score\\](/assets/library/gemma3/89dc5a19-179e-4dd3-8e5d-12ad54973148) ### Benchmark Results \\*\\*Gemma 3 270M\\*\\* | \\*\\*Benchmark\\*\\* | \\*\\*n-shot\\*\\* | \\*\\*Gemma 3 270m instruction tuned\\*\\* | | :------------------------ | :-----------: | ------------------: | | \\[HellaSwag\\]\\[hellaswag\\] | 0-shot | 37.7 | | \\[PIQA\\]\\[piqa\\] | 0-shot | 66.2 | | \\[ARC-c\\]\\[arc\\] | 0-shot | 28.2 | | \\[WinoGrande\\]\\[winogrande\\] | 0-shot | 52.3 | | \\[BIG-Bench Hard\\]\\[bbh\\] | few-shot | 26.7 | | \\[IF Eval\\]\\[ifeval\\] | 0-shot | 51.2 | \\[hellaswag\\]: https://arxiv.org/abs/1905.07830 \\[piqa\\]: https://arxiv.org/abs/1911.11641 \\[arc\\]: https://arxiv.org/abs/1911.01547 \\[winogrande\\]: https://arxiv.org/abs/1907.10641 \\[bbh\\]: https://paperswithcode.com/dataset/bbh \\[bbh\\]: https://paperswithcode.com/dataset/bbh \\[ifeval\\]: https://arxiv.org/abs/2311.07911 These models were evaluated against a large collection of different datasets and metrics to cover different aspects of text generation: #### Reasoning, logic and code capabilities | Benchmark | Metric | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B | | ------------------------------ |----------------|:--------------:|:-------------:|:--------------:|:--------------:| | \\[HellaSwag\\]\\[hellaswag\\] | 10-shot | 62.3 | 77.2 | 84.2 | 85.6 | | \\[BoolQ\\]\\[boolq\\] | 0-shot | 63.2 | 72.3 | 78.8 | 82.4 | | \\[PIQA\\]\\[piqa\\] | 0-shot | 73.8 | 79.6 | 81.8 | 83.3 | | \\[SocialIQA\\]\\[socialiqa\\] | 0-shot | 48.9 | 51.9 | 53.4 | 54.9 | | \\[TriviaQA\\]\\[triviaqa\\] | 5-shot | 39.8 | 65.8 | 78.2 | 85.5 | | \\[Natural Questions\\]\\[naturalq\\] | 5-shot | 9.48 | 20.0 | 31.4 | 36.1 | | \\[ARC-c\\]\\[arc\\] | 25-shot | 38.4 | 56.2 | 68.9 | 70.6 | | \\[ARC-e\\]\\[arc\\] | 0-shot | 73.0 | 82.4 | 88.3 | 89.0 | | \\[WinoGrande\\]\\[winogrande\\] | 5-shot | 58.2 | 64.7 | 74.3 | 78.8 | | \\[BIG-Bench Hard\\]\\[bbh\\] | | 28.4 | 50.9 | 72.6 | 77.7 | | \\[DROP\\]\\[drop\\] | 3-shot, F1 | 42.4 | 60.1 | 72.2 | 77.2 | | \\[AGIEval\\]\\[agieval\\] | 3-5-shot | 22.2 | 42.1 | 57.4 | 66.2 | | \\[MMLU\\]\\[mmlu\\] | 5-shot, top-1 | 26.5 | 59.6 | 74.5 | 78.6 | | \\[MATH\\]\\[math\\] | 4-shot | -- | 24.2 | 43.3 | 50.0 | | \\[GSM8K\\]\\[gsm8k\\] | 5-shot, maj@1 | 1.36 | 38.4 | 71.0 | 82.6 | | \\[GPQA\\]\\[gpqa\\] | | 9.38 | 15.0 | 25.4 | 24.3 | | \\[MMLU\\]\\[mmlu\\] (Pro) | 5-shot | 11.2 | 23.7 | 40.8 | 43.9 | | \\[MBPP\\]\\[mbpp\\] | 3-shot | 9.80 | 46.0 | 60.4 | 65.6 | | \\[HumanEval\\]\\[humaneval\\] | pass@1 | 6.10 | 36.0 | 45.7 | 48.8 | | \\[MMLU\\]\\[mmlu\\] (Pro COT) | 5-shot | 9.7 | NaN | NaN | NaN | \\[hellaswag\\]: https://arxiv.org/abs/1905.07830 \\[boolq\\]: https://arxiv.org/abs/1905.10044 \\[piqa\\]: https://arxiv.org/abs/1911.11641 \\[socialiqa\\]: https://arxiv.org/abs/1904.09728 \\[triviaqa\\]: https://arxiv.org/abs/1705.03551 \\[naturalq\\]: https://github.com/google-research-datasets/natural-questions \\[arc\\]: https://arxiv.org/abs/1911.01547 \\[winogrande\\]: https://arxiv.org/abs/1907.10641 \\[bbh\\]: https://paperswithcode.com/dataset/bbh \\[drop\\]: https://arxiv.org/abs/1903.00161 \\[agieval\\]: https://arxiv.org/abs/2304.06364 \\[mmlu\\]: https://arxiv.org/abs/2009.03300 \\[math\\]: https://arxiv.org/abs/2103.03874 \\[gsm8k\\]: https://arxiv.org/abs/2110.14168 \\[gpqa\\]: https://arxiv.org/abs/2311.12022 \\[mbpp\\]: https://arxiv.org/abs/2108.07732 \\[humaneval\\]: https://arxiv.org/abs/2107.03374 #### Multilingual capabilities | Benchmark | Gemma 3 PT 1B | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B | | ------------------------------------ |:-------------:|:-------------:|:--------------:|:--------------:| | \\[MGSM\\]\\[mgsm\\] | 2.04 | 34.7 | 64.3 | 74.3 | | \\[Global-MMLU-Lite\\]\\[global-mmlu-lite\\] | 24.9 | 57.0 | 69.4 | 75.7 | | \\[Belebele\\]\\[belebele\\] | 26.6 | 59.4 | 78.0 | -- | | \\[WMT24++\\]\\[wmt24pp\\] (ChrF) | 36.7 | 48.4 | 53.9 | 55.7 | | \\[FloRes\\]\\[flores\\] | 29.5 | 39.2 | 46.0 | 48.8 | | \\[XL-Sum\\]\\[xlsum\\] | 4.82 | 8.55 | 12.2 | 14.9 | | \\[XQuAD\\]\\[xquad\\] (all) | 43.9 | 68.0 | 74.5 | 76.8 | \\[mgsm\\]: https://arxiv.org/abs/2210.03057 \\[flores\\]: https://arxiv.org/abs/2106.03193 \\[belebele\\]: https://arxiv.org/abs/2308.16884 \\[xlsum\\]: https://arxiv.org/abs/2106.13822 \\[xquad\\]: https://arxiv.org/abs/1910.11856v3 \\[global-mmlu-lite\\]: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite \\[wmt24pp\\]: https://arxiv.org/abs/2502.12404v1 #### Multimodal capabilities | Benchmark | Gemma 3 PT 4B | Gemma 3 PT 12B | Gemma 3 PT 27B | | ------------------------------ |:-------------:|:--------------:|:--------------:| | \\[COCOcap\\]\\[coco-cap\\] | 102 | 111 | 116 | | \\[DocVQA\\]\\[docvqa\\] (val) | 72.8 | 82.3 | 85.6 | | \\[InfoVQA\\]\\[info-vqa\\] (val) | 44.1 | 54.8 | 59.4 | | \\[MMMU\\]\\[mmmu\\] (pt) | 39.2 | 50.3 | 56.1 | | \\[TextVQA\\]\\[textvqa\\] (val) | 58.9 | 66.5 | 68.6 | | \\[RealWorldQA\\]\\[realworldqa\\] | 45.5 | 52.2 | 53.9 | | \\[ReMI\\]\\[remi\\] | 27.3 | 38.5 | 44.8 | | \\[AI2D\\]\\[ai2d\\] | 63.2 | 75.2 | 79.0 | | \\[ChartQA\\]\\[chartqa\\] | 45.4 | 60.9 | 63.8 | | \\[ChartQA\\]\\[chartqa\\] (augmented) | 81.8 | 88.5 | 88.7 | | \\[VQAv2\\]\\[vqav2\\] | -- | -- | -- | | \\[BLINK\\]\\[blinkvqa\\] | 38.0 | 35.9 | 39.6 | | \\[OKVQA\\]\\[okvqa\\] | 51.0 | 58.7 | 60.2 | | \\[TallyQA\\]\\[tallyqa\\] | 42.5 | 51.8 | 54.3 | | \\[SpatialSense VQA\\]\\[ss-vqa\\] | 50.9 | 60.0 | 59.4 | | \\[CountBenchQA\\]\\[countbenchqa\\] | 26.1 | 17.8 | 68.0 | \\[coco-cap\\]: https://cocodataset.org/#home \\[docvqa\\]: https://www.docvqa.org/ \\[info-vqa\\]: https://arxiv.org/abs/2104.12756 \\[mmmu\\]: https://arxiv.org/abs/2311.16502 \\[textvqa\\]: https://textvqa.org/ \\[realworldqa\\]: https://paperswithcode.com/dataset/realworldqa \\[remi\\]: https://arxiv.org/html/2406.09175v1 \\[ai2d\\]: https://allenai.org/data/diagrams \\[chartqa\\]: https://arxiv.org/abs/2203.10244 \\[vqav2\\]: https://visualqa.org/index.html \\[blinkvqa\\]: https://arxiv.org/abs/2404.12390 \\[okvqa\\]: https://okvqa.allenai.org/ \\[tallyqa\\]: https://arxiv.org/abs/1810.12440 \\[ss-vqa\\]: https://arxiv.org/abs/1908.02660 \\[countbenchqa\\]: https://github.com/google-research/big\\_vision/blob/main/big\\_vision/datasets/countbenchqa/ ## Reference \\[Gemma Terms of Use\\](https://ai.google.dev/gemma/terms) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "gemma3:latest",
        "size": "gemma3:latest",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:270m",
        "size": "gemma3:270m",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gemma3:1b",
        "size": "gemma3:1b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "gemma3:4b",
        "size": "gemma3:4b",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:12b",
        "size": "gemma3:12b",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:27b",
        "size": "gemma3:27b",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:270m-it-qat",
        "size": "gemma3:270m-it-qat",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gemma3:270m-it-q8_0",
        "size": "gemma3:270m-it-q8_0",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gemma3:270m-it-fp16",
        "size": "gemma3:270m-it-fp16",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gemma3:270m-it-bf16",
        "size": "gemma3:270m-it-bf16",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "gemma3:1b-it-qat",
        "size": "gemma3:1b-it-qat",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "gemma3:1b-it-q4_K_M",
        "size": "gemma3:1b-it-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "gemma3:1b-it-q8_0",
        "size": "gemma3:1b-it-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "gemma3:1b-it-fp16",
        "size": "gemma3:1b-it-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "gemma3:4b-it-qat",
        "size": "gemma3:4b-it-qat",
        "updated": "Text, Image input • \n                    4 months ago"
      },
      {
        "name": "gemma3:4b-it-q4_K_M",
        "size": "gemma3:4b-it-q4_K_M",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:4b-it-q8_0",
        "size": "gemma3:4b-it-q8_0",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:4b-it-fp16",
        "size": "gemma3:4b-it-fp16",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:12b-it-qat",
        "size": "gemma3:12b-it-qat",
        "updated": "Text, Image input • \n                    4 months ago"
      },
      {
        "name": "gemma3:12b-it-q4_K_M",
        "size": "gemma3:12b-it-q4_K_M",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:12b-it-q8_0",
        "size": "gemma3:12b-it-q8_0",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:12b-it-fp16",
        "size": "gemma3:12b-it-fp16",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:27b-it-qat",
        "size": "gemma3:27b-it-qat",
        "updated": "Text, Image input • \n                    4 months ago"
      },
      {
        "name": "gemma3:27b-it-q4_K_M",
        "size": "gemma3:27b-it-q4_K_M",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:27b-it-q8_0",
        "size": "gemma3:27b-it-q8_0",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "gemma3:27b-it-fp16",
        "size": "gemma3:27b-it-fp16",
        "updated": "Text, Image input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "qwen3",
    "link": "https://ollama.com/library/qwen3",
    "description": "Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.",
    "pullCount": "7.5M",
    "updated": "1 month ago",
    "size": [
      "0.6b",
      "1.7b",
      "4b",
      "8b",
      "14b",
      "30b",
      "32b",
      "235b"
    ],
    "capabilities": "toolsthinking",
    "readme": "## Readme\n\n![Qwen 3 logo](/assets/library/qwen3/a5541098-87ba-4184-a5af-2b63312c2522)\n\n**Qwen 3** is the latest generation of large language models in Qwen series, with newly updated versions of the 30B and 235B models:\n\n### New 30B model\n\n```\nollama run qwen3:30b\n\n```\n\n![Qwen3-30B-A3B-Instruct-2507.jpg](/assets/library/qwen3/bc0ddfea-95b5-49fc-a36e-c817f98a5de0)\n\n### New 235B model\n\n```\nollama run qwen3:235b\n\n```\n\n![0d7zztq4GB7G2ZYowO-dQ.jpg](/assets/library/qwen3/8426a459-dd88-49cd-ae89-ece442e58ec5)\n\n### Overview\n\nThe Qwen 3 family is a comprehensive suite of dense and mixture-of-experts (MoE) models. The flagship model, **Qwen3-235B-A22B**, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, **Qwen3-30B-A3B**, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.\n\n* **Significantly enhancement in its reasoning capabilities**, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.\n* **Superior human preference alignment**, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.\n* **Expertise in agent capabilities**, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.\n* **Support of 100+ languages and dialects** with strong capabilities for **multilingual instruction following and translation**.\n\n### Reference\n\n* [Blog](https://qwenlm.github.io/blog/qwen3/)\n\nWrite Preview \n\n!\\[Qwen 3 logo\\](/assets/library/qwen3/a5541098-87ba-4184-a5af-2b63312c2522) \\*\\*Qwen 3\\*\\* is the latest generation of large language models in Qwen series, with newly updated versions of the 30B and 235B models: ### New 30B model \\`\\`\\` ollama run qwen3:30b \\`\\`\\` !\\[Qwen3-30B-A3B-Instruct-2507.jpg\\](/assets/library/qwen3/bc0ddfea-95b5-49fc-a36e-c817f98a5de0) ### New 235B model \\`\\`\\` ollama run qwen3:235b \\`\\`\\` !\\[0d7zztq4GB7G2ZYowO-dQ.jpg\\](/assets/library/qwen3/8426a459-dd88-49cd-ae89-ece442e58ec5) ### Overview The Qwen 3 family is a comprehensive suite of dense and mixture-of-experts (MoE) models. The flagship model, \\*\\*Qwen3-235B-A22B\\*\\*, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, \\*\\*Qwen3-30B-A3B\\*\\*, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct. - \\*\\*Significantly enhancement in its reasoning capabilities\\*\\*, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning. - \\*\\*Superior human preference alignment\\*\\*, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience. - \\*\\*Expertise in agent capabilities\\*\\*, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks. - \\*\\*Support of 100+ languages and dialects\\*\\* with strong capabilities for \\*\\*multilingual instruction following and translation\\*\\*. ### Reference - \\[Blog\\](https://qwenlm.github.io/blog/qwen3/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen3:latest",
        "size": "qwen3:latest",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:0.6b",
        "size": "qwen3:0.6b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:1.7b",
        "size": "qwen3:1.7b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:4b",
        "size": "qwen3:4b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:8b",
        "size": "qwen3:8b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:14b",
        "size": "qwen3:14b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:30b",
        "size": "qwen3:30b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:32b",
        "size": "qwen3:32b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:235b",
        "size": "qwen3:235b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:0.6b-q4_K_M",
        "size": "qwen3:0.6b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:0.6b-q8_0",
        "size": "qwen3:0.6b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:0.6b-fp16",
        "size": "qwen3:0.6b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:1.7b-q4_K_M",
        "size": "qwen3:1.7b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:1.7b-q8_0",
        "size": "qwen3:1.7b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:1.7b-fp16",
        "size": "qwen3:1.7b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:4b-instruct",
        "size": "qwen3:4b-instruct",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-instruct-2507-q4_K_M",
        "size": "qwen3:4b-instruct-2507-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-instruct-2507-q8_0",
        "size": "qwen3:4b-instruct-2507-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-instruct-2507-fp16",
        "size": "qwen3:4b-instruct-2507-fp16",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-thinking",
        "size": "qwen3:4b-thinking",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-thinking-2507-q4_K_M",
        "size": "qwen3:4b-thinking-2507-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-thinking-2507-q8_0",
        "size": "qwen3:4b-thinking-2507-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-thinking-2507-fp16",
        "size": "qwen3:4b-thinking-2507-fp16",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:4b-q4_K_M",
        "size": "qwen3:4b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:4b-q8_0",
        "size": "qwen3:4b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:4b-fp16",
        "size": "qwen3:4b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:8b-q4_K_M",
        "size": "qwen3:8b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:8b-q8_0",
        "size": "qwen3:8b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:8b-fp16",
        "size": "qwen3:8b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:14b-q4_K_M",
        "size": "qwen3:14b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:14b-q8_0",
        "size": "qwen3:14b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:14b-fp16",
        "size": "qwen3:14b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:30b-a3b",
        "size": "qwen3:30b-a3b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-a3b-instruct-2507-q4_K_M",
        "size": "qwen3:30b-a3b-instruct-2507-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-a3b-q4_K_M",
        "size": "qwen3:30b-a3b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:30b-a3b-instruct-2507-q8_0",
        "size": "qwen3:30b-a3b-instruct-2507-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-a3b-thinking-2507-q4_K_M",
        "size": "qwen3:30b-a3b-thinking-2507-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-a3b-q8_0",
        "size": "qwen3:30b-a3b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:30b-a3b-thinking-2507-q8_0",
        "size": "qwen3:30b-a3b-thinking-2507-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-a3b-fp16",
        "size": "qwen3:30b-a3b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:30b-a3b-instruct-2507-fp16",
        "size": "qwen3:30b-a3b-instruct-2507-fp16",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-a3b-thinking-2507-fp16",
        "size": "qwen3:30b-a3b-thinking-2507-fp16",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:30b-thinking",
        "size": "qwen3:30b-thinking",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:32b-q4_K_M",
        "size": "qwen3:32b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:32b-q8_0",
        "size": "qwen3:32b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:32b-fp16",
        "size": "qwen3:32b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:235b-a22b",
        "size": "qwen3:235b-a22b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:235b-a22b-instruct-2507-q4_K_M",
        "size": "qwen3:235b-a22b-instruct-2507-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:235b-a22b-q4_K_M",
        "size": "qwen3:235b-a22b-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:235b-a22b-instruct-2507-q8_0",
        "size": "qwen3:235b-a22b-instruct-2507-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:235b-a22b-thinking-2507-q4_K_M",
        "size": "qwen3:235b-a22b-thinking-2507-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:235b-a22b-q8_0",
        "size": "qwen3:235b-a22b-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:235b-a22b-thinking-2507-q8_0",
        "size": "qwen3:235b-a22b-thinking-2507-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:235b-a22b-fp16",
        "size": "qwen3:235b-a22b-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen3:235b-a22b-thinking-2507-fp16",
        "size": "qwen3:235b-a22b-thinking-2507-fp16",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3:235b-thinking",
        "size": "qwen3:235b-thinking",
        "updated": "Text input • \n                    1 month ago"
      }
    ]
  },
  {
    "name": "llama3.1",
    "link": "https://ollama.com/library/llama3.1",
    "description": "Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.",
    "pullCount": "101.6M",
    "updated": "9 months ago",
    "size": [
      "8b",
      "70b",
      "405b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n### Meta Llama 3.1\n\n![image.png](https://ollama.com/assets/mchiang0610/mikey3.1/4d0cab8e-952b-4c75-b110-1514d8db8fae)\n\n**Llama 3.1** family of models available:\n\n* **8B**\n* **70B**\n* **405B**\n\nLlama 3.1 405B is the first openly available model that rivals the top AI models when it comes to state-of-the-art capabilities in general knowledge, steerability, math, tool use, and multilingual translation.\n\nThe upgraded versions of the 8B and 70B models are multilingual and have a significantly longer context length of 128K, state-of-the-art tool use, and overall stronger reasoning capabilities. This enables Meta’s latest models to support advanced use cases, such as long-form text summarization, multilingual conversational agents, and coding assistants.\n\nMeta also has made changes to their license, allowing developers to use the outputs from Llama models, including the 405B model, to improve other models.\n\n### Model evaluations\n\nFor this release, Meta has evaluation the performance on over 150 benchmark datasets that span a wide range of languages. In addition, Meta performed extensive human evaluations that compare Llama 3.1 with competing models in real-world scenarios. Meta’s experimental evaluation suggests that our flagship model is competitive with leading foundation models across a range of tasks, including GPT-4, GPT-4o, and Claude 3.5 Sonnet. Additionally, Meta’s smaller models are competitive with closed and open models that have a similar number of parameters.\n\n![image.png](https://ollama.com/assets/mchiang0610/mikey3.1/73b11a5e-84e9-4397-9d47-f0299a6294b3)\n\n![image.png](https://ollama.com/assets/mchiang0610/mikey3.1/ad042a1c-bbc7-47de-bbbf-78a3cfc13485)\n\n![image.png](https://ollama.com/assets/mchiang0610/mikey3.1/2d582df5-ce45-4326-85c5-254c917554b2)\n\n### References\n\n* [Meta AI Llama 3.1 launch blog post](https://ai.meta.com/blog/meta-llama-3-1/)\n\nWrite Preview \n\n\\### Meta Llama 3.1 !\\[image.png\\](https://ollama.com/assets/mchiang0610/mikey3.1/4d0cab8e-952b-4c75-b110-1514d8db8fae) \\*\\*Llama 3.1\\*\\* family of models available: - \\*\\*8B\\*\\* - \\*\\*70B\\*\\* - \\*\\*405B\\*\\* Llama 3.1 405B is the first openly available model that rivals the top AI models when it comes to state-of-the-art capabilities in general knowledge, steerability, math, tool use, and multilingual translation. The upgraded versions of the 8B and 70B models are multilingual and have a significantly longer context length of 128K, state-of-the-art tool use, and overall stronger reasoning capabilities. This enables Meta's latest models to support advanced use cases, such as long-form text summarization, multilingual conversational agents, and coding assistants. Meta also has made changes to their license, allowing developers to use the outputs from Llama models, including the 405B model, to improve other models. ### Model evaluations For this release, Meta has evaluation the performance on over 150 benchmark datasets that span a wide range of languages. In addition, Meta performed extensive human evaluations that compare Llama 3.1 with competing models in real-world scenarios. Meta's experimental evaluation suggests that our flagship model is competitive with leading foundation models across a range of tasks, including GPT-4, GPT-4o, and Claude 3.5 Sonnet. Additionally, Meta's smaller models are competitive with closed and open models that have a similar number of parameters. !\\[image.png\\](https://ollama.com/assets/mchiang0610/mikey3.1/73b11a5e-84e9-4397-9d47-f0299a6294b3) !\\[image.png\\](https://ollama.com/assets/mchiang0610/mikey3.1/ad042a1c-bbc7-47de-bbbf-78a3cfc13485) !\\[image.png\\](https://ollama.com/assets/mchiang0610/mikey3.1/2d582df5-ce45-4326-85c5-254c917554b2) ### References - \\[Meta AI Llama 3.1 launch blog post\\](https://ai.meta.com/blog/meta-llama-3-1/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3.1:latest",
        "size": "llama3.1:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.1:8b",
        "size": "llama3.1:8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.1:70b",
        "size": "llama3.1:70b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.1:405b",
        "size": "llama3.1:405b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q2_K",
        "size": "llama3.1:8b-instruct-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q3_K_S",
        "size": "llama3.1:8b-instruct-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q3_K_M",
        "size": "llama3.1:8b-instruct-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q3_K_L",
        "size": "llama3.1:8b-instruct-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q4_0",
        "size": "llama3.1:8b-instruct-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q4_1",
        "size": "llama3.1:8b-instruct-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q4_K_S",
        "size": "llama3.1:8b-instruct-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q4_K_M",
        "size": "llama3.1:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q5_0",
        "size": "llama3.1:8b-instruct-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q5_1",
        "size": "llama3.1:8b-instruct-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q5_K_S",
        "size": "llama3.1:8b-instruct-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q5_K_M",
        "size": "llama3.1:8b-instruct-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q6_K",
        "size": "llama3.1:8b-instruct-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-q8_0",
        "size": "llama3.1:8b-instruct-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-instruct-fp16",
        "size": "llama3.1:8b-instruct-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:8b-text-q2_K",
        "size": "llama3.1:8b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q3_K_S",
        "size": "llama3.1:8b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q3_K_M",
        "size": "llama3.1:8b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q3_K_L",
        "size": "llama3.1:8b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q4_0",
        "size": "llama3.1:8b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q4_1",
        "size": "llama3.1:8b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q4_K_S",
        "size": "llama3.1:8b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q4_K_M",
        "size": "llama3.1:8b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q5_0",
        "size": "llama3.1:8b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q5_1",
        "size": "llama3.1:8b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q5_K_S",
        "size": "llama3.1:8b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q5_K_M",
        "size": "llama3.1:8b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q6_K",
        "size": "llama3.1:8b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-q8_0",
        "size": "llama3.1:8b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:8b-text-fp16",
        "size": "llama3.1:8b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-instruct-q2_K",
        "size": "llama3.1:70b-instruct-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q3_K_S",
        "size": "llama3.1:70b-instruct-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q3_K_M",
        "size": "llama3.1:70b-instruct-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q3_K_L",
        "size": "llama3.1:70b-instruct-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q4_0",
        "size": "llama3.1:70b-instruct-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q4_K_S",
        "size": "llama3.1:70b-instruct-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q4_K_M",
        "size": "llama3.1:70b-instruct-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q5_0",
        "size": "llama3.1:70b-instruct-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q5_1",
        "size": "llama3.1:70b-instruct-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q5_K_S",
        "size": "llama3.1:70b-instruct-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q5_K_M",
        "size": "llama3.1:70b-instruct-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q6_K",
        "size": "llama3.1:70b-instruct-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-q8_0",
        "size": "llama3.1:70b-instruct-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-instruct-fp16",
        "size": "llama3.1:70b-instruct-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:70b-text-q2_K",
        "size": "llama3.1:70b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q3_K_S",
        "size": "llama3.1:70b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q3_K_M",
        "size": "llama3.1:70b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q3_K_L",
        "size": "llama3.1:70b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q4_0",
        "size": "llama3.1:70b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q4_1",
        "size": "llama3.1:70b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q4_K_S",
        "size": "llama3.1:70b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q4_K_M",
        "size": "llama3.1:70b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q5_0",
        "size": "llama3.1:70b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q5_1",
        "size": "llama3.1:70b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q5_K_S",
        "size": "llama3.1:70b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q5_K_M",
        "size": "llama3.1:70b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q6_K",
        "size": "llama3.1:70b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-q8_0",
        "size": "llama3.1:70b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:70b-text-fp16",
        "size": "llama3.1:70b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-instruct-q2_K",
        "size": "llama3.1:405b-instruct-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q3_K_S",
        "size": "llama3.1:405b-instruct-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q3_K_M",
        "size": "llama3.1:405b-instruct-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q3_K_L",
        "size": "llama3.1:405b-instruct-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q4_0",
        "size": "llama3.1:405b-instruct-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q4_1",
        "size": "llama3.1:405b-instruct-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q4_K_S",
        "size": "llama3.1:405b-instruct-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q4_K_M",
        "size": "llama3.1:405b-instruct-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q5_0",
        "size": "llama3.1:405b-instruct-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q5_1",
        "size": "llama3.1:405b-instruct-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q5_K_S",
        "size": "llama3.1:405b-instruct-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q5_K_M",
        "size": "llama3.1:405b-instruct-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q6_K",
        "size": "llama3.1:405b-instruct-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-q8_0",
        "size": "llama3.1:405b-instruct-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-instruct-fp16",
        "size": "llama3.1:405b-instruct-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "llama3.1:405b-text-q2_K",
        "size": "llama3.1:405b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q3_K_S",
        "size": "llama3.1:405b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q3_K_M",
        "size": "llama3.1:405b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q3_K_L",
        "size": "llama3.1:405b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q4_0",
        "size": "llama3.1:405b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q4_1",
        "size": "llama3.1:405b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q4_K_S",
        "size": "llama3.1:405b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q4_K_M",
        "size": "llama3.1:405b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q5_0",
        "size": "llama3.1:405b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q5_1",
        "size": "llama3.1:405b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q5_K_S",
        "size": "llama3.1:405b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q5_K_M",
        "size": "llama3.1:405b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q6_K",
        "size": "llama3.1:405b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-q8_0",
        "size": "llama3.1:405b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3.1:405b-text-fp16",
        "size": "llama3.1:405b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "nomic-embed-text",
    "link": "https://ollama.com/library/nomic-embed-text",
    "description": "A high-performing open embedding model with a large token context window.",
    "pullCount": "38M",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\n![nomic_logo](https://github.com/ollama/ollama/assets/251292/bf242e43-3c1a-4590-887d-abcab76cb304)\n\n> Note: this model requires Ollama 0.1.26 or later. [Download it here](https://ollama.com/download). It can only be used to generate embeddings.\n\n`nomic-embed-text` is a large context length text encoder that surpasses OpenAI `text-embedding-ada-002` and `text-embedding-3-small` performance on short and long context tasks.\n\n## Usage\n\nThis model is an embedding model, meaning it can only be used to generate embeddings.\n\n### REST API\n\n```\ncurl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"nomic-embed-text\",\n  \"prompt\": \"The sky is blue because of Rayleigh scattering\"\n}'\n\n```\n\n### Python library\n\n```\nollama.embeddings(model='nomic-embed-text', prompt='The sky is blue because of rayleigh scattering')\n\n```\n\n### Javascript library\n\n```\nollama.embeddings({ model: 'nomic-embed-text', prompt: 'The sky is blue because of rayleigh scattering' })\n\n```\n\n## References\n\n[HuggingFace](https://huggingface.co/nomic-ai/nomic-embed-text-v1.5)\n\n[Blog Post](https://blog.nomic.ai/posts/nomic-embed-text-v1)\n\nWrite Preview \n\n!\\[nomic\\_logo\\](https://github.com/ollama/ollama/assets/251292/bf242e43-3c1a-4590-887d-abcab76cb304) > Note: this model requires Ollama 0.1.26 or later. \\[Download it here\\](https://ollama.com/download). It can only be used to generate embeddings. \\`nomic-embed-text\\` is a large context length text encoder that surpasses OpenAI \\`text-embedding-ada-002\\` and \\`text-embedding-3-small\\` performance on short and long context tasks. ## Usage This model is an embedding model, meaning it can only be used to generate embeddings. ### REST API \\`\\`\\` curl http://localhost:11434/api/embeddings -d '{ \"model\": \"nomic-embed-text\", \"prompt\": \"The sky is blue because of Rayleigh scattering\" }' \\`\\`\\` ### Python library \\`\\`\\` ollama.embeddings(model='nomic-embed-text', prompt='The sky is blue because of rayleigh scattering') \\`\\`\\` ### Javascript library \\`\\`\\` ollama.embeddings({ model: 'nomic-embed-text', prompt: 'The sky is blue because of rayleigh scattering' }) \\`\\`\\` ## References \\[HuggingFace\\](https://huggingface.co/nomic-ai/nomic-embed-text-v1.5) \\[Blog Post\\](https://blog.nomic.ai/posts/nomic-embed-text-v1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nomic-embed-text:latest",
        "size": "nomic-embed-text:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nomic-embed-text:v1.5",
        "size": "nomic-embed-text:v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nomic-embed-text:137m-v1.5-fp16",
        "size": "nomic-embed-text:137m-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama3.2",
    "link": "https://ollama.com/library/llama3.2",
    "description": "Meta's Llama 3.2 goes small with 1B and 3B models.",
    "pullCount": "33.5M",
    "updated": "11 months ago",
    "size": [
      "1b",
      "3b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/llama3.2/be01fadf-7fbd-404d-929b-50a77249b030)\n\nThe Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.\n\n## Sizes\n\n### 3B parameters (default)\n\nThe 3B model outperforms the Gemma 2 2.6B and Phi 3.5-mini models on tasks such as:\n\n* Following instructions\n* Summarization\n* Prompt rewriting\n* Tool use\n\n```\nollama run llama3.2\n\n```\n\n### 1B parameters\n\nThe 1B model is competitive with other 1-3B parameter models. It’s use cases include:\n\n* Personal information management\n* Multilingual knowledge retrieval\n* Rewriting tasks running locally on edge\n\n```\nollama run llama3.2:1b\n\n```\n\n### Benchmarks\n\n![Llama 3.2 instruction-tuned benchmarks](https://ollama.com/assets/library/llama3.2/c1a51716-d8bb-4642-8044-48f5022b777d)\n\n**Supported Languages:** English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported. Llama 3.2 has been trained on a broader collection of languages than these 8 supported languages.\n\nWrite Preview \n\n<img src=\"/assets/library/llama3.2/be01fadf-7fbd-404d-929b-50a77249b030\" width=\"280\" /> The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks. ## Sizes ### 3B parameters (default) The 3B model outperforms the Gemma 2 2.6B and Phi 3.5-mini models on tasks such as: \\* Following instructions \\* Summarization \\* Prompt rewriting \\* Tool use \\`\\`\\` ollama run llama3.2 \\`\\`\\` ### 1B parameters The 1B model is competitive with other 1-3B parameter models. It's use cases include: \\* Personal information management \\* Multilingual knowledge retrieval \\* Rewriting tasks running locally on edge \\`\\`\\` ollama run llama3.2:1b \\`\\`\\` ### Benchmarks !\\[Llama 3.2 instruction-tuned benchmarks\\](https://ollama.com/assets/library/llama3.2/c1a51716-d8bb-4642-8044-48f5022b777d) \\*\\*Supported Languages:\\*\\* English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported. Llama 3.2 has been trained on a broader collection of languages than these 8 supported languages. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3.2:latest",
        "size": "llama3.2:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b",
        "size": "llama3.2:1b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b",
        "size": "llama3.2:3b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q2_K",
        "size": "llama3.2:1b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q3_K_S",
        "size": "llama3.2:1b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q3_K_M",
        "size": "llama3.2:1b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q3_K_L",
        "size": "llama3.2:1b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q4_0",
        "size": "llama3.2:1b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q4_1",
        "size": "llama3.2:1b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q4_K_S",
        "size": "llama3.2:1b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q4_K_M",
        "size": "llama3.2:1b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q5_0",
        "size": "llama3.2:1b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q5_1",
        "size": "llama3.2:1b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q5_K_S",
        "size": "llama3.2:1b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q5_K_M",
        "size": "llama3.2:1b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q6_K",
        "size": "llama3.2:1b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-q8_0",
        "size": "llama3.2:1b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-instruct-fp16",
        "size": "llama3.2:1b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q2_K",
        "size": "llama3.2:1b-text-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q3_K_S",
        "size": "llama3.2:1b-text-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q3_K_M",
        "size": "llama3.2:1b-text-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q3_K_L",
        "size": "llama3.2:1b-text-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q4_0",
        "size": "llama3.2:1b-text-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q4_1",
        "size": "llama3.2:1b-text-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q4_K_S",
        "size": "llama3.2:1b-text-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q4_K_M",
        "size": "llama3.2:1b-text-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q5_0",
        "size": "llama3.2:1b-text-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q5_1",
        "size": "llama3.2:1b-text-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q5_K_S",
        "size": "llama3.2:1b-text-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q5_K_M",
        "size": "llama3.2:1b-text-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q6_K",
        "size": "llama3.2:1b-text-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-q8_0",
        "size": "llama3.2:1b-text-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:1b-text-fp16",
        "size": "llama3.2:1b-text-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q2_K",
        "size": "llama3.2:3b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q3_K_S",
        "size": "llama3.2:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q3_K_M",
        "size": "llama3.2:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q3_K_L",
        "size": "llama3.2:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q4_0",
        "size": "llama3.2:3b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q4_1",
        "size": "llama3.2:3b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q4_K_S",
        "size": "llama3.2:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q4_K_M",
        "size": "llama3.2:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q5_0",
        "size": "llama3.2:3b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q5_1",
        "size": "llama3.2:3b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q5_K_S",
        "size": "llama3.2:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q5_K_M",
        "size": "llama3.2:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q6_K",
        "size": "llama3.2:3b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-q8_0",
        "size": "llama3.2:3b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-instruct-fp16",
        "size": "llama3.2:3b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q2_K",
        "size": "llama3.2:3b-text-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q3_K_S",
        "size": "llama3.2:3b-text-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q3_K_M",
        "size": "llama3.2:3b-text-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q3_K_L",
        "size": "llama3.2:3b-text-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q4_0",
        "size": "llama3.2:3b-text-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q4_1",
        "size": "llama3.2:3b-text-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q4_K_S",
        "size": "llama3.2:3b-text-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q4_K_M",
        "size": "llama3.2:3b-text-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q5_0",
        "size": "llama3.2:3b-text-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q5_1",
        "size": "llama3.2:3b-text-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q5_K_S",
        "size": "llama3.2:3b-text-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q5_K_M",
        "size": "llama3.2:3b-text-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q6_K",
        "size": "llama3.2:3b-text-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-q8_0",
        "size": "llama3.2:3b-text-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama3.2:3b-text-fp16",
        "size": "llama3.2:3b-text-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "mistral",
    "link": "https://ollama.com/library/mistral",
    "description": "The 7B model released by Mistral AI, updated to version 0.3.",
    "pullCount": "18.8M",
    "updated": "1 month ago",
    "size": [
      "7b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/3325447/d6be0694-eb35-417b-8f08-47d3b6c2a171)\n\nMistral is a 7B parameter model, distributed with the Apache license. It is available in both instruct (instruction following) and text completion.\n\nThe Mistral AI team has noted that Mistral 7B:\n\n* Outperforms Llama 2 13B on all benchmarks\n* Outperforms Llama 1 34B on many benchmarks\n* Approaches CodeLlama 7B performance on code, while remaining good at English tasks\n\n### Versions\n\n| Tag         | Date       | Notes                                                       |\n| ----------- | ---------- | ----------------------------------------------------------- |\n| v0.3 latest | 05/22/2024 | A new version of Mistral 7B that supports function calling. |\n| v0.2        | 03/23/2024 | A minor release of Mistral 7B                               |\n| v0.1        | 09/27/2023 | Initial release                                             |\n\n### Function calling\n\nMistral 0.3 supports function calling with Ollama’s **raw mode**.\n\nExample raw prompt\n\n```\n[AVAILABLE_TOOLS] [{\"type\": \"function\", \"function\": {\"name\": \"get_current_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}, \"format\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"The temperature unit to use. Infer this from the users location.\"}}, \"required\": [\"location\", \"format\"]}}}][/AVAILABLE_TOOLS][INST] What is the weather like today in San Francisco [/INST]\n\n```\n\nExample response\n\n```\n[TOOL_CALLS] [{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"San Francisco, CA\", \"format\": \"celsius\"}}]\n\n```\n\nFor more information on raw mode, see the [API documentation](https://github.com/ollama/ollama/blob/main/docs/api.md#request-raw-mode).\n\n### Variations\n\n| instruct | Instruct models follow instructions                                                                                                |\n| -------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n| text     | Text models are the base foundation model without any fine-tuning for conversations, and are best used for simple text completion. |\n\n## Usage\n\n### CLI\n\nInstruct:\n\n```\nollama run mistral\n\n```\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"mistral\",\n  \"prompt\":\"Here is a story about llamas eating grass\"\n }'\n\n```\n\n## References\n\n[HuggingFace](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)\n\n[Mistral AI News Release](https://mistral.ai/news/announcing-mistral-7b/)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/3325447/d6be0694-eb35-417b-8f08-47d3b6c2a171\" width=\"200\"/> Mistral is a 7B parameter model, distributed with the Apache license. It is available in both instruct (instruction following) and text completion. The Mistral AI team has noted that Mistral 7B: - Outperforms Llama 2 13B on all benchmarks - Outperforms Llama 1 34B on many benchmarks - Approaches CodeLlama 7B performance on code, while remaining good at English tasks ### Versions | Tag | Date | Notes | | --------------- | ---------- | ----------------------------------------------------------- | | \\`v0.3\\` \\`latest\\` | 05/22/2024 | A new version of Mistral 7B that supports function calling. | | \\`v0.2\\` | 03/23/2024 | A minor release of Mistral 7B | | \\`v0.1\\` | 09/27/2023 | Initial release | ### Function calling Mistral 0.3 supports function calling with Ollama's \\*\\*raw mode\\*\\*. <sub>Example raw prompt</sub> \\`\\`\\` \\[AVAILABLE\\_TOOLS\\] \\[{\"type\": \"function\", \"function\": {\"name\": \"get\\_current\\_weather\", \"description\": \"Get the current weather\", \"parameters\": {\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}, \"format\": {\"type\": \"string\", \"enum\": \\[\"celsius\", \"fahrenheit\"\\], \"description\": \"The temperature unit to use. Infer this from the users location.\"}}, \"required\": \\[\"location\", \"format\"\\]}}}\\]\\[/AVAILABLE\\_TOOLS\\]\\[INST\\] What is the weather like today in San Francisco \\[/INST\\] \\`\\`\\` <sub>Example response</sub> \\`\\`\\` \\[TOOL\\_CALLS\\] \\[{\"name\": \"get\\_current\\_weather\", \"arguments\": {\"location\": \"San Francisco, CA\", \"format\": \"celsius\"}}\\] \\`\\`\\` For more information on raw mode, see the \\[API documentation\\](https://github.com/ollama/ollama/blob/main/docs/api.md#request-raw-mode). ### Variations | | | | ---------- | ---------------------------------------------------------------------------------------------------------------------------------- | | \\`instruct\\` | Instruct models follow instructions | | \\`text\\` | Text models are the base foundation model without any fine-tuning for conversations, and are best used for simple text completion. | ## Usage ### CLI Instruct: \\`\\`\\` ollama run mistral \\`\\`\\` ### API Example: \\`\\`\\` curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"mistral\", \"prompt\":\"Here is a story about llamas eating grass\" }' \\`\\`\\` ## References \\[HuggingFace\\](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) \\[Mistral AI News Release\\](https://mistral.ai/news/announcing-mistral-7b/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral:latest",
        "size": "mistral:latest",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral:instruct",
        "size": "mistral:instruct",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:text",
        "size": "mistral:text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:v0.1",
        "size": "mistral:v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:v0.2",
        "size": "mistral:v0.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:v0.3",
        "size": "mistral:v0.3",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral:7b",
        "size": "mistral:7b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral:7b-instruct",
        "size": "mistral:7b-instruct",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral:7b-instruct-q2_K",
        "size": "mistral:7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q2_K",
        "size": "mistral:7b-instruct-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-q3_K_S",
        "size": "mistral:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q3_K_S",
        "size": "mistral:7b-instruct-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-q3_K_M",
        "size": "mistral:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q3_K_M",
        "size": "mistral:7b-instruct-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-q3_K_L",
        "size": "mistral:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q3_K_L",
        "size": "mistral:7b-instruct-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-q4_0",
        "size": "mistral:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q4_0",
        "size": "mistral:7b-instruct-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-q4_1",
        "size": "mistral:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q4_1",
        "size": "mistral:7b-instruct-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-q4_K_S",
        "size": "mistral:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q4_K_S",
        "size": "mistral:7b-instruct-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q4_K_M",
        "size": "mistral:7b-instruct-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q5_0",
        "size": "mistral:7b-instruct-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q5_1",
        "size": "mistral:7b-instruct-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q5_K_S",
        "size": "mistral:7b-instruct-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q5_K_M",
        "size": "mistral:7b-instruct-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q6_K",
        "size": "mistral:7b-instruct-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-q8_0",
        "size": "mistral:7b-instruct-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.2-fp16",
        "size": "mistral:7b-instruct-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q2_K",
        "size": "mistral:7b-instruct-v0.3-q2_K",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q3_K_S",
        "size": "mistral:7b-instruct-v0.3-q3_K_S",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q3_K_M",
        "size": "mistral:7b-instruct-v0.3-q3_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q3_K_L",
        "size": "mistral:7b-instruct-v0.3-q3_K_L",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q4_0",
        "size": "mistral:7b-instruct-v0.3-q4_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q4_1",
        "size": "mistral:7b-instruct-v0.3-q4_1",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q4_K_S",
        "size": "mistral:7b-instruct-v0.3-q4_K_S",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q4_K_M",
        "size": "mistral:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q4_K_M",
        "size": "mistral:7b-instruct-v0.3-q4_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q5_0",
        "size": "mistral:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q5_0",
        "size": "mistral:7b-instruct-v0.3-q5_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q5_1",
        "size": "mistral:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q5_1",
        "size": "mistral:7b-instruct-v0.3-q5_1",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q5_K_S",
        "size": "mistral:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q5_K_S",
        "size": "mistral:7b-instruct-v0.3-q5_K_S",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q5_K_M",
        "size": "mistral:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q5_K_M",
        "size": "mistral:7b-instruct-v0.3-q5_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q6_K",
        "size": "mistral:7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q6_K",
        "size": "mistral:7b-instruct-v0.3-q6_K",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-q8_0",
        "size": "mistral:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-q8_0",
        "size": "mistral:7b-instruct-v0.3-q8_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-instruct-fp16",
        "size": "mistral:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-instruct-v0.3-fp16",
        "size": "mistral:7b-instruct-v0.3-fp16",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "mistral:7b-text",
        "size": "mistral:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q2_K",
        "size": "mistral:7b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q2_K",
        "size": "mistral:7b-text-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q3_K_S",
        "size": "mistral:7b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q3_K_S",
        "size": "mistral:7b-text-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q3_K_M",
        "size": "mistral:7b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q3_K_M",
        "size": "mistral:7b-text-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q3_K_L",
        "size": "mistral:7b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q3_K_L",
        "size": "mistral:7b-text-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q4_0",
        "size": "mistral:7b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q4_0",
        "size": "mistral:7b-text-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q4_1",
        "size": "mistral:7b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q4_1",
        "size": "mistral:7b-text-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q4_K_S",
        "size": "mistral:7b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q4_K_S",
        "size": "mistral:7b-text-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q4_K_M",
        "size": "mistral:7b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q4_K_M",
        "size": "mistral:7b-text-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q5_0",
        "size": "mistral:7b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q5_0",
        "size": "mistral:7b-text-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q5_1",
        "size": "mistral:7b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q5_1",
        "size": "mistral:7b-text-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q5_K_S",
        "size": "mistral:7b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q5_K_S",
        "size": "mistral:7b-text-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q5_K_M",
        "size": "mistral:7b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q5_K_M",
        "size": "mistral:7b-text-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q6_K",
        "size": "mistral:7b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q6_K",
        "size": "mistral:7b-text-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-q8_0",
        "size": "mistral:7b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-q8_0",
        "size": "mistral:7b-text-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-fp16",
        "size": "mistral:7b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral:7b-text-v0.2-fp16",
        "size": "mistral:7b-text-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "qwen2.5",
    "link": "https://ollama.com/library/qwen2.5",
    "description": "Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support.",
    "pullCount": "13.4M",
    "updated": "11 months ago",
    "size": [
      "0.5b",
      "1.5b",
      "3b",
      "7b",
      "14b",
      "32b",
      "72b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/qwen2.5/4b4f719f-c327-489e-8dc1-89a455c21e89)\n\nQwen2.5 is the latest series of Qwen large language models. For Qwen2.5, a range of base language models and instruction-tuned models are released, with sizes ranging from 0.5 to 72 billion parameters. Qwen2.5 introduces the following improvements over Qwen2:\n\n* It possesses **significantly more knowledge** and has greatly enhanced capabilities in **coding** and **mathematics**, due to specialized expert models in these domains.\n* It demonstrates significant advancements in **instruction following**, **long-text generation** (over 8K tokens), **understanding structured data** (e.g., tables), and **generating structured outputs**, especially in JSON format. It is also **more resilient to diverse system prompts**, improving role-play and condition-setting for chatbots.\n* It supports **long contexts** of up to 128K tokens and can generate up to 8K tokens.\n* It offers **multilingual support** for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more.\n\nPlease note: all models except the 3B and 72B are released under the Apache 2.0 license, while the 3B and 72B models are under the Qwen license.\n\n## References\n\n[GitHub](https://github.com/QwenLM/Qwen2.5)\n\n[Blog post](https://qwenlm.github.io/blog/qwen2.5/)\n\n[HuggingFace](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/qwen2.5/4b4f719f-c327-489e-8dc1-89a455c21e89\" width=\"320\" /> Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, a range of base language models and instruction-tuned models are released, with sizes ranging from 0.5 to 72 billion parameters. Qwen2.5 introduces the following improvements over Qwen2: - It possesses \\*\\*significantly more knowledge\\*\\* and has greatly enhanced capabilities in \\*\\*coding\\*\\* and \\*\\*mathematics\\*\\*, due to specialized expert models in these domains. - It demonstrates significant advancements in \\*\\*instruction following\\*\\*, \\*\\*long-text generation\\*\\* (over 8K tokens), \\*\\*understanding structured data\\*\\* (e.g., tables), and \\*\\*generating structured outputs\\*\\*, especially in JSON format. It is also \\*\\*more resilient to diverse system prompts\\*\\*, improving role-play and condition-setting for chatbots. - It supports \\*\\*long contexts\\*\\* of up to 128K tokens and can generate up to 8K tokens. - It offers \\*\\*multilingual support\\*\\* for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. Please note: all models except the 3B and 72B are released under the Apache 2.0 license, while the 3B and 72B models are under the Qwen license. ## References \\[GitHub\\](https://github.com/QwenLM/Qwen2.5) \\[Blog post\\](https://qwenlm.github.io/blog/qwen2.5/) \\[HuggingFace\\](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen2.5:latest",
        "size": "qwen2.5:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b",
        "size": "qwen2.5:0.5b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b",
        "size": "qwen2.5:1.5b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b",
        "size": "qwen2.5:3b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b",
        "size": "qwen2.5:7b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b",
        "size": "qwen2.5:14b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b",
        "size": "qwen2.5:32b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b",
        "size": "qwen2.5:72b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base",
        "size": "qwen2.5:0.5b-base",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q2_K",
        "size": "qwen2.5:0.5b-base-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q3_K_S",
        "size": "qwen2.5:0.5b-base-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q3_K_M",
        "size": "qwen2.5:0.5b-base-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q3_K_L",
        "size": "qwen2.5:0.5b-base-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q4_0",
        "size": "qwen2.5:0.5b-base-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q4_1",
        "size": "qwen2.5:0.5b-base-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q4_K_S",
        "size": "qwen2.5:0.5b-base-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q4_K_M",
        "size": "qwen2.5:0.5b-base-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q5_0",
        "size": "qwen2.5:0.5b-base-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q5_1",
        "size": "qwen2.5:0.5b-base-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q5_K_S",
        "size": "qwen2.5:0.5b-base-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-base-q8_0",
        "size": "qwen2.5:0.5b-base-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct",
        "size": "qwen2.5:0.5b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q2_K",
        "size": "qwen2.5:0.5b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q3_K_S",
        "size": "qwen2.5:0.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q3_K_M",
        "size": "qwen2.5:0.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q3_K_L",
        "size": "qwen2.5:0.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q4_0",
        "size": "qwen2.5:0.5b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q4_1",
        "size": "qwen2.5:0.5b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q4_K_S",
        "size": "qwen2.5:0.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q4_K_M",
        "size": "qwen2.5:0.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q5_0",
        "size": "qwen2.5:0.5b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q5_1",
        "size": "qwen2.5:0.5b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q5_K_S",
        "size": "qwen2.5:0.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q5_K_M",
        "size": "qwen2.5:0.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q6_K",
        "size": "qwen2.5:0.5b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-q8_0",
        "size": "qwen2.5:0.5b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:0.5b-instruct-fp16",
        "size": "qwen2.5:0.5b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct",
        "size": "qwen2.5:1.5b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q2_K",
        "size": "qwen2.5:1.5b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q3_K_S",
        "size": "qwen2.5:1.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q3_K_M",
        "size": "qwen2.5:1.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q3_K_L",
        "size": "qwen2.5:1.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q4_0",
        "size": "qwen2.5:1.5b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q4_1",
        "size": "qwen2.5:1.5b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q4_K_S",
        "size": "qwen2.5:1.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q4_K_M",
        "size": "qwen2.5:1.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q5_0",
        "size": "qwen2.5:1.5b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q5_1",
        "size": "qwen2.5:1.5b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q5_K_S",
        "size": "qwen2.5:1.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q5_K_M",
        "size": "qwen2.5:1.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q6_K",
        "size": "qwen2.5:1.5b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-q8_0",
        "size": "qwen2.5:1.5b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:1.5b-instruct-fp16",
        "size": "qwen2.5:1.5b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct",
        "size": "qwen2.5:3b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q2_K",
        "size": "qwen2.5:3b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q3_K_S",
        "size": "qwen2.5:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q3_K_M",
        "size": "qwen2.5:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q3_K_L",
        "size": "qwen2.5:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q4_0",
        "size": "qwen2.5:3b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q4_1",
        "size": "qwen2.5:3b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q4_K_S",
        "size": "qwen2.5:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q4_K_M",
        "size": "qwen2.5:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q5_0",
        "size": "qwen2.5:3b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q5_1",
        "size": "qwen2.5:3b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q5_K_S",
        "size": "qwen2.5:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q5_K_M",
        "size": "qwen2.5:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q6_K",
        "size": "qwen2.5:3b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-q8_0",
        "size": "qwen2.5:3b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:3b-instruct-fp16",
        "size": "qwen2.5:3b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct",
        "size": "qwen2.5:7b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q2_K",
        "size": "qwen2.5:7b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q3_K_S",
        "size": "qwen2.5:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q3_K_M",
        "size": "qwen2.5:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q3_K_L",
        "size": "qwen2.5:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q4_0",
        "size": "qwen2.5:7b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q4_1",
        "size": "qwen2.5:7b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q4_K_S",
        "size": "qwen2.5:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q4_K_M",
        "size": "qwen2.5:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q5_0",
        "size": "qwen2.5:7b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q5_1",
        "size": "qwen2.5:7b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q5_K_S",
        "size": "qwen2.5:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q5_K_M",
        "size": "qwen2.5:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q6_K",
        "size": "qwen2.5:7b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-q8_0",
        "size": "qwen2.5:7b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:7b-instruct-fp16",
        "size": "qwen2.5:7b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct",
        "size": "qwen2.5:14b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q2_K",
        "size": "qwen2.5:14b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q3_K_S",
        "size": "qwen2.5:14b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q3_K_M",
        "size": "qwen2.5:14b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q3_K_L",
        "size": "qwen2.5:14b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q4_0",
        "size": "qwen2.5:14b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q4_1",
        "size": "qwen2.5:14b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q4_K_S",
        "size": "qwen2.5:14b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q4_K_M",
        "size": "qwen2.5:14b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q5_0",
        "size": "qwen2.5:14b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q5_1",
        "size": "qwen2.5:14b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q5_K_S",
        "size": "qwen2.5:14b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q5_K_M",
        "size": "qwen2.5:14b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q6_K",
        "size": "qwen2.5:14b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-q8_0",
        "size": "qwen2.5:14b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:14b-instruct-fp16",
        "size": "qwen2.5:14b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct",
        "size": "qwen2.5:32b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q2_K",
        "size": "qwen2.5:32b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q3_K_S",
        "size": "qwen2.5:32b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q3_K_M",
        "size": "qwen2.5:32b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q3_K_L",
        "size": "qwen2.5:32b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q4_0",
        "size": "qwen2.5:32b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q4_1",
        "size": "qwen2.5:32b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q4_K_S",
        "size": "qwen2.5:32b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q4_K_M",
        "size": "qwen2.5:32b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q5_0",
        "size": "qwen2.5:32b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q5_1",
        "size": "qwen2.5:32b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q5_K_S",
        "size": "qwen2.5:32b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q5_K_M",
        "size": "qwen2.5:32b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q6_K",
        "size": "qwen2.5:32b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-q8_0",
        "size": "qwen2.5:32b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:32b-instruct-fp16",
        "size": "qwen2.5:32b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct",
        "size": "qwen2.5:72b-instruct",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q2_K",
        "size": "qwen2.5:72b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q3_K_S",
        "size": "qwen2.5:72b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q3_K_M",
        "size": "qwen2.5:72b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q3_K_L",
        "size": "qwen2.5:72b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q4_0",
        "size": "qwen2.5:72b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q4_1",
        "size": "qwen2.5:72b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q4_K_S",
        "size": "qwen2.5:72b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q4_K_M",
        "size": "qwen2.5:72b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q5_0",
        "size": "qwen2.5:72b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q5_1",
        "size": "qwen2.5:72b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q5_K_S",
        "size": "qwen2.5:72b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q5_K_M",
        "size": "qwen2.5:72b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q6_K",
        "size": "qwen2.5:72b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-q8_0",
        "size": "qwen2.5:72b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "qwen2.5:72b-instruct-fp16",
        "size": "qwen2.5:72b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "llama3",
    "link": "https://ollama.com/library/llama3",
    "description": "Meta Llama 3: The most capable openly available LLM to date",
    "pullCount": "10.8M",
    "updated": "1 year ago",
    "size": [
      "8b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n# Llama 3\n\nThe most capable openly available LLM to date.\n\n![](https://github.com/ollama/ollama/assets/3325447/15750d75-668c-42bd-aaf2-d0d203136d55)\n\nMeta Llama 3, a family of models developed by Meta Inc. are new state-of-the-art , available in both **8B** and **70B** parameter sizes (pre-trained or instruction-tuned).\n\nLlama 3 instruction-tuned models are fine-tuned and optimized for dialogue/chat use cases and outperform many of the available open-source chat models on common benchmarks.\n\n![](https://github.com/ollama/ollama/assets/3325447/8910aebc-cd9e-4d2d-b9c2-258b5ac3eeac)\n\n![](https://github.com/ollama/ollama/assets/3325447/f6df22a6-fd54-4aa2-876b-2b9354821ec6)\n\n### CLI\n\nOpen the terminal and run `ollama run llama3`\n\n### API\n\nExample using curl:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3\",\n  \"prompt\":\"Why is the sky blue?\"\n }'\n\n```\n\n[API documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)\n\n## Model variants\n\n**Instruct** is fine-tuned for chat/dialogue use cases.\n\n_Example:_ `ollama run llama3` `ollama run llama3:70b`\n\n**Pre-trained** is the base model.\n\n_Example:_ `ollama run llama3:text` `ollama run llama3:70b-text`\n\n## References\n\n[Introducing Meta Llama 3: The most capable openly available LLM to date](https://ai.meta.com/blog/meta-llama-3/)\n\nWrite Preview \n\n\\# Llama 3 The most capable openly available LLM to date. <img src=\"https://github.com/ollama/ollama/assets/3325447/15750d75-668c-42bd-aaf2-d0d203136d55\" width=\"660\" /> Meta Llama 3, a family of models developed by Meta Inc. are new state-of-the-art , available in both \\*\\*8B\\*\\* and \\*\\*70B\\*\\* parameter sizes (pre-trained or instruction-tuned). Llama 3 instruction-tuned models are fine-tuned and optimized for dialogue/chat use cases and outperform many of the available open-source chat models on common benchmarks. <img src=\"https://github.com/ollama/ollama/assets/3325447/8910aebc-cd9e-4d2d-b9c2-258b5ac3eeac\" /> <img src=\"https://github.com/ollama/ollama/assets/3325447/f6df22a6-fd54-4aa2-876b-2b9354821ec6\" /> ### CLI Open the terminal and run \\`ollama run llama3\\` ### API Example using curl: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"llama3\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` \\[API documentation\\](https://github.com/ollama/ollama/blob/main/docs/api.md) ## Model variants \\*\\*Instruct\\*\\* is fine-tuned for chat/dialogue use cases. \\*Example:\\* \\`ollama run llama3\\` \\`ollama run llama3:70b\\` \\*\\*Pre-trained\\*\\* is the base model. \\*Example:\\* \\`ollama run llama3:text\\` \\`ollama run llama3:70b-text\\` ## References \\[Introducing Meta Llama 3: The most capable openly available LLM to date\\](https://ai.meta.com/blog/meta-llama-3/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3:latest",
        "size": "llama3:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:instruct",
        "size": "llama3:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:text",
        "size": "llama3:text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b",
        "size": "llama3:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b",
        "size": "llama3:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q2_K",
        "size": "llama3:8b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q3_K_S",
        "size": "llama3:8b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q3_K_M",
        "size": "llama3:8b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q3_K_L",
        "size": "llama3:8b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q4_0",
        "size": "llama3:8b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q4_1",
        "size": "llama3:8b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q4_K_S",
        "size": "llama3:8b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q4_K_M",
        "size": "llama3:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q5_0",
        "size": "llama3:8b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q5_1",
        "size": "llama3:8b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q5_K_S",
        "size": "llama3:8b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q5_K_M",
        "size": "llama3:8b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q6_K",
        "size": "llama3:8b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-q8_0",
        "size": "llama3:8b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-instruct-fp16",
        "size": "llama3:8b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text",
        "size": "llama3:8b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q2_K",
        "size": "llama3:8b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q3_K_S",
        "size": "llama3:8b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q3_K_M",
        "size": "llama3:8b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q3_K_L",
        "size": "llama3:8b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q4_0",
        "size": "llama3:8b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q4_1",
        "size": "llama3:8b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q4_K_S",
        "size": "llama3:8b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q4_K_M",
        "size": "llama3:8b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q5_0",
        "size": "llama3:8b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q5_1",
        "size": "llama3:8b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q5_K_S",
        "size": "llama3:8b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q5_K_M",
        "size": "llama3:8b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q6_K",
        "size": "llama3:8b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-q8_0",
        "size": "llama3:8b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:8b-text-fp16",
        "size": "llama3:8b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct",
        "size": "llama3:70b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q2_K",
        "size": "llama3:70b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q3_K_S",
        "size": "llama3:70b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q3_K_M",
        "size": "llama3:70b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q3_K_L",
        "size": "llama3:70b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q4_0",
        "size": "llama3:70b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q4_1",
        "size": "llama3:70b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q4_K_S",
        "size": "llama3:70b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q4_K_M",
        "size": "llama3:70b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q5_0",
        "size": "llama3:70b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q5_1",
        "size": "llama3:70b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q5_K_S",
        "size": "llama3:70b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q5_K_M",
        "size": "llama3:70b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q6_K",
        "size": "llama3:70b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-q8_0",
        "size": "llama3:70b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-instruct-fp16",
        "size": "llama3:70b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text",
        "size": "llama3:70b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q2_K",
        "size": "llama3:70b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q3_K_S",
        "size": "llama3:70b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q3_K_M",
        "size": "llama3:70b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q3_K_L",
        "size": "llama3:70b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q4_0",
        "size": "llama3:70b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q4_1",
        "size": "llama3:70b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q4_K_S",
        "size": "llama3:70b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q4_K_M",
        "size": "llama3:70b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q5_0",
        "size": "llama3:70b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q5_1",
        "size": "llama3:70b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q5_K_S",
        "size": "llama3:70b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q5_K_M",
        "size": "llama3:70b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q6_K",
        "size": "llama3:70b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-q8_0",
        "size": "llama3:70b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3:70b-text-fp16",
        "size": "llama3:70b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llava",
    "link": "https://ollama.com/library/llava",
    "description": "🌋 LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.",
    "pullCount": "9.3M",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "34b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n# 🌋 LLaVA: Large Language and Vision Assistant\n\nLLaVA is a multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding, achieving impressive chat capabilities mimicking spirits of the multimodal GPT-4.\n\n### New in LLaVA 1.6:\n\n* Increasing the input image resolution to up to 4x more pixels, supporting 672x672, 336x1344, 1344x336 resolutions.\n* Better visual reasoning and OCR capability with an improved visual instruction tuning data mixture.\n* Better visual conversation for more scenarios, covering different applications.\n* Better world knowledge and logical reasoning.\n\n### CLI Usage\n\nRun the model:\n\n```\nollama run llava\n\n```\n\nThen at the prompt, include the path to your image in the prompt:\n\n```\n>>> What's in this image? /Users/jmorgan/Desktop/smile.png\nThe image features a yellow smiley face, which is likely the central focus of the picture.\n\n```\n\n### API Usage\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llava\",\n  \"prompt\":\"What is in this picture?\",\n  \"images\": [\"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\"]\n}'\n\n```\n\n## References\n\n[Website](https://llava-vl.github.io/)\n\n[GitHub](https://github.com/haotian-liu/LLaVA)\n\n[HuggingFace](https://huggingface.co/liuhaotian/llava-v1.5-7b)\n\nWrite Preview \n\n\\# 🌋 LLaVA: Large Language and Vision Assistant LLaVA is a multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding, achieving impressive chat capabilities mimicking spirits of the multimodal GPT-4\\. ### New in LLaVA 1.6: \\* Increasing the input image resolution to up to 4x more pixels, supporting 672x672, 336x1344, 1344x336 resolutions. \\* Better visual reasoning and OCR capability with an improved visual instruction tuning data mixture. \\* Better visual conversation for more scenarios, covering different applications. \\* Better world knowledge and logical reasoning. ### CLI Usage Run the model: \\`\\`\\` ollama run llava \\`\\`\\` Then at the prompt, include the path to your image in the prompt: \\`\\`\\` >>> What's in this image? /Users/jmorgan/Desktop/smile.png The image features a yellow smiley face, which is likely the central focus of the picture. \\`\\`\\` ### API Usage \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"llava\", \"prompt\":\"What is in this picture?\", \"images\": \\[\"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\"\\] }' \\`\\`\\` ## References \\[Website\\](https://llava-vl.github.io/) \\[GitHub\\](https://github.com/haotian-liu/LLaVA) \\[HuggingFace\\](https://huggingface.co/liuhaotian/llava-v1.5-7b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llava:latest",
        "size": "llava:latest",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:v1.6",
        "size": "llava:v1.6",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b",
        "size": "llava:7b",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:13b",
        "size": "llava:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b",
        "size": "llava:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q2_K",
        "size": "llava:7b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q3_K_S",
        "size": "llava:7b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q3_K_M",
        "size": "llava:7b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q3_K_L",
        "size": "llava:7b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q4_0",
        "size": "llava:7b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q4_1",
        "size": "llava:7b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q4_K_S",
        "size": "llava:7b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q4_K_M",
        "size": "llava:7b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q5_0",
        "size": "llava:7b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q5_1",
        "size": "llava:7b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q5_K_S",
        "size": "llava:7b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q5_K_M",
        "size": "llava:7b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q6_K",
        "size": "llava:7b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-q8_0",
        "size": "llava:7b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.5-fp16",
        "size": "llava:7b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6",
        "size": "llava:7b-v1.6",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q2_K",
        "size": "llava:7b-v1.6-mistral-q2_K",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q3_K_S",
        "size": "llava:7b-v1.6-mistral-q3_K_S",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q3_K_M",
        "size": "llava:7b-v1.6-mistral-q3_K_M",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q3_K_L",
        "size": "llava:7b-v1.6-mistral-q3_K_L",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q4_0",
        "size": "llava:7b-v1.6-mistral-q4_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q4_1",
        "size": "llava:7b-v1.6-mistral-q4_1",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q4_K_S",
        "size": "llava:7b-v1.6-mistral-q4_K_S",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q4_K_M",
        "size": "llava:7b-v1.6-mistral-q4_K_M",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q5_0",
        "size": "llava:7b-v1.6-mistral-q5_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q5_1",
        "size": "llava:7b-v1.6-mistral-q5_1",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q5_K_S",
        "size": "llava:7b-v1.6-mistral-q5_K_S",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q5_K_M",
        "size": "llava:7b-v1.6-mistral-q5_K_M",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q6_K",
        "size": "llava:7b-v1.6-mistral-q6_K",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-q8_0",
        "size": "llava:7b-v1.6-mistral-q8_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-mistral-fp16",
        "size": "llava:7b-v1.6-mistral-fp16",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q2_K",
        "size": "llava:7b-v1.6-vicuna-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q3_K_S",
        "size": "llava:7b-v1.6-vicuna-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q3_K_M",
        "size": "llava:7b-v1.6-vicuna-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q3_K_L",
        "size": "llava:7b-v1.6-vicuna-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q4_0",
        "size": "llava:7b-v1.6-vicuna-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q4_1",
        "size": "llava:7b-v1.6-vicuna-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q4_K_S",
        "size": "llava:7b-v1.6-vicuna-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q4_K_M",
        "size": "llava:7b-v1.6-vicuna-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q5_0",
        "size": "llava:7b-v1.6-vicuna-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q5_1",
        "size": "llava:7b-v1.6-vicuna-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q5_K_S",
        "size": "llava:7b-v1.6-vicuna-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q5_K_M",
        "size": "llava:7b-v1.6-vicuna-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q6_K",
        "size": "llava:7b-v1.6-vicuna-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-q8_0",
        "size": "llava:7b-v1.6-vicuna-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:7b-v1.6-vicuna-fp16",
        "size": "llava:7b-v1.6-vicuna-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q2_K",
        "size": "llava:13b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q3_K_S",
        "size": "llava:13b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q3_K_M",
        "size": "llava:13b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q3_K_L",
        "size": "llava:13b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q4_0",
        "size": "llava:13b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q4_1",
        "size": "llava:13b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q4_K_S",
        "size": "llava:13b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q4_K_M",
        "size": "llava:13b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q5_0",
        "size": "llava:13b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q5_1",
        "size": "llava:13b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q5_K_S",
        "size": "llava:13b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q5_K_M",
        "size": "llava:13b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q6_K",
        "size": "llava:13b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-q8_0",
        "size": "llava:13b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.5-fp16",
        "size": "llava:13b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6",
        "size": "llava:13b-v1.6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q2_K",
        "size": "llava:13b-v1.6-vicuna-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q3_K_S",
        "size": "llava:13b-v1.6-vicuna-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q3_K_M",
        "size": "llava:13b-v1.6-vicuna-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q3_K_L",
        "size": "llava:13b-v1.6-vicuna-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q4_0",
        "size": "llava:13b-v1.6-vicuna-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q4_1",
        "size": "llava:13b-v1.6-vicuna-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q4_K_S",
        "size": "llava:13b-v1.6-vicuna-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q4_K_M",
        "size": "llava:13b-v1.6-vicuna-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q5_0",
        "size": "llava:13b-v1.6-vicuna-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q5_1",
        "size": "llava:13b-v1.6-vicuna-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q5_K_S",
        "size": "llava:13b-v1.6-vicuna-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q5_K_M",
        "size": "llava:13b-v1.6-vicuna-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q6_K",
        "size": "llava:13b-v1.6-vicuna-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-q8_0",
        "size": "llava:13b-v1.6-vicuna-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:13b-v1.6-vicuna-fp16",
        "size": "llava:13b-v1.6-vicuna-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6",
        "size": "llava:34b-v1.6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q2_K",
        "size": "llava:34b-v1.6-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q3_K_S",
        "size": "llava:34b-v1.6-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q3_K_M",
        "size": "llava:34b-v1.6-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q3_K_L",
        "size": "llava:34b-v1.6-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q4_0",
        "size": "llava:34b-v1.6-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q4_1",
        "size": "llava:34b-v1.6-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q4_K_S",
        "size": "llava:34b-v1.6-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q4_K_M",
        "size": "llava:34b-v1.6-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q5_0",
        "size": "llava:34b-v1.6-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q5_1",
        "size": "llava:34b-v1.6-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q5_K_S",
        "size": "llava:34b-v1.6-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q5_K_M",
        "size": "llava:34b-v1.6-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q6_K",
        "size": "llava:34b-v1.6-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-q8_0",
        "size": "llava:34b-v1.6-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava:34b-v1.6-fp16",
        "size": "llava:34b-v1.6-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "phi3",
    "link": "https://ollama.com/library/phi3",
    "description": "Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.",
    "pullCount": "8.9M",
    "updated": "1 year ago",
    "size": [
      "3.8b",
      "14b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/e06e1a36-97b2-417a-b2b2-028c980359b1)\n\nPhi-3 is a family of open AI models developed by Microsoft.\n\n## Parameter sizes\n\n* [Phi-3 Mini](https://ollama.com/library/phi3:mini) – 3B parameters – `ollama run phi3:mini`\n* [Phi-3 Medium](https://ollama.com/library/phi3:medium) – 14B parameters – `ollama run phi3:medium`\n\n## Context window sizes\n\n> Note: the 128k version of this model requires [Ollama 0.1.39](https://github.com/ollama/ollama/releases/tag/v0.1.39) or later.\n\n* 4k `ollama run phi3:mini` `ollama run phi3:medium`\n* 128k `ollama run phi3:medium-128k`\n\n![image.png](https://ollama.com/assets/library/phi3/83b3de66-82d8-4455-9117-256802c1b82e)\n\n## Phi-3 Mini\n\nPhi-3 Mini is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties.\n\nThe model has underwent a post-training process that incorporates both supervised fine-tuning and direct preference optimization to ensure precise instruction adherence and robust safety measures.\n\nWhen assessed against benchmarks testing common sense, language understanding, math, code, long context and logical reasoning, Phi-3 Mini-4K-Instruct showcased a robust and state-of-the-art performance among models with less than 13 billion parameters.\n\n## Phi-3 Medium\n\nPhi-3 Medium is a 14B parameter language model, and outperforms Gemini 1.0 Pro.\n\n![image.png](https://ollama.com/assets/library/phi3/2868e29b-3bba-4c4a-a6ed-1a27fb102867)\n\n## Intended Uses\n\n**Primary use cases**\n\nThe model is intended for commercial and research use in English. The model provides uses for applications which require 1) memory/compute constrained environments 2) latency bound scenarios 3) strong reasoning (especially math and logic) 4) long context\n\nOur model is designed to accelerate research on language and multimodal models, for use as a building block for generative AI powered features.\n\n**Use case considerations**\n\nOur models are not specifically designed or evaluated for all downstream purposes. Developers should consider common limitations of language models as they select use cases, and evaluate and mitigate for accuracy, safety, and fariness before using within a specific downstream use case, particularly for high risk scenarios. Developers should be aware of and adhere to applicable laws or regulations (including privacy, trade compliance laws, etc.) that are relevant to their use case. Nothing contained in this Model Card should be interpreted as or deemed a restriction or modification to the license the model is released under.\n\n## Responsible AI Considerations\n\nLike other language models, the Phi series models can potentially behave in ways that are unfair, unreliable, or offensive. Some of the limiting behaviors to be aware of include:\n\n* Quality of Service: the Phi models are trained primarily on English text. Languages other than English will experience worse performance. English language varieties with less representation in the training data might experience worse performance than standard American English.\n* Representation of Harms & Perpetuation of Stereotypes: These models can over- or under-represent groups of people, erase representation of some groups, or reinforce demeaning or negative stereotypes. Despite safety post-training, these limitations may still be present due to differing levels of representation of different groups or prevalence of examples of negative stereotypes in training data that reflect real-world patterns and societal biases.\n* Inappropriate or Offensive Content: these models may produce other types of inappropriate or offensive content, which may make it inappropriate to deploy for sensitive contexts without additional mitigations that are specific to the use case.\n* Information Reliability: Language models can generate nonsensical content or fabricate content that might sound reasonable but is inaccurate or outdated.\n* Limited Scope for Code: Majority of Phi-3 training data is based in Python and use common packages such as “typing, math, random, collections, datetime, itertools”. If the model generates Python scripts that utilize other packages or scripts in other languages, we strongly recommend users manually verify all API uses.\n\nDevelopers should apply responsible AI best practices and are responsible for ensuring that a specific use case complies with relevant laws and regulations (e.g. privacy, trade, etc.). Important areas for consideration include: + Allocation: Models may not be suitable for scenarios that could have consequential impact on legal status or the allocation of resources or life opportunities (ex: housing, employment, credit, etc.) without further assessments and additional debiasing techniques.\n\n* High-Risk Scenarios: Developers should assess suitability of using models in high-risk scenarios where unfair, unreliable or offensive outputs might be extremely costly or lead to harm. This includes providing advice in sensitive or expert domains where accuracy and reliability are critical (ex: legal or health advice). Additional safeguards should be implemented at the application level according to the deployment context.\n* Misinformation: Models may produce inaccurate information. Developers should follow transparency best practices and inform end-users they are interacting with an AI system. At the application level, developers can build feedback mechanisms and pipelines to ground responses in use-case specific, contextual information, a technique known as Retrieval Augmented Generation (RAG).\n* Generation of Harmful Content: Developers should assess outputs for their context and use available safety classifiers or custom solutions appropriate for their use case.\n* Misuse: Other forms of misuse such as fraud, spam, or malware production may be possible, and developers should ensure that their applications do not violate applicable laws and regulations.\n\n## Training\n\n### Model\n\n* Architecture: Phi-3 Mini has 3.8B parameters and is a dense decoder-only Transformer model. The model is fine-tuned with Supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) to ensure alignment with human preferences and safety guidelines.\n* Inputs: Text. It is best suited for prompts using chat format.\n* Context length: 128K tokens\n* GPUS: 512 H100-80G\n* Training time: 7 days\n* Training data: 3.3T tokens\n* Outputs: Generated text in response to the input\n* Dates: Our models were trained between February and April 2024\n* Status: This is a static model trained on an offline dataset with cutoff date October 2023\\. Future versions of the tuned models may be released as we improve models.\n\n### Datasets\n\nOur training data includes a wide variety of sources, totaling 3.3 trillion tokens, and is a combination of 1) publicly available documents filtered rigorously for quality, selected high-quality educational data, and code; 2) newly created synthetic, “textbook-like” data for the purpose of teaching math, coding, common sense reasoning, general knowledge of the world (science, daily activities, theory of mind, etc.); 3) high quality chat format supervised data covering various topics to reflect human preferences on different aspects such as instruct-following, truthfulness, honesty and helpfulness.\n\n### Software\n\n* [PyTorch](https://github.com/pytorch/pytorch)\n* [DeepSpeed](https://github.com/microsoft/DeepSpeed)\n* [Transformers](https://github.com/huggingface/transformers)\n* [Flash-Attention](https://github.com/HazyResearch/flash-attention)\n\n### License\n\nThe model is licensed under the [MIT license](https://ollama.com/library/phi3:latest/blobs/fa8235e5b48fENSE).\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft’s Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party’s policies.\n\n## Resources\n\n* [HuggingFace](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf)\n* [Phi-3 Microsoft Blog](https://aka.ms/phi3-blog)\n* [Phi-3 Technical Report](https://aka.ms/phi3-tech-report)\n* [Phi-3 on Azure AI Studio](https://aka.ms/phi3-azure-ai)\n* [Phi-3 on Hugging Face](https://aka.ms/phi3-hf)\n* Phi-3 ONNX: [4K](https://aka.ms/phi3-mini-4k-instruct-onnx) and [128K](https://aka.ms/phi3-mini-128k-instruct-onnx)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/e06e1a36-97b2-417a-b2b2-028c980359b1\" width=\"240\" /> Phi-3 is a family of open AI models developed by Microsoft. ## Parameter sizes - \\[Phi-3 Mini\\](https://ollama.com/library/phi3:mini) – 3B parameters – \\`ollama run phi3:mini\\` - \\[Phi-3 Medium\\](https://ollama.com/library/phi3:medium) – 14B parameters – \\`ollama run phi3:medium\\` ## Context window sizes > Note: the 128k version of this model requires \\[Ollama 0.1.39\\](https://github.com/ollama/ollama/releases/tag/v0.1.39) or later. - 4k \\`ollama run phi3:mini\\` \\`ollama run phi3:medium\\` - 128k \\`ollama run phi3:medium-128k\\` !\\[image.png\\](https://ollama.com/assets/library/phi3/83b3de66-82d8-4455-9117-256802c1b82e) ## Phi-3 Mini Phi-3 Mini is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties. The model has underwent a post-training process that incorporates both supervised fine-tuning and direct preference optimization to ensure precise instruction adherence and robust safety measures. When assessed against benchmarks testing common sense, language understanding, math, code, long context and logical reasoning, Phi-3 Mini-4K-Instruct showcased a robust and state-of-the-art performance among models with less than 13 billion parameters. ## Phi-3 Medium Phi-3 Medium is a 14B parameter language model, and outperforms Gemini 1.0 Pro. !\\[image.png\\](https://ollama.com/assets/library/phi3/2868e29b-3bba-4c4a-a6ed-1a27fb102867) ## Intended Uses \\*\\*Primary use cases\\*\\* The model is intended for commercial and research use in English. The model provides uses for applications which require 1) memory/compute constrained environments 2) latency bound scenarios 3) strong reasoning (especially math and logic) 4) long context Our model is designed to accelerate research on language and multimodal models, for use as a building block for generative AI powered features. \\*\\*Use case considerations\\*\\* Our models are not specifically designed or evaluated for all downstream purposes. Developers should consider common limitations of language models as they select use cases, and evaluate and mitigate for accuracy, safety, and fariness before using within a specific downstream use case, particularly for high risk scenarios. Developers should be aware of and adhere to applicable laws or regulations (including privacy, trade compliance laws, etc.) that are relevant to their use case. Nothing contained in this Model Card should be interpreted as or deemed a restriction or modification to the license the model is released under. ## Responsible AI Considerations Like other language models, the Phi series models can potentially behave in ways that are unfair, unreliable, or offensive. Some of the limiting behaviors to be aware of include: + Quality of Service: the Phi models are trained primarily on English text. Languages other than English will experience worse performance. English language varieties with less representation in the training data might experience worse performance than standard American English. + Representation of Harms & Perpetuation of Stereotypes: These models can over- or under-represent groups of people, erase representation of some groups, or reinforce demeaning or negative stereotypes. Despite safety post-training, these limitations may still be present due to differing levels of representation of different groups or prevalence of examples of negative stereotypes in training data that reflect real-world patterns and societal biases. + Inappropriate or Offensive Content: these models may produce other types of inappropriate or offensive content, which may make it inappropriate to deploy for sensitive contexts without additional mitigations that are specific to the use case. + Information Reliability: Language models can generate nonsensical content or fabricate content that might sound reasonable but is inaccurate or outdated. + Limited Scope for Code: Majority of Phi-3 training data is based in Python and use common packages such as \"typing, math, random, collections, datetime, itertools\". If the model generates Python scripts that utilize other packages or scripts in other languages, we strongly recommend users manually verify all API uses. Developers should apply responsible AI best practices and are responsible for ensuring that a specific use case complies with relevant laws and regulations (e.g. privacy, trade, etc.). Important areas for consideration include: + Allocation: Models may not be suitable for scenarios that could have consequential impact on legal status or the allocation of resources or life opportunities (ex: housing, employment, credit, etc.) without further assessments and additional debiasing techniques. + High-Risk Scenarios: Developers should assess suitability of using models in high-risk scenarios where unfair, unreliable or offensive outputs might be extremely costly or lead to harm. This includes providing advice in sensitive or expert domains where accuracy and reliability are critical (ex: legal or health advice). Additional safeguards should be implemented at the application level according to the deployment context. + Misinformation: Models may produce inaccurate information. Developers should follow transparency best practices and inform end-users they are interacting with an AI system. At the application level, developers can build feedback mechanisms and pipelines to ground responses in use-case specific, contextual information, a technique known as Retrieval Augmented Generation (RAG). + Generation of Harmful Content: Developers should assess outputs for their context and use available safety classifiers or custom solutions appropriate for their use case. + Misuse: Other forms of misuse such as fraud, spam, or malware production may be possible, and developers should ensure that their applications do not violate applicable laws and regulations. ## Training ### Model \\* Architecture: Phi-3 Mini has 3.8B parameters and is a dense decoder-only Transformer model. The model is fine-tuned with Supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) to ensure alignment with human preferences and safety guidelines. \\* Inputs: Text. It is best suited for prompts using chat format. \\* Context length: 128K tokens \\* GPUS: 512 H100-80G \\* Training time: 7 days \\* Training data: 3.3T tokens \\* Outputs: Generated text in response to the input \\* Dates: Our models were trained between February and April 2024 \\* Status: This is a static model trained on an offline dataset with cutoff date October 2023\\. Future versions of the tuned models may be released as we improve models. ### Datasets Our training data includes a wide variety of sources, totaling 3.3 trillion tokens, and is a combination of 1) publicly available documents filtered rigorously for quality, selected high-quality educational data, and code; 2) newly created synthetic, “textbook-like” data for the purpose of teaching math, coding, common sense reasoning, general knowledge of the world (science, daily activities, theory of mind, etc.); 3) high quality chat format supervised data covering various topics to reflect human preferences on different aspects such as instruct-following, truthfulness, honesty and helpfulness. ### Software \\* \\[PyTorch\\](https://github.com/pytorch/pytorch) \\* \\[DeepSpeed\\](https://github.com/microsoft/DeepSpeed) \\* \\[Transformers\\](https://github.com/huggingface/transformers) \\* \\[Flash-Attention\\](https://github.com/HazyResearch/flash-attention) ### License The model is licensed under the \\[MIT license\\](https://ollama.com/library/phi3:latest/blobs/fa8235e5b48fENSE). ## Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow \\[Microsoft’s Trademark & Brand Guidelines\\](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party’s policies. ## Resources + \\[HuggingFace\\](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf) + \\[Phi-3 Microsoft Blog\\](https://aka.ms/phi3-blog) + \\[Phi-3 Technical Report\\](https://aka.ms/phi3-tech-report) + \\[Phi-3 on Azure AI Studio\\](https://aka.ms/phi3-azure-ai) + \\[Phi-3 on Hugging Face\\](https://aka.ms/phi3-hf) + Phi-3 ONNX: \\[4K\\](https://aka.ms/phi3-mini-4k-instruct-onnx) and \\[128K\\](https://aka.ms/phi3-mini-128k-instruct-onnx) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi3:latest",
        "size": "phi3:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:instruct",
        "size": "phi3:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:medium",
        "size": "phi3:medium",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:mini",
        "size": "phi3:mini",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b",
        "size": "phi3:3.8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b",
        "size": "phi3:14b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-instruct",
        "size": "phi3:3.8b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q2_K",
        "size": "phi3:3.8b-mini-128k-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q3_K_S",
        "size": "phi3:3.8b-mini-128k-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q3_K_M",
        "size": "phi3:3.8b-mini-128k-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q3_K_L",
        "size": "phi3:3.8b-mini-128k-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q4_0",
        "size": "phi3:3.8b-mini-128k-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q4_1",
        "size": "phi3:3.8b-mini-128k-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q4_K_S",
        "size": "phi3:3.8b-mini-128k-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q4_K_M",
        "size": "phi3:3.8b-mini-128k-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q5_0",
        "size": "phi3:3.8b-mini-128k-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q5_1",
        "size": "phi3:3.8b-mini-128k-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q5_K_S",
        "size": "phi3:3.8b-mini-128k-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q5_K_M",
        "size": "phi3:3.8b-mini-128k-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q6_K",
        "size": "phi3:3.8b-mini-128k-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-q8_0",
        "size": "phi3:3.8b-mini-128k-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-128k-instruct-fp16",
        "size": "phi3:3.8b-mini-128k-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q2_K",
        "size": "phi3:3.8b-mini-4k-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q3_K_S",
        "size": "phi3:3.8b-mini-4k-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q3_K_M",
        "size": "phi3:3.8b-mini-4k-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q3_K_L",
        "size": "phi3:3.8b-mini-4k-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q4_0",
        "size": "phi3:3.8b-mini-4k-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q4_1",
        "size": "phi3:3.8b-mini-4k-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q4_K_S",
        "size": "phi3:3.8b-mini-4k-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q4_K_M",
        "size": "phi3:3.8b-mini-4k-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q5_0",
        "size": "phi3:3.8b-mini-4k-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q5_1",
        "size": "phi3:3.8b-mini-4k-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q5_K_S",
        "size": "phi3:3.8b-mini-4k-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q5_K_M",
        "size": "phi3:3.8b-mini-4k-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q6_K",
        "size": "phi3:3.8b-mini-4k-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-q8_0",
        "size": "phi3:3.8b-mini-4k-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:3.8b-mini-4k-instruct-fp16",
        "size": "phi3:3.8b-mini-4k-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-instruct",
        "size": "phi3:14b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q2_K",
        "size": "phi3:14b-medium-128k-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q3_K_S",
        "size": "phi3:14b-medium-128k-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q3_K_M",
        "size": "phi3:14b-medium-128k-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q3_K_L",
        "size": "phi3:14b-medium-128k-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q4_0",
        "size": "phi3:14b-medium-128k-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q4_1",
        "size": "phi3:14b-medium-128k-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q4_K_S",
        "size": "phi3:14b-medium-128k-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q4_K_M",
        "size": "phi3:14b-medium-128k-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q5_0",
        "size": "phi3:14b-medium-128k-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q5_1",
        "size": "phi3:14b-medium-128k-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q5_K_S",
        "size": "phi3:14b-medium-128k-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q5_K_M",
        "size": "phi3:14b-medium-128k-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q6_K",
        "size": "phi3:14b-medium-128k-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-q8_0",
        "size": "phi3:14b-medium-128k-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-128k-instruct-fp16",
        "size": "phi3:14b-medium-128k-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q2_K",
        "size": "phi3:14b-medium-4k-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q3_K_S",
        "size": "phi3:14b-medium-4k-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q3_K_M",
        "size": "phi3:14b-medium-4k-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q3_K_L",
        "size": "phi3:14b-medium-4k-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q4_0",
        "size": "phi3:14b-medium-4k-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q4_1",
        "size": "phi3:14b-medium-4k-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q4_K_S",
        "size": "phi3:14b-medium-4k-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q4_K_M",
        "size": "phi3:14b-medium-4k-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q5_0",
        "size": "phi3:14b-medium-4k-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q5_1",
        "size": "phi3:14b-medium-4k-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q5_K_S",
        "size": "phi3:14b-medium-4k-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q5_K_M",
        "size": "phi3:14b-medium-4k-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q6_K",
        "size": "phi3:14b-medium-4k-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-q8_0",
        "size": "phi3:14b-medium-4k-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:14b-medium-4k-instruct-fp16",
        "size": "phi3:14b-medium-4k-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:medium-128k",
        "size": "phi3:medium-128k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:medium-4k",
        "size": "phi3:medium-4k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:mini-128k",
        "size": "phi3:mini-128k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3:mini-4k",
        "size": "phi3:mini-4k",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "gemma2",
    "link": "https://ollama.com/library/gemma2",
    "description": "Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.",
    "pullCount": "7.3M",
    "updated": "1 year ago",
    "size": [
      "2b",
      "9b",
      "27b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![Ollama in a Noogler hat with the Gemma 2 logo](https://ollama.com/assets/library/gemma2/58a4be20-b402-4dfa-8f1d-05d820f1204f)\n\nGoogle’s Gemma 2 model is available in three sizes, 2B, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.\n\n## Class leading performance\n\nAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.\n\n## Three sizes: 2B, 9B and 27B parameters\n\n* 2B Parameters `ollama run gemma2:2b`\n* 9B Parameters `ollama run gemma2`\n* 27B Parameters `ollama run gemma2:27b`\n\n## Benchmark\n\n![Benchmark](https://ollama.com/assets/library/gemma2/79663012-1c9c-4451-871b-4621f1a898d6)\n\n## Intended Usage\n\nOpen Large Language Models (LLMs) have a wide range of applications across various industries and domains. The following list of potential uses is not comprehensive. The purpose of this list is to provide contextual information about the possible use-cases that the model creators considered as part of model training and development.\n\n* Content Creation and Communication  \n   * Text Generation: These models can be used to generate creative text formats such as poems, scripts, code, marketing copy, and email drafts.  \n   * Chatbots and Conversational AI: Power conversational interfaces for customer service, virtual assistants, or interactive applications.  \n   * Text Summarization: Generate concise summaries of a text corpus, research papers, or reports.\n* Research and Education  \n   * Natural Language Processing (NLP) Research: These models can serve as a foundation for researchers to experiment with NLP techniques, develop algorithms, and contribute to the advancement of the field.  \n   * Language Learning Tools: Support interactive language learning experiences, aiding in grammar correction or providing writing practice.  \n   * Knowledge Exploration: Assist researchers in exploring large bodies of text by generating summaries or answering questions about specific topics.\n\n## Using Gemma 2 with popular tooling\n\n### LangChain\n\n```\nfrom langchain_community.llms import Ollama\nllm = Ollama(model=\"gemma2\")\nllm.invoke(\"Why is the sky blue?\")\n\n```\n\n### LlamaIndex\n\n```\nfrom llama_index.llms.ollama import Ollama\nllm = Ollama(model=\"gemma2\")\nllm.complete(\"Why is the sky blue?\")\n\n```\n\nWrite Preview \n\n!\\[Ollama in a Noogler hat with the Gemma 2 logo\\](https://ollama.com/assets/library/gemma2/58a4be20-b402-4dfa-8f1d-05d820f1204f) Google's Gemma 2 model is available in three sizes, 2B, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency. ## Class leading performance At 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape. ## Three sizes: 2B, 9B and 27B parameters \\* 2B Parameters \\`ollama run gemma2:2b\\` \\* 9B Parameters \\`ollama run gemma2\\` \\* 27B Parameters \\`ollama run gemma2:27b\\` ## Benchmark !\\[Benchmark\\](https://ollama.com/assets/library/gemma2/79663012-1c9c-4451-871b-4621f1a898d6) ## Intended Usage Open Large Language Models (LLMs) have a wide range of applications across various industries and domains. The following list of potential uses is not comprehensive. The purpose of this list is to provide contextual information about the possible use-cases that the model creators considered as part of model training and development. \\* Content Creation and Communication \\* Text Generation: These models can be used to generate creative text formats such as poems, scripts, code, marketing copy, and email drafts. \\* Chatbots and Conversational AI: Power conversational interfaces for customer service, virtual assistants, or interactive applications. \\* Text Summarization: Generate concise summaries of a text corpus, research papers, or reports. \\* Research and Education \\* Natural Language Processing (NLP) Research: These models can serve as a foundation for researchers to experiment with NLP techniques, develop algorithms, and contribute to the advancement of the field. \\* Language Learning Tools: Support interactive language learning experiences, aiding in grammar correction or providing writing practice. \\* Knowledge Exploration: Assist researchers in exploring large bodies of text by generating summaries or answering questions about specific topics. ## Using Gemma 2 with popular tooling ### LangChain \\`\\`\\`python from langchain\\_community.llms import Ollama llm = Ollama(model=\"gemma2\") llm.invoke(\"Why is the sky blue?\") \\`\\`\\` ### LlamaIndex \\`\\`\\`python from llama\\_index.llms.ollama import Ollama llm = Ollama(model=\"gemma2\") llm.complete(\"Why is the sky blue?\") \\`\\`\\` \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "gemma2:latest",
        "size": "gemma2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b",
        "size": "gemma2:2b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b",
        "size": "gemma2:9b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b",
        "size": "gemma2:27b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q2_K",
        "size": "gemma2:2b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q3_K_S",
        "size": "gemma2:2b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q3_K_M",
        "size": "gemma2:2b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q3_K_L",
        "size": "gemma2:2b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q4_0",
        "size": "gemma2:2b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q4_1",
        "size": "gemma2:2b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q4_K_S",
        "size": "gemma2:2b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q4_K_M",
        "size": "gemma2:2b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q5_0",
        "size": "gemma2:2b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q5_1",
        "size": "gemma2:2b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q5_K_S",
        "size": "gemma2:2b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q5_K_M",
        "size": "gemma2:2b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q6_K",
        "size": "gemma2:2b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-q8_0",
        "size": "gemma2:2b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-instruct-fp16",
        "size": "gemma2:2b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q2_K",
        "size": "gemma2:2b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q3_K_S",
        "size": "gemma2:2b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q3_K_M",
        "size": "gemma2:2b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q3_K_L",
        "size": "gemma2:2b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q4_0",
        "size": "gemma2:2b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q4_1",
        "size": "gemma2:2b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q4_K_S",
        "size": "gemma2:2b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q4_K_M",
        "size": "gemma2:2b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q5_0",
        "size": "gemma2:2b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q5_1",
        "size": "gemma2:2b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q5_K_S",
        "size": "gemma2:2b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q5_K_M",
        "size": "gemma2:2b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q6_K",
        "size": "gemma2:2b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-q8_0",
        "size": "gemma2:2b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:2b-text-fp16",
        "size": "gemma2:2b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q2_K",
        "size": "gemma2:9b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q3_K_S",
        "size": "gemma2:9b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q3_K_M",
        "size": "gemma2:9b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q3_K_L",
        "size": "gemma2:9b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q4_0",
        "size": "gemma2:9b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q4_1",
        "size": "gemma2:9b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q4_K_S",
        "size": "gemma2:9b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q4_K_M",
        "size": "gemma2:9b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q5_0",
        "size": "gemma2:9b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q5_1",
        "size": "gemma2:9b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q5_K_S",
        "size": "gemma2:9b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q5_K_M",
        "size": "gemma2:9b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q6_K",
        "size": "gemma2:9b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-q8_0",
        "size": "gemma2:9b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-instruct-fp16",
        "size": "gemma2:9b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q2_K",
        "size": "gemma2:9b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q3_K_S",
        "size": "gemma2:9b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q3_K_M",
        "size": "gemma2:9b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q3_K_L",
        "size": "gemma2:9b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q4_0",
        "size": "gemma2:9b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q4_1",
        "size": "gemma2:9b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q4_K_S",
        "size": "gemma2:9b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q4_K_M",
        "size": "gemma2:9b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q5_0",
        "size": "gemma2:9b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q5_1",
        "size": "gemma2:9b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q5_K_S",
        "size": "gemma2:9b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q5_K_M",
        "size": "gemma2:9b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q6_K",
        "size": "gemma2:9b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-q8_0",
        "size": "gemma2:9b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:9b-text-fp16",
        "size": "gemma2:9b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q2_K",
        "size": "gemma2:27b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q3_K_S",
        "size": "gemma2:27b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q3_K_M",
        "size": "gemma2:27b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q3_K_L",
        "size": "gemma2:27b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q4_0",
        "size": "gemma2:27b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q4_1",
        "size": "gemma2:27b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q4_K_S",
        "size": "gemma2:27b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q4_K_M",
        "size": "gemma2:27b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q5_0",
        "size": "gemma2:27b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q5_1",
        "size": "gemma2:27b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q5_K_S",
        "size": "gemma2:27b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q5_K_M",
        "size": "gemma2:27b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q6_K",
        "size": "gemma2:27b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-q8_0",
        "size": "gemma2:27b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-instruct-fp16",
        "size": "gemma2:27b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q2_K",
        "size": "gemma2:27b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q3_K_S",
        "size": "gemma2:27b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q3_K_M",
        "size": "gemma2:27b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q3_K_L",
        "size": "gemma2:27b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q4_0",
        "size": "gemma2:27b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q4_1",
        "size": "gemma2:27b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q4_K_S",
        "size": "gemma2:27b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q4_K_M",
        "size": "gemma2:27b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q5_0",
        "size": "gemma2:27b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q5_1",
        "size": "gemma2:27b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q5_K_S",
        "size": "gemma2:27b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q5_K_M",
        "size": "gemma2:27b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q6_K",
        "size": "gemma2:27b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-q8_0",
        "size": "gemma2:27b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma2:27b-text-fp16",
        "size": "gemma2:27b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "qwen2.5-coder",
    "link": "https://ollama.com/library/qwen2.5-coder",
    "description": "The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.",
    "pullCount": "6.8M",
    "updated": "3 months ago",
    "size": [
      "0.5b",
      "1.5b",
      "3b",
      "7b",
      "14b",
      "32b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/qwen2.5-coder/59b3c116-2653-4d50-9b5f-1fefd24a61bf)\n\nQwen 2.5 Coder series of models are now updated in 6 sizes: **0.5B, 1.5B, 3B, 7B, 14B and 32B**.\n\nThere are significant improvements in **code generation**, **code reasoning** and **code fixing**. The 32B model has competitive performance with OpenAI’s GPT-4o.\n\n**32B:** `ollama run qwen2.5-coder:32b`\n\n**14B:** `ollama run qwen2.5-coder:14b`\n\n**7B:** `ollama run qwen2.5-coder:7b`\n\n**3B:** `ollama run qwen2.5-coder:3b`\n\n**1.5B:** `ollama run qwen2.5-coder:1.5b`\n\n**0.5B:** `ollama run qwen2.5-coder:0.5b`\n\n### Code capabilities reaching state of the art for open-source models\n\n![Comparison benchmarks](/assets/library/qwen2.5-coder/05059413-3cc4-4b07-b546-001594d0ae26)\n\n**Code Generation:** Qwen2.5 Coder 32B Instruct, as the flagship model of this open-source release, has achieved the best performance among open-source models on multiple popular code generation benchmarks (EvalPlus, LiveCodeBench, BigCodeBench), and has competitive performance with GPT-4o.\n\n**Code Repair:** Code repair is an important programming skill. Qwen2.5 Coder 32B Instruct can help users fix errors in their code, making programming more efficient. Aider is a popular benchmark for code repair, and Qwen2.5 Coder 32B Instruct scored 73.7, performing comparably to GPT-4o on Aider.\n\n**Code Reasoning:** Code reasoning refers to the model’s ability to learn the process of code execution and accurately predict the model’s inputs and outputs. The recently released Qwen2.5 Coder 7B Instruct has already shown impressive performance in code reasoning, and this 32B model takes it a step further.\n\n![Benchmarks](/assets/library/qwen2.5-coder/0bd9e1aa-a87b-474b-84ba-264a85041605)\n\n### Multiple programming languages\n\nAn intelligent programming assistant should be familiar with all programming languages. Qwen 2.5 Coder 32B performs excellent across more than 40 programming languages, scoring 65.9 on McEval, with impressive performances in languages like Haskell and Racket. The Qwen team used their own unique data cleaning and balancing during the pre-training phase.\n\n![McEval Performance](/assets/library/qwen2.5-coder/6436978b-1371-48a4-a21a-b6da729b74e1)\n\nAdditionally, the multi-language code repair capabilities of Qwen 2.5 Coder 32B Instruct remain impressive, aiding users in understanding and modifying programming languages they are familiar with, significantly reducing the learning cost of unfamiliar languages. Similar to McEval, MdEval is a multi-language code repair benchmark, where Qwen 2.5 Coder 32B Instruct scored 75.2, ranking first among all open-source models.\n\n![MdEval Performance](/assets/library/qwen2.5-coder/f2401bd6-f6d7-41ca-981d-98abc62f1493)\n\n### Human Preference\n\nTo evaluate the alignment performance of Qwen 2.5 Coder 32B Instruct with human preferences, we constructed an internal annotated code preference evaluation benchmark called Code Arena (similar to Arena Hard). We used GPT-4o as the evaluation model for preference alignment, employing an ‘A vs. B win’ evaluation method, which measures the percentage of instances in the test set where model A’s score exceeds model B’s. The results below demonstrate the advantages of Qwen 2.5 Coder 32B Instruct in preference alignment.\n\n![human preference](/assets/library/qwen2.5-coder/bbf378d8-c80e-4ae3-98ab-90111dfbf3e7)\n\n### Comprehensive model sizes to fit your device\n\n![Model sizes](/assets/library/qwen2.5-coder/752764ea-d510-4bc5-8658-dc5d8ba51019)\n\n## References\n\n[Blog Post](https://qwenlm.github.io/blog/qwen2.5-coder-family/)\n\n[HuggingFace](https://huggingface.co/collections/Qwen/qwen25-coder-66eaa22e6f99801bf65b0c2f)\n\nWrite Preview \n\n<img src=\"/assets/library/qwen2.5-coder/59b3c116-2653-4d50-9b5f-1fefd24a61bf\" width=\"450\" /> Qwen 2.5 Coder series of models are now updated in 6 sizes: \\*\\*0.5B, 1.5B, 3B, 7B, 14B and 32B\\*\\*. There are significant improvements in \\*\\*code generation\\*\\*, \\*\\*code reasoning\\*\\* and \\*\\*code fixing\\*\\*. The 32B model has competitive performance with OpenAI's GPT-4o. \\*\\*32B:\\*\\* \\`ollama run qwen2.5-coder:32b\\` \\*\\*14B:\\*\\* \\`ollama run qwen2.5-coder:14b\\` \\*\\*7B:\\*\\* \\`ollama run qwen2.5-coder:7b\\` \\*\\*3B:\\*\\* \\`ollama run qwen2.5-coder:3b\\` \\*\\*1.5B:\\*\\* \\`ollama run qwen2.5-coder:1.5b\\` \\*\\*0.5B:\\*\\* \\`ollama run qwen2.5-coder:0.5b\\` ### Code capabilities reaching state of the art for open-source models !\\[Comparison benchmarks\\](/assets/library/qwen2.5-coder/05059413-3cc4-4b07-b546-001594d0ae26) \\*\\*Code Generation:\\*\\* Qwen2.5 Coder 32B Instruct, as the flagship model of this open-source release, has achieved the best performance among open-source models on multiple popular code generation benchmarks (EvalPlus, LiveCodeBench, BigCodeBench), and has competitive performance with GPT-4o. \\*\\*Code Repair:\\*\\* Code repair is an important programming skill. Qwen2.5 Coder 32B Instruct can help users fix errors in their code, making programming more efficient. Aider is a popular benchmark for code repair, and Qwen2.5 Coder 32B Instruct scored 73.7, performing comparably to GPT-4o on Aider. \\*\\*Code Reasoning:\\*\\* Code reasoning refers to the model’s ability to learn the process of code execution and accurately predict the model’s inputs and outputs. The recently released Qwen2.5 Coder 7B Instruct has already shown impressive performance in code reasoning, and this 32B model takes it a step further. !\\[Benchmarks\\](/assets/library/qwen2.5-coder/0bd9e1aa-a87b-474b-84ba-264a85041605) ### Multiple programming languages An intelligent programming assistant should be familiar with all programming languages. Qwen 2.5 Coder 32B performs excellent across more than 40 programming languages, scoring 65.9 on McEval, with impressive performances in languages like Haskell and Racket. The Qwen team used their own unique data cleaning and balancing during the pre-training phase. !\\[McEval Performance\\](/assets/library/qwen2.5-coder/6436978b-1371-48a4-a21a-b6da729b74e1) Additionally, the multi-language code repair capabilities of Qwen 2.5 Coder 32B Instruct remain impressive, aiding users in understanding and modifying programming languages they are familiar with, significantly reducing the learning cost of unfamiliar languages. Similar to McEval, MdEval is a multi-language code repair benchmark, where Qwen 2.5 Coder 32B Instruct scored 75.2, ranking first among all open-source models. !\\[MdEval Performance\\](/assets/library/qwen2.5-coder/f2401bd6-f6d7-41ca-981d-98abc62f1493) ### Human Preference To evaluate the alignment performance of Qwen 2.5 Coder 32B Instruct with human preferences, we constructed an internal annotated code preference evaluation benchmark called Code Arena (similar to Arena Hard). We used GPT-4o as the evaluation model for preference alignment, employing an ‘A vs. B win’ evaluation method, which measures the percentage of instances in the test set where model A’s score exceeds model B’s. The results below demonstrate the advantages of Qwen 2.5 Coder 32B Instruct in preference alignment. !\\[human preference\\](/assets/library/qwen2.5-coder/bbf378d8-c80e-4ae3-98ab-90111dfbf3e7) ### Comprehensive model sizes to fit your device !\\[Model sizes\\](/assets/library/qwen2.5-coder/752764ea-d510-4bc5-8658-dc5d8ba51019) ## References \\[Blog Post\\](https://qwenlm.github.io/blog/qwen2.5-coder-family/) \\[HuggingFace\\](https://huggingface.co/collections/Qwen/qwen25-coder-66eaa22e6f99801bf65b0c2f) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen2.5-coder:latest",
        "size": "qwen2.5-coder:latest",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b",
        "size": "qwen2.5-coder:0.5b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b",
        "size": "qwen2.5-coder:1.5b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b",
        "size": "qwen2.5-coder:3b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b",
        "size": "qwen2.5-coder:7b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b",
        "size": "qwen2.5-coder:14b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b",
        "size": "qwen2.5-coder:32b",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base",
        "size": "qwen2.5-coder:0.5b-base",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q2_K",
        "size": "qwen2.5-coder:0.5b-base-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q3_K_S",
        "size": "qwen2.5-coder:0.5b-base-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q3_K_M",
        "size": "qwen2.5-coder:0.5b-base-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q3_K_L",
        "size": "qwen2.5-coder:0.5b-base-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q4_0",
        "size": "qwen2.5-coder:0.5b-base-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q4_1",
        "size": "qwen2.5-coder:0.5b-base-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q4_K_S",
        "size": "qwen2.5-coder:0.5b-base-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q4_K_M",
        "size": "qwen2.5-coder:0.5b-base-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q5_0",
        "size": "qwen2.5-coder:0.5b-base-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q5_1",
        "size": "qwen2.5-coder:0.5b-base-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q5_K_S",
        "size": "qwen2.5-coder:0.5b-base-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q5_K_M",
        "size": "qwen2.5-coder:0.5b-base-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q6_K",
        "size": "qwen2.5-coder:0.5b-base-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-q8_0",
        "size": "qwen2.5-coder:0.5b-base-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-base-fp16",
        "size": "qwen2.5-coder:0.5b-base-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct",
        "size": "qwen2.5-coder:0.5b-instruct",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q2_K",
        "size": "qwen2.5-coder:0.5b-instruct-q2_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q3_K_S",
        "size": "qwen2.5-coder:0.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q3_K_M",
        "size": "qwen2.5-coder:0.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q3_K_L",
        "size": "qwen2.5-coder:0.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q4_0",
        "size": "qwen2.5-coder:0.5b-instruct-q4_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q4_1",
        "size": "qwen2.5-coder:0.5b-instruct-q4_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q4_K_S",
        "size": "qwen2.5-coder:0.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q4_K_M",
        "size": "qwen2.5-coder:0.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q5_0",
        "size": "qwen2.5-coder:0.5b-instruct-q5_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q5_1",
        "size": "qwen2.5-coder:0.5b-instruct-q5_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q5_K_S",
        "size": "qwen2.5-coder:0.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q5_K_M",
        "size": "qwen2.5-coder:0.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q6_K",
        "size": "qwen2.5-coder:0.5b-instruct-q6_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-q8_0",
        "size": "qwen2.5-coder:0.5b-instruct-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:0.5b-instruct-fp16",
        "size": "qwen2.5-coder:0.5b-instruct-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base",
        "size": "qwen2.5-coder:1.5b-base",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q2_K",
        "size": "qwen2.5-coder:1.5b-base-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q3_K_S",
        "size": "qwen2.5-coder:1.5b-base-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q3_K_M",
        "size": "qwen2.5-coder:1.5b-base-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q3_K_L",
        "size": "qwen2.5-coder:1.5b-base-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q4_0",
        "size": "qwen2.5-coder:1.5b-base-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q4_1",
        "size": "qwen2.5-coder:1.5b-base-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q4_K_S",
        "size": "qwen2.5-coder:1.5b-base-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q4_K_M",
        "size": "qwen2.5-coder:1.5b-base-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q5_0",
        "size": "qwen2.5-coder:1.5b-base-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q5_1",
        "size": "qwen2.5-coder:1.5b-base-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q5_K_S",
        "size": "qwen2.5-coder:1.5b-base-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q5_K_M",
        "size": "qwen2.5-coder:1.5b-base-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q6_K",
        "size": "qwen2.5-coder:1.5b-base-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-q8_0",
        "size": "qwen2.5-coder:1.5b-base-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-base-fp16",
        "size": "qwen2.5-coder:1.5b-base-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct",
        "size": "qwen2.5-coder:1.5b-instruct",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q2_K",
        "size": "qwen2.5-coder:1.5b-instruct-q2_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q3_K_S",
        "size": "qwen2.5-coder:1.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q3_K_M",
        "size": "qwen2.5-coder:1.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q3_K_L",
        "size": "qwen2.5-coder:1.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q4_0",
        "size": "qwen2.5-coder:1.5b-instruct-q4_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q4_1",
        "size": "qwen2.5-coder:1.5b-instruct-q4_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q4_K_S",
        "size": "qwen2.5-coder:1.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q4_K_M",
        "size": "qwen2.5-coder:1.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q5_0",
        "size": "qwen2.5-coder:1.5b-instruct-q5_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q5_1",
        "size": "qwen2.5-coder:1.5b-instruct-q5_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q5_K_S",
        "size": "qwen2.5-coder:1.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q5_K_M",
        "size": "qwen2.5-coder:1.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q6_K",
        "size": "qwen2.5-coder:1.5b-instruct-q6_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-q8_0",
        "size": "qwen2.5-coder:1.5b-instruct-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:1.5b-instruct-fp16",
        "size": "qwen2.5-coder:1.5b-instruct-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base",
        "size": "qwen2.5-coder:3b-base",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q2_K",
        "size": "qwen2.5-coder:3b-base-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q3_K_S",
        "size": "qwen2.5-coder:3b-base-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q3_K_M",
        "size": "qwen2.5-coder:3b-base-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q3_K_L",
        "size": "qwen2.5-coder:3b-base-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q4_0",
        "size": "qwen2.5-coder:3b-base-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q4_1",
        "size": "qwen2.5-coder:3b-base-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q4_K_S",
        "size": "qwen2.5-coder:3b-base-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q4_K_M",
        "size": "qwen2.5-coder:3b-base-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q5_0",
        "size": "qwen2.5-coder:3b-base-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q5_1",
        "size": "qwen2.5-coder:3b-base-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q5_K_S",
        "size": "qwen2.5-coder:3b-base-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q5_K_M",
        "size": "qwen2.5-coder:3b-base-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q6_K",
        "size": "qwen2.5-coder:3b-base-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-q8_0",
        "size": "qwen2.5-coder:3b-base-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-base-fp16",
        "size": "qwen2.5-coder:3b-base-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct",
        "size": "qwen2.5-coder:3b-instruct",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q2_K",
        "size": "qwen2.5-coder:3b-instruct-q2_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q3_K_S",
        "size": "qwen2.5-coder:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q3_K_M",
        "size": "qwen2.5-coder:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q3_K_L",
        "size": "qwen2.5-coder:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q4_0",
        "size": "qwen2.5-coder:3b-instruct-q4_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q4_1",
        "size": "qwen2.5-coder:3b-instruct-q4_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q4_K_S",
        "size": "qwen2.5-coder:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q4_K_M",
        "size": "qwen2.5-coder:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q5_0",
        "size": "qwen2.5-coder:3b-instruct-q5_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q5_1",
        "size": "qwen2.5-coder:3b-instruct-q5_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q5_K_S",
        "size": "qwen2.5-coder:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q5_K_M",
        "size": "qwen2.5-coder:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q6_K",
        "size": "qwen2.5-coder:3b-instruct-q6_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-q8_0",
        "size": "qwen2.5-coder:3b-instruct-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:3b-instruct-fp16",
        "size": "qwen2.5-coder:3b-instruct-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base",
        "size": "qwen2.5-coder:7b-base",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q2_K",
        "size": "qwen2.5-coder:7b-base-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q3_K_S",
        "size": "qwen2.5-coder:7b-base-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q3_K_M",
        "size": "qwen2.5-coder:7b-base-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q3_K_L",
        "size": "qwen2.5-coder:7b-base-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q4_0",
        "size": "qwen2.5-coder:7b-base-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q4_1",
        "size": "qwen2.5-coder:7b-base-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q4_K_S",
        "size": "qwen2.5-coder:7b-base-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q4_K_M",
        "size": "qwen2.5-coder:7b-base-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q5_0",
        "size": "qwen2.5-coder:7b-base-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q5_1",
        "size": "qwen2.5-coder:7b-base-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q5_K_S",
        "size": "qwen2.5-coder:7b-base-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q5_K_M",
        "size": "qwen2.5-coder:7b-base-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q6_K",
        "size": "qwen2.5-coder:7b-base-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-q8_0",
        "size": "qwen2.5-coder:7b-base-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-base-fp16",
        "size": "qwen2.5-coder:7b-base-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct",
        "size": "qwen2.5-coder:7b-instruct",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q2_K",
        "size": "qwen2.5-coder:7b-instruct-q2_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q3_K_S",
        "size": "qwen2.5-coder:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q3_K_M",
        "size": "qwen2.5-coder:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q3_K_L",
        "size": "qwen2.5-coder:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q4_0",
        "size": "qwen2.5-coder:7b-instruct-q4_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q4_1",
        "size": "qwen2.5-coder:7b-instruct-q4_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q4_K_S",
        "size": "qwen2.5-coder:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q4_K_M",
        "size": "qwen2.5-coder:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q5_0",
        "size": "qwen2.5-coder:7b-instruct-q5_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q5_1",
        "size": "qwen2.5-coder:7b-instruct-q5_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q5_K_S",
        "size": "qwen2.5-coder:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q5_K_M",
        "size": "qwen2.5-coder:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q6_K",
        "size": "qwen2.5-coder:7b-instruct-q6_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-q8_0",
        "size": "qwen2.5-coder:7b-instruct-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:7b-instruct-fp16",
        "size": "qwen2.5-coder:7b-instruct-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base",
        "size": "qwen2.5-coder:14b-base",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q2_K",
        "size": "qwen2.5-coder:14b-base-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q3_K_S",
        "size": "qwen2.5-coder:14b-base-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q3_K_M",
        "size": "qwen2.5-coder:14b-base-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q3_K_L",
        "size": "qwen2.5-coder:14b-base-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q4_0",
        "size": "qwen2.5-coder:14b-base-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q4_1",
        "size": "qwen2.5-coder:14b-base-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q4_K_S",
        "size": "qwen2.5-coder:14b-base-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q4_K_M",
        "size": "qwen2.5-coder:14b-base-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q5_0",
        "size": "qwen2.5-coder:14b-base-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q5_1",
        "size": "qwen2.5-coder:14b-base-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q5_K_S",
        "size": "qwen2.5-coder:14b-base-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q5_K_M",
        "size": "qwen2.5-coder:14b-base-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q6_K",
        "size": "qwen2.5-coder:14b-base-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-q8_0",
        "size": "qwen2.5-coder:14b-base-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-base-fp16",
        "size": "qwen2.5-coder:14b-base-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct",
        "size": "qwen2.5-coder:14b-instruct",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q2_K",
        "size": "qwen2.5-coder:14b-instruct-q2_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q3_K_S",
        "size": "qwen2.5-coder:14b-instruct-q3_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q3_K_M",
        "size": "qwen2.5-coder:14b-instruct-q3_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q3_K_L",
        "size": "qwen2.5-coder:14b-instruct-q3_K_L",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q4_0",
        "size": "qwen2.5-coder:14b-instruct-q4_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q4_1",
        "size": "qwen2.5-coder:14b-instruct-q4_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q4_K_S",
        "size": "qwen2.5-coder:14b-instruct-q4_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q4_K_M",
        "size": "qwen2.5-coder:14b-instruct-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q5_0",
        "size": "qwen2.5-coder:14b-instruct-q5_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q5_1",
        "size": "qwen2.5-coder:14b-instruct-q5_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q5_K_S",
        "size": "qwen2.5-coder:14b-instruct-q5_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q5_K_M",
        "size": "qwen2.5-coder:14b-instruct-q5_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q6_K",
        "size": "qwen2.5-coder:14b-instruct-q6_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-q8_0",
        "size": "qwen2.5-coder:14b-instruct-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:14b-instruct-fp16",
        "size": "qwen2.5-coder:14b-instruct-fp16",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base",
        "size": "qwen2.5-coder:32b-base",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q2_K",
        "size": "qwen2.5-coder:32b-base-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q3_K_S",
        "size": "qwen2.5-coder:32b-base-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q3_K_M",
        "size": "qwen2.5-coder:32b-base-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q3_K_L",
        "size": "qwen2.5-coder:32b-base-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q4_0",
        "size": "qwen2.5-coder:32b-base-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q4_1",
        "size": "qwen2.5-coder:32b-base-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q4_K_S",
        "size": "qwen2.5-coder:32b-base-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q4_K_M",
        "size": "qwen2.5-coder:32b-base-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q5_0",
        "size": "qwen2.5-coder:32b-base-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q5_1",
        "size": "qwen2.5-coder:32b-base-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q5_K_S",
        "size": "qwen2.5-coder:32b-base-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q5_K_M",
        "size": "qwen2.5-coder:32b-base-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q6_K",
        "size": "qwen2.5-coder:32b-base-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-q8_0",
        "size": "qwen2.5-coder:32b-base-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-base-fp16",
        "size": "qwen2.5-coder:32b-base-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct",
        "size": "qwen2.5-coder:32b-instruct",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q2_K",
        "size": "qwen2.5-coder:32b-instruct-q2_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q3_K_S",
        "size": "qwen2.5-coder:32b-instruct-q3_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q3_K_M",
        "size": "qwen2.5-coder:32b-instruct-q3_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q3_K_L",
        "size": "qwen2.5-coder:32b-instruct-q3_K_L",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q4_0",
        "size": "qwen2.5-coder:32b-instruct-q4_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q4_1",
        "size": "qwen2.5-coder:32b-instruct-q4_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q4_K_S",
        "size": "qwen2.5-coder:32b-instruct-q4_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q4_K_M",
        "size": "qwen2.5-coder:32b-instruct-q4_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q5_0",
        "size": "qwen2.5-coder:32b-instruct-q5_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q5_1",
        "size": "qwen2.5-coder:32b-instruct-q5_1",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q5_K_S",
        "size": "qwen2.5-coder:32b-instruct-q5_K_S",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q5_K_M",
        "size": "qwen2.5-coder:32b-instruct-q5_K_M",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q6_K",
        "size": "qwen2.5-coder:32b-instruct-q6_K",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-q8_0",
        "size": "qwen2.5-coder:32b-instruct-q8_0",
        "updated": "Text input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5-coder:32b-instruct-fp16",
        "size": "qwen2.5-coder:32b-instruct-fp16",
        "updated": "Text input • \n                    3 months ago"
      }
    ]
  },
  {
    "name": "gemma",
    "link": "https://ollama.com/library/gemma",
    "description": "Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.1",
    "pullCount": "5.3M",
    "updated": "1 year ago",
    "size": [
      "2b",
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/01333db3-c27b-4044-88b3-9b2ffbe06415)\n\n> Note: this model requires Ollama 0.1.26 or later. [Download it here](https://ollama.com/download).\n\nGemma is a new open model developed by Google and its DeepMind team. It’s inspired by Gemini models at Google.\n\nGemma is available in both `2b` and `7b` parameter sizes:\n\n* `ollama run gemma:2b`\n* `ollama run gemma:7b` (default)\n\nThe models undergo training on a diverse dataset of web documents to expose them to a wide range of linguistic styles, topics, and vocabularies. This includes code to learn syntax and patterns of programming languages, as well as mathematical text to grasp logical reasoning.\n\nTo ensure the safety of the model, the team employed various data cleaning and filtering techniques, including rigorous filtering for CSAM (child sexual abuse material), sensitive data filtering, and filtering based on content quality in compliance with Google’s policies.\n\n# Reference\n\n[Google Gemma](https://ai.google.dev/gemma/docs/model%5Fcard)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/01333db3-c27b-4044-88b3-9b2ffbe06415\"/> > Note: this model requires Ollama 0.1.26 or later. \\[Download it here\\](https://ollama.com/download). Gemma is a new open model developed by Google and its DeepMind team. It’s inspired by Gemini models at Google. Gemma is available in both \\`2b\\` and \\`7b\\` parameter sizes: \\* \\`ollama run gemma:2b\\` \\* \\`ollama run gemma:7b\\` (default) The models undergo training on a diverse dataset of web documents to expose them to a wide range of linguistic styles, topics, and vocabularies. This includes code to learn syntax and patterns of programming languages, as well as mathematical text to grasp logical reasoning. To ensure the safety of the model, the team employed various data cleaning and filtering techniques, including rigorous filtering for CSAM (child sexual abuse material), sensitive data filtering, and filtering based on content quality in compliance with Google’s policies. # Reference \\[Google Gemma\\](https://ai.google.dev/gemma/docs/model\\_card) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "gemma:latest",
        "size": "gemma:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:instruct",
        "size": "gemma:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:text",
        "size": "gemma:text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:v1.1",
        "size": "gemma:v1.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b",
        "size": "gemma:2b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b",
        "size": "gemma:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct",
        "size": "gemma:2b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q2_K",
        "size": "gemma:2b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q2_K",
        "size": "gemma:2b-instruct-v1.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q3_K_S",
        "size": "gemma:2b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q3_K_S",
        "size": "gemma:2b-instruct-v1.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q3_K_M",
        "size": "gemma:2b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q3_K_M",
        "size": "gemma:2b-instruct-v1.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q3_K_L",
        "size": "gemma:2b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q3_K_L",
        "size": "gemma:2b-instruct-v1.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q4_0",
        "size": "gemma:2b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q4_0",
        "size": "gemma:2b-instruct-v1.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q4_1",
        "size": "gemma:2b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q4_1",
        "size": "gemma:2b-instruct-v1.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q4_K_S",
        "size": "gemma:2b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q4_K_S",
        "size": "gemma:2b-instruct-v1.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q4_K_M",
        "size": "gemma:2b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q4_K_M",
        "size": "gemma:2b-instruct-v1.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q5_0",
        "size": "gemma:2b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q5_0",
        "size": "gemma:2b-instruct-v1.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q5_1",
        "size": "gemma:2b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q5_1",
        "size": "gemma:2b-instruct-v1.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q5_K_S",
        "size": "gemma:2b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q5_K_S",
        "size": "gemma:2b-instruct-v1.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q5_K_M",
        "size": "gemma:2b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q5_K_M",
        "size": "gemma:2b-instruct-v1.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q6_K",
        "size": "gemma:2b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q6_K",
        "size": "gemma:2b-instruct-v1.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-q8_0",
        "size": "gemma:2b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-q8_0",
        "size": "gemma:2b-instruct-v1.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-fp16",
        "size": "gemma:2b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-instruct-v1.1-fp16",
        "size": "gemma:2b-instruct-v1.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text",
        "size": "gemma:2b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q2_K",
        "size": "gemma:2b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q3_K_S",
        "size": "gemma:2b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q3_K_M",
        "size": "gemma:2b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q3_K_L",
        "size": "gemma:2b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q4_0",
        "size": "gemma:2b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q4_1",
        "size": "gemma:2b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q4_K_S",
        "size": "gemma:2b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q4_K_M",
        "size": "gemma:2b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q5_0",
        "size": "gemma:2b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q5_1",
        "size": "gemma:2b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q5_K_S",
        "size": "gemma:2b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q5_K_M",
        "size": "gemma:2b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q6_K",
        "size": "gemma:2b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-q8_0",
        "size": "gemma:2b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-text-fp16",
        "size": "gemma:2b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:2b-v1.1",
        "size": "gemma:2b-v1.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct",
        "size": "gemma:7b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q2_K",
        "size": "gemma:7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q2_K",
        "size": "gemma:7b-instruct-v1.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q3_K_S",
        "size": "gemma:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q3_K_S",
        "size": "gemma:7b-instruct-v1.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q3_K_M",
        "size": "gemma:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q3_K_M",
        "size": "gemma:7b-instruct-v1.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q3_K_L",
        "size": "gemma:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q3_K_L",
        "size": "gemma:7b-instruct-v1.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q4_0",
        "size": "gemma:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q4_0",
        "size": "gemma:7b-instruct-v1.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q4_1",
        "size": "gemma:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q4_1",
        "size": "gemma:7b-instruct-v1.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q4_K_S",
        "size": "gemma:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q4_K_S",
        "size": "gemma:7b-instruct-v1.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q4_K_M",
        "size": "gemma:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q4_K_M",
        "size": "gemma:7b-instruct-v1.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q5_0",
        "size": "gemma:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q5_0",
        "size": "gemma:7b-instruct-v1.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q5_1",
        "size": "gemma:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q5_1",
        "size": "gemma:7b-instruct-v1.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q5_K_S",
        "size": "gemma:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q5_K_S",
        "size": "gemma:7b-instruct-v1.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q5_K_M",
        "size": "gemma:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q5_K_M",
        "size": "gemma:7b-instruct-v1.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q6_K",
        "size": "gemma:7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q6_K",
        "size": "gemma:7b-instruct-v1.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-q8_0",
        "size": "gemma:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-q8_0",
        "size": "gemma:7b-instruct-v1.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-fp16",
        "size": "gemma:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-instruct-v1.1-fp16",
        "size": "gemma:7b-instruct-v1.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text",
        "size": "gemma:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q2_K",
        "size": "gemma:7b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q3_K_S",
        "size": "gemma:7b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q3_K_M",
        "size": "gemma:7b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q3_K_L",
        "size": "gemma:7b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q4_0",
        "size": "gemma:7b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q4_1",
        "size": "gemma:7b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q4_K_S",
        "size": "gemma:7b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q4_K_M",
        "size": "gemma:7b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q5_0",
        "size": "gemma:7b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q5_1",
        "size": "gemma:7b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q5_K_S",
        "size": "gemma:7b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q5_K_M",
        "size": "gemma:7b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q6_K",
        "size": "gemma:7b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-q8_0",
        "size": "gemma:7b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-text-fp16",
        "size": "gemma:7b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "gemma:7b-v1.1",
        "size": "gemma:7b-v1.1",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "qwen",
    "link": "https://ollama.com/library/qwen",
    "description": "Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters",
    "pullCount": "4.9M",
    "updated": "1 year ago",
    "size": [
      "0.5b",
      "1.8b",
      "4b",
      "7b",
      "14b",
      "32b",
      "72b",
      "110b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nQwen 2 is now available [here](https://ollama.com/library/qwen2).\n\n![](https://github.com/jmorganca/ollama/assets/251292/160726a3-a986-427d-b1df-3b75357903a4)\n\nQwen is a series of transformer-based large language models by Alibaba Cloud, pre-trained on a large volume of data, including web texts, books, code, etc.\n\n### New in Qwen 1.5\n\n* 6 model sizes, including 0.5B, 1.8B, 4B (default), 7B, 14B, 32B (new) and 72B  \n   * `ollama run qwen:0.5b`  \n   * `ollama run qwen:1.8b`  \n   * `ollama run qwen:4b`  \n   * `ollama run qwen:7b`  \n   * `ollama run qwen:14b`  \n   * `ollama run qwen:32b`  \n   * `ollama run qwen:72b`  \n   * `ollama run qwen:110b`\n* Significant performance improvement in human preference for chat models\n* Multilingual support of both base and chat models\n* Stable support of 32K context length for models of all sizes\n\nThe original Qwen model is offered in four different parameter sizes: 1.8B, 7B, 14B, and 72B.\n\n## Features\n\n* **Low-cost deployment**: the minimum memory requirement for inference is less than 2GB.\n* **Large-scale high-quality training corpora**: Models are pre-trained on over 2.2 trillion tokens, including Chinese, English, multilingual texts, code, and mathematics, covering general and professional fields. The distribution of the pre-training corpus has been optimized through a large number of ablation experiments.\n* **Good performance**: Qwen supports long context lengths (8K on the `1.8b`, `7b` and `14b` parameter models, and 32K on the `72b` parameter model), and significantly surpasses existing open-source models of similar scale on multiple Chinese and English downstream evaluation tasks (including common-sense, reasoning, code, mathematics, etc.), and even surpasses some larger-scale models in several benchmarks.\n* **More comprehensive vocabulary coverage**: Compared with other open-source models based on Chinese and English vocabularies, Qwen uses a vocabulary of over 150K tokens. This vocabulary is more friendly to multiple languages, enabling users to directly further enhance the capability for certain languages without expanding the vocabulary.\n* **System prompt**: Qwen can realize role playing, language style transfer, task setting, and behavior-setting by using a system prompt.\n\n## Reference\n\n[GitHub](https://github.com/QwenLM/Qwen)\n\n[Hugging Face](https://huggingface.co/Qwen)\n\nWrite Preview \n\nQwen 2 is now available \\[here\\](https://ollama.com/library/qwen2). <img src=\"https://github.com/jmorganca/ollama/assets/251292/160726a3-a986-427d-b1df-3b75357903a4\" width=\"280\" /> Qwen is a series of transformer-based large language models by Alibaba Cloud, pre-trained on a large volume of data, including web texts, books, code, etc. ### New in Qwen 1.5 - 6 model sizes, including 0.5B, 1.8B, 4B (default), 7B, 14B, 32B (new) and 72B \\* \\`ollama run qwen:0.5b\\` \\* \\`ollama run qwen:1.8b\\` \\* \\`ollama run qwen:4b\\` \\* \\`ollama run qwen:7b\\` \\* \\`ollama run qwen:14b\\` \\* \\`ollama run qwen:32b\\` \\* \\`ollama run qwen:72b\\` \\* \\`ollama run qwen:110b\\` - Significant performance improvement in human preference for chat models - Multilingual support of both base and chat models - Stable support of 32K context length for models of all sizes The original Qwen model is offered in four different parameter sizes: 1.8B, 7B, 14B, and 72B. ## Features \\* \\*\\*Low-cost deployment\\*\\*: the minimum memory requirement for inference is less than 2GB. \\* \\*\\*Large-scale high-quality training corpora\\*\\*: Models are pre-trained on over 2.2 trillion tokens, including Chinese, English, multilingual texts, code, and mathematics, covering general and professional fields. The distribution of the pre-training corpus has been optimized through a large number of ablation experiments. \\* \\*\\*Good performance\\*\\*: Qwen supports long context lengths (8K on the \\`1.8b\\`, \\`7b\\` and \\`14b\\` parameter models, and 32K on the \\`72b\\` parameter model), and significantly surpasses existing open-source models of similar scale on multiple Chinese and English downstream evaluation tasks (including common-sense, reasoning, code, mathematics, etc.), and even surpasses some larger-scale models in several benchmarks. \\* \\*\\*More comprehensive vocabulary coverage\\*\\*: Compared with other open-source models based on Chinese and English vocabularies, Qwen uses a vocabulary of over 150K tokens. This vocabulary is more friendly to multiple languages, enabling users to directly further enhance the capability for certain languages without expanding the vocabulary. \\* \\*\\*System prompt\\*\\*: Qwen can realize role playing, language style transfer, task setting, and behavior-setting by using a system prompt. ## Reference \\[GitHub\\](https://github.com/QwenLM/Qwen) \\[Hugging Face\\](https://huggingface.co/Qwen) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen:latest",
        "size": "qwen:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b",
        "size": "qwen:0.5b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b",
        "size": "qwen:1.8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b",
        "size": "qwen:4b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b",
        "size": "qwen:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b",
        "size": "qwen:14b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b",
        "size": "qwen:32b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b",
        "size": "qwen:72b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b",
        "size": "qwen:110b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat",
        "size": "qwen:0.5b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q2_K",
        "size": "qwen:0.5b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q3_K_S",
        "size": "qwen:0.5b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q3_K_M",
        "size": "qwen:0.5b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q3_K_L",
        "size": "qwen:0.5b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q4_0",
        "size": "qwen:0.5b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q4_1",
        "size": "qwen:0.5b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q4_K_S",
        "size": "qwen:0.5b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q4_K_M",
        "size": "qwen:0.5b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q5_0",
        "size": "qwen:0.5b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q5_1",
        "size": "qwen:0.5b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q5_K_S",
        "size": "qwen:0.5b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q5_K_M",
        "size": "qwen:0.5b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q6_K",
        "size": "qwen:0.5b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-q8_0",
        "size": "qwen:0.5b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-chat-v1.5-fp16",
        "size": "qwen:0.5b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text",
        "size": "qwen:0.5b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q2_K",
        "size": "qwen:0.5b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q3_K_S",
        "size": "qwen:0.5b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q3_K_M",
        "size": "qwen:0.5b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q3_K_L",
        "size": "qwen:0.5b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q4_0",
        "size": "qwen:0.5b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q4_1",
        "size": "qwen:0.5b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q4_K_S",
        "size": "qwen:0.5b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q4_K_M",
        "size": "qwen:0.5b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q5_0",
        "size": "qwen:0.5b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q5_1",
        "size": "qwen:0.5b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q5_K_S",
        "size": "qwen:0.5b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q5_K_M",
        "size": "qwen:0.5b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q6_K",
        "size": "qwen:0.5b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-q8_0",
        "size": "qwen:0.5b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:0.5b-text-v1.5-fp16",
        "size": "qwen:0.5b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat",
        "size": "qwen:1.8b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q2_K",
        "size": "qwen:1.8b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q2_K",
        "size": "qwen:1.8b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q3_K_S",
        "size": "qwen:1.8b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q3_K_S",
        "size": "qwen:1.8b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q3_K_M",
        "size": "qwen:1.8b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q3_K_M",
        "size": "qwen:1.8b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q3_K_L",
        "size": "qwen:1.8b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q3_K_L",
        "size": "qwen:1.8b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q4_0",
        "size": "qwen:1.8b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q4_0",
        "size": "qwen:1.8b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q4_1",
        "size": "qwen:1.8b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q4_1",
        "size": "qwen:1.8b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q4_K_S",
        "size": "qwen:1.8b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q4_K_S",
        "size": "qwen:1.8b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q4_K_M",
        "size": "qwen:1.8b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q4_K_M",
        "size": "qwen:1.8b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q5_0",
        "size": "qwen:1.8b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q5_0",
        "size": "qwen:1.8b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q5_1",
        "size": "qwen:1.8b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q5_1",
        "size": "qwen:1.8b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q5_K_S",
        "size": "qwen:1.8b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q5_K_S",
        "size": "qwen:1.8b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q5_K_M",
        "size": "qwen:1.8b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q5_K_M",
        "size": "qwen:1.8b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q6_K",
        "size": "qwen:1.8b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q6_K",
        "size": "qwen:1.8b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-q8_0",
        "size": "qwen:1.8b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-q8_0",
        "size": "qwen:1.8b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-fp16",
        "size": "qwen:1.8b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-chat-v1.5-fp16",
        "size": "qwen:1.8b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text",
        "size": "qwen:1.8b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q2_K",
        "size": "qwen:1.8b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q2_K",
        "size": "qwen:1.8b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q3_K_S",
        "size": "qwen:1.8b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q3_K_S",
        "size": "qwen:1.8b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q3_K_M",
        "size": "qwen:1.8b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q3_K_M",
        "size": "qwen:1.8b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q3_K_L",
        "size": "qwen:1.8b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q3_K_L",
        "size": "qwen:1.8b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q4_0",
        "size": "qwen:1.8b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q4_0",
        "size": "qwen:1.8b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q4_1",
        "size": "qwen:1.8b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q4_1",
        "size": "qwen:1.8b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q4_K_S",
        "size": "qwen:1.8b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q4_K_S",
        "size": "qwen:1.8b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q4_K_M",
        "size": "qwen:1.8b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q4_K_M",
        "size": "qwen:1.8b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q5_0",
        "size": "qwen:1.8b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q5_0",
        "size": "qwen:1.8b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q5_1",
        "size": "qwen:1.8b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q5_1",
        "size": "qwen:1.8b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q5_K_S",
        "size": "qwen:1.8b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q5_K_S",
        "size": "qwen:1.8b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q5_K_M",
        "size": "qwen:1.8b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q5_K_M",
        "size": "qwen:1.8b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q6_K",
        "size": "qwen:1.8b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q6_K",
        "size": "qwen:1.8b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-q8_0",
        "size": "qwen:1.8b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-q8_0",
        "size": "qwen:1.8b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-fp16",
        "size": "qwen:1.8b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:1.8b-text-v1.5-fp16",
        "size": "qwen:1.8b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat",
        "size": "qwen:4b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q2_K",
        "size": "qwen:4b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q3_K_S",
        "size": "qwen:4b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q3_K_M",
        "size": "qwen:4b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q3_K_L",
        "size": "qwen:4b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q4_0",
        "size": "qwen:4b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q4_1",
        "size": "qwen:4b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q4_K_S",
        "size": "qwen:4b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q4_K_M",
        "size": "qwen:4b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q5_0",
        "size": "qwen:4b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q5_1",
        "size": "qwen:4b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q5_K_S",
        "size": "qwen:4b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q5_K_M",
        "size": "qwen:4b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q6_K",
        "size": "qwen:4b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-q8_0",
        "size": "qwen:4b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-chat-v1.5-fp16",
        "size": "qwen:4b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text",
        "size": "qwen:4b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q2_K",
        "size": "qwen:4b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q3_K_S",
        "size": "qwen:4b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q3_K_M",
        "size": "qwen:4b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q3_K_L",
        "size": "qwen:4b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q4_0",
        "size": "qwen:4b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q4_1",
        "size": "qwen:4b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q4_K_S",
        "size": "qwen:4b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q4_K_M",
        "size": "qwen:4b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q5_0",
        "size": "qwen:4b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q5_1",
        "size": "qwen:4b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q5_K_S",
        "size": "qwen:4b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q5_K_M",
        "size": "qwen:4b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q6_K",
        "size": "qwen:4b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-q8_0",
        "size": "qwen:4b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:4b-text-v1.5-fp16",
        "size": "qwen:4b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat",
        "size": "qwen:7b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q2_K",
        "size": "qwen:7b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q2_K",
        "size": "qwen:7b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q3_K_S",
        "size": "qwen:7b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q3_K_S",
        "size": "qwen:7b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q3_K_M",
        "size": "qwen:7b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q3_K_M",
        "size": "qwen:7b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q3_K_L",
        "size": "qwen:7b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q3_K_L",
        "size": "qwen:7b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q4_0",
        "size": "qwen:7b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q4_0",
        "size": "qwen:7b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q4_1",
        "size": "qwen:7b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q4_1",
        "size": "qwen:7b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q4_K_S",
        "size": "qwen:7b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q4_K_S",
        "size": "qwen:7b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q4_K_M",
        "size": "qwen:7b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q4_K_M",
        "size": "qwen:7b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q5_0",
        "size": "qwen:7b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q5_0",
        "size": "qwen:7b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q5_1",
        "size": "qwen:7b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q5_1",
        "size": "qwen:7b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q5_K_S",
        "size": "qwen:7b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q5_K_S",
        "size": "qwen:7b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q5_K_M",
        "size": "qwen:7b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q5_K_M",
        "size": "qwen:7b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q6_K",
        "size": "qwen:7b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q6_K",
        "size": "qwen:7b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-q8_0",
        "size": "qwen:7b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-q8_0",
        "size": "qwen:7b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-fp16",
        "size": "qwen:7b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-chat-v1.5-fp16",
        "size": "qwen:7b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text",
        "size": "qwen:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q2_K",
        "size": "qwen:7b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q3_K_S",
        "size": "qwen:7b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q3_K_M",
        "size": "qwen:7b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q3_K_L",
        "size": "qwen:7b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q4_0",
        "size": "qwen:7b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q4_1",
        "size": "qwen:7b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q4_K_S",
        "size": "qwen:7b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q4_K_M",
        "size": "qwen:7b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q5_0",
        "size": "qwen:7b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q5_1",
        "size": "qwen:7b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q5_K_S",
        "size": "qwen:7b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q5_K_M",
        "size": "qwen:7b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q6_K",
        "size": "qwen:7b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-q8_0",
        "size": "qwen:7b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-text-v1.5-fp16",
        "size": "qwen:7b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q2_K",
        "size": "qwen:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q3_K_S",
        "size": "qwen:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q3_K_M",
        "size": "qwen:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q3_K_L",
        "size": "qwen:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q4_0",
        "size": "qwen:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q4_1",
        "size": "qwen:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q4_K_S",
        "size": "qwen:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q4_K_M",
        "size": "qwen:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q5_0",
        "size": "qwen:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q5_1",
        "size": "qwen:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q5_K_S",
        "size": "qwen:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q5_K_M",
        "size": "qwen:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q6_K",
        "size": "qwen:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-q8_0",
        "size": "qwen:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:7b-fp16",
        "size": "qwen:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat",
        "size": "qwen:14b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q2_K",
        "size": "qwen:14b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q2_K",
        "size": "qwen:14b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q3_K_S",
        "size": "qwen:14b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q3_K_S",
        "size": "qwen:14b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q3_K_M",
        "size": "qwen:14b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q3_K_M",
        "size": "qwen:14b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q3_K_L",
        "size": "qwen:14b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q3_K_L",
        "size": "qwen:14b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q4_0",
        "size": "qwen:14b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q4_0",
        "size": "qwen:14b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q4_1",
        "size": "qwen:14b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q4_1",
        "size": "qwen:14b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q4_K_S",
        "size": "qwen:14b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q4_K_S",
        "size": "qwen:14b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q4_K_M",
        "size": "qwen:14b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q4_K_M",
        "size": "qwen:14b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q5_0",
        "size": "qwen:14b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q5_0",
        "size": "qwen:14b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q5_1",
        "size": "qwen:14b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q5_1",
        "size": "qwen:14b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q5_K_S",
        "size": "qwen:14b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q5_K_S",
        "size": "qwen:14b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q5_K_M",
        "size": "qwen:14b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q5_K_M",
        "size": "qwen:14b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q6_K",
        "size": "qwen:14b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q6_K",
        "size": "qwen:14b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-q8_0",
        "size": "qwen:14b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-q8_0",
        "size": "qwen:14b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-fp16",
        "size": "qwen:14b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-chat-v1.5-fp16",
        "size": "qwen:14b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text",
        "size": "qwen:14b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q2_K",
        "size": "qwen:14b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q2_K",
        "size": "qwen:14b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q3_K_S",
        "size": "qwen:14b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q3_K_S",
        "size": "qwen:14b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q3_K_M",
        "size": "qwen:14b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q3_K_M",
        "size": "qwen:14b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q3_K_L",
        "size": "qwen:14b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q3_K_L",
        "size": "qwen:14b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q4_0",
        "size": "qwen:14b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q4_0",
        "size": "qwen:14b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q4_1",
        "size": "qwen:14b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q4_1",
        "size": "qwen:14b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q4_K_S",
        "size": "qwen:14b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q4_K_S",
        "size": "qwen:14b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q4_K_M",
        "size": "qwen:14b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q4_K_M",
        "size": "qwen:14b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q5_0",
        "size": "qwen:14b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q5_0",
        "size": "qwen:14b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q5_1",
        "size": "qwen:14b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q5_1",
        "size": "qwen:14b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q5_K_S",
        "size": "qwen:14b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q5_K_S",
        "size": "qwen:14b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q5_K_M",
        "size": "qwen:14b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q5_K_M",
        "size": "qwen:14b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q6_K",
        "size": "qwen:14b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q6_K",
        "size": "qwen:14b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-q8_0",
        "size": "qwen:14b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-q8_0",
        "size": "qwen:14b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-fp16",
        "size": "qwen:14b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:14b-text-v1.5-fp16",
        "size": "qwen:14b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat",
        "size": "qwen:32b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q2_K",
        "size": "qwen:32b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q3_K_S",
        "size": "qwen:32b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q3_K_M",
        "size": "qwen:32b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q3_K_L",
        "size": "qwen:32b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q4_0",
        "size": "qwen:32b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q4_1",
        "size": "qwen:32b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q4_K_S",
        "size": "qwen:32b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q4_K_M",
        "size": "qwen:32b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q5_0",
        "size": "qwen:32b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q5_1",
        "size": "qwen:32b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q5_K_S",
        "size": "qwen:32b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q5_K_M",
        "size": "qwen:32b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q6_K",
        "size": "qwen:32b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-q8_0",
        "size": "qwen:32b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-chat-v1.5-fp16",
        "size": "qwen:32b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text",
        "size": "qwen:32b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q2_K",
        "size": "qwen:32b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q3_K_S",
        "size": "qwen:32b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q3_K_M",
        "size": "qwen:32b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q3_K_L",
        "size": "qwen:32b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q4_0",
        "size": "qwen:32b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q4_1",
        "size": "qwen:32b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q4_K_S",
        "size": "qwen:32b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q5_0",
        "size": "qwen:32b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q5_1",
        "size": "qwen:32b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:32b-text-v1.5-q8_0",
        "size": "qwen:32b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat",
        "size": "qwen:72b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q2_K",
        "size": "qwen:72b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q2_K",
        "size": "qwen:72b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q3_K_S",
        "size": "qwen:72b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q3_K_S",
        "size": "qwen:72b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q3_K_M",
        "size": "qwen:72b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q3_K_M",
        "size": "qwen:72b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q3_K_L",
        "size": "qwen:72b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q3_K_L",
        "size": "qwen:72b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q4_0",
        "size": "qwen:72b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q4_0",
        "size": "qwen:72b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q4_1",
        "size": "qwen:72b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q4_1",
        "size": "qwen:72b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q4_K_S",
        "size": "qwen:72b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q4_K_S",
        "size": "qwen:72b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q4_K_M",
        "size": "qwen:72b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q4_K_M",
        "size": "qwen:72b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q5_0",
        "size": "qwen:72b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q5_0",
        "size": "qwen:72b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q5_1",
        "size": "qwen:72b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q5_1",
        "size": "qwen:72b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q5_K_S",
        "size": "qwen:72b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q5_K_S",
        "size": "qwen:72b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q5_K_M",
        "size": "qwen:72b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q5_K_M",
        "size": "qwen:72b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q6_K",
        "size": "qwen:72b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q6_K",
        "size": "qwen:72b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-q8_0",
        "size": "qwen:72b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-q8_0",
        "size": "qwen:72b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-fp16",
        "size": "qwen:72b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-chat-v1.5-fp16",
        "size": "qwen:72b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text",
        "size": "qwen:72b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q2_K",
        "size": "qwen:72b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q2_K",
        "size": "qwen:72b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q3_K_S",
        "size": "qwen:72b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q3_K_S",
        "size": "qwen:72b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q3_K_M",
        "size": "qwen:72b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q3_K_M",
        "size": "qwen:72b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q3_K_L",
        "size": "qwen:72b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q3_K_L",
        "size": "qwen:72b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q4_0",
        "size": "qwen:72b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q4_0",
        "size": "qwen:72b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q4_1",
        "size": "qwen:72b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q4_1",
        "size": "qwen:72b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q4_K_S",
        "size": "qwen:72b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q4_K_S",
        "size": "qwen:72b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q4_K_M",
        "size": "qwen:72b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q4_K_M",
        "size": "qwen:72b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q5_0",
        "size": "qwen:72b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q5_0",
        "size": "qwen:72b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q5_1",
        "size": "qwen:72b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q5_1",
        "size": "qwen:72b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q5_K_S",
        "size": "qwen:72b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q5_K_S",
        "size": "qwen:72b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q5_K_M",
        "size": "qwen:72b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q5_K_M",
        "size": "qwen:72b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q6_K",
        "size": "qwen:72b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q6_K",
        "size": "qwen:72b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-q8_0",
        "size": "qwen:72b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-q8_0",
        "size": "qwen:72b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-fp16",
        "size": "qwen:72b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:72b-text-v1.5-fp16",
        "size": "qwen:72b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat",
        "size": "qwen:110b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q2_K",
        "size": "qwen:110b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q3_K_S",
        "size": "qwen:110b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q3_K_M",
        "size": "qwen:110b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q3_K_L",
        "size": "qwen:110b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q4_0",
        "size": "qwen:110b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q4_1",
        "size": "qwen:110b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q4_K_S",
        "size": "qwen:110b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q4_K_M",
        "size": "qwen:110b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q5_0",
        "size": "qwen:110b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q5_1",
        "size": "qwen:110b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q5_K_S",
        "size": "qwen:110b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q5_K_M",
        "size": "qwen:110b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q6_K",
        "size": "qwen:110b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-q8_0",
        "size": "qwen:110b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-chat-v1.5-fp16",
        "size": "qwen:110b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q2_K",
        "size": "qwen:110b-text-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q3_K_S",
        "size": "qwen:110b-text-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q3_K_M",
        "size": "qwen:110b-text-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q3_K_L",
        "size": "qwen:110b-text-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q4_0",
        "size": "qwen:110b-text-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q4_1",
        "size": "qwen:110b-text-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q4_K_S",
        "size": "qwen:110b-text-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q4_K_M",
        "size": "qwen:110b-text-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q5_0",
        "size": "qwen:110b-text-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q5_1",
        "size": "qwen:110b-text-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q5_K_S",
        "size": "qwen:110b-text-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q5_K_M",
        "size": "qwen:110b-text-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q6_K",
        "size": "qwen:110b-text-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-q8_0",
        "size": "qwen:110b-text-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen:110b-text-v1.5-fp16",
        "size": "qwen:110b-text-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "mxbai-embed-large",
    "link": "https://ollama.com/library/mxbai-embed-large",
    "description": "State-of-the-art large embedding model from mixedbread.ai",
    "pullCount": "4.8M",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\n## mxbai-embed-large\n\n![](https://github.com/ollama/ollama/assets/251292/215cfb6a-8efa-4e9b-824d-e5f466b58c49)\n\nAs of March 2024, this model archives SOTA performance for Bert-large sized models on the MTEB. It outperforms commercial models like OpenAIs `text-embedding-3-large` model and matches the performance of model 20x its size.\n\n`mxbai-embed-large` was trained with no overlap of the MTEB data, which indicates that the model generalizes well across several domains, tasks and text length.\n\n## Usage\n\n### REST API\n\n```\ncurl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"mxbai-embed-large\",\n  \"prompt\": \"Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering\"\n}'\n\n```\n\n### Python library\n\n```\nollama.embeddings(model='mxbai-embed-large', prompt='Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering')\n\n```\n\n### Javascript library\n\n```\nollama.embeddings({ model: 'mxbai-embed-large', prompt: 'Represent this sentence for searching relevant passages:  The sky is blue because of Rayleigh scattering' })\n\n```\n\n## References\n\n[Blog post](https://www.mixedbread.ai/blog/mxbai-embed-large-v1)\n\n[Hugging Face](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1)\n\nWrite Preview \n\n\\## mxbai-embed-large <img src=\"https://github.com/ollama/ollama/assets/251292/215cfb6a-8efa-4e9b-824d-e5f466b58c49\" widht=\"400\"> As of March 2024, this model archives SOTA performance for Bert-large sized models on the MTEB. It outperforms commercial models like OpenAIs \\`text-embedding-3-large\\` model and matches the performance of model 20x its size. \\`mxbai-embed-large\\` was trained with no overlap of the MTEB data, which indicates that the model generalizes well across several domains, tasks and text length. ## Usage ### REST API \\`\\`\\` curl http://localhost:11434/api/embeddings -d '{ \"model\": \"mxbai-embed-large\", \"prompt\": \"Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering\" }' \\`\\`\\` ### Python library \\`\\`\\` ollama.embeddings(model='mxbai-embed-large', prompt='Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering') \\`\\`\\` ### Javascript library \\`\\`\\` ollama.embeddings({ model: 'mxbai-embed-large', prompt: 'Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering' }) \\`\\`\\` ## References \\[Blog post\\](https://www.mixedbread.ai/blog/mxbai-embed-large-v1) \\[Hugging Face\\](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mxbai-embed-large:latest",
        "size": "mxbai-embed-large:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mxbai-embed-large:v1",
        "size": "mxbai-embed-large:v1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mxbai-embed-large:335m",
        "size": "mxbai-embed-large:335m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mxbai-embed-large:335m-v1-fp16",
        "size": "mxbai-embed-large:335m-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "phi4",
    "link": "https://ollama.com/library/phi4",
    "description": "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft.",
    "pullCount": "4.4M",
    "updated": "8 months ago",
    "size": [
      "14b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/phi3.5/dbf19a17-e3fd-46b6-a059-e6b4f1fae59f)\n\n**Phi-4** is a 14B parameter, state-of-the-art open model built upon a blend of synthetic datasets, data from filtered public domain websites, and acquired academic books and Q&A datasets.\n\n![Phi-4 benchmark](/assets/library/phi4/67391ae2-e565-4173-ac3c-5e49bc977ac4)\n\nThe model underwent a rigorous enhancement and alignment process, incorporating both supervised fine-tuning and direct preference optimization to ensure precise instruction adherence and robust safety measures.\n\n**Context length:** 16k tokens\n\n![Phi-4 performance eval by Microsoft](/assets/library/phi4/5da7d0b6-53df-42f9-9c1b-651bfc380cdd)\n\n### Primary use cases\n\nThe model is designed to accelerate research on language models, for use as a building block for generative AI powered features. It provides uses for general purpose AI systems and applications (primarily in English) which require:\n\n1. Memory/compute constrained environments.\n2. Latency bound scenarios.\n3. Reasoning and logic.\n\n### Out-of-scope use cases\n\nThe models are not specifically designed or evaluated for all downstream purposes, thus:\n\n1. Developers should consider common limitations of language models as they select use cases, and evaluate and mitigate for accuracy, safety, and fairness before using within a specific downstream use case, particularly for high-risk scenarios.\n2. Developers should be aware of and adhere to applicable laws or regulations (including privacy, trade compliance laws, etc.) that are relevant to their use case, including the model’s focus on English.\n3. Nothing contained in this readme should be interpreted as or deemed a restriction or modification to the license the model is released under.\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/phi3.5/dbf19a17-e3fd-46b6-a059-e6b4f1fae59f\" width=\"320\" /> \\*\\*Phi-4\\*\\* is a 14B parameter, state-of-the-art open model built upon a blend of synthetic datasets, data from filtered public domain websites, and acquired academic books and Q&A datasets. !\\[Phi-4 benchmark\\](/assets/library/phi4/67391ae2-e565-4173-ac3c-5e49bc977ac4) The model underwent a rigorous enhancement and alignment process, incorporating both supervised fine-tuning and direct preference optimization to ensure precise instruction adherence and robust safety measures. \\*\\*Context length:\\*\\* 16k tokens !\\[Phi-4 performance eval by Microsoft\\](/assets/library/phi4/5da7d0b6-53df-42f9-9c1b-651bfc380cdd) ### Primary use cases The model is designed to accelerate research on language models, for use as a building block for generative AI powered features. It provides uses for general purpose AI systems and applications (primarily in English) which require: 1\\. Memory/compute constrained environments. 2\\. Latency bound scenarios. 3\\. Reasoning and logic. ### Out-of-scope use cases The models are not specifically designed or evaluated for all downstream purposes, thus: 1\\. Developers should consider common limitations of language models as they select use cases, and evaluate and mitigate for accuracy, safety, and fairness before using within a specific downstream use case, particularly for high-risk scenarios. 2\\. Developers should be aware of and adhere to applicable laws or regulations (including privacy, trade compliance laws, etc.) that are relevant to their use case, including the model’s focus on English. 3\\. Nothing contained in this readme should be interpreted as or deemed a restriction or modification to the license the model is released under. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi4:latest",
        "size": "phi4:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "phi4:14b",
        "size": "phi4:14b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "phi4:14b-q4_K_M",
        "size": "phi4:14b-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "phi4:14b-q8_0",
        "size": "phi4:14b-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "phi4:14b-fp16",
        "size": "phi4:14b-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "qwen2",
    "link": "https://ollama.com/library/qwen2",
    "description": "Qwen2 is a new series of large language models from Alibaba group",
    "pullCount": "4.3M",
    "updated": "12 months ago",
    "size": [
      "0.5b",
      "1.5b",
      "7b",
      "72b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/qwen2/c011288c-fb07-42eb-b802-7287a5f12ea6)\n\n**Qwen2** is trained on data in **29 languages**, including **English and Chinese**.\n\nIt is available in 4 parameter sizes: **0.5B**, **1.5B**, **7B**, **72B**.\n\nIn the 7B and 72B models, context length has been extended to **128k tokens**.\n\n| Models         | Qwen2-0.5B | Qwen2-1.5B | Qwen2-7B | Qwen2-72B |\n| -------------- | ---------- | ---------- | -------- | --------- |\n| Params         | 0.49B      | 1.54B      | 7.07B    | 72.71B    |\n| Non-Emb Params | 0.35B      | 1.31B      | 5.98B    | 70.21B    |\n| GQA            | True       | True       | True     | True      |\n| Tie Embedding  | True       | True       | False    | False     |\n| Context Length | 32K        | 32K        | 128K     | 128K      |\n\n### Supported languages\n\nThis is in addition to English and Chinese\n\n| Regions                  | Languages                                                                  |\n| ------------------------ | -------------------------------------------------------------------------- |\n| Western Europe           | German, French, Spanish, Portuguese, Italian, Dutch                        |\n| Eastern & Central Europe | Russian, Czech, Polish                                                     |\n| Middle East              | Arabic, Persian, Hebrew, Turkish                                           |\n| Eastern Asia             | Japanese, Korean                                                           |\n| South-Eastern Asia       | Vietnamese, Thai, Indonesian, Malay, Lao, Burmese, Cebuano, Khmer, Tagalog |\n| Southern Asia            | Hindi, Bengali, Urdu                                                       |\n\n### Performance\n\n![image.png](https://ollama.com/assets/library/qwen2/68b445e3-bf1b-4fff-9621-4e5bbf4a72a2)\n\n![image.png](https://ollama.com/assets/library/qwen2/72e9bf41-f8d6-4b7a-a7ef-9599ef533af6)\n\n![image.png](https://ollama.com/assets/library/qwen2/6c978d72-c37c-45a2-b7f4-c06178c0182c)\n\n![image.png](https://ollama.com/assets/library/qwen2/5247046f-3c32-4edc-a8e1-a10f831ef916)\n\n### License\n\nAll models with the exception of Qwen2 72B (both instruct and base models) are Apache 2.0 licensed.\n\nQwen2 72B model still uses the original Qianwen License.\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/qwen2/c011288c-fb07-42eb-b802-7287a5f12ea6\" width=\"320\" /> \\*\\*Qwen2\\*\\* is trained on data in \\*\\*29 languages\\*\\*, including \\*\\*English and Chinese\\*\\*. It is available in 4 parameter sizes: \\*\\*0.5B\\*\\*, \\*\\*1.5B\\*\\*, \\*\\*7B\\*\\*, \\*\\*72B\\*\\*. In the 7B and 72B models, context length has been extended to \\*\\*128k tokens\\*\\*. Models | Qwen2-0.5B | Qwen2-1.5B | Qwen2-7B | Qwen2-72B -- | -- | -- | -- | -- Params | 0.49B | 1.54B | 7.07B | 72.71B Non-Emb Params | 0.35B | 1.31B | 5.98B | 70.21B GQA | True | True | True | True Tie Embedding | True | True | False | False Context Length | 32K | 32K | 128K | 128K ### Supported languages This is in addition to English and Chinese Regions | Languages -- | -- Western Europe | German, French, Spanish, Portuguese, Italian, Dutch Eastern & Central Europe | Russian, Czech, Polish Middle East | Arabic, Persian, Hebrew, Turkish Eastern Asia | Japanese, Korean South-Eastern Asia | Vietnamese, Thai, Indonesian, Malay, Lao, Burmese, Cebuano, Khmer, Tagalog Southern Asia | Hindi, Bengali, Urdu ### Performance !\\[image.png\\](https://ollama.com/assets/library/qwen2/68b445e3-bf1b-4fff-9621-4e5bbf4a72a2) !\\[image.png\\](https://ollama.com/assets/library/qwen2/72e9bf41-f8d6-4b7a-a7ef-9599ef533af6) !\\[image.png\\](https://ollama.com/assets/library/qwen2/6c978d72-c37c-45a2-b7f4-c06178c0182c) !\\[image.png\\](https://ollama.com/assets/library/qwen2/5247046f-3c32-4edc-a8e1-a10f831ef916) ### License All models with the exception of Qwen2 72B (both instruct and base models) are Apache 2.0 licensed. Qwen2 72B model still uses the original Qianwen License. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen2:latest",
        "size": "qwen2:latest",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:0.5b",
        "size": "qwen2:0.5b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b",
        "size": "qwen2:1.5b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b",
        "size": "qwen2:7b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b",
        "size": "qwen2:72b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:0.5b-instruct",
        "size": "qwen2:0.5b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q2_K",
        "size": "qwen2:0.5b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q3_K_S",
        "size": "qwen2:0.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q3_K_M",
        "size": "qwen2:0.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q3_K_L",
        "size": "qwen2:0.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q4_0",
        "size": "qwen2:0.5b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q4_1",
        "size": "qwen2:0.5b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q4_K_S",
        "size": "qwen2:0.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q4_K_M",
        "size": "qwen2:0.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q5_0",
        "size": "qwen2:0.5b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q5_1",
        "size": "qwen2:0.5b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q5_K_S",
        "size": "qwen2:0.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q5_K_M",
        "size": "qwen2:0.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q6_K",
        "size": "qwen2:0.5b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-q8_0",
        "size": "qwen2:0.5b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:0.5b-instruct-fp16",
        "size": "qwen2:0.5b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct",
        "size": "qwen2:1.5b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q2_K",
        "size": "qwen2:1.5b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q3_K_S",
        "size": "qwen2:1.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q3_K_M",
        "size": "qwen2:1.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q3_K_L",
        "size": "qwen2:1.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q4_0",
        "size": "qwen2:1.5b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q4_1",
        "size": "qwen2:1.5b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q4_K_S",
        "size": "qwen2:1.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q4_K_M",
        "size": "qwen2:1.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q5_0",
        "size": "qwen2:1.5b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q5_1",
        "size": "qwen2:1.5b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q5_K_S",
        "size": "qwen2:1.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q5_K_M",
        "size": "qwen2:1.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q6_K",
        "size": "qwen2:1.5b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-q8_0",
        "size": "qwen2:1.5b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:1.5b-instruct-fp16",
        "size": "qwen2:1.5b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-instruct",
        "size": "qwen2:7b-instruct",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q2_K",
        "size": "qwen2:7b-instruct-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q3_K_S",
        "size": "qwen2:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q3_K_M",
        "size": "qwen2:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q3_K_L",
        "size": "qwen2:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q4_0",
        "size": "qwen2:7b-instruct-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q4_1",
        "size": "qwen2:7b-instruct-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q4_K_S",
        "size": "qwen2:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q4_K_M",
        "size": "qwen2:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q5_0",
        "size": "qwen2:7b-instruct-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q5_1",
        "size": "qwen2:7b-instruct-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q5_K_S",
        "size": "qwen2:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q5_K_M",
        "size": "qwen2:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q6_K",
        "size": "qwen2:7b-instruct-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-q8_0",
        "size": "qwen2:7b-instruct-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-instruct-fp16",
        "size": "qwen2:7b-instruct-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:7b-text",
        "size": "qwen2:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q2_K",
        "size": "qwen2:7b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q3_K_S",
        "size": "qwen2:7b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q3_K_M",
        "size": "qwen2:7b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q3_K_L",
        "size": "qwen2:7b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q4_0",
        "size": "qwen2:7b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q4_1",
        "size": "qwen2:7b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q4_K_S",
        "size": "qwen2:7b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q4_K_M",
        "size": "qwen2:7b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q5_0",
        "size": "qwen2:7b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q5_1",
        "size": "qwen2:7b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:7b-text-q8_0",
        "size": "qwen2:7b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-instruct",
        "size": "qwen2:72b-instruct",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q2_K",
        "size": "qwen2:72b-instruct-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q3_K_S",
        "size": "qwen2:72b-instruct-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q3_K_M",
        "size": "qwen2:72b-instruct-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q3_K_L",
        "size": "qwen2:72b-instruct-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q4_0",
        "size": "qwen2:72b-instruct-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q4_1",
        "size": "qwen2:72b-instruct-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q4_K_S",
        "size": "qwen2:72b-instruct-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q4_K_M",
        "size": "qwen2:72b-instruct-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q5_0",
        "size": "qwen2:72b-instruct-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q5_1",
        "size": "qwen2:72b-instruct-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q5_K_S",
        "size": "qwen2:72b-instruct-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q5_K_M",
        "size": "qwen2:72b-instruct-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q6_K",
        "size": "qwen2:72b-instruct-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-q8_0",
        "size": "qwen2:72b-instruct-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-instruct-fp16",
        "size": "qwen2:72b-instruct-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "qwen2:72b-text",
        "size": "qwen2:72b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q2_K",
        "size": "qwen2:72b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q3_K_S",
        "size": "qwen2:72b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q3_K_M",
        "size": "qwen2:72b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q3_K_L",
        "size": "qwen2:72b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q4_0",
        "size": "qwen2:72b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q4_1",
        "size": "qwen2:72b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q4_K_S",
        "size": "qwen2:72b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q4_K_M",
        "size": "qwen2:72b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q5_0",
        "size": "qwen2:72b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q5_1",
        "size": "qwen2:72b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q5_K_S",
        "size": "qwen2:72b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q5_K_M",
        "size": "qwen2:72b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q6_K",
        "size": "qwen2:72b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-q8_0",
        "size": "qwen2:72b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2:72b-text-fp16",
        "size": "qwen2:72b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama2",
    "link": "https://ollama.com/library/llama2",
    "description": "Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.",
    "pullCount": "4M",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/3325447/286e4e13-0b2b-43a4-9b07-23a50d3a3d33)\n\nLlama 2 is released by Meta Platforms, Inc. This model is trained on 2 trillion tokens, and by default supports a context length of 4096\\. Llama 2 Chat models are fine-tuned on over 1 million human annotations, and are made for chat.\n\n### CLI\n\nOpen the terminal and run `ollama run llama2`\n\n### API\n\nExample using curl:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2\",\n  \"prompt\":\"Why is the sky blue?\"\n }'\n\n```\n\n[API documentation](https://github.com/jmorganca/ollama/blob/main/docs/api.md)\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 13b models generally require at least 16GB of RAM\n* 70b models generally require at least 64GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\n**Chat** is fine-tuned for chat/dialogue use cases. These are the default in Ollama, and for models tagged with -chat in the tags tab.\n\n_Example: `ollama run llama2`_\n\n**Pre-trained** is without the chat fine-tuning. This is tagged as -text in the tags tab.\n\n_Example: `ollama run llama2:text`_\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n## References\n\n[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)\n\n[Meta’s Hugging Face repo](https://huggingface.co/meta-llama)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/3325447/286e4e13-0b2b-43a4-9b07-23a50d3a3d33\" width=\"360\" /> Llama 2 is released by Meta Platforms, Inc. This model is trained on 2 trillion tokens, and by default supports a context length of 4096\\. Llama 2 Chat models are fine-tuned on over 1 million human annotations, and are made for chat. ### CLI Open the terminal and run \\`ollama run llama2\\` ### API Example using curl: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"llama2\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` \\[API documentation\\](https://github.com/jmorganca/ollama/blob/main/docs/api.md) ## Memory requirements - 7b models generally require at least 8GB of RAM - 13b models generally require at least 16GB of RAM - 70b models generally require at least 64GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants \\*\\*Chat\\*\\* is fine-tuned for chat/dialogue use cases. These are the default in Ollama, and for models tagged with -chat in the tags tab. \\*Example: \\`ollama run llama2\\`\\* \\*\\*Pre-trained\\*\\* is without the chat fine-tuning. This is tagged as -text in the tags tab. \\*Example: \\`ollama run llama2:text\\`\\* By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. ## References \\[Llama 2: Open Foundation and Fine-Tuned Chat Models\\](https://arxiv.org/abs/2307.09288) \\[Meta's Hugging Face repo\\](https://huggingface.co/meta-llama) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama2:latest",
        "size": "llama2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:chat",
        "size": "llama2:chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:text",
        "size": "llama2:text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b",
        "size": "llama2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b",
        "size": "llama2:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b",
        "size": "llama2:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat",
        "size": "llama2:7b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q2_K",
        "size": "llama2:7b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q3_K_S",
        "size": "llama2:7b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q3_K_M",
        "size": "llama2:7b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q3_K_L",
        "size": "llama2:7b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q4_0",
        "size": "llama2:7b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q4_1",
        "size": "llama2:7b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q4_K_S",
        "size": "llama2:7b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q4_K_M",
        "size": "llama2:7b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q5_0",
        "size": "llama2:7b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q5_1",
        "size": "llama2:7b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q5_K_S",
        "size": "llama2:7b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q5_K_M",
        "size": "llama2:7b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q6_K",
        "size": "llama2:7b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-q8_0",
        "size": "llama2:7b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-chat-fp16",
        "size": "llama2:7b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text",
        "size": "llama2:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q2_K",
        "size": "llama2:7b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q3_K_S",
        "size": "llama2:7b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q3_K_M",
        "size": "llama2:7b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q3_K_L",
        "size": "llama2:7b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q4_0",
        "size": "llama2:7b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q4_1",
        "size": "llama2:7b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q4_K_S",
        "size": "llama2:7b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q4_K_M",
        "size": "llama2:7b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q5_0",
        "size": "llama2:7b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q5_1",
        "size": "llama2:7b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q5_K_S",
        "size": "llama2:7b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q5_K_M",
        "size": "llama2:7b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q6_K",
        "size": "llama2:7b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-q8_0",
        "size": "llama2:7b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:7b-text-fp16",
        "size": "llama2:7b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat",
        "size": "llama2:13b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q2_K",
        "size": "llama2:13b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q3_K_S",
        "size": "llama2:13b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q3_K_M",
        "size": "llama2:13b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q3_K_L",
        "size": "llama2:13b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q4_0",
        "size": "llama2:13b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q4_1",
        "size": "llama2:13b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q4_K_S",
        "size": "llama2:13b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q4_K_M",
        "size": "llama2:13b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q5_0",
        "size": "llama2:13b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q5_1",
        "size": "llama2:13b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q5_K_S",
        "size": "llama2:13b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q5_K_M",
        "size": "llama2:13b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q6_K",
        "size": "llama2:13b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-q8_0",
        "size": "llama2:13b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-chat-fp16",
        "size": "llama2:13b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text",
        "size": "llama2:13b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q2_K",
        "size": "llama2:13b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q3_K_S",
        "size": "llama2:13b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q3_K_M",
        "size": "llama2:13b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q3_K_L",
        "size": "llama2:13b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q4_0",
        "size": "llama2:13b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q4_1",
        "size": "llama2:13b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q4_K_S",
        "size": "llama2:13b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q4_K_M",
        "size": "llama2:13b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q5_0",
        "size": "llama2:13b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q5_1",
        "size": "llama2:13b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q5_K_S",
        "size": "llama2:13b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q5_K_M",
        "size": "llama2:13b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q6_K",
        "size": "llama2:13b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-q8_0",
        "size": "llama2:13b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:13b-text-fp16",
        "size": "llama2:13b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat",
        "size": "llama2:70b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q2_K",
        "size": "llama2:70b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q3_K_S",
        "size": "llama2:70b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q3_K_M",
        "size": "llama2:70b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q3_K_L",
        "size": "llama2:70b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q4_0",
        "size": "llama2:70b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q4_1",
        "size": "llama2:70b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q4_K_S",
        "size": "llama2:70b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q4_K_M",
        "size": "llama2:70b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q5_0",
        "size": "llama2:70b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q5_1",
        "size": "llama2:70b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q5_K_S",
        "size": "llama2:70b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q5_K_M",
        "size": "llama2:70b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q6_K",
        "size": "llama2:70b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-q8_0",
        "size": "llama2:70b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-chat-fp16",
        "size": "llama2:70b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text",
        "size": "llama2:70b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q2_K",
        "size": "llama2:70b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q3_K_S",
        "size": "llama2:70b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q3_K_M",
        "size": "llama2:70b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q3_K_L",
        "size": "llama2:70b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q4_0",
        "size": "llama2:70b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q4_1",
        "size": "llama2:70b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q4_K_S",
        "size": "llama2:70b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q4_K_M",
        "size": "llama2:70b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q5_0",
        "size": "llama2:70b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q5_1",
        "size": "llama2:70b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q5_K_S",
        "size": "llama2:70b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q5_K_M",
        "size": "llama2:70b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q6_K",
        "size": "llama2:70b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-q8_0",
        "size": "llama2:70b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2:70b-text-fp16",
        "size": "llama2:70b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "minicpm-v",
    "link": "https://ollama.com/library/minicpm-v",
    "description": "A series of multimodal LLMs (MLLMs) designed for vision-language understanding.",
    "pullCount": "3.1M",
    "updated": "9 months ago",
    "size": [
      "8b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/minicpm-v/9252c73d-2c9c-434c-8a34-21f4d5cdd25e)\n\n> Note: this model requires [Ollama 0.3.10](https://github.com/ollama/ollama/releases/tag/v0.3.10) or later.\n\nMiniCPM-V 2.6 is the latest and most capable model in the MiniCPM-V series. The model is built on SigLip-400M and Qwen2-7B with a total of 8B parameters. It exhibits a significant performance improvement over MiniCPM-Llama3-V 2.5, and introduces new features for multi-image and video understanding. Notable features of MiniCPM-V 2.6 include:\n\n* **🔥 Leading Performance**: MiniCPM-V 2.6 achieves an average score of 65.2 on the latest version of OpenCompass, a comprehensive evaluation over 8 popular benchmarks. With only 8B parameters, it surpasses widely used proprietary models like GPT-4o mini, GPT-4V, Gemini 1.5 Pro, and Claude 3.5 Sonnet for single image understanding.\n* **🖼️ Multi Image Understanding and In-context Learning**. MiniCPM-V 2.6 can also perform conversation and reasoning over multiple images. It achieves state-of-the-art performance on popular multi-image benchmarks such as Mantis-Eval, BLINK, Mathverse mv and Sciverse mv, and also shows promising in-context learning capability.\n* **💪 Strong OCR Capability**: MiniCPM-V 2.6 can process images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344). It achieves state-of-the-art performance on OCRBench, surpassing proprietary models such as GPT-4o, GPT-4V, and Gemini 1.5 Pro. Based on the the latest RLAIF-V and VisCPM techniques, it features trustworthy behaviors, with significantly lower hallucination rates than GPT-4o and GPT-4V on Object HalBench, and supports multilingual capabilities on English, Chinese, German, French, Italian, Korean, etc.\n* **🚀 Superior Efficiency**: In addition to its friendly size, MiniCPM-V 2.6 also shows state-of-the-art token density (i.e., number of pixels encoded into each visual token). It produces only 640 tokens when processing a 1.8M pixel image, which is 75% fewer than most models. This directly improves the inference speed, first-token latency, memory usage, and power consumption.\n\n## Refrences\n\n[GitHub](https://github.com/OpenBMB/MiniCPM-V)\n\n[Hugging Face](https://huggingface.co/openbmb/MiniCPM-V-2%5F6)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/minicpm-v/9252c73d-2c9c-434c-8a34-21f4d5cdd25e\" width=\"320\" /> > Note: this model requires \\[Ollama 0.3.10\\](https://github.com/ollama/ollama/releases/tag/v0.3.10) or later. MiniCPM-V 2.6 is the latest and most capable model in the MiniCPM-V series. The model is built on SigLip-400M and Qwen2-7B with a total of 8B parameters. It exhibits a significant performance improvement over MiniCPM-Llama3-V 2.5, and introduces new features for multi-image and video understanding. Notable features of MiniCPM-V 2.6 include: \\* \\*\\*🔥 Leading Performance\\*\\*: MiniCPM-V 2.6 achieves an average score of 65.2 on the latest version of OpenCompass, a comprehensive evaluation over 8 popular benchmarks. With only 8B parameters, it surpasses widely used proprietary models like GPT-4o mini, GPT-4V, Gemini 1.5 Pro, and Claude 3.5 Sonnet for single image understanding. \\* \\*\\*🖼️ Multi Image Understanding and In-context Learning\\*\\*. MiniCPM-V 2.6 can also perform conversation and reasoning over multiple images. It achieves state-of-the-art performance on popular multi-image benchmarks such as Mantis-Eval, BLINK, Mathverse mv and Sciverse mv, and also shows promising in-context learning capability. \\* \\*\\*💪 Strong OCR Capability\\*\\*: MiniCPM-V 2.6 can process images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344). It achieves state-of-the-art performance on OCRBench, surpassing proprietary models such as GPT-4o, GPT-4V, and Gemini 1.5 Pro. Based on the the latest RLAIF-V and VisCPM techniques, it features trustworthy behaviors, with significantly lower hallucination rates than GPT-4o and GPT-4V on Object HalBench, and supports multilingual capabilities on English, Chinese, German, French, Italian, Korean, etc. \\* \\*\\*🚀 Superior Efficiency\\*\\*: In addition to its friendly size, MiniCPM-V 2.6 also shows state-of-the-art token density (i.e., number of pixels encoded into each visual token). It produces only 640 tokens when processing a 1.8M pixel image, which is 75% fewer than most models. This directly improves the inference speed, first-token latency, memory usage, and power consumption. ## Refrences \\[GitHub\\](https://github.com/OpenBMB/MiniCPM-V) \\[Hugging Face\\](https://huggingface.co/openbmb/MiniCPM-V-2\\_6) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "minicpm-v:latest",
        "size": "minicpm-v:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b",
        "size": "minicpm-v:8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q2_K",
        "size": "minicpm-v:8b-2.6-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q3_K_S",
        "size": "minicpm-v:8b-2.6-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q3_K_M",
        "size": "minicpm-v:8b-2.6-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q3_K_L",
        "size": "minicpm-v:8b-2.6-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q4_0",
        "size": "minicpm-v:8b-2.6-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q4_1",
        "size": "minicpm-v:8b-2.6-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q4_K_S",
        "size": "minicpm-v:8b-2.6-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q4_K_M",
        "size": "minicpm-v:8b-2.6-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q5_0",
        "size": "minicpm-v:8b-2.6-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q5_1",
        "size": "minicpm-v:8b-2.6-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q5_K_S",
        "size": "minicpm-v:8b-2.6-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q5_K_M",
        "size": "minicpm-v:8b-2.6-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q6_K",
        "size": "minicpm-v:8b-2.6-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-q8_0",
        "size": "minicpm-v:8b-2.6-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "minicpm-v:8b-2.6-fp16",
        "size": "minicpm-v:8b-2.6-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "codellama",
    "link": "https://ollama.com/library/codellama",
    "description": "A large language model that can use text prompts to generate and discuss code.",
    "pullCount": "2.9M",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "34b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/3325447/286e4e13-0b2b-43a4-9b07-23a50d3a3d33)\n\nCode Llama is a model for generating and discussing code, built on top of [Llama 2](https://ollama.ai/library/llama2). It’s designed to make workflows faster and efficient for developers and make it easier for people to learn how to code. It can generate both code and natural language about code. Code Llama supports many of the most popular programming languages used today, including Python, C++, Java, PHP, Typescript (Javascript), C#, Bash and more.\n\n## Parameter counts\n\n| Parameter Count |                                |                          |\n| --------------- | ------------------------------ | ------------------------ |\n| 7 billion       | [View](/library/codellama:7b)  | ollama run codellama:7b  |\n| 13 billion      | [View](/library/codellama:13b) | ollama run codellama:13b |\n| 34 billion      | [View](/library/codellama:34b) | ollama run codellama:34b |\n| 70 billion      | [View](/library/codellama:70b) | ollama run codellama:70b |\n\n## Usage\n\n### CLI\n\n```\nollama run codellama \"Write me a function that outputs the fibonacci sequence\"\n\n```\n\n### API\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"codellama\",\n  \"prompt\": \"Write me a function that outputs the fibonacci sequence\"\n}'\n\n```\n\n## Variations\n\n| instruct | Fine-tuned to generate helpful and safe answers in natural language                    |\n| -------- | -------------------------------------------------------------------------------------- |\n| python   | A specialized variation of Code Llama further fine-tuned on 100B tokens of Python code |\n| code     | Base model for code completion                                                         |\n\n## Example prompts\n\n### Ask questions\n\n```\nollama run codellama:7b-instruct 'You are an expert programmer that writes simple, concise code and explanations. Write a python function to generate the nth fibonacci number.'\n\n```\n\n### Fill-in-the-middle (FIM) or infill\n\n```\nollama run codellama:7b-code '<PRE> def compute_gcd(x, y): <SUF>return result <MID>'\n\n```\n\nFill-in-the-middle (FIM) is a special prompt format supported by the code completion model can complete code between two already written code blocks. Code Llama expects a specific format for infilling code:\n\n```\n<PRE> {prefix} <SUF>{suffix} <MID>\n\n```\n\n`<PRE>`, `<SUF>` and `<MID>` are special tokens that guide the model.\n\n### Code review\n\n```\nollama run codellama '\nWhere is the bug in this code?\n\ndef fib(n):\n    if n <= 0:\n        return n\n    else:\n        return fib(n-1) + fib(n-2)\n'\n\n```\n\n### Writing tests\n\n```\nollama run codellama \"write a unit test for this function: $(cat example.py)\"\n\n```\n\n### Code completion\n\n```\nollama run codellama:7b-code '# A simple python function to remove whitespace from a string:'\n\n```\n\n## More information\n\n* [How to prompt Code Llama](https://ollama.ai/blog/how-to-prompt-code-llama)\n* [Whitepaper](https://arxiv.org/abs/2308.12950)\n* [CodeLlama GitHub](https://github.com/facebookresearch/codellama)\n* [Hugging Face](https://huggingface.co/codellama)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/3325447/286e4e13-0b2b-43a4-9b07-23a50d3a3d33\" width=\"360\" /> Code Llama is a model for generating and discussing code, built on top of \\[Llama 2\\](https://ollama.ai/library/llama2). It's designed to make workflows faster and efficient for developers and make it easier for people to learn how to code. It can generate both code and natural language about code. Code Llama supports many of the most popular programming languages used today, including Python, C++, Java, PHP, Typescript (Javascript), C#, Bash and more. ## Parameter counts | Parameter Count | | | | --------------- | ------------------------------ | -------------------------- | | 7 billion | \\[View\\](/library/codellama:7b) | \\`ollama run codellama:7b\\` | | 13 billion | \\[View\\](/library/codellama:13b) | \\`ollama run codellama:13b\\` | | 34 billion | \\[View\\](/library/codellama:34b) | \\`ollama run codellama:34b\\` | | 70 billion | \\[View\\](/library/codellama:70b) | \\`ollama run codellama:70b\\` | ## Usage ### CLI \\`\\`\\` ollama run codellama \"Write me a function that outputs the fibonacci sequence\" \\`\\`\\` ### API \\`\\`\\` curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"codellama\", \"prompt\": \"Write me a function that outputs the fibonacci sequence\" }' \\`\\`\\` ## Variations | | | | ---------- | -------------------------------------------------------------------------------------- | | \\`instruct\\` | Fine-tuned to generate helpful and safe answers in natural language | | \\`python\\` | A specialized variation of Code Llama further fine-tuned on 100B tokens of Python code | | \\`code\\` | Base model for code completion | ## Example prompts ### Ask questions \\`\\`\\` ollama run codellama:7b-instruct 'You are an expert programmer that writes simple, concise code and explanations. Write a python function to generate the nth fibonacci number.' \\`\\`\\` ### Fill-in-the-middle (FIM) or infill \\`\\`\\` ollama run codellama:7b-code '<PRE> def compute\\_gcd(x, y): <SUF>return result <MID>' \\`\\`\\` Fill-in-the-middle (FIM) is a special prompt format supported by the code completion model can complete code between two already written code blocks. Code Llama expects a specific format for infilling code: \\`\\`\\` <PRE> {prefix} <SUF>{suffix} <MID> \\`\\`\\` \\`<PRE>\\`, \\`<SUF>\\` and \\`<MID>\\` are special tokens that guide the model. ### Code review \\`\\`\\` ollama run codellama ' Where is the bug in this code? def fib(n): if n <= 0: return n else: return fib(n-1) + fib(n-2) ' \\`\\`\\` ### Writing tests \\`\\`\\` ollama run codellama \"write a unit test for this function: $(cat example.py)\" \\`\\`\\` ### Code completion \\`\\`\\` ollama run codellama:7b-code '# A simple python function to remove whitespace from a string:' \\`\\`\\` ## More information - \\[How to prompt Code Llama\\](https://ollama.ai/blog/how-to-prompt-code-llama) - \\[Whitepaper\\](https://arxiv.org/abs/2308.12950) - \\[CodeLlama GitHub\\](https://github.com/facebookresearch/codellama) - \\[Hugging Face\\](https://huggingface.co/codellama) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codellama:latest",
        "size": "codellama:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:code",
        "size": "codellama:code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:instruct",
        "size": "codellama:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:python",
        "size": "codellama:python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b",
        "size": "codellama:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b",
        "size": "codellama:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b",
        "size": "codellama:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b",
        "size": "codellama:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code",
        "size": "codellama:7b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q2_K",
        "size": "codellama:7b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q3_K_S",
        "size": "codellama:7b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q3_K_M",
        "size": "codellama:7b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q3_K_L",
        "size": "codellama:7b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q4_0",
        "size": "codellama:7b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q4_1",
        "size": "codellama:7b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q4_K_S",
        "size": "codellama:7b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q4_K_M",
        "size": "codellama:7b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q5_0",
        "size": "codellama:7b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q5_1",
        "size": "codellama:7b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q5_K_S",
        "size": "codellama:7b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q5_K_M",
        "size": "codellama:7b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q6_K",
        "size": "codellama:7b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-q8_0",
        "size": "codellama:7b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-code-fp16",
        "size": "codellama:7b-code-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct",
        "size": "codellama:7b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q2_K",
        "size": "codellama:7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q3_K_S",
        "size": "codellama:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q3_K_M",
        "size": "codellama:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q3_K_L",
        "size": "codellama:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q4_0",
        "size": "codellama:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q4_1",
        "size": "codellama:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q4_K_S",
        "size": "codellama:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q4_K_M",
        "size": "codellama:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q5_0",
        "size": "codellama:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q5_1",
        "size": "codellama:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q5_K_S",
        "size": "codellama:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q5_K_M",
        "size": "codellama:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q6_K",
        "size": "codellama:7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-q8_0",
        "size": "codellama:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-instruct-fp16",
        "size": "codellama:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python",
        "size": "codellama:7b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q2_K",
        "size": "codellama:7b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q3_K_S",
        "size": "codellama:7b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q3_K_M",
        "size": "codellama:7b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q3_K_L",
        "size": "codellama:7b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q4_0",
        "size": "codellama:7b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q4_1",
        "size": "codellama:7b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q4_K_S",
        "size": "codellama:7b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q4_K_M",
        "size": "codellama:7b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q5_0",
        "size": "codellama:7b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q5_1",
        "size": "codellama:7b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q5_K_S",
        "size": "codellama:7b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q5_K_M",
        "size": "codellama:7b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q6_K",
        "size": "codellama:7b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-q8_0",
        "size": "codellama:7b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:7b-python-fp16",
        "size": "codellama:7b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code",
        "size": "codellama:13b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q2_K",
        "size": "codellama:13b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q3_K_S",
        "size": "codellama:13b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q3_K_M",
        "size": "codellama:13b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q3_K_L",
        "size": "codellama:13b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q4_0",
        "size": "codellama:13b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q4_1",
        "size": "codellama:13b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q4_K_S",
        "size": "codellama:13b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q4_K_M",
        "size": "codellama:13b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q5_0",
        "size": "codellama:13b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q5_1",
        "size": "codellama:13b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q5_K_S",
        "size": "codellama:13b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q5_K_M",
        "size": "codellama:13b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q6_K",
        "size": "codellama:13b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-q8_0",
        "size": "codellama:13b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-code-fp16",
        "size": "codellama:13b-code-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct",
        "size": "codellama:13b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q2_K",
        "size": "codellama:13b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q3_K_S",
        "size": "codellama:13b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q3_K_M",
        "size": "codellama:13b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q3_K_L",
        "size": "codellama:13b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q4_0",
        "size": "codellama:13b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q4_1",
        "size": "codellama:13b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q4_K_S",
        "size": "codellama:13b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q4_K_M",
        "size": "codellama:13b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q5_0",
        "size": "codellama:13b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q5_1",
        "size": "codellama:13b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q5_K_S",
        "size": "codellama:13b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q5_K_M",
        "size": "codellama:13b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q6_K",
        "size": "codellama:13b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-q8_0",
        "size": "codellama:13b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-instruct-fp16",
        "size": "codellama:13b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python",
        "size": "codellama:13b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q2_K",
        "size": "codellama:13b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q3_K_S",
        "size": "codellama:13b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q3_K_M",
        "size": "codellama:13b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q3_K_L",
        "size": "codellama:13b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q4_0",
        "size": "codellama:13b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q4_1",
        "size": "codellama:13b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q4_K_S",
        "size": "codellama:13b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q4_K_M",
        "size": "codellama:13b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q5_0",
        "size": "codellama:13b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q5_1",
        "size": "codellama:13b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q5_K_S",
        "size": "codellama:13b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q5_K_M",
        "size": "codellama:13b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q6_K",
        "size": "codellama:13b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-q8_0",
        "size": "codellama:13b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:13b-python-fp16",
        "size": "codellama:13b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code",
        "size": "codellama:34b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q2_K",
        "size": "codellama:34b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q3_K_S",
        "size": "codellama:34b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q3_K_M",
        "size": "codellama:34b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q3_K_L",
        "size": "codellama:34b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q4_0",
        "size": "codellama:34b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q4_1",
        "size": "codellama:34b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q4_K_S",
        "size": "codellama:34b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q4_K_M",
        "size": "codellama:34b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q5_0",
        "size": "codellama:34b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q5_1",
        "size": "codellama:34b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q5_K_S",
        "size": "codellama:34b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q5_K_M",
        "size": "codellama:34b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q6_K",
        "size": "codellama:34b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-code-q8_0",
        "size": "codellama:34b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct",
        "size": "codellama:34b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q2_K",
        "size": "codellama:34b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q3_K_S",
        "size": "codellama:34b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q3_K_M",
        "size": "codellama:34b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q3_K_L",
        "size": "codellama:34b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q4_0",
        "size": "codellama:34b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q4_1",
        "size": "codellama:34b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q4_K_S",
        "size": "codellama:34b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q4_K_M",
        "size": "codellama:34b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q5_0",
        "size": "codellama:34b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q5_1",
        "size": "codellama:34b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q5_K_S",
        "size": "codellama:34b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q5_K_M",
        "size": "codellama:34b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q6_K",
        "size": "codellama:34b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-q8_0",
        "size": "codellama:34b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-instruct-fp16",
        "size": "codellama:34b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python",
        "size": "codellama:34b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q2_K",
        "size": "codellama:34b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q3_K_S",
        "size": "codellama:34b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q3_K_M",
        "size": "codellama:34b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q3_K_L",
        "size": "codellama:34b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q4_0",
        "size": "codellama:34b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q4_1",
        "size": "codellama:34b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q4_K_S",
        "size": "codellama:34b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q4_K_M",
        "size": "codellama:34b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q5_0",
        "size": "codellama:34b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q5_1",
        "size": "codellama:34b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q5_K_S",
        "size": "codellama:34b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q5_K_M",
        "size": "codellama:34b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q6_K",
        "size": "codellama:34b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-q8_0",
        "size": "codellama:34b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:34b-python-fp16",
        "size": "codellama:34b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code",
        "size": "codellama:70b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q2_K",
        "size": "codellama:70b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q3_K_S",
        "size": "codellama:70b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q3_K_M",
        "size": "codellama:70b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q3_K_L",
        "size": "codellama:70b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q4_0",
        "size": "codellama:70b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q4_1",
        "size": "codellama:70b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q4_K_S",
        "size": "codellama:70b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q4_K_M",
        "size": "codellama:70b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q5_0",
        "size": "codellama:70b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q5_1",
        "size": "codellama:70b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q5_K_S",
        "size": "codellama:70b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q5_K_M",
        "size": "codellama:70b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q6_K",
        "size": "codellama:70b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-q8_0",
        "size": "codellama:70b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-code-fp16",
        "size": "codellama:70b-code-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct",
        "size": "codellama:70b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q2_K",
        "size": "codellama:70b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q3_K_S",
        "size": "codellama:70b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q3_K_M",
        "size": "codellama:70b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q3_K_L",
        "size": "codellama:70b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q4_0",
        "size": "codellama:70b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q4_1",
        "size": "codellama:70b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q4_K_S",
        "size": "codellama:70b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q4_K_M",
        "size": "codellama:70b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q5_0",
        "size": "codellama:70b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q5_1",
        "size": "codellama:70b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q5_K_S",
        "size": "codellama:70b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q5_K_M",
        "size": "codellama:70b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q6_K",
        "size": "codellama:70b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-q8_0",
        "size": "codellama:70b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-instruct-fp16",
        "size": "codellama:70b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python",
        "size": "codellama:70b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q2_K",
        "size": "codellama:70b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q3_K_S",
        "size": "codellama:70b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q3_K_M",
        "size": "codellama:70b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q3_K_L",
        "size": "codellama:70b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q4_0",
        "size": "codellama:70b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q4_1",
        "size": "codellama:70b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q4_K_S",
        "size": "codellama:70b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q4_K_M",
        "size": "codellama:70b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q5_0",
        "size": "codellama:70b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q5_1",
        "size": "codellama:70b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q5_K_S",
        "size": "codellama:70b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q5_K_M",
        "size": "codellama:70b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q6_K",
        "size": "codellama:70b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-q8_0",
        "size": "codellama:70b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codellama:70b-python-fp16",
        "size": "codellama:70b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "tinyllama",
    "link": "https://ollama.com/library/tinyllama",
    "description": "The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.",
    "pullCount": "2.8M",
    "updated": "1 year ago",
    "size": [
      "1.1b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/6f17d445-d019-4e54-bac8-9cb6b3b01a26)\n\nTinyLlama is a compact model with only 1.1B parameters. This compactness allows it to cater to a multitude of applications demanding a restricted computation and memory footprint.\n\n## References\n\n[Hugging Face](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6)\n\n[GitHub](https://github.com/jzhang38/TinyLlama)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/6f17d445-d019-4e54-bac8-9cb6b3b01a26\" width=\"320\" /> TinyLlama is a compact model with only 1.1B parameters. This compactness allows it to cater to a multitude of applications demanding a restricted computation and memory footprint. ## References \\[Hugging Face\\](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6) \\[GitHub\\](https://github.com/jzhang38/TinyLlama) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "tinyllama:latest",
        "size": "tinyllama:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:chat",
        "size": "tinyllama:chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:v0.6",
        "size": "tinyllama:v0.6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:v1",
        "size": "tinyllama:v1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b",
        "size": "tinyllama:1.1b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat",
        "size": "tinyllama:1.1b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q2_K",
        "size": "tinyllama:1.1b-chat-v0.6-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q3_K_S",
        "size": "tinyllama:1.1b-chat-v0.6-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q3_K_M",
        "size": "tinyllama:1.1b-chat-v0.6-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q3_K_L",
        "size": "tinyllama:1.1b-chat-v0.6-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q4_0",
        "size": "tinyllama:1.1b-chat-v0.6-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q4_1",
        "size": "tinyllama:1.1b-chat-v0.6-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q4_K_S",
        "size": "tinyllama:1.1b-chat-v0.6-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q4_K_M",
        "size": "tinyllama:1.1b-chat-v0.6-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q5_0",
        "size": "tinyllama:1.1b-chat-v0.6-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q5_1",
        "size": "tinyllama:1.1b-chat-v0.6-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q5_K_S",
        "size": "tinyllama:1.1b-chat-v0.6-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q5_K_M",
        "size": "tinyllama:1.1b-chat-v0.6-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q6_K",
        "size": "tinyllama:1.1b-chat-v0.6-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-q8_0",
        "size": "tinyllama:1.1b-chat-v0.6-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v0.6-fp16",
        "size": "tinyllama:1.1b-chat-v0.6-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q2_K",
        "size": "tinyllama:1.1b-chat-v1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q3_K_S",
        "size": "tinyllama:1.1b-chat-v1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q3_K_M",
        "size": "tinyllama:1.1b-chat-v1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q3_K_L",
        "size": "tinyllama:1.1b-chat-v1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q4_0",
        "size": "tinyllama:1.1b-chat-v1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q4_1",
        "size": "tinyllama:1.1b-chat-v1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q4_K_S",
        "size": "tinyllama:1.1b-chat-v1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q4_K_M",
        "size": "tinyllama:1.1b-chat-v1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q5_0",
        "size": "tinyllama:1.1b-chat-v1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q5_1",
        "size": "tinyllama:1.1b-chat-v1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q5_K_S",
        "size": "tinyllama:1.1b-chat-v1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q5_K_M",
        "size": "tinyllama:1.1b-chat-v1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q6_K",
        "size": "tinyllama:1.1b-chat-v1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-q8_0",
        "size": "tinyllama:1.1b-chat-v1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinyllama:1.1b-chat-v1-fp16",
        "size": "tinyllama:1.1b-chat-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "dolphin3",
    "link": "https://ollama.com/library/dolphin3",
    "description": "Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.",
    "pullCount": "2.6M",
    "updated": "8 months ago",
    "size": [
      "8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/dolphin3/ce75cebe-b012-4195-9a6b-aa6c4b68f93f)\n\nDolphin 3.0 is the next generation of the Dolphin series of instruct-tuned models. Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.\n\nDolphin aims to be a general purpose model, similar to the models behind ChatGPT, Claude, Gemini. But these models present problems for businesses seeking to include AI in their products.\n\n1. They maintain control of the system prompt, deprecating and changing things as they wish, often causing software to break.\n2. They maintain control of the model versions, sometimes changing things silently, or deprecating older models that your business relies on.\n3. They maintain control of the alignment, and in particular the alignment is one-size-fits all, not tailored to the application.\n4. They can see all your queries and they can potentially use that data in ways you wouldn’t want. Dolphin, in contrast, is steerable and gives control to the system owner. You set the system prompt. You decide the alignment. You have control of your data. Dolphin does not impose its ethics or guidelines on you. You are the one who decides the guidelines.\n\n## References\n\n[Hugging Face](https://huggingface.co/cognitivecomputations/Dolphin3.0-Llama3.1-8B)\n\nWrite Preview \n\n<img src=\"/assets/library/dolphin3/ce75cebe-b012-4195-9a6b-aa6c4b68f93f\" width=\"360\" /> Dolphin 3.0 is the next generation of the Dolphin series of instruct-tuned models. Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases. Dolphin aims to be a general purpose model, similar to the models behind ChatGPT, Claude, Gemini. But these models present problems for businesses seeking to include AI in their products. 1\\. They maintain control of the system prompt, deprecating and changing things as they wish, often causing software to break. 2\\. They maintain control of the model versions, sometimes changing things silently, or deprecating older models that your business relies on. 3\\. They maintain control of the alignment, and in particular the alignment is one-size-fits all, not tailored to the application. 4\\. They can see all your queries and they can potentially use that data in ways you wouldn't want. Dolphin, in contrast, is steerable and gives control to the system owner. You set the system prompt. You decide the alignment. You have control of your data. Dolphin does not impose its ethics or guidelines on you. You are the one who decides the guidelines. ## References \\[Hugging Face\\](https://huggingface.co/cognitivecomputations/Dolphin3.0-Llama3.1-8B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dolphin3:latest",
        "size": "dolphin3:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin3:8b",
        "size": "dolphin3:8b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin3:8b-llama3.1-q4_K_M",
        "size": "dolphin3:8b-llama3.1-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin3:8b-llama3.1-q8_0",
        "size": "dolphin3:8b-llama3.1-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin3:8b-llama3.1-fp16",
        "size": "dolphin3:8b-llama3.1-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "olmo2",
    "link": "https://ollama.com/library/olmo2",
    "description": "OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks.",
    "pullCount": "2.5M",
    "updated": "7 months ago",
    "size": [
      "7b",
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n> Note: this model requires [Ollama 0.5.5](https://github.com/ollama/ollama/releases/tag/v0.5.5)\n\n![1732650119-wide-4x.webp](/assets/library/olmo2/71e694b3-a4fe-4bd1-8338-684506f85e8d)\n\nOLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks.\n\n## References\n\n[Blog post](https://allenai.org/blog/olmo2)\n\nWrite Preview \n\n\\> Note: this model requires \\[Ollama 0.5.5\\](https://github.com/ollama/ollama/releases/tag/v0.5.5) !\\[1732650119-wide-4x.webp\\](/assets/library/olmo2/71e694b3-a4fe-4bd1-8338-684506f85e8d) OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks. ## References \\[Blog post\\](https://allenai.org/blog/olmo2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "olmo2:latest",
        "size": "olmo2:latest",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:7b",
        "size": "olmo2:7b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:13b",
        "size": "olmo2:13b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:7b-1124-instruct-q4_K_M",
        "size": "olmo2:7b-1124-instruct-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:7b-1124-instruct-q8_0",
        "size": "olmo2:7b-1124-instruct-q8_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:7b-1124-instruct-fp16",
        "size": "olmo2:7b-1124-instruct-fp16",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:13b-1124-instruct-q4_K_M",
        "size": "olmo2:13b-1124-instruct-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:13b-1124-instruct-q8_0",
        "size": "olmo2:13b-1124-instruct-q8_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "olmo2:13b-1124-instruct-fp16",
        "size": "olmo2:13b-1124-instruct-fp16",
        "updated": "Text input • \n                    7 months ago"
      }
    ]
  },
  {
    "name": "mistral-nemo",
    "link": "https://ollama.com/library/mistral-nemo",
    "description": "A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.",
    "pullCount": "2.5M",
    "updated": "1 month ago",
    "size": [
      "12b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/mistral-nemo/72045292-694a-4867-88c8-8635c9d97030)\n\nMistral NeMo is a 12B model built in collaboration with NVIDIA. Mistral NeMo offers a large context window of up to 128k tokens. Its reasoning, world knowledge, and coding accuracy are state-of-the-art in its size category. As it relies on standard architecture, Mistral NeMo is easy to use and a drop-in replacement in any system using Mistral 7B.\n\n![nemo-base-performance.png](https://ollama.com/assets/library/mistral-nemo/1adf7b56-30e3-49a0-8a52-bb74c19d8a78)\n\n## Reference\n\n[Blog](https://mistral.ai/news/mistral-nemo/)\n\n[Hugging Face](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/mistral-nemo/72045292-694a-4867-88c8-8635c9d97030\" width=\"280\" /> Mistral NeMo is a 12B model built in collaboration with NVIDIA. Mistral NeMo offers a large context window of up to 128k tokens. Its reasoning, world knowledge, and coding accuracy are state-of-the-art in its size category. As it relies on standard architecture, Mistral NeMo is easy to use and a drop-in replacement in any system using Mistral 7B. !\\[nemo-base-performance.png\\](https://ollama.com/assets/library/mistral-nemo/1adf7b56-30e3-49a0-8a52-bb74c19d8a78) ## Reference \\[Blog\\](https://mistral.ai/news/mistral-nemo/) \\[Hugging Face\\](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral-nemo:latest",
        "size": "mistral-nemo:latest",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b",
        "size": "mistral-nemo:12b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q2_K",
        "size": "mistral-nemo:12b-instruct-2407-q2_K",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q3_K_S",
        "size": "mistral-nemo:12b-instruct-2407-q3_K_S",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q3_K_M",
        "size": "mistral-nemo:12b-instruct-2407-q3_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q3_K_L",
        "size": "mistral-nemo:12b-instruct-2407-q3_K_L",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q4_0",
        "size": "mistral-nemo:12b-instruct-2407-q4_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q4_1",
        "size": "mistral-nemo:12b-instruct-2407-q4_1",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q4_K_S",
        "size": "mistral-nemo:12b-instruct-2407-q4_K_S",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q4_K_M",
        "size": "mistral-nemo:12b-instruct-2407-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q5_0",
        "size": "mistral-nemo:12b-instruct-2407-q5_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q5_1",
        "size": "mistral-nemo:12b-instruct-2407-q5_1",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q5_K_S",
        "size": "mistral-nemo:12b-instruct-2407-q5_K_S",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q5_K_M",
        "size": "mistral-nemo:12b-instruct-2407-q5_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q6_K",
        "size": "mistral-nemo:12b-instruct-2407-q6_K",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-q8_0",
        "size": "mistral-nemo:12b-instruct-2407-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "mistral-nemo:12b-instruct-2407-fp16",
        "size": "mistral-nemo:12b-instruct-2407-fp16",
        "updated": "Text input • \n                    1 month ago"
      }
    ]
  },
  {
    "name": "llama3.2-vision",
    "link": "https://ollama.com/library/llama3.2-vision",
    "description": "Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.",
    "pullCount": "2.4M",
    "updated": "3 months ago",
    "size": [
      "11b",
      "90b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n![](/assets/library/llama3.2-vision/ea1fa75c-0d15-453d-a291-ce2d97d8646a)\n\nThe Llama 3.2-Vision collection of multimodal large language models (LLMs) is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes (text + images in / text out). The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. The models outperform many of the available open source and closed multimodal models on common industry benchmarks.\n\nSupported Languages: For text only tasks, English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported. Llama 3.2 has been trained on a broader collection of languages than these 8 supported languages. Note for image+text applications, English is the only language supported.\n\n## Usage\n\nFirst, pull the model:\n\n```\nollama pull llama3.2-vision\n\n```\n\n### Python Library\n\nTo use Llama 3.2 Vision with the Ollama [Python library](https://github.com/ollama/ollama-python):\n\n```\nimport ollama\n\nresponse = ollama.chat(\n    model='llama3.2-vision',\n    messages=[{\n        'role': 'user',\n        'content': 'What is in this image?',\n        'images': ['image.jpg']\n    }]\n)\n\nprint(response)\n\n```\n\n### JavaScript Library\n\nTo use Llama 3.2 Vision with the Ollama [JavaScript library](https://github.com/ollama/ollama-js):\n\n```\nimport ollama from 'ollama'\n\nconst response = await ollama.chat({\n  model: 'llama3.2-vision',\n  messages: [{\n    role: 'user',\n    content: 'What is in this image?',\n    images: ['image.jpg']\n  }]\n})\n\nconsole.log(response)\n\n```\n\n### cURL\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.2-vision\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"what is in this image?\",\n      \"images\": [\"<base64-encoded image data>\"]\n    }\n  ]\n}'\n\n```\n\n## References\n\n[GitHub](https://github.com/meta-llama/llama-models)\n\n[HuggingFace](https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf)\n\nWrite Preview \n\n<img src=\"/assets/library/llama3.2-vision/ea1fa75c-0d15-453d-a291-ce2d97d8646a\" width=\"280\" /> The Llama 3.2-Vision collection of multimodal large language models (LLMs) is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes (text + images in / text out). The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. The models outperform many of the available open source and closed multimodal models on common industry benchmarks. Supported Languages: For text only tasks, English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported. Llama 3.2 has been trained on a broader collection of languages than these 8 supported languages. Note for image+text applications, English is the only language supported. ## Usage First, pull the model: \\`\\`\\`bash ollama pull llama3.2-vision \\`\\`\\` ### Python Library To use Llama 3.2 Vision with the Ollama \\[Python library\\](https://github.com/ollama/ollama-python): \\`\\`\\`python import ollama response = ollama.chat( model='llama3.2-vision', messages=\\[{ 'role': 'user', 'content': 'What is in this image?', 'images': \\['image.jpg'\\] }\\] ) print(response) \\`\\`\\` ### JavaScript Library To use Llama 3.2 Vision with the Ollama \\[JavaScript library\\](https://github.com/ollama/ollama-js): \\`\\`\\`javascript import ollama from 'ollama' const response = await ollama.chat({ model: 'llama3.2-vision', messages: \\[{ role: 'user', content: 'What is in this image?', images: \\['image.jpg'\\] }\\] }) console.log(response) \\`\\`\\` ### cURL \\`\\`\\`shell curl http://localhost:11434/api/chat -d '{ \"model\": \"llama3.2-vision\", \"messages\": \\[ { \"role\": \"user\", \"content\": \"what is in this image?\", \"images\": \\[\"<base64-encoded image data>\"\\] } \\] }' \\`\\`\\` ## References \\[GitHub\\](https://github.com/meta-llama/llama-models) \\[HuggingFace\\](https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3.2-vision:latest",
        "size": "llama3.2-vision:latest",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:11b",
        "size": "llama3.2-vision:11b",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:90b",
        "size": "llama3.2-vision:90b",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:11b-instruct-q4_K_M",
        "size": "llama3.2-vision:11b-instruct-q4_K_M",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:11b-instruct-q8_0",
        "size": "llama3.2-vision:11b-instruct-q8_0",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:11b-instruct-fp16",
        "size": "llama3.2-vision:11b-instruct-fp16",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:90b-instruct-q4_K_M",
        "size": "llama3.2-vision:90b-instruct-q4_K_M",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:90b-instruct-q8_0",
        "size": "llama3.2-vision:90b-instruct-q8_0",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "llama3.2-vision:90b-instruct-fp16",
        "size": "llama3.2-vision:90b-instruct-fp16",
        "updated": "Text, Image input • \n                    3 months ago"
      }
    ]
  },
  {
    "name": "llama3.3",
    "link": "https://ollama.com/library/llama3.3",
    "description": "New state of the art 70B model. Llama 3.3 70B offers similar performance compared to the Llama 3.1 405B model.",
    "pullCount": "2.4M",
    "updated": "9 months ago",
    "size": [
      "70b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/llama3.2/be01fadf-7fbd-404d-929b-50a77249b030)\n\n**New state-of-the-art 70B** model from Meta that offers similar performance compared to Llama 3.1 405B model.\n\nThe Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.\n\n![llama 3.3 benchmark](/assets/library/llama3.3/70cc3470-fa00-4179-b32e-d40d6494ff4e)\n\n**Supported languages**: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n### New capabilities\n\nThis release introduces new capabilities, including a longer context window, multilingual inputs and outputs and possible integrations by developers with third party tools. Building with these new capabilities requires specific considerations in addition to the best practices that generally apply across all Generative AI use cases.\n\n**Tool-use:** Just like in standard software development, developers are responsible for the integration of the LLM with the tools and services of their choice. They should define a clear policy for their use case and assess the integrity of the third party services they use to be aware of the safety and security limitations when using this capability. Refer to the Responsible Use Guide for best practices on the safe deployment of the third party safeguards.\n\n**Multilinguality:** Llama 3.3 supports 7 languages in addition to English: French, German, Hindi, Italian, Portuguese, Spanish, and Thai. Llama may be able to output text in other languages than those that meet performance thresholds for safety and helpfulness. We strongly discourage developers from using this model to converse in non-supported languages without implementing finetuning and system controls in alignment with their policies and the best practices shared in the Responsible Use Guide.\n\n### Intended Use\n\n**Intended Use Cases** Llama 3.3 is intended for commercial and research use in multiple languages. Instruction tuned text only models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks. The Llama 3.3 model also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation. The Llama 3.3 Community License allows for these use cases.\n\n**Out-of-scope** Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 3.3 Community License. Use in languages beyond those explicitly referenced as supported in this model card\\*\\*.\n\n**Note:** Llama 3.3 has been trained on a broader collection of languages than the 8 supported languages. Developers may fine-tune Llama 3.3 models for languages beyond the 8 supported languages provided they comply with the Llama 3.3 Community License and the Acceptable Use Policy and in such cases are responsible for ensuring that any uses of Llama 3.3 in additional languages is done in a safe and responsible manner.\n\nWrite Preview \n\n<img src=\"/assets/library/llama3.2/be01fadf-7fbd-404d-929b-50a77249b030\" width=\"280\" /> \\*\\*New state-of-the-art 70B\\*\\* model from Meta that offers similar performance compared to Llama 3.1 405B model. The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. !\\[llama 3.3 benchmark\\](/assets/library/llama3.3/70cc3470-fa00-4179-b32e-d40d6494ff4e) \\*\\*Supported languages\\*\\*: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai. ### New capabilities This release introduces new capabilities, including a longer context window, multilingual inputs and outputs and possible integrations by developers with third party tools. Building with these new capabilities requires specific considerations in addition to the best practices that generally apply across all Generative AI use cases. \\*\\*Tool-use:\\*\\* Just like in standard software development, developers are responsible for the integration of the LLM with the tools and services of their choice. They should define a clear policy for their use case and assess the integrity of the third party services they use to be aware of the safety and security limitations when using this capability. Refer to the Responsible Use Guide for best practices on the safe deployment of the third party safeguards. \\*\\*Multilinguality:\\*\\* Llama 3.3 supports 7 languages in addition to English: French, German, Hindi, Italian, Portuguese, Spanish, and Thai. Llama may be able to output text in other languages than those that meet performance thresholds for safety and helpfulness. We strongly discourage developers from using this model to converse in non-supported languages without implementing finetuning and system controls in alignment with their policies and the best practices shared in the Responsible Use Guide. ### Intended Use \\*\\*Intended Use Cases\\*\\* Llama 3.3 is intended for commercial and research use in multiple languages. Instruction tuned text only models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks. The Llama 3.3 model also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation. The Llama 3.3 Community License allows for these use cases. \\*\\*Out-of-scope\\*\\* Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 3.3 Community License. Use in languages beyond those explicitly referenced as supported in this model card\\*\\*. \\*\\*Note:\\*\\* Llama 3.3 has been trained on a broader collection of languages than the 8 supported languages. Developers may fine-tune Llama 3.3 models for languages beyond the 8 supported languages provided they comply with the Llama 3.3 Community License and the Acceptable Use Policy and in such cases are responsible for ensuring that any uses of Llama 3.3 in additional languages is done in a safe and responsible manner. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3.3:latest",
        "size": "llama3.3:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b",
        "size": "llama3.3:70b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q2_K",
        "size": "llama3.3:70b-instruct-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q3_K_S",
        "size": "llama3.3:70b-instruct-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q3_K_M",
        "size": "llama3.3:70b-instruct-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q4_0",
        "size": "llama3.3:70b-instruct-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q4_K_S",
        "size": "llama3.3:70b-instruct-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q4_K_M",
        "size": "llama3.3:70b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q5_0",
        "size": "llama3.3:70b-instruct-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q5_1",
        "size": "llama3.3:70b-instruct-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q5_K_M",
        "size": "llama3.3:70b-instruct-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q6_K",
        "size": "llama3.3:70b-instruct-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-q8_0",
        "size": "llama3.3:70b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "llama3.3:70b-instruct-fp16",
        "size": "llama3.3:70b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "deepseek-v3",
    "link": "https://ollama.com/library/deepseek-v3",
    "description": "A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.",
    "pullCount": "2.2M",
    "updated": "7 months ago",
    "size": [
      "671b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n> Note: this model requires [Ollama 0.5.5](https://github.com/ollama/ollama/releases/tag/v0.5.5) or later.\n\n![](/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a)\n\nDeepSeek-V3 achieves a significant breakthrough in inference speed over previous models. It tops the leaderboard among open-source models and rivals the most advanced closed-source models globally.\n\n## References\n\n[GitHub](https://github.com/deepseek-ai/DeepSeek-V3)\n\n[Paper](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek%5FV3.pdf)\n\nWrite Preview \n\n\\> Note: this model requires \\[Ollama 0.5.5\\](https://github.com/ollama/ollama/releases/tag/v0.5.5) or later. <img src=\"/assets/library/deepseek-v3/069ccc94-63b0-41e6-b2b3-e8e56068ab1a\" width=\"320\" /> DeepSeek-V3 achieves a significant breakthrough in inference speed over previous models. It tops the leaderboard among open-source models and rivals the most advanced closed-source models globally. ## References \\[GitHub\\](https://github.com/deepseek-ai/DeepSeek-V3) \\[Paper\\](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek\\_V3.pdf) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-v3:latest",
        "size": "deepseek-v3:latest",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "deepseek-v3:671b",
        "size": "deepseek-v3:671b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "deepseek-v3:671b-q4_K_M",
        "size": "deepseek-v3:671b-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "deepseek-v3:671b-q8_0",
        "size": "deepseek-v3:671b-q8_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "deepseek-v3:671b-fp16",
        "size": "deepseek-v3:671b-fp16",
        "updated": "Text input • \n                    7 months ago"
      }
    ]
  },
  {
    "name": "bge-m3",
    "link": "https://ollama.com/library/bge-m3",
    "description": "BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.",
    "pullCount": "2M",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\nBGE-M3 is based on the XLM-RoBERTa architecture and is distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity:\n\n* Multi-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval.\n* Multi-Linguality: It can support more than 100 working languages.\n* Multi-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.\n\n**Benchmarks from the open-source community** ![image.png](https://ollama.com/assets/library/bge-m3/17a9804b-f3da-4d09-bd18-90d4fe8900d3)\n\n```\n@misc{bge-m3,\n      title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation}, \n      author={Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu},\n      year={2024},\n      eprint={2402.03216},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n```\n\nWrite Preview \n\nBGE-M3 is based on the XLM-RoBERTa architecture and is distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity: - Multi-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval. - Multi-Linguality: It can support more than 100 working languages. - Multi-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens. \\*\\*Benchmarks from the open-source community\\*\\* !\\[image.png\\](https://ollama.com/assets/library/bge-m3/17a9804b-f3da-4d09-bd18-90d4fe8900d3) \\`\\`\\` @misc{bge-m3, title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation}, author={Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu}, year={2024}, eprint={2402.03216}, archivePrefix={arXiv}, primaryClass={cs.CL} } \\`\\`\\` \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "bge-m3:latest",
        "size": "bge-m3:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bge-m3:567m",
        "size": "bge-m3:567m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bge-m3:567m-fp16",
        "size": "bge-m3:567m-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "mistral-small",
    "link": "https://ollama.com/library/mistral-small",
    "description": "Mistral Small 3 sets a new benchmark in the “small” Large Language Models category below 70B.",
    "pullCount": "1.7M",
    "updated": "7 months ago",
    "size": [
      "22b",
      "24b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/mistral-small/87657512-b656-4c53-a8bd-64f0591d6fa9)\n\nMistral Small 3 sets a new benchmark in the “small” Large Language Models category below 70B, boasting 24B parameters and achieving state-of-the-art capabilities comparable to larger models.\n\nMistral Small can be deployed locally and is exceptionally “knowledge-dense”, fitting in a single RTX 4090 or a 32GB RAM MacBook once quantized. Perfect for:\n\n* Fast response conversational agents.\n* Low latency function calling.\n* Subject matter experts via fine-tuning.\n* Local inference for hobbyists and organizations handling sensitive data.\n\n### Key Features\n\n* **Multilingual:** Supports dozens of languages, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch, and Polish.\n* **Agent-Centric:** Offers best-in-class agentic capabilities with native function calling and JSON outputting.\n* **Advanced Reasoning:** State-of-the-art conversational and reasoning capabilities.\n* **Apache 2.0 License:** Open license allowing usage and modification for both commercial and non-commercial purposes.\n* **Context Window:** A 32k context window.\n* **System Prompt:** Maintains strong adherence and support for system prompts.\n* **Tokenizer:** Utilizes a Tekken tokenizer with a 131k vocabulary size.\n\n### Human Evaluations\n\n![Human ratings](/assets/library/mistral-small/90f227bd-9751-4fe9-aa23-4d5d89b9d0c6)\n\nWe conducted side by side evaluations with an external third-party vendor, on a set of over 1k proprietary coding and generalist prompts. Evaluators were tasked with selecting their preferred model response from anonymized generations produced by Mistral Small 3 vs another model. We are aware that in some cases the benchmarks on human judgement starkly differ from publicly available benchmarks, but have taken extra caution in verifying a fair evaluation. We are confident that the above benchmarks are valid.\n\n### Instruct performance\n\nOur instruction tuned model performs competitively with open weight models three times its size and with proprietary GPT4o-mini model across Code, Math, General knowledge and Instruction following benchmarks.\n\n![instruct performance](/assets/library/mistral-small/d27f75e4-0dae-4721-bade-2999a1dd4a7b) ![instruct performance](/assets/library/mistral-small/e677ae9e-edfa-47f9-a35c-b1eb9dfb51c8)\n\n![instruct performance](/assets/library/mistral-small/4545bb49-d87f-4731-bfdb-e191dc2c2a9a)\n\nPerformance accuracy on all benchmarks were obtained through the same internal evaluation pipeline - as such, numbers may vary slightly from previously reported performance (Qwen2.5-32B-Instruct, Llama-3.3-70B-Instruct, Gemma-2-27B-IT). Judge based evals such as Wildbench, Arena hard and MTBench were based on gpt-4o-2024-05-13.\n\nCustomers are evaluating Mistral Small 3 across multiple industries, including:\n\n* Financial services customers for fraud detection\n* Healthcare providers for customer triaging\n* Robotics, automotive, and manufacturing companies for on-device command and control\n* Horizontal use cases across customers include virtual customer service, and sentiment and feedback analysis.\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/mistral-small/87657512-b656-4c53-a8bd-64f0591d6fa9\" width=\"200\"/> Mistral Small 3 sets a new benchmark in the \"small\" Large Language Models category below 70B, boasting 24B parameters and achieving state-of-the-art capabilities comparable to larger models. Mistral Small can be deployed locally and is exceptionally \"knowledge-dense\", fitting in a single RTX 4090 or a 32GB RAM MacBook once quantized. Perfect for: - Fast response conversational agents. - Low latency function calling. - Subject matter experts via fine-tuning. - Local inference for hobbyists and organizations handling sensitive data. ### Key Features - \\*\\*Multilingual:\\*\\* Supports dozens of languages, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch, and Polish. - \\*\\*Agent-Centric:\\*\\* Offers best-in-class agentic capabilities with native function calling and JSON outputting. - \\*\\*Advanced Reasoning:\\*\\* State-of-the-art conversational and reasoning capabilities. - \\*\\*Apache 2.0 License:\\*\\* Open license allowing usage and modification for both commercial and non-commercial purposes. - \\*\\*Context Window:\\*\\* A 32k context window. - \\*\\*System Prompt:\\*\\* Maintains strong adherence and support for system prompts. - \\*\\*Tokenizer:\\*\\* Utilizes a Tekken tokenizer with a 131k vocabulary size. ### Human Evaluations !\\[Human ratings\\](/assets/library/mistral-small/90f227bd-9751-4fe9-aa23-4d5d89b9d0c6) We conducted side by side evaluations with an external third-party vendor, on a set of over 1k proprietary coding and generalist prompts. Evaluators were tasked with selecting their preferred model response from anonymized generations produced by Mistral Small 3 vs another model. We are aware that in some cases the benchmarks on human judgement starkly differ from publicly available benchmarks, but have taken extra caution in verifying a fair evaluation. We are confident that the above benchmarks are valid. ### Instruct performance Our instruction tuned model performs competitively with open weight models three times its size and with proprietary GPT4o-mini model across Code, Math, General knowledge and Instruction following benchmarks. !\\[instruct performance\\](/assets/library/mistral-small/d27f75e4-0dae-4721-bade-2999a1dd4a7b) !\\[instruct performance\\](/assets/library/mistral-small/e677ae9e-edfa-47f9-a35c-b1eb9dfb51c8) !\\[instruct performance\\](/assets/library/mistral-small/4545bb49-d87f-4731-bfdb-e191dc2c2a9a) Performance accuracy on all benchmarks were obtained through the same internal evaluation pipeline - as such, numbers may vary slightly from previously reported performance (Qwen2.5-32B-Instruct, Llama-3.3-70B-Instruct, Gemma-2-27B-IT). Judge based evals such as Wildbench, Arena hard and MTBench were based on gpt-4o-2024-05-13\\. Customers are evaluating Mistral Small 3 across multiple industries, including: - Financial services customers for fraud detection - Healthcare providers for customer triaging - Robotics, automotive, and manufacturing companies for on-device command and control - Horizontal use cases across customers include virtual customer service, and sentiment and feedback analysis. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral-small:latest",
        "size": "mistral-small:latest",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "mistral-small:22b",
        "size": "mistral-small:22b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:24b",
        "size": "mistral-small:24b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q2_K",
        "size": "mistral-small:22b-instruct-2409-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q3_K_S",
        "size": "mistral-small:22b-instruct-2409-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q3_K_M",
        "size": "mistral-small:22b-instruct-2409-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q3_K_L",
        "size": "mistral-small:22b-instruct-2409-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q4_0",
        "size": "mistral-small:22b-instruct-2409-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q4_1",
        "size": "mistral-small:22b-instruct-2409-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q4_K_S",
        "size": "mistral-small:22b-instruct-2409-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q4_K_M",
        "size": "mistral-small:22b-instruct-2409-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q5_0",
        "size": "mistral-small:22b-instruct-2409-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q5_1",
        "size": "mistral-small:22b-instruct-2409-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q5_K_S",
        "size": "mistral-small:22b-instruct-2409-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q5_K_M",
        "size": "mistral-small:22b-instruct-2409-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q6_K",
        "size": "mistral-small:22b-instruct-2409-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-q8_0",
        "size": "mistral-small:22b-instruct-2409-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:22b-instruct-2409-fp16",
        "size": "mistral-small:22b-instruct-2409-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "mistral-small:24b-instruct-2501-q4_K_M",
        "size": "mistral-small:24b-instruct-2501-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "mistral-small:24b-instruct-2501-q8_0",
        "size": "mistral-small:24b-instruct-2501-q8_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "mistral-small:24b-instruct-2501-fp16",
        "size": "mistral-small:24b-instruct-2501-fp16",
        "updated": "Text input • \n                    7 months ago"
      }
    ]
  },
  {
    "name": "qwq",
    "link": "https://ollama.com/library/qwq",
    "description": "QwQ is the reasoning model of the Qwen series.",
    "pullCount": "1.6M",
    "updated": "5 months ago",
    "size": [
      "32b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\nQwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.\n\n![](/assets/library/qwq/e3d71b1c-9c62-413a-a63a-1ca604189a17)\n\n### Future Work\n\nThis marks Qwen’s initial step in scaling Reinforcement Learning (RL) to enhance reasoning capabilities. Through this journey, we have not only witnessed the immense potential of scaled RL but also recognized the untapped possibilities within pretrained language models. As we work towards developing the next generation of Qwen, we are confident that combining stronger foundation models with RL powered by scaled computational resources will propel us closer to achieving Artificial General Intelligence (AGI). Additionally, we are actively exploring the integration of agents with RL to enable long-horizon reasoning, aiming to unlock greater intelligence with inference time scaling.\n\n### Reference\n\n* [Blog](https://qwenlm.github.io/blog/qwq-32b/)\n\nWrite Preview \n\nQwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini. !\\[\\](/assets/library/qwq/e3d71b1c-9c62-413a-a63a-1ca604189a17) ### Future Work This marks Qwen’s initial step in scaling Reinforcement Learning (RL) to enhance reasoning capabilities. Through this journey, we have not only witnessed the immense potential of scaled RL but also recognized the untapped possibilities within pretrained language models. As we work towards developing the next generation of Qwen, we are confident that combining stronger foundation models with RL powered by scaled computational resources will propel us closer to achieving Artificial General Intelligence (AGI). Additionally, we are actively exploring the integration of agents with RL to enable long-horizon reasoning, aiming to unlock greater intelligence with inference time scaling. ### Reference - \\[Blog\\](https://qwenlm.github.io/blog/qwq-32b/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwq:latest",
        "size": "qwq:latest",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "qwq:32b",
        "size": "qwq:32b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "qwq:32b-preview-q4_K_M",
        "size": "qwq:32b-preview-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwq:32b-preview-q8_0",
        "size": "qwq:32b-preview-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwq:32b-preview-fp16",
        "size": "qwq:32b-preview-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "qwq:32b-q4_K_M",
        "size": "qwq:32b-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "qwq:32b-q8_0",
        "size": "qwq:32b-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "qwq:32b-fp16",
        "size": "qwq:32b-fp16",
        "updated": "Text input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "smollm2",
    "link": "https://ollama.com/library/smollm2",
    "description": "SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters.",
    "pullCount": "1.6M",
    "updated": "10 months ago",
    "size": [
      "135m360m1.7b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![y45hIMNREW7w_XpHYB_0q.png](/assets/library/smollm2/2616a6ce-5645-48c3-bd5d-9a00f1dd0c9e)\n\nSmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters. They are capable of solving a wide range of tasks while being lightweight enough to run on-device.\n\n![benchmark](/assets/library/smollm2/1a637eca-6f07-4572-8e01-011339c072d8)\n\n## References\n\n[HuggingFace](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9)\n\nWrite Preview \n\n!\\[y45hIMNREW7w\\_XpHYB\\_0q.png\\](/assets/library/smollm2/2616a6ce-5645-48c3-bd5d-9a00f1dd0c9e) SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters. They are capable of solving a wide range of tasks while being lightweight enough to run on-device. !\\[benchmark\\](/assets/library/smollm2/1a637eca-6f07-4572-8e01-011339c072d8) ## References \\[HuggingFace\\](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "smollm2:latest",
        "size": "smollm2:latest",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m",
        "size": "smollm2:135m",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m",
        "size": "smollm2:360m",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b",
        "size": "smollm2:1.7b",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q2_K",
        "size": "smollm2:135m-instruct-q2_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q3_K_S",
        "size": "smollm2:135m-instruct-q3_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q3_K_M",
        "size": "smollm2:135m-instruct-q3_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q3_K_L",
        "size": "smollm2:135m-instruct-q3_K_L",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q4_0",
        "size": "smollm2:135m-instruct-q4_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q4_1",
        "size": "smollm2:135m-instruct-q4_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q4_K_S",
        "size": "smollm2:135m-instruct-q4_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q4_K_M",
        "size": "smollm2:135m-instruct-q4_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q5_0",
        "size": "smollm2:135m-instruct-q5_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q5_1",
        "size": "smollm2:135m-instruct-q5_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q5_K_S",
        "size": "smollm2:135m-instruct-q5_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q5_K_M",
        "size": "smollm2:135m-instruct-q5_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q6_K",
        "size": "smollm2:135m-instruct-q6_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-q8_0",
        "size": "smollm2:135m-instruct-q8_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:135m-instruct-fp16",
        "size": "smollm2:135m-instruct-fp16",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q2_K",
        "size": "smollm2:360m-instruct-q2_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q3_K_S",
        "size": "smollm2:360m-instruct-q3_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q3_K_M",
        "size": "smollm2:360m-instruct-q3_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q3_K_L",
        "size": "smollm2:360m-instruct-q3_K_L",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q4_0",
        "size": "smollm2:360m-instruct-q4_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q4_1",
        "size": "smollm2:360m-instruct-q4_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q4_K_S",
        "size": "smollm2:360m-instruct-q4_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q4_K_M",
        "size": "smollm2:360m-instruct-q4_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q5_0",
        "size": "smollm2:360m-instruct-q5_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q5_1",
        "size": "smollm2:360m-instruct-q5_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q5_K_S",
        "size": "smollm2:360m-instruct-q5_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q5_K_M",
        "size": "smollm2:360m-instruct-q5_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q6_K",
        "size": "smollm2:360m-instruct-q6_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-q8_0",
        "size": "smollm2:360m-instruct-q8_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:360m-instruct-fp16",
        "size": "smollm2:360m-instruct-fp16",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q2_K",
        "size": "smollm2:1.7b-instruct-q2_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q3_K_S",
        "size": "smollm2:1.7b-instruct-q3_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q3_K_M",
        "size": "smollm2:1.7b-instruct-q3_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q3_K_L",
        "size": "smollm2:1.7b-instruct-q3_K_L",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q4_0",
        "size": "smollm2:1.7b-instruct-q4_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q4_1",
        "size": "smollm2:1.7b-instruct-q4_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q4_K_S",
        "size": "smollm2:1.7b-instruct-q4_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q4_K_M",
        "size": "smollm2:1.7b-instruct-q4_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q5_0",
        "size": "smollm2:1.7b-instruct-q5_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q5_1",
        "size": "smollm2:1.7b-instruct-q5_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q5_K_S",
        "size": "smollm2:1.7b-instruct-q5_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q5_K_M",
        "size": "smollm2:1.7b-instruct-q5_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q6_K",
        "size": "smollm2:1.7b-instruct-q6_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-q8_0",
        "size": "smollm2:1.7b-instruct-q8_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "smollm2:1.7b-instruct-fp16",
        "size": "smollm2:1.7b-instruct-fp16",
        "updated": "Text input • \n                    10 months ago"
      }
    ]
  },
  {
    "name": "llava-llama3",
    "link": "https://ollama.com/library/llava-llama3",
    "description": "A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several benchmarks.",
    "pullCount": "1.6M",
    "updated": "1 year ago",
    "size": [
      "8b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/llava-llama3/dc3b65cd-62de-45cd-93f9-5c6da62214fa)\n\n`llava-llama3` is a LLaVA model fine-tuned from Llama 3 Instruct and CLIP-ViT-Large-patch14-336 with ShareGPT4V-PT and InternVL-SFT by XTuner.\n\n![](https://ollama.com/assets/library/llava-llama3/a4be49e3-b088-4f59-8536-4e55a98ccf4c)\n\n## References\n\n[Hugging Face](https://huggingface.co/xtuner/llava-llama-3-8b-v1%5F1-gguf)\n\n[GitHub](https://github.com/InternLM/xtuner/tree/main)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/llava-llama3/dc3b65cd-62de-45cd-93f9-5c6da62214fa\" width=\"320\" /> \\`llava-llama3\\` is a LLaVA model fine-tuned from Llama 3 Instruct and CLIP-ViT-Large-patch14-336 with ShareGPT4V-PT and InternVL-SFT by XTuner. <img src=\"https://ollama.com/assets/library/llava-llama3/a4be49e3-b088-4f59-8536-4e55a98ccf4c\" width=\"480\" /> ## References \\[Hugging Face\\](https://huggingface.co/xtuner/llava-llama-3-8b-v1\\_1-gguf) \\[GitHub\\](https://github.com/InternLM/xtuner/tree/main) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llava-llama3:latest",
        "size": "llava-llama3:latest",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava-llama3:8b",
        "size": "llava-llama3:8b",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava-llama3:8b-v1.1-q4_0",
        "size": "llava-llama3:8b-v1.1-q4_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "llava-llama3:8b-v1.1-fp16",
        "size": "llava-llama3:8b-v1.1-fp16",
        "updated": "Text, Image input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "mixtral",
    "link": "https://ollama.com/library/mixtral",
    "description": "A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes.",
    "pullCount": "1.3M",
    "updated": "8 months ago",
    "size": [
      "8x7b",
      "8x22b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/59bf76bc-1f6f-4a45-be4f-d6a13d7f0645)\n\nThe Mixtral large Language Models (LLM) are a set of pretrained generative Sparse Mixture of Experts.\n\n## Sizes\n\n* `mixtral:8x22b`\n* `mixtral:8x7b`\n\n## Mixtral 8x22b\n\n```\nollama run mixtral:8x22b\n\n```\n\nMixtral 8x22B sets a new standard for performance and efficiency within the AI community. It is a sparse Mixture-of-Experts (SMoE) model that uses only 39B active parameters out of 141B, offering unparalleled cost efficiency for its size.\n\nMixtral 8x22B comes with the following strengths:\n\n* It is fluent in English, French, Italian, German, and Spanish\n* It has strong maths and coding capabilities\n* It is natively capable of function calling\n* 64K tokens context window allows precise information recall from large documents\n\n## References\n\n[Announcement](https://mistral.ai/news/mixtral-of-experts/)\n\n[HuggingFace](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/59bf76bc-1f6f-4a45-be4f-d6a13d7f0645\" width=\"320\"> The Mixtral large Language Models (LLM) are a set of pretrained generative Sparse Mixture of Experts. ## Sizes \\* \\`mixtral:8x22b\\` \\* \\`mixtral:8x7b\\` ## Mixtral 8x22b \\`\\`\\` ollama run mixtral:8x22b \\`\\`\\` Mixtral 8x22B sets a new standard for performance and efficiency within the AI community. It is a sparse Mixture-of-Experts (SMoE) model that uses only 39B active parameters out of 141B, offering unparalleled cost efficiency for its size. Mixtral 8x22B comes with the following strengths: \\* It is fluent in English, French, Italian, German, and Spanish \\* It has strong maths and coding capabilities \\* It is natively capable of function calling \\* 64K tokens context window allows precise information recall from large documents ## References \\[Announcement\\](https://mistral.ai/news/mixtral-of-experts/) \\[HuggingFace\\](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mixtral:latest",
        "size": "mixtral:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:instruct",
        "size": "mixtral:instruct",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:text",
        "size": "mixtral:text",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:v0.1",
        "size": "mixtral:v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x7b",
        "size": "mixtral:8x7b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x22b",
        "size": "mixtral:8x22b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q2_K",
        "size": "mixtral:8x7b-instruct-v0.1-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q3_K_S",
        "size": "mixtral:8x7b-instruct-v0.1-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q3_K_M",
        "size": "mixtral:8x7b-instruct-v0.1-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q3_K_L",
        "size": "mixtral:8x7b-instruct-v0.1-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q4_0",
        "size": "mixtral:8x7b-instruct-v0.1-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q4_1",
        "size": "mixtral:8x7b-instruct-v0.1-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q4_K_S",
        "size": "mixtral:8x7b-instruct-v0.1-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q4_K_M",
        "size": "mixtral:8x7b-instruct-v0.1-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q5_0",
        "size": "mixtral:8x7b-instruct-v0.1-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q5_1",
        "size": "mixtral:8x7b-instruct-v0.1-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q5_K_S",
        "size": "mixtral:8x7b-instruct-v0.1-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q5_K_M",
        "size": "mixtral:8x7b-instruct-v0.1-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q6_K",
        "size": "mixtral:8x7b-instruct-v0.1-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-q8_0",
        "size": "mixtral:8x7b-instruct-v0.1-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-instruct-v0.1-fp16",
        "size": "mixtral:8x7b-instruct-v0.1-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text",
        "size": "mixtral:8x7b-text",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q2_K",
        "size": "mixtral:8x7b-text-v0.1-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q3_K_S",
        "size": "mixtral:8x7b-text-v0.1-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q3_K_M",
        "size": "mixtral:8x7b-text-v0.1-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q3_K_L",
        "size": "mixtral:8x7b-text-v0.1-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q4_0",
        "size": "mixtral:8x7b-text-v0.1-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q4_1",
        "size": "mixtral:8x7b-text-v0.1-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q4_K_S",
        "size": "mixtral:8x7b-text-v0.1-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q4_K_M",
        "size": "mixtral:8x7b-text-v0.1-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q5_0",
        "size": "mixtral:8x7b-text-v0.1-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q5_1",
        "size": "mixtral:8x7b-text-v0.1-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q5_K_S",
        "size": "mixtral:8x7b-text-v0.1-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q5_K_M",
        "size": "mixtral:8x7b-text-v0.1-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q6_K",
        "size": "mixtral:8x7b-text-v0.1-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-q8_0",
        "size": "mixtral:8x7b-text-v0.1-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x7b-text-v0.1-fp16",
        "size": "mixtral:8x7b-text-v0.1-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "mixtral:8x22b-instruct",
        "size": "mixtral:8x22b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q2_K",
        "size": "mixtral:8x22b-instruct-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q3_K_S",
        "size": "mixtral:8x22b-instruct-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q3_K_M",
        "size": "mixtral:8x22b-instruct-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q3_K_L",
        "size": "mixtral:8x22b-instruct-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q4_0",
        "size": "mixtral:8x22b-instruct-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q4_1",
        "size": "mixtral:8x22b-instruct-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q4_K_S",
        "size": "mixtral:8x22b-instruct-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q4_K_M",
        "size": "mixtral:8x22b-instruct-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q5_0",
        "size": "mixtral:8x22b-instruct-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q5_1",
        "size": "mixtral:8x22b-instruct-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q5_K_S",
        "size": "mixtral:8x22b-instruct-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q5_K_M",
        "size": "mixtral:8x22b-instruct-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q6_K",
        "size": "mixtral:8x22b-instruct-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-q8_0",
        "size": "mixtral:8x22b-instruct-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-instruct-v0.1-fp16",
        "size": "mixtral:8x22b-instruct-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text",
        "size": "mixtral:8x22b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q2_K",
        "size": "mixtral:8x22b-text-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q3_K_S",
        "size": "mixtral:8x22b-text-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q3_K_M",
        "size": "mixtral:8x22b-text-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q3_K_L",
        "size": "mixtral:8x22b-text-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q4_0",
        "size": "mixtral:8x22b-text-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q4_1",
        "size": "mixtral:8x22b-text-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q4_K_S",
        "size": "mixtral:8x22b-text-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q4_K_M",
        "size": "mixtral:8x22b-text-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q5_0",
        "size": "mixtral:8x22b-text-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q5_1",
        "size": "mixtral:8x22b-text-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q5_K_S",
        "size": "mixtral:8x22b-text-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q5_K_M",
        "size": "mixtral:8x22b-text-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q6_K",
        "size": "mixtral:8x22b-text-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-q8_0",
        "size": "mixtral:8x22b-text-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:8x22b-text-v0.1-fp16",
        "size": "mixtral:8x22b-text-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mixtral:v0.1-instruct",
        "size": "mixtral:v0.1-instruct",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "all-minilm",
    "link": "https://ollama.com/library/all-minilm",
    "description": "Embedding models on very large sentence level datasets.",
    "pullCount": "1.3M",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/4a6d8231-b7b5-411b-80b9-db37e5323cf9)\n\n> Note: this model requires Ollama 0.1.26 or later. [Download it here](https://ollama.com/download). It can only be used to generate embeddings.\n\nThe project aims to train sentence embedding models on very large sentence level datasets using a self-supervised contrastive learning objective.\n\n## Usage\n\n### REST API\n\n```\ncurl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"all-minilm\",\n  \"prompt\": \"The sky is blue because of Rayleigh scattering\"\n}'\n\n```\n\n### Python library\n\n```\nollama.embeddings(model='all-minilm', prompt='The sky is blue because of Rayleigh scattering')\n\n```\n\n### Javascript library\n\n```\nollama.embeddings({ model: 'all-minilm', prompt: 'The sky is blue because of Rayleigh scattering' })\n\n```\n\n## References\n\n[HuggingFace](https://huggingface.co/sentence-transformers)\n\n[Website](https://www.sbert.net/)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/4a6d8231-b7b5-411b-80b9-db37e5323cf9\" width=\"320\" /> > Note: this model requires Ollama 0.1.26 or later. \\[Download it here\\](https://ollama.com/download). It can only be used to generate embeddings. The project aims to train sentence embedding models on very large sentence level datasets using a self-supervised contrastive learning objective. ## Usage ### REST API \\`\\`\\` curl http://localhost:11434/api/embeddings -d '{ \"model\": \"all-minilm\", \"prompt\": \"The sky is blue because of Rayleigh scattering\" }' \\`\\`\\` ### Python library \\`\\`\\` ollama.embeddings(model='all-minilm', prompt='The sky is blue because of Rayleigh scattering') \\`\\`\\` ### Javascript library \\`\\`\\` ollama.embeddings({ model: 'all-minilm', prompt: 'The sky is blue because of Rayleigh scattering' }) \\`\\`\\` ## References \\[HuggingFace\\](https://huggingface.co/sentence-transformers) \\[Website\\](https://www.sbert.net/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "all-minilm:latest",
        "size": "all-minilm:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:l12",
        "size": "all-minilm:l12",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:l6",
        "size": "all-minilm:l6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:v2",
        "size": "all-minilm:v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:22m",
        "size": "all-minilm:22m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:33m",
        "size": "all-minilm:33m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:22m-l6-v2-fp16",
        "size": "all-minilm:22m-l6-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:33m-l12-v2-fp16",
        "size": "all-minilm:33m-l12-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:l12-v2",
        "size": "all-minilm:l12-v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "all-minilm:l6-v2",
        "size": "all-minilm:l6-v2",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama2-uncensored",
    "link": "https://ollama.com/library/llama2-uncensored",
    "description": "Uncensored Llama 2 model by George Sung and Jarrad Hope.",
    "pullCount": "1.3M",
    "updated": "1 year ago",
    "size": [
      "7b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nLlama 2 Uncensored is based on Meta’s Llama 2 model, and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford in his [blog post](https://erichartford.com/uncensored-models).\n\n### CLI\n\nOpen the terminal and run `ollama run llama2-uncensored`\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2-uncensored\",\n  \"prompt\":\"Write a recipe for dangerously spicy mayo.\"\n }'\n\n```\n\n[API documentation](https://github.com/jmorganca/ollama/blob/main/docs/api.md)\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 70b models generally require at least 64GB of RAM\n\n## References\n\n<https://erichartford.com/uncensored-models>\n\n7b parameters original source:[George Sung](https://huggingface.co/georgesung/llama2%5F7b%5Fchat%5Funcensored)\n\n70b parameters original source:[George Sung](https://huggingface.co/jarradh/llama2%5F70b%5Fchat%5Funcensored)\n\nWrite Preview \n\nLlama 2 Uncensored is based on Meta's Llama 2 model, and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford in his \\[blog post\\](https://erichartford.com/uncensored-models). ### CLI Open the terminal and run \\`ollama run llama2-uncensored\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"llama2-uncensored\", \"prompt\":\"Write a recipe for dangerously spicy mayo.\" }' \\`\\`\\` \\[API documentation\\](https://github.com/jmorganca/ollama/blob/main/docs/api.md) ## Memory requirements - 7b models generally require at least 8GB of RAM - 70b models generally require at least 64GB of RAM ## References \\[https://erichartford.com/uncensored-models\\](https://erichartford.com/uncensored-models ) 7b parameters original source: \\[George Sung\\](https://huggingface.co/georgesung/llama2\\_7b\\_chat\\_uncensored) 70b parameters original source: \\[George Sung\\](https://huggingface.co/jarradh/llama2\\_70b\\_chat\\_uncensored) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama2-uncensored:latest",
        "size": "llama2-uncensored:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b",
        "size": "llama2-uncensored:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b",
        "size": "llama2-uncensored:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat",
        "size": "llama2-uncensored:7b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q2_K",
        "size": "llama2-uncensored:7b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q3_K_S",
        "size": "llama2-uncensored:7b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q3_K_M",
        "size": "llama2-uncensored:7b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q3_K_L",
        "size": "llama2-uncensored:7b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q4_0",
        "size": "llama2-uncensored:7b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q4_1",
        "size": "llama2-uncensored:7b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q4_K_S",
        "size": "llama2-uncensored:7b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q4_K_M",
        "size": "llama2-uncensored:7b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q5_0",
        "size": "llama2-uncensored:7b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q5_1",
        "size": "llama2-uncensored:7b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q5_K_S",
        "size": "llama2-uncensored:7b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q5_K_M",
        "size": "llama2-uncensored:7b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q6_K",
        "size": "llama2-uncensored:7b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-q8_0",
        "size": "llama2-uncensored:7b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:7b-chat-fp16",
        "size": "llama2-uncensored:7b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat",
        "size": "llama2-uncensored:70b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q2_K",
        "size": "llama2-uncensored:70b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q3_K_S",
        "size": "llama2-uncensored:70b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q3_K_M",
        "size": "llama2-uncensored:70b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q3_K_L",
        "size": "llama2-uncensored:70b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q4_0",
        "size": "llama2-uncensored:70b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q4_1",
        "size": "llama2-uncensored:70b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q4_K_S",
        "size": "llama2-uncensored:70b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q4_K_M",
        "size": "llama2-uncensored:70b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q5_0",
        "size": "llama2-uncensored:70b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q5_1",
        "size": "llama2-uncensored:70b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q5_K_S",
        "size": "llama2-uncensored:70b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q5_K_M",
        "size": "llama2-uncensored:70b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q6_K",
        "size": "llama2-uncensored:70b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-uncensored:70b-chat-q8_0",
        "size": "llama2-uncensored:70b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "starcoder2",
    "link": "https://ollama.com/library/starcoder2",
    "description": "StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters.",
    "pullCount": "1.2M",
    "updated": "1 year ago",
    "size": [
      "3b",
      "7b",
      "15b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![StarCode 2](https://github.com/ollama/ollama/assets/251292/5456bb29-de2a-4463-930c-3aaad585f430)\n\nSupporting a context window of up to 16,384 tokens, StarCoder2 is the next generation of transparently trained open code LLMs.\n\n* `starcoder2:instruct`: a 15B model that follows natural and human-written instructions\n* `starcoder2:15b` was trained on 600+ programming languages and 4+ trillion tokens.\n* `starcoder2:7b` was trained on 17 programming languages and 3.5+ trillion tokens.\n* `starcoder2:3b` was trained on 17 programming languages and 3+ trillion tokens.\n\nStarCoder2-15B is the best in its size class and matches 33B+ models on many evaluations. StarCoder2-3B matches the performance of StarCoder1-15B.\n\n## References\n\n* [GitHub](https://github.com/bigcode-project/starcoder2)\n* [HuggingFace](https://huggingface.co/bigcode)\n* [Paper](https://arxiv.org/abs/2402.19173)\n\nWrite Preview \n\n!\\[StarCode 2\\](https://github.com/ollama/ollama/assets/251292/5456bb29-de2a-4463-930c-3aaad585f430) Supporting a context window of up to 16,384 tokens, StarCoder2 is the next generation of transparently trained open code LLMs. \\* \\`starcoder2:instruct\\`: a 15B model that follows natural and human-written instructions \\* \\`starcoder2:15b\\` was trained on 600+ programming languages and 4+ trillion tokens. \\* \\`starcoder2:7b\\` was trained on 17 programming languages and 3.5+ trillion tokens. \\* \\`starcoder2:3b\\` was trained on 17 programming languages and 3+ trillion tokens. StarCoder2-15B is the best in its size class and matches 33B+ models on many evaluations. StarCoder2-3B matches the performance of StarCoder1-15B. ## References - \\[GitHub\\](https://github.com/bigcode-project/starcoder2) - \\[HuggingFace\\](https://huggingface.co/bigcode) - \\[Paper\\](https://arxiv.org/abs/2402.19173) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "starcoder2:latest",
        "size": "starcoder2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:instruct",
        "size": "starcoder2:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b",
        "size": "starcoder2:3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b",
        "size": "starcoder2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b",
        "size": "starcoder2:15b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q2_K",
        "size": "starcoder2:3b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q3_K_S",
        "size": "starcoder2:3b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q3_K_M",
        "size": "starcoder2:3b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q3_K_L",
        "size": "starcoder2:3b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q4_0",
        "size": "starcoder2:3b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q4_1",
        "size": "starcoder2:3b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q4_K_S",
        "size": "starcoder2:3b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q4_K_M",
        "size": "starcoder2:3b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q5_0",
        "size": "starcoder2:3b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q5_1",
        "size": "starcoder2:3b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q5_K_S",
        "size": "starcoder2:3b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q5_K_M",
        "size": "starcoder2:3b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q6_K",
        "size": "starcoder2:3b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-q8_0",
        "size": "starcoder2:3b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:3b-fp16",
        "size": "starcoder2:3b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q2_K",
        "size": "starcoder2:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q3_K_S",
        "size": "starcoder2:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q3_K_M",
        "size": "starcoder2:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q3_K_L",
        "size": "starcoder2:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q4_0",
        "size": "starcoder2:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q4_1",
        "size": "starcoder2:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q4_K_S",
        "size": "starcoder2:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q4_K_M",
        "size": "starcoder2:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q5_0",
        "size": "starcoder2:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q5_1",
        "size": "starcoder2:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q5_K_S",
        "size": "starcoder2:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q5_K_M",
        "size": "starcoder2:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q6_K",
        "size": "starcoder2:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-q8_0",
        "size": "starcoder2:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:7b-fp16",
        "size": "starcoder2:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct",
        "size": "starcoder2:15b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q2_K",
        "size": "starcoder2:15b-instruct-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q3_K_S",
        "size": "starcoder2:15b-instruct-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q3_K_M",
        "size": "starcoder2:15b-instruct-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q3_K_L",
        "size": "starcoder2:15b-instruct-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-q4_0",
        "size": "starcoder2:15b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q4_0",
        "size": "starcoder2:15b-instruct-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q4_1",
        "size": "starcoder2:15b-instruct-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q4_K_S",
        "size": "starcoder2:15b-instruct-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q4_K_M",
        "size": "starcoder2:15b-instruct-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q5_0",
        "size": "starcoder2:15b-instruct-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q5_1",
        "size": "starcoder2:15b-instruct-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q5_K_S",
        "size": "starcoder2:15b-instruct-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q5_K_M",
        "size": "starcoder2:15b-instruct-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q6_K",
        "size": "starcoder2:15b-instruct-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-q8_0",
        "size": "starcoder2:15b-instruct-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-instruct-v0.1-fp16",
        "size": "starcoder2:15b-instruct-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q2_K",
        "size": "starcoder2:15b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q3_K_S",
        "size": "starcoder2:15b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q3_K_M",
        "size": "starcoder2:15b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q3_K_L",
        "size": "starcoder2:15b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q4_0",
        "size": "starcoder2:15b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q4_1",
        "size": "starcoder2:15b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q4_K_S",
        "size": "starcoder2:15b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q4_K_M",
        "size": "starcoder2:15b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q5_0",
        "size": "starcoder2:15b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q5_1",
        "size": "starcoder2:15b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q5_K_S",
        "size": "starcoder2:15b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q5_K_M",
        "size": "starcoder2:15b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q6_K",
        "size": "starcoder2:15b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-q8_0",
        "size": "starcoder2:15b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder2:15b-fp16",
        "size": "starcoder2:15b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepseek-coder",
    "link": "https://ollama.com/library/deepseek-coder",
    "description": "DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.",
    "pullCount": "1.2M",
    "updated": "1 year ago",
    "size": [
      "1.3b",
      "6.7b",
      "33b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/0e18bfb4-2964-41e4-b01c-043670228690)\n\nDeepSeek Coder is trained from scratch on both 87% code and 13% natural language in English and Chinese. Each of the models are pre-trained on 2 trillion tokens.\n\n### Models available\n\n1.3 billion parameter model\n\n```\nollama run deepseek-coder\n\n```\n\n6.7 billion parameter model\n\n```\nollama run deepseek-coder:6.7b\n\n```\n\n33 billion parameter model\n\n```\nollama run deepseek-coder:33b\n\n```\n\n### CLI\n\nOpen the terminal and run `ollama run deepseek-coder`\n\n### API\n\nExample using curl:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"deepseek-coder\",\n  \"prompt\":\"Why is the sky blue?\"\n }'\n\n```\n\n[API documentation](https://github.com/jmorganca/ollama/blob/main/docs/api.md)\n\n## References\n\n[HuggingFace](https://huggingface.co/deepseek-ai)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/0e18bfb4-2964-41e4-b01c-043670228690\" width=\"460\"> DeepSeek Coder is trained from scratch on both 87% code and 13% natural language in English and Chinese. Each of the models are pre-trained on 2 trillion tokens. ### Models available 1.3 billion parameter model \\`\\`\\` ollama run deepseek-coder \\`\\`\\` 6.7 billion parameter model \\`\\`\\` ollama run deepseek-coder:6.7b \\`\\`\\` 33 billion parameter model \\`\\`\\` ollama run deepseek-coder:33b \\`\\`\\` ### CLI Open the terminal and run \\`ollama run deepseek-coder\\` ### API Example using curl: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"deepseek-coder\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` \\[API documentation\\](https://github.com/jmorganca/ollama/blob/main/docs/api.md) ## References \\[HuggingFace\\](https://huggingface.co/deepseek-ai) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-coder:latest",
        "size": "deepseek-coder:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:base",
        "size": "deepseek-coder:base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:instruct",
        "size": "deepseek-coder:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b",
        "size": "deepseek-coder:1.3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b",
        "size": "deepseek-coder:6.7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b",
        "size": "deepseek-coder:33b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base",
        "size": "deepseek-coder:1.3b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q2_K",
        "size": "deepseek-coder:1.3b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q3_K_S",
        "size": "deepseek-coder:1.3b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q3_K_M",
        "size": "deepseek-coder:1.3b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q3_K_L",
        "size": "deepseek-coder:1.3b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q4_0",
        "size": "deepseek-coder:1.3b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q4_1",
        "size": "deepseek-coder:1.3b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q4_K_S",
        "size": "deepseek-coder:1.3b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q4_K_M",
        "size": "deepseek-coder:1.3b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q5_0",
        "size": "deepseek-coder:1.3b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q5_1",
        "size": "deepseek-coder:1.3b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q5_K_S",
        "size": "deepseek-coder:1.3b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q5_K_M",
        "size": "deepseek-coder:1.3b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q6_K",
        "size": "deepseek-coder:1.3b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-q8_0",
        "size": "deepseek-coder:1.3b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-base-fp16",
        "size": "deepseek-coder:1.3b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct",
        "size": "deepseek-coder:1.3b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q2_K",
        "size": "deepseek-coder:1.3b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q3_K_S",
        "size": "deepseek-coder:1.3b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q3_K_M",
        "size": "deepseek-coder:1.3b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q3_K_L",
        "size": "deepseek-coder:1.3b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q4_0",
        "size": "deepseek-coder:1.3b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q4_1",
        "size": "deepseek-coder:1.3b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q4_K_S",
        "size": "deepseek-coder:1.3b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q4_K_M",
        "size": "deepseek-coder:1.3b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q5_0",
        "size": "deepseek-coder:1.3b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q5_1",
        "size": "deepseek-coder:1.3b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q5_K_S",
        "size": "deepseek-coder:1.3b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q5_K_M",
        "size": "deepseek-coder:1.3b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q6_K",
        "size": "deepseek-coder:1.3b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-q8_0",
        "size": "deepseek-coder:1.3b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:1.3b-instruct-fp16",
        "size": "deepseek-coder:1.3b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base",
        "size": "deepseek-coder:6.7b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q2_K",
        "size": "deepseek-coder:6.7b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q3_K_S",
        "size": "deepseek-coder:6.7b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q3_K_M",
        "size": "deepseek-coder:6.7b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q3_K_L",
        "size": "deepseek-coder:6.7b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q4_0",
        "size": "deepseek-coder:6.7b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q4_1",
        "size": "deepseek-coder:6.7b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q4_K_S",
        "size": "deepseek-coder:6.7b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q4_K_M",
        "size": "deepseek-coder:6.7b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q5_0",
        "size": "deepseek-coder:6.7b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q5_1",
        "size": "deepseek-coder:6.7b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q5_K_S",
        "size": "deepseek-coder:6.7b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q5_K_M",
        "size": "deepseek-coder:6.7b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q6_K",
        "size": "deepseek-coder:6.7b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-q8_0",
        "size": "deepseek-coder:6.7b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-base-fp16",
        "size": "deepseek-coder:6.7b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct",
        "size": "deepseek-coder:6.7b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q2_K",
        "size": "deepseek-coder:6.7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q3_K_S",
        "size": "deepseek-coder:6.7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q3_K_M",
        "size": "deepseek-coder:6.7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q3_K_L",
        "size": "deepseek-coder:6.7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q4_0",
        "size": "deepseek-coder:6.7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q4_1",
        "size": "deepseek-coder:6.7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q4_K_S",
        "size": "deepseek-coder:6.7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q4_K_M",
        "size": "deepseek-coder:6.7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q5_0",
        "size": "deepseek-coder:6.7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q5_1",
        "size": "deepseek-coder:6.7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q5_K_S",
        "size": "deepseek-coder:6.7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q5_K_M",
        "size": "deepseek-coder:6.7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q6_K",
        "size": "deepseek-coder:6.7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-q8_0",
        "size": "deepseek-coder:6.7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:6.7b-instruct-fp16",
        "size": "deepseek-coder:6.7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base",
        "size": "deepseek-coder:33b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q2_K",
        "size": "deepseek-coder:33b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q3_K_S",
        "size": "deepseek-coder:33b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q3_K_M",
        "size": "deepseek-coder:33b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q3_K_L",
        "size": "deepseek-coder:33b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q4_0",
        "size": "deepseek-coder:33b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q4_1",
        "size": "deepseek-coder:33b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q4_K_S",
        "size": "deepseek-coder:33b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q4_K_M",
        "size": "deepseek-coder:33b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q5_0",
        "size": "deepseek-coder:33b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q5_1",
        "size": "deepseek-coder:33b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q5_K_S",
        "size": "deepseek-coder:33b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q5_K_M",
        "size": "deepseek-coder:33b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q6_K",
        "size": "deepseek-coder:33b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-q8_0",
        "size": "deepseek-coder:33b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-base-fp16",
        "size": "deepseek-coder:33b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct",
        "size": "deepseek-coder:33b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q2_K",
        "size": "deepseek-coder:33b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q3_K_S",
        "size": "deepseek-coder:33b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q3_K_M",
        "size": "deepseek-coder:33b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q3_K_L",
        "size": "deepseek-coder:33b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q4_0",
        "size": "deepseek-coder:33b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q4_1",
        "size": "deepseek-coder:33b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q4_K_S",
        "size": "deepseek-coder:33b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q4_K_M",
        "size": "deepseek-coder:33b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q5_0",
        "size": "deepseek-coder:33b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q5_1",
        "size": "deepseek-coder:33b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q5_K_S",
        "size": "deepseek-coder:33b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q5_K_M",
        "size": "deepseek-coder:33b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q6_K",
        "size": "deepseek-coder:33b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-q8_0",
        "size": "deepseek-coder:33b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder:33b-instruct-fp16",
        "size": "deepseek-coder:33b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepseek-coder-v2",
    "link": "https://ollama.com/library/deepseek-coder-v2",
    "description": "An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.",
    "pullCount": "1.1M",
    "updated": "1 year ago",
    "size": [
      "16b",
      "236b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/deepseek-coder-v2/cce4988a-b798-4c63-82ab-14c5c09462fe)\n\nDeepSeek-Coder-V2 is an open-source Mixture-of-Experts (MoE) code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks. DeepSeek-Coder-V2 is further pre-trained from DeepSeek-Coder-V2-Base with 6 trillion tokens sourced from a high-quality and multi-source corpus.\n\n## References\n\n[Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/deepseek-coder-v2/cce4988a-b798-4c63-82ab-14c5c09462fe\" width=\"280\" /> DeepSeek-Coder-V2 is an open-source Mixture-of-Experts (MoE) code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks. DeepSeek-Coder-V2 is further pre-trained from DeepSeek-Coder-V2-Base with 6 trillion tokens sourced from a high-quality and multi-source corpus. ## References \\[Hugging Face\\](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-coder-v2:latest",
        "size": "deepseek-coder-v2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:lite",
        "size": "deepseek-coder-v2:lite",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b",
        "size": "deepseek-coder-v2:16b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b",
        "size": "deepseek-coder-v2:236b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q2_K",
        "size": "deepseek-coder-v2:16b-lite-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q3_K_S",
        "size": "deepseek-coder-v2:16b-lite-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q3_K_M",
        "size": "deepseek-coder-v2:16b-lite-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q3_K_L",
        "size": "deepseek-coder-v2:16b-lite-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q4_0",
        "size": "deepseek-coder-v2:16b-lite-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q4_1",
        "size": "deepseek-coder-v2:16b-lite-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q4_K_S",
        "size": "deepseek-coder-v2:16b-lite-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q4_K_M",
        "size": "deepseek-coder-v2:16b-lite-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q5_0",
        "size": "deepseek-coder-v2:16b-lite-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q5_1",
        "size": "deepseek-coder-v2:16b-lite-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q5_K_S",
        "size": "deepseek-coder-v2:16b-lite-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q5_K_M",
        "size": "deepseek-coder-v2:16b-lite-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q6_K",
        "size": "deepseek-coder-v2:16b-lite-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-q8_0",
        "size": "deepseek-coder-v2:16b-lite-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-base-fp16",
        "size": "deepseek-coder-v2:16b-lite-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q2_K",
        "size": "deepseek-coder-v2:16b-lite-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q3_K_S",
        "size": "deepseek-coder-v2:16b-lite-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q3_K_M",
        "size": "deepseek-coder-v2:16b-lite-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q3_K_L",
        "size": "deepseek-coder-v2:16b-lite-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q4_0",
        "size": "deepseek-coder-v2:16b-lite-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q4_1",
        "size": "deepseek-coder-v2:16b-lite-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q4_K_S",
        "size": "deepseek-coder-v2:16b-lite-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q4_K_M",
        "size": "deepseek-coder-v2:16b-lite-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q5_0",
        "size": "deepseek-coder-v2:16b-lite-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q5_1",
        "size": "deepseek-coder-v2:16b-lite-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q5_K_S",
        "size": "deepseek-coder-v2:16b-lite-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q5_K_M",
        "size": "deepseek-coder-v2:16b-lite-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q6_K",
        "size": "deepseek-coder-v2:16b-lite-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-q8_0",
        "size": "deepseek-coder-v2:16b-lite-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:16b-lite-instruct-fp16",
        "size": "deepseek-coder-v2:16b-lite-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q2_K",
        "size": "deepseek-coder-v2:236b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q3_K_S",
        "size": "deepseek-coder-v2:236b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q3_K_M",
        "size": "deepseek-coder-v2:236b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q3_K_L",
        "size": "deepseek-coder-v2:236b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q4_0",
        "size": "deepseek-coder-v2:236b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q4_1",
        "size": "deepseek-coder-v2:236b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q4_K_S",
        "size": "deepseek-coder-v2:236b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q4_K_M",
        "size": "deepseek-coder-v2:236b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q5_0",
        "size": "deepseek-coder-v2:236b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q5_1",
        "size": "deepseek-coder-v2:236b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q5_K_S",
        "size": "deepseek-coder-v2:236b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q5_K_M",
        "size": "deepseek-coder-v2:236b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q6_K",
        "size": "deepseek-coder-v2:236b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-q8_0",
        "size": "deepseek-coder-v2:236b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-base-fp16",
        "size": "deepseek-coder-v2:236b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q2_K",
        "size": "deepseek-coder-v2:236b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q3_K_S",
        "size": "deepseek-coder-v2:236b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q3_K_M",
        "size": "deepseek-coder-v2:236b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q3_K_L",
        "size": "deepseek-coder-v2:236b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q4_0",
        "size": "deepseek-coder-v2:236b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q4_1",
        "size": "deepseek-coder-v2:236b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q4_K_S",
        "size": "deepseek-coder-v2:236b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q4_K_M",
        "size": "deepseek-coder-v2:236b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q5_0",
        "size": "deepseek-coder-v2:236b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q5_1",
        "size": "deepseek-coder-v2:236b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q5_K_S",
        "size": "deepseek-coder-v2:236b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q5_K_M",
        "size": "deepseek-coder-v2:236b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q6_K",
        "size": "deepseek-coder-v2:236b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-q8_0",
        "size": "deepseek-coder-v2:236b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-coder-v2:236b-instruct-fp16",
        "size": "deepseek-coder-v2:236b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "codegemma",
    "link": "https://ollama.com/library/codegemma",
    "description": "CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.",
    "pullCount": "933.9K",
    "updated": "1 year ago",
    "size": [
      "2b",
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/56ffc5fc-0c30-4ab5-a0e3-65fc66de17bc)\n\nCodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.\n\n### Variants:\n\n* `instruct` a 7b instruction-tuned variant for natural language-to-code chat and instruction following\n* `code` a 7b pretrained variant that specializes in code completion and generation from code prefixes and/or suffixes\n* `2b` a state of the art 2B pretrained variant that provides up to 2x faster code completion\n\n### Advantages:\n\n* **Intelligent code completion and generation**: Complete lines, functions, and even generate entire blocks of code, whether you’re working locally or using Google Cloud resources.\n* **Enhanced accuracy**: Trained on 500 billion tokens of primarily English language data from web documents, mathematics, and code, CodeGemma models generate code that’s not only more syntactically correct but also semantically meaningful, reducing errors and debugging time.\n* **Multi-language proficiency**: Supports Python, JavaScript, Java, Kotlin, C++, C#, Rust, Go, and other languages.\n* **Streamlined workflows**: Integrate a CodeGemma model into your development environment to write less boilerplate and focus on interesting and differentiated code that matters, faster.\n\n![benchmarks](https://github.com/ollama/ollama/assets/251292/0d8473cb-bcee-4bd0-9214-c527ce367d88)\n\n### Fill-in-the-middle\n\nCodeGemma models support fill-in-the-middle (FIM), for use in autocomplete or coding assistant tooling. Below is an example using the Ollama [Python](https://github.com/ollama/ollama-python) library:\n\n```\nresponse = generate(\n  model='codegemma:2b-code',\n  prompt=f'<|fim_prefix|>{prefix}<|fim_suffix|>{suffix}<|fim_middle|>',\n  options={\n    'num_predict': 128,\n    'temperature': 0,\n    'top_p': 0.9,\n    'stop': ['<|file_separator|>'],\n  },\n)\n\n```\n\n### References\n\n[Hugging Face](https://huggingface.co/collections/google/codegemma-release-66152ac7b683e2667abdee11)\n\n[Report](https://storage.googleapis.com/deepmind-media/gemma/codegemma%5Freport.pdf)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/56ffc5fc-0c30-4ab5-a0e3-65fc66de17bc\" width=\"320\" /> CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following. ### Variants: \\* \\`instruct\\` a 7b instruction-tuned variant for natural language-to-code chat and instruction following \\* \\`code\\` a 7b pretrained variant that specializes in code completion and generation from code prefixes and/or suffixes \\* \\`2b\\` a state of the art 2B pretrained variant that provides up to 2x faster code completion ### Advantages: \\* \\*\\*Intelligent code completion and generation\\*\\*: Complete lines, functions, and even generate entire blocks of code, whether you're working locally or using Google Cloud resources. \\* \\*\\*Enhanced accuracy\\*\\*: Trained on 500 billion tokens of primarily English language data from web documents, mathematics, and code, CodeGemma models generate code that's not only more syntactically correct but also semantically meaningful, reducing errors and debugging time. \\* \\*\\*Multi-language proficiency\\*\\*: Supports Python, JavaScript, Java, Kotlin, C++, C#, Rust, Go, and other languages. \\* \\*\\*Streamlined workflows\\*\\*: Integrate a CodeGemma model into your development environment to write less boilerplate and focus on interesting and differentiated code that matters, faster. !\\[benchmarks\\](https://github.com/ollama/ollama/assets/251292/0d8473cb-bcee-4bd0-9214-c527ce367d88) ### Fill-in-the-middle CodeGemma models support fill-in-the-middle (FIM), for use in autocomplete or coding assistant tooling. Below is an example using the Ollama \\[Python\\](https://github.com/ollama/ollama-python) library: \\`\\`\\`python response = generate( model='codegemma:2b-code', prompt=f'<|fim\\_prefix|>{prefix}<|fim\\_suffix|>{suffix}<|fim\\_middle|>', options={ 'num\\_predict': 128, 'temperature': 0, 'top\\_p': 0.9, 'stop': \\['<|file\\_separator|>'\\], }, ) \\`\\`\\` ### References \\[Hugging Face\\](https://huggingface.co/collections/google/codegemma-release-66152ac7b683e2667abdee11) \\[Report\\](https://storage.googleapis.com/deepmind-media/gemma/codegemma\\_report.pdf) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codegemma:latest",
        "size": "codegemma:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:code",
        "size": "codegemma:code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:instruct",
        "size": "codegemma:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b",
        "size": "codegemma:2b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b",
        "size": "codegemma:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code",
        "size": "codegemma:2b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q2_K",
        "size": "codegemma:2b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q2_K",
        "size": "codegemma:2b-code-v1.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q3_K_S",
        "size": "codegemma:2b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q3_K_S",
        "size": "codegemma:2b-code-v1.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q3_K_M",
        "size": "codegemma:2b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q3_K_M",
        "size": "codegemma:2b-code-v1.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q3_K_L",
        "size": "codegemma:2b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q3_K_L",
        "size": "codegemma:2b-code-v1.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q4_0",
        "size": "codegemma:2b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q4_0",
        "size": "codegemma:2b-code-v1.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q4_1",
        "size": "codegemma:2b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q4_1",
        "size": "codegemma:2b-code-v1.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q4_K_S",
        "size": "codegemma:2b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q4_K_S",
        "size": "codegemma:2b-code-v1.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q4_K_M",
        "size": "codegemma:2b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q4_K_M",
        "size": "codegemma:2b-code-v1.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q5_0",
        "size": "codegemma:2b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q5_0",
        "size": "codegemma:2b-code-v1.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q5_1",
        "size": "codegemma:2b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q5_1",
        "size": "codegemma:2b-code-v1.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q5_K_S",
        "size": "codegemma:2b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q5_K_S",
        "size": "codegemma:2b-code-v1.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q5_K_M",
        "size": "codegemma:2b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q5_K_M",
        "size": "codegemma:2b-code-v1.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q6_K",
        "size": "codegemma:2b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q6_K",
        "size": "codegemma:2b-code-v1.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-q8_0",
        "size": "codegemma:2b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-q8_0",
        "size": "codegemma:2b-code-v1.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-fp16",
        "size": "codegemma:2b-code-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-code-v1.1-fp16",
        "size": "codegemma:2b-code-v1.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:2b-v1.1",
        "size": "codegemma:2b-v1.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code",
        "size": "codegemma:7b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q2_K",
        "size": "codegemma:7b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q3_K_S",
        "size": "codegemma:7b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q3_K_M",
        "size": "codegemma:7b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q3_K_L",
        "size": "codegemma:7b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q4_0",
        "size": "codegemma:7b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q4_1",
        "size": "codegemma:7b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q4_K_S",
        "size": "codegemma:7b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q4_K_M",
        "size": "codegemma:7b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q5_0",
        "size": "codegemma:7b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q5_1",
        "size": "codegemma:7b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q5_K_S",
        "size": "codegemma:7b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q5_K_M",
        "size": "codegemma:7b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q6_K",
        "size": "codegemma:7b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-q8_0",
        "size": "codegemma:7b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-code-fp16",
        "size": "codegemma:7b-code-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct",
        "size": "codegemma:7b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q2_K",
        "size": "codegemma:7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q2_K",
        "size": "codegemma:7b-instruct-v1.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q3_K_S",
        "size": "codegemma:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q3_K_S",
        "size": "codegemma:7b-instruct-v1.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q3_K_M",
        "size": "codegemma:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q3_K_M",
        "size": "codegemma:7b-instruct-v1.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q3_K_L",
        "size": "codegemma:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q3_K_L",
        "size": "codegemma:7b-instruct-v1.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q4_0",
        "size": "codegemma:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q4_0",
        "size": "codegemma:7b-instruct-v1.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q4_1",
        "size": "codegemma:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q4_1",
        "size": "codegemma:7b-instruct-v1.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q4_K_S",
        "size": "codegemma:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q4_K_S",
        "size": "codegemma:7b-instruct-v1.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q4_K_M",
        "size": "codegemma:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q4_K_M",
        "size": "codegemma:7b-instruct-v1.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q5_0",
        "size": "codegemma:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q5_0",
        "size": "codegemma:7b-instruct-v1.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q5_1",
        "size": "codegemma:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q5_1",
        "size": "codegemma:7b-instruct-v1.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q5_K_S",
        "size": "codegemma:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q5_K_S",
        "size": "codegemma:7b-instruct-v1.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q5_K_M",
        "size": "codegemma:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q5_K_M",
        "size": "codegemma:7b-instruct-v1.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q6_K",
        "size": "codegemma:7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q6_K",
        "size": "codegemma:7b-instruct-v1.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-q8_0",
        "size": "codegemma:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-q8_0",
        "size": "codegemma:7b-instruct-v1.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-fp16",
        "size": "codegemma:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-instruct-v1.1-fp16",
        "size": "codegemma:7b-instruct-v1.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegemma:7b-v1.1",
        "size": "codegemma:7b-v1.1",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "snowflake-arctic-embed",
    "link": "https://ollama.com/library/snowflake-arctic-embed",
    "description": "A suite of text embedding models by Snowflake, optimized for performance.",
    "pullCount": "863.6K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/115f484a-1911-46e9-902f-65a70f84e1d0)\n\n`snowflake-arctic-embed` is a suite of text embedding models that focuses on creating high-quality retrieval models optimized for performance.\n\nThe models are trained by leveraging existing open-source text representation models, such as bert-base-uncased, and are trained in a multi-stage pipeline to optimize their retrieval performance.\n\nThis model is available in 5 parameter sizes:\n\n* `snowflake-arctic-embed:335m` (default)\n* `snowflake-arctic-embed:137m`\n* `snowflake-arctic-embed:110m`\n* `snowflake-arctic-embed:33m`\n* `snowflake-arctic-embed:22m`\n\n## Reference\n\n[Blog Post](https://www.snowflake.com/blog/introducing-snowflake-arctic-embed-snowflakes-state-of-the-art-text-embedding-family-of-models/)\n\n[HuggingFace](https://huggingface.co/Snowflake)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/115f484a-1911-46e9-902f-65a70f84e1d0\" width=\"320\" /> \\`snowflake-arctic-embed\\` is a suite of text embedding models that focuses on creating high-quality retrieval models optimized for performance. The models are trained by leveraging existing open-source text representation models, such as bert-base-uncased, and are trained in a multi-stage pipeline to optimize their retrieval performance. This model is available in 5 parameter sizes: \\* \\`snowflake-arctic-embed:335m\\` (default) \\* \\`snowflake-arctic-embed:137m\\` \\* \\`snowflake-arctic-embed:110m\\` \\* \\`snowflake-arctic-embed:33m\\` \\* \\`snowflake-arctic-embed:22m\\` ## Reference \\[Blog Post\\](https://www.snowflake.com/blog/introducing-snowflake-arctic-embed-snowflakes-state-of-the-art-text-embedding-family-of-models/) \\[HuggingFace\\](https://huggingface.co/Snowflake) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "snowflake-arctic-embed:latest",
        "size": "snowflake-arctic-embed:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:l",
        "size": "snowflake-arctic-embed:l",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:m",
        "size": "snowflake-arctic-embed:m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:s",
        "size": "snowflake-arctic-embed:s",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:xs",
        "size": "snowflake-arctic-embed:xs",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:22m",
        "size": "snowflake-arctic-embed:22m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:33m",
        "size": "snowflake-arctic-embed:33m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:110m",
        "size": "snowflake-arctic-embed:110m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:137m",
        "size": "snowflake-arctic-embed:137m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:335m",
        "size": "snowflake-arctic-embed:335m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:22m-xs-fp16",
        "size": "snowflake-arctic-embed:22m-xs-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:33m-s-fp16",
        "size": "snowflake-arctic-embed:33m-s-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:110m-m-fp16",
        "size": "snowflake-arctic-embed:110m-m-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:137m-m-long-fp16",
        "size": "snowflake-arctic-embed:137m-m-long-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:335m-l-fp16",
        "size": "snowflake-arctic-embed:335m-l-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "snowflake-arctic-embed:m-long",
        "size": "snowflake-arctic-embed:m-long",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "phi",
    "link": "https://ollama.com/library/phi",
    "description": "Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.",
    "pullCount": "704.2K",
    "updated": "1 year ago",
    "size": [
      "2.7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/e06e1a36-97b2-417a-b2b2-028c980359b1)\n\nPhi-2 is a small language model capable of common-sense reasoning and language understanding. It showcases “state-of-the-art performance” among language models with less than 13 billion parameters.\n\n### Example prompt\n\nBy default, `phi` includes a chat prompt template designed for multi-turn conversations:\n\n```\n% ollama run phi\n>>> Hello, can you help me find my way to Toronto?\n Certainly! What is the exact location in Toronto that you are looking for?\n\n>>> Yonge & Bloor\n Sure, Yonge and Bloor is a busy intersection in downtown Toronto. Would you like to take public transportation or drive there?\n\n>>> Public transportation\n Great! The easiest way to get there is by taking the TTC subway. You can take Line 1, which runs along Yonge Street and passes through downtown Toronto.\n\n```\n\nUsing Ollama’s API:\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"phi\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n\n```\n\n### Example prompts (raw mode)\n\nPhi also responds well to a wide variety of prompt formats when using [raw mode](https://github.com/jmorganca/ollama/blob/main/docs/api.md#request-raw-mode) in Ollama’s API, which bypasses all default prompt templating:\n\n#### Instruct\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"phi\",\n  \"prompt\": \"Instruct: Write a detailed analogy between mathematics and a lighthouse.\\nOutput:\",\n  \"options\": {\n    \"stop\": [\"Instruct:\", \"Output:\"]\n  },\n  \"raw\": true,\n  \"stream\": false\n}'\n\n```\n\n#### Code Completion\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"phi\",\n  \"prompt\": \"def print_prime(n):\\n  \",\n  \"raw\": true,\n  \"stream\": false\n}'\n\n```\n\n#### Text completion\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"phi\",\n  \"prompt\": \"There once was a mouse named\",\n  \"raw\": true,\n  \"stream\": false\n}'\n\n```\n\n## References\n\n[HuggingFace](https://huggingface.co/microsoft/phi-2)\n\n[Blog Post](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/e06e1a36-97b2-417a-b2b2-028c980359b1\" width=\"240\" /> Phi-2 is a small language model capable of common-sense reasoning and language understanding. It showcases \"state-of-the-art performance\" among language models with less than 13 billion parameters. ### Example prompt By default, \\`phi\\` includes a chat prompt template designed for multi-turn conversations: \\`\\`\\` % ollama run phi >>> Hello, can you help me find my way to Toronto? Certainly! What is the exact location in Toronto that you are looking for? >>> Yonge & Bloor Sure, Yonge and Bloor is a busy intersection in downtown Toronto. Would you like to take public transportation or drive there? >>> Public transportation Great! The easiest way to get there is by taking the TTC subway. You can take Line 1, which runs along Yonge Street and passes through downtown Toronto. \\`\\`\\` Using Ollama's API: \\`\\`\\` curl http://localhost:11434/api/chat -d '{ \"model\": \"phi\", \"messages\": \\[ { \"role\": \"user\", \"content\": \"why is the sky blue?\" } \\] }' \\`\\`\\` ### Example prompts (raw mode) Phi also responds well to a wide variety of prompt formats when using \\[raw mode\\](https://github.com/jmorganca/ollama/blob/main/docs/api.md#request-raw-mode) in Ollama's API, which bypasses all default prompt templating: #### Instruct \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"phi\", \"prompt\": \"Instruct: Write a detailed analogy between mathematics and a lighthouse.\\\\nOutput:\", \"options\": { \"stop\": \\[\"Instruct:\", \"Output:\"\\] }, \"raw\": true, \"stream\": false }' \\`\\`\\` #### Code Completion \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"phi\", \"prompt\": \"def print\\_prime(n):\\\\n \", \"raw\": true, \"stream\": false }' \\`\\`\\` #### Text completion \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"phi\", \"prompt\": \"There once was a mouse named\", \"raw\": true, \"stream\": false }' \\`\\`\\` ## References \\[HuggingFace\\](https://huggingface.co/microsoft/phi-2) \\[Blog Post\\](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi:latest",
        "size": "phi:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:chat",
        "size": "phi:chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b",
        "size": "phi:2.7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q2_K",
        "size": "phi:2.7b-chat-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q3_K_S",
        "size": "phi:2.7b-chat-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q3_K_M",
        "size": "phi:2.7b-chat-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q3_K_L",
        "size": "phi:2.7b-chat-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q4_0",
        "size": "phi:2.7b-chat-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q4_1",
        "size": "phi:2.7b-chat-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q4_K_S",
        "size": "phi:2.7b-chat-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q4_K_M",
        "size": "phi:2.7b-chat-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q5_0",
        "size": "phi:2.7b-chat-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q5_1",
        "size": "phi:2.7b-chat-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q5_K_S",
        "size": "phi:2.7b-chat-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q5_K_M",
        "size": "phi:2.7b-chat-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q6_K",
        "size": "phi:2.7b-chat-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-q8_0",
        "size": "phi:2.7b-chat-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi:2.7b-chat-v2-fp16",
        "size": "phi:2.7b-chat-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama4",
    "link": "https://ollama.com/library/llama4",
    "description": "Meta's latest collection of multimodal models.",
    "pullCount": "651.6K",
    "updated": "2 months ago",
    "size": [
      "16x17b",
      "128x17b"
    ],
    "capabilities": "visiontools",
    "readme": "## Readme\n\n![image.png](/assets/library/llama4/e7b65449-da66-4a50-b36c-d0c2359295b4)\n\nThe Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These two models leverage a mixture-of-experts (MoE) architecture and support native multimodality (image input).\n\n**Supported languages:** Arabic, English, French, German, Hindi, Indonesian, Italian, Portuguese, Spanish, Tagalog, Thai, and Vietnamese.\n\n**Input:** multilingual text, image\n\n**Output:** multilingual text, code\n\n### Models\n\n#### Llama 4 Scout\n\n```\nollama run llama4:scout\n\n```\n\n109B parameter MoE model with 17B active parameters\n\n#### Llama 4 Maverick\n\n```\nollama run llama4:maverick\n\n```\n\n400B parameter MoE model with 17B active parameters\n\n### Intended Use\n\n**Intended Use Cases:** Llama 4 is intended for commercial and research use in multiple languages. Instruction tuned models are intended for assistant-like chat and visual reasoning tasks, whereas pretrained models can be adapted for natural language generation. For vision, Llama 4 models are also optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. The Llama 4 model collection also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation. The Llama 4 Community License allows for these use cases.\n\n**Out-of-scope**: Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 4 Community License. Use in languages or capabilities beyond those explicitly referenced as supported in this model card.\n\nNote:\n\n1. Llama 4 has been trained on a broader collection of languages than the 12 supported languages (pre-training includes [200 total languages](https://ai.meta.com/research/no-language-left-behind/)). Developers may fine-tune Llama 4 models for languages beyond the 12 supported languages provided they comply with the Llama 4 Community License and the Acceptable Use Policy. Developers are responsible for ensuring that their use of Llama 4 in additional languages is done in a safe and responsible manner.\n2. Llama 4 has been tested for image understanding up to 5 input images. If leveraging additional image understanding capabilities beyond this, Developers are responsible for ensuring that their deployments are mitigated for risks and should perform additional testing and tuning tailored to their specific applications.\n\n### Benchmarks\n\n| Category                              | Benchmark                             | \\# Shots | Metric            | Llama 3.3 70B          | Llama 3.1 405B | Llama 4 Scout | Llama 4 Maverick |\n| ------------------------------------- | ------------------------------------- | -------- | ----------------- | ---------------------- | -------------- | ------------- | ---------------- |\n| Image Reasoning                       | MMMU                                  | 0        | accuracy          | No multimodal support  | 69.4           | 73.4          |                  |\n| |  MMMU Pro^                          | 0                                     | accuracy |                   | 52.2                   | 59.6           |               |                  |\n| |  MathVista                          | 0                                     | accuracy |                   | 70.7                   | 73.7           |               |                  |\n| Image Understanding                   | ChartQA                               | 0        | relaxed\\_accuracy |                        | 88.8           | 90.0          |                  |\n| |  DocVQA (test)                      | 0                                     | anls     |                   | 94.4                   | 94.4           |               |                  |\n| Code                                  | LiveCodeBench (10/01/2024-02/01/2025) | 0        | pass@1            | 33.3                   | 27.7           | 32.8          | 43.4             |\n| Reasoning & Knowledge                 | MMLU Pro                              | 0        | macro\\_avg/acc    | 68.9                   | 73.4           | 74.3          | 80.5             |\n| |  GPQA Diamond                       | 0                                     | accuracy | 50.5              | 49.0                   | 57.2           | 69.8          |                  |\n| Multilingual                          | MGSM                                  | 0        | average/em        | 91.1                   | 91.6           | 90.6          | 92.3             |\n| Long Context                          | MTOB (half book) eng->kgv/kgv->eng    | \\-       | chrF              | Context window is 128K | 42.2 / 36.6    | 54.0 / 46.4   |                  |\n| |  MTOB (full book) eng->kgv/kgv->eng | \\-                                    | chrF     |                   | 39.7 / 36.3            | 50.8 / 46.7    |               |                  |\n\n\\*reported numbers for MMMU Pro is the average of Standard and Vision tasks \n\n### Reference\n\n* Meta Llama 4 [post](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)\n\nWrite Preview \n\n!\\[image.png\\](/assets/library/llama4/e7b65449-da66-4a50-b36c-d0c2359295b4) The Llama 4 collection of models are natively multimodal AI models that enable text and multimodal experiences. These two models leverage a mixture-of-experts (MoE) architecture and support native multimodality (image input). \\*\\*Supported languages:\\*\\* Arabic, English, French, German, Hindi, Indonesian, Italian, Portuguese, Spanish, Tagalog, Thai, and Vietnamese. \\*\\*Input:\\*\\* multilingual text, image \\*\\*Output:\\*\\* multilingual text, code ### Models #### Llama 4 Scout \\`\\`\\` ollama run llama4:scout \\`\\`\\` 109B parameter MoE model with 17B active parameters #### Llama 4 Maverick \\`\\`\\` ollama run llama4:maverick \\`\\`\\` 400B parameter MoE model with 17B active parameters ### Intended Use \\*\\*Intended Use Cases:\\*\\* Llama 4 is intended for commercial and research use in multiple languages. Instruction tuned models are intended for assistant-like chat and visual reasoning tasks, whereas pretrained models can be adapted for natural language generation. For vision, Llama 4 models are also optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. The Llama 4 model collection also supports the ability to leverage the outputs of its models to improve other models including synthetic data generation and distillation. The Llama 4 Community License allows for these use cases. \\*\\*Out-of-scope\\*\\*: Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in any other way that is prohibited by the Acceptable Use Policy and Llama 4 Community License. Use in languages or capabilities beyond those explicitly referenced as supported in this model card. Note: 1\\. Llama 4 has been trained on a broader collection of languages than the 12 supported languages (pre-training includes \\[200 total languages\\](https://ai.meta.com/research/no-language-left-behind/)). Developers may fine-tune Llama 4 models for languages beyond the 12 supported languages provided they comply with the Llama 4 Community License and the Acceptable Use Policy. Developers are responsible for ensuring that their use of Llama 4 in additional languages is done in a safe and responsible manner. 2\\. Llama 4 has been tested for image understanding up to 5 input images. If leveraging additional image understanding capabilities beyond this, Developers are responsible for ensuring that their deployments are mitigated for risks and should perform additional testing and tuning tailored to their specific applications. ### Benchmarks <table> <tr> <th>Category</th> <th>Benchmark</th> <th># Shots</th> <th>Metric</th> <th>Llama 3.3 70B</th> <th>Llama 3.1 405B</th> <th>Llama 4 Scout</th> <th>Llama 4 Maverick</th> </tr> <tr> <td> Image Reasoning</td> <td>MMMU</td> <td>0</td> <td>accuracy</td> <td colspan=\"2\"> No multimodal support </td> <td>69.4</td> <td>73.4</td> </tr> <tr> <td> </td> <td>MMMU Pro^</td> <td>0</td> <td>accuracy</td> <td colspan=\"2\"> </td> <td>52.2</td> <td>59.6</td> </tr> <tr> <td> </td> <td>MathVista</td> <td>0</td> <td>accuracy</td> <td colspan=\"2\"> </td> <td>70.7</td> <td>73.7</td> </tr> <tr> <td> Image Understanding </td> <td>ChartQA</td> <td>0</td> <td>relaxed\\_accuracy</td> <td colspan=\"2\"> </td> <td>88.8</td> <td>90.0</td> </tr> <tr> <td> </td> <td>DocVQA (test)</td> <td>0</td> <td>anls</td> <td colspan=\"2\"> </td> <td>94.4</td> <td>94.4</td> </tr> <tr> <td> Code </td> <td> LiveCodeBench (10/01/2024-02/01/2025) </td> <td>0</td> <td>pass@1</td> <td> 33.3 </td> <td> 27.7 </td> <td>32.8</td> <td>43.4</td> </tr> <tr> <td> Reasoning & Knowledge </td> <td> MMLU Pro</td> <td>0</td> <td>macro\\_avg/acc</td> <td> 68.9 </td> <td> 73.4 </td> <td>74.3</td> <td>80.5</td> </tr> <tr> <td> </td> <td> GPQA Diamond</td> <td>0</td> <td>accuracy</td> <td> 50.5 </td> <td> 49.0 </td> <td>57.2</td> <td>69.8</td> </tr> <tr> <td> Multilingual </td> <td> MGSM</td> <td>0</td> <td>average/em</td> <td> 91.1 </td> <td> 91.6</td> <td>90.6</td> <td>92.3</td> </tr> <tr> <td> Long Context </td> <td> MTOB (half book) eng->kgv/kgv->eng </td> <td>-</td> <td>chrF</td> <td colspan=\"2\"> Context window is 128K </td> <td>42.2 / 36.6</td> <td>54.0 / 46.4</td> </tr> <tr> <td> </td> <td> MTOB (full book) eng->kgv/kgv->eng </td> <td>-</td> <td>chrF</td> <td colspan=\"2\"> </td> <td>39.7 / 36.3</td> <td>50.8 / 46.7</td> </tr> </table> \\*reported numbers for MMMU Pro is the average of Standard and Vision tasks ### Reference - Meta Llama 4 \\[post\\](https://ai.meta.com/blog/llama-4-multimodal-intelligence/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama4:latest",
        "size": "llama4:latest",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:maverick",
        "size": "llama4:maverick",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:scout",
        "size": "llama4:scout",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:16x17b",
        "size": "llama4:16x17b",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:128x17b",
        "size": "llama4:128x17b",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:17b-maverick-128e-instruct-q4_K_M",
        "size": "llama4:17b-maverick-128e-instruct-q4_K_M",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:17b-maverick-128e-instruct-q8_0",
        "size": "llama4:17b-maverick-128e-instruct-q8_0",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:17b-maverick-128e-instruct-fp16",
        "size": "llama4:17b-maverick-128e-instruct-fp16",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:17b-scout-16e-instruct-q4_K_M",
        "size": "llama4:17b-scout-16e-instruct-q4_K_M",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:17b-scout-16e-instruct-q8_0",
        "size": "llama4:17b-scout-16e-instruct-q8_0",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "llama4:17b-scout-16e-instruct-fp16",
        "size": "llama4:17b-scout-16e-instruct-fp16",
        "updated": "Text, Image input • \n                    2 months ago"
      }
    ]
  },
  {
    "name": "dolphin-mixtral",
    "link": "https://ollama.com/library/dolphin-mixtral",
    "description": "Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford.",
    "pullCount": "634.4K",
    "updated": "8 months ago",
    "size": [
      "8x7b",
      "8x22b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/c65aad4e-7a58-4645-97f2-5e8ca158275f)\n\nThe Dolphin model by Eric Hartford based on [Mixtral](https://ollama.ai/library/mixtral) that is trained with additional datasets:\n\n* Synthia, OpenHermes and PureDove\n* New Dolphin-Coder\n* MagiCoder\n\n### Sizes\n\n* `dolphin-mixtral:8x22b`\n* `dolphin-mixtral:8x7b`\n\n## References\n\n[HuggingFace](https://huggingface.co/ehartford/dolphin-2.5-mixtral-8x7b)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/c65aad4e-7a58-4645-97f2-5e8ca158275f\" width=\"280\" /> The Dolphin model by Eric Hartford based on \\[Mixtral\\](https://ollama.ai/library/mixtral) that is trained with additional datasets: \\* Synthia, OpenHermes and PureDove \\* New Dolphin-Coder \\* MagiCoder ### Sizes \\* \\`dolphin-mixtral:8x22b\\` \\* \\`dolphin-mixtral:8x7b\\` ## References \\[HuggingFace\\](https://huggingface.co/ehartford/dolphin-2.5-mixtral-8x7b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dolphin-mixtral:latest",
        "size": "dolphin-mixtral:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:v2.5",
        "size": "dolphin-mixtral:v2.5",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:v2.6",
        "size": "dolphin-mixtral:v2.6",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:v2.7",
        "size": "dolphin-mixtral:v2.7",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b",
        "size": "dolphin-mixtral:8x7b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x22b",
        "size": "dolphin-mixtral:8x22b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5",
        "size": "dolphin-mixtral:8x7b-v2.5",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q2_K",
        "size": "dolphin-mixtral:8x7b-v2.5-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q3_K_S",
        "size": "dolphin-mixtral:8x7b-v2.5-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q3_K_M",
        "size": "dolphin-mixtral:8x7b-v2.5-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q3_K_L",
        "size": "dolphin-mixtral:8x7b-v2.5-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q4_0",
        "size": "dolphin-mixtral:8x7b-v2.5-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q4_1",
        "size": "dolphin-mixtral:8x7b-v2.5-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q4_K_S",
        "size": "dolphin-mixtral:8x7b-v2.5-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q4_K_M",
        "size": "dolphin-mixtral:8x7b-v2.5-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q5_0",
        "size": "dolphin-mixtral:8x7b-v2.5-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q5_1",
        "size": "dolphin-mixtral:8x7b-v2.5-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q5_K_S",
        "size": "dolphin-mixtral:8x7b-v2.5-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q5_K_M",
        "size": "dolphin-mixtral:8x7b-v2.5-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q6_K",
        "size": "dolphin-mixtral:8x7b-v2.5-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-q8_0",
        "size": "dolphin-mixtral:8x7b-v2.5-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.5-fp16",
        "size": "dolphin-mixtral:8x7b-v2.5-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6",
        "size": "dolphin-mixtral:8x7b-v2.6",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q2_K",
        "size": "dolphin-mixtral:8x7b-v2.6-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q3_K_S",
        "size": "dolphin-mixtral:8x7b-v2.6-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q3_K_M",
        "size": "dolphin-mixtral:8x7b-v2.6-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q3_K_L",
        "size": "dolphin-mixtral:8x7b-v2.6-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q4_0",
        "size": "dolphin-mixtral:8x7b-v2.6-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q4_1",
        "size": "dolphin-mixtral:8x7b-v2.6-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q4_K_S",
        "size": "dolphin-mixtral:8x7b-v2.6-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q4_K_M",
        "size": "dolphin-mixtral:8x7b-v2.6-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q5_0",
        "size": "dolphin-mixtral:8x7b-v2.6-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q5_1",
        "size": "dolphin-mixtral:8x7b-v2.6-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q5_K_S",
        "size": "dolphin-mixtral:8x7b-v2.6-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q5_K_M",
        "size": "dolphin-mixtral:8x7b-v2.6-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q6_K",
        "size": "dolphin-mixtral:8x7b-v2.6-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-q8_0",
        "size": "dolphin-mixtral:8x7b-v2.6-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.6-fp16",
        "size": "dolphin-mixtral:8x7b-v2.6-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7",
        "size": "dolphin-mixtral:8x7b-v2.7",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q2_K",
        "size": "dolphin-mixtral:8x7b-v2.7-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q3_K_S",
        "size": "dolphin-mixtral:8x7b-v2.7-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q3_K_M",
        "size": "dolphin-mixtral:8x7b-v2.7-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q3_K_L",
        "size": "dolphin-mixtral:8x7b-v2.7-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q4_0",
        "size": "dolphin-mixtral:8x7b-v2.7-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q4_1",
        "size": "dolphin-mixtral:8x7b-v2.7-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q4_K_S",
        "size": "dolphin-mixtral:8x7b-v2.7-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q4_K_M",
        "size": "dolphin-mixtral:8x7b-v2.7-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q5_0",
        "size": "dolphin-mixtral:8x7b-v2.7-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q5_1",
        "size": "dolphin-mixtral:8x7b-v2.7-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q5_K_S",
        "size": "dolphin-mixtral:8x7b-v2.7-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q5_K_M",
        "size": "dolphin-mixtral:8x7b-v2.7-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q6_K",
        "size": "dolphin-mixtral:8x7b-v2.7-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-q8_0",
        "size": "dolphin-mixtral:8x7b-v2.7-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x7b-v2.7-fp16",
        "size": "dolphin-mixtral:8x7b-v2.7-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9",
        "size": "dolphin-mixtral:8x22b-v2.9",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q2_K",
        "size": "dolphin-mixtral:8x22b-v2.9-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q3_K_S",
        "size": "dolphin-mixtral:8x22b-v2.9-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q3_K_M",
        "size": "dolphin-mixtral:8x22b-v2.9-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q3_K_L",
        "size": "dolphin-mixtral:8x22b-v2.9-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q4_0",
        "size": "dolphin-mixtral:8x22b-v2.9-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q4_1",
        "size": "dolphin-mixtral:8x22b-v2.9-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q4_K_S",
        "size": "dolphin-mixtral:8x22b-v2.9-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q4_K_M",
        "size": "dolphin-mixtral:8x22b-v2.9-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q5_0",
        "size": "dolphin-mixtral:8x22b-v2.9-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q5_1",
        "size": "dolphin-mixtral:8x22b-v2.9-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q5_K_S",
        "size": "dolphin-mixtral:8x22b-v2.9-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q5_K_M",
        "size": "dolphin-mixtral:8x22b-v2.9-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q6_K",
        "size": "dolphin-mixtral:8x22b-v2.9-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-q8_0",
        "size": "dolphin-mixtral:8x22b-v2.9-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mixtral:8x22b-v2.9-fp16",
        "size": "dolphin-mixtral:8x22b-v2.9-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "orca-mini",
    "link": "https://ollama.com/library/orca-mini",
    "description": "A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware.",
    "pullCount": "631.9K",
    "updated": "1 year ago",
    "size": [
      "3b",
      "7b",
      "13b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nOrca Mini is a Llama and Llama 2 model trained on Orca Style datasets created using the approaches defined in the paper, Orca: Progressive Learning from Complex Explanation Traces of GPT-4\\. There are two variations available. The original Orca Mini based on Llama in 3, 7, and 13 billion parameter sizes, and v3 based on Llama 2 in 7, 13, and 70 billion parameter sizes.\n\n## Usage\n\n### CLI\n\nOpen the terminal and run `ollama run orca-mini`\n\n### API\n\nExample:\n\n```\n  curl -X POST http://localhost:11434/api/generate -d '{\n    \"model\": \"orca-mini\",\n    \"prompt\":\"Why is the sky blue?\"\n   }'\n\n```\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 13b models generally require at least 16GB of RAM\n* 70b models generally require at least 64GB of RAM\n\n## Reference\n\n3b parameters original source:[Pankaj Mathur](https://huggingface.co/psmathur/orca%5Fmini%5F3b)\n\n7b parameters original source:[Pankaj Mathur](https://huggingface.co/psmathur/orca%5Fmini%5F7b)\n\n13b parameters original source:[Pankaj Mathur](https://huggingface.co/psmathur/orca%5Fmini%5F13b)\n\n**Orca Mini v3 source on Ollama**\n\n13b parameters original source:[Pankaj Mathur](https://huggingface.co/psmathur/orca%5Fmini%5Fv3%5F13b)\n\n70b parameters source:[Pankaj Mathur](https://huggingface.co/psmathur/orca%5Fmini%5Fv3%5F70b)\n\n[Orca: Progressive Learning from Complex Explanation Traces of GPT-4](https://arxiv.org/abs/2306.02707)\n\nWrite Preview \n\nOrca Mini is a Llama and Llama 2 model trained on Orca Style datasets created using the approaches defined in the paper, Orca: Progressive Learning from Complex Explanation Traces of GPT-4\\. There are two variations available. The original Orca Mini based on Llama in 3, 7, and 13 billion parameter sizes, and v3 based on Llama 2 in 7, 13, and 70 billion parameter sizes. ## Usage ### CLI Open the terminal and run \\`ollama run orca-mini\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"orca-mini\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` ## Memory requirements - 7b models generally require at least 8GB of RAM - 13b models generally require at least 16GB of RAM - 70b models generally require at least 64GB of RAM ## Reference 3b parameters original source: \\[Pankaj Mathur\\](https://huggingface.co/psmathur/orca\\_mini\\_3b) 7b parameters original source: \\[Pankaj Mathur\\](https://huggingface.co/psmathur/orca\\_mini\\_7b) 13b parameters original source: \\[Pankaj Mathur\\](https://huggingface.co/psmathur/orca\\_mini\\_13b) \\*\\*Orca Mini v3 source on Ollama\\*\\* 13b parameters original source: \\[Pankaj Mathur\\](https://huggingface.co/psmathur/orca\\_mini\\_v3\\_13b) 70b parameters source: \\[Pankaj Mathur\\](https://huggingface.co/psmathur/orca\\_mini\\_v3\\_70b) \\[Orca: Progressive Learning from Complex Explanation Traces of GPT-4\\](https://arxiv.org/abs/2306.02707 ) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "orca-mini:latest",
        "size": "orca-mini:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b",
        "size": "orca-mini:3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b",
        "size": "orca-mini:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b",
        "size": "orca-mini:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b",
        "size": "orca-mini:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b-q4_0",
        "size": "orca-mini:3b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b-q4_1",
        "size": "orca-mini:3b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b-q5_0",
        "size": "orca-mini:3b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b-q5_1",
        "size": "orca-mini:3b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b-q8_0",
        "size": "orca-mini:3b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:3b-fp16",
        "size": "orca-mini:3b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q2_K",
        "size": "orca-mini:7b-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q3_K_S",
        "size": "orca-mini:7b-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q3_K_M",
        "size": "orca-mini:7b-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q3_K_L",
        "size": "orca-mini:7b-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q4_0",
        "size": "orca-mini:7b-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q4_1",
        "size": "orca-mini:7b-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q4_K_S",
        "size": "orca-mini:7b-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q4_K_M",
        "size": "orca-mini:7b-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q5_0",
        "size": "orca-mini:7b-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q5_1",
        "size": "orca-mini:7b-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q5_K_S",
        "size": "orca-mini:7b-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q5_K_M",
        "size": "orca-mini:7b-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q6_K",
        "size": "orca-mini:7b-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-q8_0",
        "size": "orca-mini:7b-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v2-fp16",
        "size": "orca-mini:7b-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3",
        "size": "orca-mini:7b-v3",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q2_K",
        "size": "orca-mini:7b-v3-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q3_K_S",
        "size": "orca-mini:7b-v3-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q3_K_M",
        "size": "orca-mini:7b-v3-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q3_K_L",
        "size": "orca-mini:7b-v3-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q4_0",
        "size": "orca-mini:7b-v3-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q4_1",
        "size": "orca-mini:7b-v3-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q4_K_S",
        "size": "orca-mini:7b-v3-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q4_K_M",
        "size": "orca-mini:7b-v3-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q5_0",
        "size": "orca-mini:7b-v3-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q5_1",
        "size": "orca-mini:7b-v3-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q5_K_S",
        "size": "orca-mini:7b-v3-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q5_K_M",
        "size": "orca-mini:7b-v3-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q6_K",
        "size": "orca-mini:7b-v3-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-q8_0",
        "size": "orca-mini:7b-v3-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-v3-fp16",
        "size": "orca-mini:7b-v3-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q2_K",
        "size": "orca-mini:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q3_K_S",
        "size": "orca-mini:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q3_K_M",
        "size": "orca-mini:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q3_K_L",
        "size": "orca-mini:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q4_0",
        "size": "orca-mini:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q4_1",
        "size": "orca-mini:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q4_K_S",
        "size": "orca-mini:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q4_K_M",
        "size": "orca-mini:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q5_0",
        "size": "orca-mini:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q5_1",
        "size": "orca-mini:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q5_K_S",
        "size": "orca-mini:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q5_K_M",
        "size": "orca-mini:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q6_K",
        "size": "orca-mini:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-q8_0",
        "size": "orca-mini:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:7b-fp16",
        "size": "orca-mini:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q2_K",
        "size": "orca-mini:13b-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q3_K_S",
        "size": "orca-mini:13b-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q3_K_M",
        "size": "orca-mini:13b-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q3_K_L",
        "size": "orca-mini:13b-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q4_0",
        "size": "orca-mini:13b-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q4_1",
        "size": "orca-mini:13b-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q4_K_S",
        "size": "orca-mini:13b-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q4_K_M",
        "size": "orca-mini:13b-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q5_0",
        "size": "orca-mini:13b-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q5_1",
        "size": "orca-mini:13b-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q5_K_S",
        "size": "orca-mini:13b-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q5_K_M",
        "size": "orca-mini:13b-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q6_K",
        "size": "orca-mini:13b-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-q8_0",
        "size": "orca-mini:13b-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v2-fp16",
        "size": "orca-mini:13b-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3",
        "size": "orca-mini:13b-v3",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q2_K",
        "size": "orca-mini:13b-v3-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q3_K_S",
        "size": "orca-mini:13b-v3-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q3_K_M",
        "size": "orca-mini:13b-v3-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q3_K_L",
        "size": "orca-mini:13b-v3-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q4_0",
        "size": "orca-mini:13b-v3-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q4_1",
        "size": "orca-mini:13b-v3-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q4_K_S",
        "size": "orca-mini:13b-v3-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q4_K_M",
        "size": "orca-mini:13b-v3-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q5_0",
        "size": "orca-mini:13b-v3-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q5_1",
        "size": "orca-mini:13b-v3-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q5_K_S",
        "size": "orca-mini:13b-v3-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q5_K_M",
        "size": "orca-mini:13b-v3-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q6_K",
        "size": "orca-mini:13b-v3-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-q8_0",
        "size": "orca-mini:13b-v3-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-v3-fp16",
        "size": "orca-mini:13b-v3-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q2_K",
        "size": "orca-mini:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q3_K_S",
        "size": "orca-mini:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q3_K_M",
        "size": "orca-mini:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q3_K_L",
        "size": "orca-mini:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q4_0",
        "size": "orca-mini:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q4_1",
        "size": "orca-mini:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q4_K_S",
        "size": "orca-mini:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q4_K_M",
        "size": "orca-mini:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q5_0",
        "size": "orca-mini:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q5_1",
        "size": "orca-mini:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q5_K_S",
        "size": "orca-mini:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q5_K_M",
        "size": "orca-mini:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q6_K",
        "size": "orca-mini:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-q8_0",
        "size": "orca-mini:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:13b-fp16",
        "size": "orca-mini:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3",
        "size": "orca-mini:70b-v3",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q2_K",
        "size": "orca-mini:70b-v3-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q3_K_S",
        "size": "orca-mini:70b-v3-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q3_K_M",
        "size": "orca-mini:70b-v3-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q3_K_L",
        "size": "orca-mini:70b-v3-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q4_0",
        "size": "orca-mini:70b-v3-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q4_1",
        "size": "orca-mini:70b-v3-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q4_K_S",
        "size": "orca-mini:70b-v3-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q4_K_M",
        "size": "orca-mini:70b-v3-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q5_0",
        "size": "orca-mini:70b-v3-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q5_1",
        "size": "orca-mini:70b-v3-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q5_K_S",
        "size": "orca-mini:70b-v3-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q5_K_M",
        "size": "orca-mini:70b-v3-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q6_K",
        "size": "orca-mini:70b-v3-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-q8_0",
        "size": "orca-mini:70b-v3-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca-mini:70b-v3-fp16",
        "size": "orca-mini:70b-v3-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "openthinker",
    "link": "https://ollama.com/library/openthinker",
    "description": "A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.",
    "pullCount": "596K",
    "updated": "5 months ago",
    "size": [
      "7b",
      "32b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/openthinker/0ef3a0d3-aae1-4855-b56b-50875e9683e8)\n\nOpenThinker is a family of fine-tuned models from Qwen2.5 on the [OpenThoughts-114k dataset](https://huggingface.co/datasets/open-thoughts/open-thoughts-114k), surpassing DeepSeek-R1 distillation models on some benchmarks.\n\nThe dataset is derived by distilling DeepSeek-R1 using the data pipeline available on github. More info about the dataset can be found on the dataset card at OpenThoughts-114k dataset.\n\n### Models\n\n#### 32B\n\n```\nollama run openthinker:32b\n\n```\n\n| Model Name                   | Dataset Size  | AIME24 I/II | AIME25 I | MATH500  | GPQA Diamond | LCBv2    |\n| ---------------------------- | ------------- | ----------- | -------- | -------- | ------------ | -------- |\n| LIMO-32B                     | 0.8k          | 56.7        | 49.3     | 86.6     | 58.1         | 60.0     |\n| s1-32B                       | 1k            | 36.0        | 25.3     | 84.8     | 50.5         | 40.9     |\n| s1.1-32B                     | 1k            | 64.7        | 49.3     | 89.0     | 60.1         | 65.5     |\n| DeepSeek-R1-Distill-Qwen-32B | 800k (closed) | **76.7**    | **55.9** | 89.4     | 57.6         | **71.2** |\n| **OpenThinker-32B**          | 114k          | 66.0        | 53.3     | **90.6** | **61.6**     | 68.9     |\n\n#### 7B (default)\n\n```\nollama run openthinker:7b\n\n```\n\n| AIME24                      | MATH500 | GPQA-Diamond | LCBv2 Easy | LCBv2 Medium | LCBv2 Hard | LCBv2 All |      |\n| --------------------------- | ------- | ------------ | ---------- | ------------ | ---------- | --------- | ---- |\n| OpenThinker-7B              | 31.3    | 83.0         | 42.4       | 75.3         | 28.6       | 6.5       | 39.9 |\n| Bespoke-Stratos-7B          | 22.7    | 79.6         | 38.9       | 71.4         | 25.2       | 0.8       | 35.8 |\n| DeepSeek-R1-Distill-Qwen-7B | 60      | 88.2         | 46.9       | 79.7         | 45.1       | 14.6      | 50.1 |\n| gpt-4o-0513                 | 8.7     | 75.8         | 46.5       | 87.4         | 42.7       | 8.9       | 50.5 |\n| o1-mini                     | 64      | 85.6         | 60         | 92.8         | 74.7       | 39.8      | 72.8 |\n\n## References\n\n[GitHub](https://github.com/open-thoughts/open-thoughts)\n\n[Blog post](https://www.open-thoughts.ai/blog/launch)\n\nWrite Preview \n\n<img src=\"/assets/library/openthinker/0ef3a0d3-aae1-4855-b56b-50875e9683e8\" width=\"320\" /> OpenThinker is a family of fine-tuned models from Qwen2.5 on the \\[OpenThoughts-114k dataset\\](https://huggingface.co/datasets/open-thoughts/open-thoughts-114k), surpassing DeepSeek-R1 distillation models on some benchmarks. The dataset is derived by distilling DeepSeek-R1 using the data pipeline available on github. More info about the dataset can be found on the dataset card at OpenThoughts-114k dataset. ### Models #### 32B \\`\\`\\` ollama run openthinker:32b \\`\\`\\` |Model Name|Dataset Size|AIME24 I/II|AIME25 I|MATH500|GPQA Diamond|LCBv2| |---|---|---|---|---|---|---| |LIMO-32B|0.8k|56.7|49.3|86.6|58.1|60.0| |s1-32B|1k|36.0|25.3|84.8|50.5|40.9| |s1.1-32B|1k|64.7|49.3|89.0|60.1|65.5| |DeepSeek-R1-Distill-Qwen-32B|800k (closed)|\\*\\*76.7\\*\\*|\\*\\*55.9\\*\\*|89.4|57.6|\\*\\*71.2\\*\\*| |\\*\\*OpenThinker-32B\\*\\*|114k|66.0|53.3|\\*\\*90.6\\*\\*|\\*\\*61.6\\*\\*|68.9| #### 7B (default) \\`\\`\\` ollama run openthinker:7b \\`\\`\\` | | AIME24 | MATH500 | GPQA-Diamond | LCBv2 Easy | LCBv2 Medium | LCBv2 Hard | LCBv2 All | | --------------------------- | -------- | ------- | ------------ | ----------- | ------------- | ----------- | ---------- | | OpenThinker-7B | 31.3 | 83.0 | 42.4 | 75.3 | 28.6 | 6.5 | 39.9 | | Bespoke-Stratos-7B | 22.7 | 79.6 | 38.9 | 71.4 | 25.2 | 0.8 | 35.8 | | DeepSeek-R1-Distill-Qwen-7B | 60 | 88.2 | 46.9 | 79.7 | 45.1 | 14.6 | 50.1 | | gpt-4o-0513 | 8.7 | 75.8 | 46.5 | 87.4 | 42.7 | 8.9 | 50.5 | | o1-mini | 64 | 85.6 | 60 | 92.8 | 74.7 | 39.8 | 72.8 | ## References \\[GitHub\\](https://github.com/open-thoughts/open-thoughts) \\[Blog post\\](https://www.open-thoughts.ai/blog/launch) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "openthinker:latest",
        "size": "openthinker:latest",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:7b",
        "size": "openthinker:7b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:32b",
        "size": "openthinker:32b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:7b-v2-q4_K_M",
        "size": "openthinker:7b-v2-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:7b-v2-q8_0",
        "size": "openthinker:7b-v2-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:7b-v2-fp16",
        "size": "openthinker:7b-v2-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:7b-q4_K_M",
        "size": "openthinker:7b-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "openthinker:7b-q8_0",
        "size": "openthinker:7b-q8_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "openthinker:7b-fp16",
        "size": "openthinker:7b-fp16",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "openthinker:32b-v2-q4_K_M",
        "size": "openthinker:32b-v2-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:32b-v2-q8_0",
        "size": "openthinker:32b-v2-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:32b-v2-fp16",
        "size": "openthinker:32b-v2-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "openthinker:32b-q4_K_M",
        "size": "openthinker:32b-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "openthinker:32b-q8_0",
        "size": "openthinker:32b-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "openthinker:32b-fp16",
        "size": "openthinker:32b-fp16",
        "updated": "Text input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "qwen2.5vl",
    "link": "https://ollama.com/library/qwen2.5vl",
    "description": "Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.",
    "pullCount": "546.8K",
    "updated": "3 months ago",
    "size": [
      "3b",
      "7b",
      "32b",
      "72b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n> Note: this model requires Ollama 0.7.0\\. [Download Ollama](https://ollama.com/download)\n\n![](/assets/library/qwen2.5vl/7bd5aad3-d5c5-43b1-b915-1e85a378f1c4)\n\nQwen2.5-VL, the new flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.\n\nThe key features include:\n\n* **Understand things visually:** Qwen2.5-VL is not only proficient in recognizing common objects such as flowers, birds, fish, and insects, but it is highly capable of analyzing texts, charts, icons, graphics, and layouts within images.\n* **Being agentic:** Qwen2.5-VL directly plays as a visual agent that can reason and dynamically direct tools, which is capable of computer use and phone use.\n* **Capable of visual localization in different formats:** Qwen2.5-VL can accurately localize objects in an image by generating bounding boxes or points, and it can provide stable JSON outputs for coordinates and attributes.\n* **Generating structured outputs:** for data like scans of invoices, forms, tables, etc. Qwen2.5-VL supports structured outputs of their contents, benefiting usages in finance, commerce, etc.\n\n## Performance\n\nWe evaluate our models with the SOTA models as well as the best models of similar model sizes. In terms of the flagship model Qwen2.5-VL-72B-Instruct, it achieves competitive performance in a series of benchmarks covering domains and tasks, including college-level problems, math, document understanding, general question answering, math, and visual agent. Notably, Qwen2.5-VL achieves significant advantages in understanding documents and diagrams, and it is capable of playing as a visual agent without task-specific fine tuning.\n\n![image.png](/assets/library/qwen2.5vl/440a5a81-c4e4-4b5e-aa3d-f75ab2ad04cc)\n\nIn terms of smaller models, Qwen2.5-VL-7B-Instruct outperforms GPT-4o-mini in a number of tasks, and Qwen2.5-VL-3B, which is a solution for edge AI, even outperforms the 7B model of our previous version Qwen2-VL.\n\n![image.png](/assets/library/qwen2.5vl/533ec184-7b82-4bcf-a4ab-af9a41ac0810)\n\n![image.png](/assets/library/qwen2.5vl/c90b8e4b-d023-4953-9cd5-e515324ca73c)\n\n## References\n\n[Blog](https://qwenlm.github.io/blog/qwen2.5-vl/)\n\n[Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)\n\nWrite Preview \n\n\\> Note: this model requires Ollama 0.7.0\\. \\[Download Ollama\\](https://ollama.com/download) <img src=\"/assets/library/qwen2.5vl/7bd5aad3-d5c5-43b1-b915-1e85a378f1c4\" width=\"280\" /> Qwen2.5-VL, the new flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL. The key features include: - \\*\\*Understand things visually:\\*\\* Qwen2.5-VL is not only proficient in recognizing common objects such as flowers, birds, fish, and insects, but it is highly capable of analyzing texts, charts, icons, graphics, and layouts within images. - \\*\\*Being agentic:\\*\\* Qwen2.5-VL directly plays as a visual agent that can reason and dynamically direct tools, which is capable of computer use and phone use. - \\*\\*Capable of visual localization in different formats:\\*\\* Qwen2.5-VL can accurately localize objects in an image by generating bounding boxes or points, and it can provide stable JSON outputs for coordinates and attributes. - \\*\\*Generating structured outputs:\\*\\* for data like scans of invoices, forms, tables, etc. Qwen2.5-VL supports structured outputs of their contents, benefiting usages in finance, commerce, etc. ## Performance We evaluate our models with the SOTA models as well as the best models of similar model sizes. In terms of the flagship model Qwen2.5-VL-72B-Instruct, it achieves competitive performance in a series of benchmarks covering domains and tasks, including college-level problems, math, document understanding, general question answering, math, and visual agent. Notably, Qwen2.5-VL achieves significant advantages in understanding documents and diagrams, and it is capable of playing as a visual agent without task-specific fine tuning. !\\[image.png\\](/assets/library/qwen2.5vl/440a5a81-c4e4-4b5e-aa3d-f75ab2ad04cc) In terms of smaller models, Qwen2.5-VL-7B-Instruct outperforms GPT-4o-mini in a number of tasks, and Qwen2.5-VL-3B, which is a solution for edge AI, even outperforms the 7B model of our previous version Qwen2-VL. !\\[image.png\\](/assets/library/qwen2.5vl/533ec184-7b82-4bcf-a4ab-af9a41ac0810) !\\[image.png\\](/assets/library/qwen2.5vl/c90b8e4b-d023-4953-9cd5-e515324ca73c) ## References \\[Blog\\](https://qwenlm.github.io/blog/qwen2.5-vl/) \\[Qwen2.5-VL Technical Report\\](https://arxiv.org/abs/2502.13923) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen2.5vl:latest",
        "size": "qwen2.5vl:latest",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:3b",
        "size": "qwen2.5vl:3b",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:7b",
        "size": "qwen2.5vl:7b",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:32b",
        "size": "qwen2.5vl:32b",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:72b",
        "size": "qwen2.5vl:72b",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:3b-q4_K_M",
        "size": "qwen2.5vl:3b-q4_K_M",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:3b-q8_0",
        "size": "qwen2.5vl:3b-q8_0",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:3b-fp16",
        "size": "qwen2.5vl:3b-fp16",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:7b-q4_K_M",
        "size": "qwen2.5vl:7b-q4_K_M",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:7b-q8_0",
        "size": "qwen2.5vl:7b-q8_0",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:7b-fp16",
        "size": "qwen2.5vl:7b-fp16",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:32b-q4_K_M",
        "size": "qwen2.5vl:32b-q4_K_M",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:32b-q8_0",
        "size": "qwen2.5vl:32b-q8_0",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:32b-fp16",
        "size": "qwen2.5vl:32b-fp16",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:72b-q4_K_M",
        "size": "qwen2.5vl:72b-q4_K_M",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:72b-q8_0",
        "size": "qwen2.5vl:72b-q8_0",
        "updated": "Text, Image input • \n                    3 months ago"
      },
      {
        "name": "qwen2.5vl:72b-fp16",
        "size": "qwen2.5vl:72b-fp16",
        "updated": "Text, Image input • \n                    3 months ago"
      }
    ]
  },
  {
    "name": "falcon3",
    "link": "https://ollama.com/library/falcon3",
    "description": "A family of efficient AI models under 10B parameters performant in science, math, and coding through innovative training techniques.",
    "pullCount": "468.8K",
    "updated": "8 months ago",
    "size": [
      "1b",
      "3b",
      "7b",
      "10b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/falcon3/7ead93c7-c315-42ad-b49f-3aa370c3e7db)\n\nFalcon3 represents TII’s latest advancement in efficient language models under 10B parameters, focused on enhancing science, math, and code capabilities while maintaining training efficiency.\n\n# Key Features\n\n* Four sizes: 1B, 3B, 7B, 10B\n* Depth up-scaling technique used to create 10B model from 7B\n* Knowledge distillation for smaller models (1B, 3B)\n\n# Performance Highlights\n\n* `falcon3:1b` outperforms `smollm2:1.7b`, matches `gemma2:2b`\n* `falcon3:10b` achieves SOTA in under-13B category\n* Extended context length up to 32K tokens (8K for 1B model)\n\n# References\n\n[Hugging Face](https://huggingface.co/blog/falcon3)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/falcon3/7ead93c7-c315-42ad-b49f-3aa370c3e7db\" width=\"425\" /> Falcon3 represents TII's latest advancement in efficient language models under 10B parameters, focused on enhancing science, math, and code capabilities while maintaining training efficiency. # Key Features - Four sizes: 1B, 3B, 7B, 10B - Depth up-scaling technique used to create 10B model from 7B - Knowledge distillation for smaller models (1B, 3B) # Performance Highlights - \\`falcon3:1b\\` outperforms \\`smollm2:1.7b\\`, matches \\`gemma2:2b\\` - \\`falcon3:10b\\` achieves SOTA in under-13B category - Extended context length up to 32K tokens (8K for 1B model) # References \\[Hugging Face\\](https://huggingface.co/blog/falcon3) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "falcon3:latest",
        "size": "falcon3:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:1b",
        "size": "falcon3:1b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:3b",
        "size": "falcon3:3b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:7b",
        "size": "falcon3:7b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:10b",
        "size": "falcon3:10b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:1b-instruct-q4_K_M",
        "size": "falcon3:1b-instruct-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:1b-instruct-q8_0",
        "size": "falcon3:1b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:1b-instruct-fp16",
        "size": "falcon3:1b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:3b-instruct-q4_K_M",
        "size": "falcon3:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:3b-instruct-q8_0",
        "size": "falcon3:3b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:3b-instruct-fp16",
        "size": "falcon3:3b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:7b-instruct-q4_K_M",
        "size": "falcon3:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:7b-instruct-q8_0",
        "size": "falcon3:7b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:7b-instruct-fp16",
        "size": "falcon3:7b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:10b-instruct-q4_K_M",
        "size": "falcon3:10b-instruct-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:10b-instruct-q8_0",
        "size": "falcon3:10b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "falcon3:10b-instruct-fp16",
        "size": "falcon3:10b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "gemma3n",
    "link": "https://ollama.com/library/gemma3n",
    "description": "Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones.",
    "pullCount": "434.8K",
    "updated": "2 months ago",
    "size": [
      "e2b",
      "e4b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/gemma3n/440e8da2-ddf4-482f-a341-4eeb3c08a332)\n\nGemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones. These models were trained with data in over 140 spoken languages.\n\nGemma 3n models use selective parameter activation technology to reduce resource requirements. This technique allows the models to operate at an effective size of 2B and 4B parameters, which is lower than the total number of parameters they contain.\n\n## Models\n\n### Effective 2B\n\n```\nollama run gemma3n:e2b\n\n```\n\n### Effective 4B\n\n```\nollama run gemma3n:e4b\n\n```\n\n## Evaluation\n\nModel evaluation metrics and results.\n\n### Benchmark Results\n\nThese models were evaluated at full precision (float32) against a large collection of different datasets and metrics to cover different aspects of content generation. Evaluation results marked with **IT** are for instruction-tuned models. Evaluation results marked with **PT** are for pre-trained models. The models available on Ollama are instruction-tuned models.\n\n![lm arena](/assets/library/gemma3n/b131b187-c935-4310-931b-439ce30533fd)\n\n#### Reasoning and factuality\n\n| Benchmark                                                                          | Metric         | n-shot   | E2B PT | E4B PT |\n| ---------------------------------------------------------------------------------- | -------------- | -------- | ------ | ------ |\n| [HellaSwag](https://arxiv.org/abs/1905.07830)                                      | Accuracy       | 10-shot  | 72.2   | 78.6   |\n| [BoolQ](https://arxiv.org/abs/1905.10044)                                          | Accuracy       | 0-shot   | 76.4   | 81.6   |\n| [PIQA](https://arxiv.org/abs/1911.11641)                                           | Accuracy       | 0-shot   | 78.9   | 81.0   |\n| [SocialIQA](https://arxiv.org/abs/1904.09728)                                      | Accuracy       | 0-shot   | 48.8   | 50.0   |\n| [TriviaQA](https://arxiv.org/abs/1705.03551)                                       | Accuracy       | 5-shot   | 60.8   | 70.2   |\n| [Natural Questions](https://github.com/google-research-datasets/natural-questions) | Accuracy       | 5-shot   | 15.5   | 20.9   |\n| [ARC-c](https://arxiv.org/abs/1911.01547)                                          | Accuracy       | 25-shot  | 51.7   | 61.6   |\n| [ARC-e](https://arxiv.org/abs/1911.01547)                                          | Accuracy       | 0-shot   | 75.8   | 81.6   |\n| [WinoGrande](https://arxiv.org/abs/1907.10641)                                     | Accuracy       | 5-shot   | 66.8   | 71.7   |\n| [BIG-Bench Hard](https://paperswithcode.com/dataset/bbh)                           | Accuracy       | few-shot | 44.3   | 52.9   |\n| [DROP](https://arxiv.org/abs/1903.00161)                                           | Token F1 score | 1-shot   | 53.9   | 60.8   |\n\n#### Multilingual\n\n| Benchmark                                                             | Metric                  | n-shot | E2B IT | E4B IT |\n| --------------------------------------------------------------------- | ----------------------- | ------ | ------ | ------ |\n| [MGSM](https://arxiv.org/abs/2210.03057)                              | Accuracy                | 0-shot | 53.1   | 60.7   |\n| [WMT24++](https://arxiv.org/abs/2502.12404v1) (ChrF)                  | Character-level F-score | 0-shot | 42.7   | 50.1   |\n| [Include](https://arxiv.org/abs/2411.19799)                           | Accuracy                | 0-shot | 38.6   | 57.2   |\n| [MMLU](https://arxiv.org/abs/2009.03300) (ProX)                       | Accuracy                | 0-shot | 8.1    | 19.9   |\n| [OpenAI MMLU](https://huggingface.co/datasets/openai/MMMLU)           | Accuracy                | 0-shot | 22.3   | 35.6   |\n| [Global-MMLU](https://huggingface.co/datasets/CohereLabs/Global-MMLU) | Accuracy                | 0-shot | 55.1   | 60.3   |\n| [ECLeKTic](https://arxiv.org/abs/2502.21228)                          | ECLeKTic score          | 0-shot | 2.5    | 1.9    |\n\n#### STEM and code\n\n| Benchmark                                                   | Metric                   | n-shot | E2B IT | E4B IT |\n| ----------------------------------------------------------- | ------------------------ | ------ | ------ | ------ |\n| [GPQA](https://arxiv.org/abs/2311.12022) Diamond            | RelaxedAccuracy/accuracy | 0-shot | 24.8   | 23.7   |\n| [LiveCodeBench](https://arxiv.org/abs/2403.07974) v5        | pass@1                   | 0-shot | 18.6   | 25.7   |\n| Codegolf v2.2                                               | pass@1                   | 0-shot | 11.0   | 16.8   |\n| [AIME 2025](https://www.vals.ai/benchmarks/aime-2025-05-09) | Accuracy                 | 0-shot | 6.7    | 11.6   |\n\n#### Additional benchmarks\n\n| Benchmark                                                                        | Metric   | n-shot | E2B IT | E4B IT |\n| -------------------------------------------------------------------------------- | -------- | ------ | ------ | ------ |\n| [MMLU](https://arxiv.org/abs/2009.03300)                                         | Accuracy | 0-shot | 60.1   | 64.9   |\n| [MBPP](https://arxiv.org/abs/2108.07732)                                         | pass@1   | 3-shot | 56.6   | 63.6   |\n| [HumanEval](https://arxiv.org/abs/2107.03374)                                    | pass@1   | 0-shot | 66.5   | 75.0   |\n| [LiveCodeBench](https://arxiv.org/abs/2403.07974)                                | pass@1   | 0-shot | 13.2   | 13.2   |\n| HiddenMath                                                                       | Accuracy | 0-shot | 27.7   | 37.7   |\n| [Global-MMLU-Lite](https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite) | Accuracy | 0-shot | 59.0   | 64.5   |\n| [MMLU](https://arxiv.org/abs/2009.03300) (Pro)                                   | Accuracy | 0-shot | 40.5   | 50.6   |\n\n## Usage and Limitations\n\nThese models have certain limitations that users should be aware of.\n\n### Intended Usage\n\nOpen generative models have a wide range of applications across various industries and domains. The following list of potential uses is not comprehensive. The purpose of this list is to provide contextual information about the possible use-cases that the model creators considered as part of model training and development.\n\n* Content Creation and Communication  \n   * **Text Generation**: Generate creative text formats such as poems, scripts, code, marketing copy, and email drafts.  \n   * **Chatbots and Conversational AI**: Power conversational interfaces for customer service, virtual assistants, or interactive applications.  \n   * **Text Summarization**: Generate concise summaries of a text corpus, research papers, or reports.  \n   * **Image Data Extraction**: Extract, interpret, and summarize visual data for text communications.  \n   * **Audio Data Extraction**: Transcribe spoken language, translate speech to text in other languages, and analyze sound-based data.\n* Research and Education  \n   * **Natural Language Processing (NLP) and generative model Research**: These models can serve as a foundation for researchers to experiment with generative models and NLP techniques, develop algorithms, and contribute to the advancement of the field.  \n   * **Language Learning Tools**: Support interactive language learning experiences, aiding in grammar correction or providing writing practice.  \n   * **Knowledge Exploration**: Assist researchers in exploring large bodies of data by generating summaries or answering questions about specific topics.\n\n## Ethics and Safety\n\nEthics and safety evaluation approach and results.\n\n### Evaluation Approach\n\nOur evaluation methods include structured evaluations and internal red-teaming testing of relevant content policies. Red-teaming was conducted by a number of different teams, each with different goals and human evaluation metrics. These models were evaluated against a number of different categories relevant to ethics and safety, including:\n\n* **Child Safety**: Evaluation of text-to-text and image to text prompts covering child safety policies, including child sexual abuse and exploitation.\n* **Content Safety:** Evaluation of text-to-text and image to text prompts covering safety policies including, harassment, violence and gore, and hate speech.\n* **Representational Harms**: Evaluation of text-to-text and image to text prompts covering safety policies including bias, stereotyping, and harmful associations or inaccuracies.\n\nIn addition to development level evaluations, we conduct “assurance evaluations” which are our ‘arms-length’ internal evaluations for responsibility governance decision making. They are conducted separately from the model development team, to inform decision making about release. High level findings are fed back to the model team, but prompt sets are held-out to prevent overfitting and preserve the results’ ability to inform decision making. Notable assurance evaluation results are reported to our Responsibility & Safety Council as part of release review.\n\n### Evaluation Results\n\nFor all areas of safety testing, we saw safe levels of performance across the categories of child safety, content safety, and representational harms relative to previous Gemma models. All testing was conducted without safety filters to evaluate the model capabilities and behaviors. For text-to-text, image-to-text, and audio-to-text, and across all model sizes, the model produced minimal policy violations, and showed significant improvements over previous Gemma models’ performance with respect to high severity violations. A limitation of our evaluations was they included primarily English language prompts.\n\nWrite Preview \n\n<img src=\"/assets/library/gemma3n/440e8da2-ddf4-482f-a341-4eeb3c08a332\" width=\"320\" /> Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones. These models were trained with data in over 140 spoken languages. Gemma 3n models use selective parameter activation technology to reduce resource requirements. This technique allows the models to operate at an effective size of 2B and 4B parameters, which is lower than the total number of parameters they contain. ## Models ### Effective 2B \\`\\`\\` ollama run gemma3n:e2b \\`\\`\\` ### Effective 4B \\`\\`\\` ollama run gemma3n:e4b \\`\\`\\` ## Evaluation Model evaluation metrics and results. ### Benchmark Results These models were evaluated at full precision (float32) against a large collection of different datasets and metrics to cover different aspects of content generation. Evaluation results marked with \\*\\*IT\\*\\* are for instruction-tuned models. Evaluation results marked with \\*\\*PT\\*\\* are for pre-trained models. The models available on Ollama are instruction-tuned models. !\\[lm arena\\](/assets/library/gemma3n/b131b187-c935-4310-931b-439ce30533fd) #### Reasoning and factuality | Benchmark | Metric | n-shot | E2B PT | E4B PT | | ------------------------------ |----------------|----------|:--------:|:--------:| | \\[HellaSwag\\]\\[hellaswag\\] | Accuracy | 10-shot | 72.2 | 78.6 | | \\[BoolQ\\]\\[boolq\\] | Accuracy | 0-shot | 76.4 | 81.6 | | \\[PIQA\\]\\[piqa\\] | Accuracy | 0-shot | 78.9 | 81.0 | | \\[SocialIQA\\]\\[socialiqa\\] | Accuracy | 0-shot | 48.8 | 50.0 | | \\[TriviaQA\\]\\[triviaqa\\] | Accuracy | 5-shot | 60.8 | 70.2 | | \\[Natural Questions\\]\\[naturalq\\] | Accuracy | 5-shot | 15.5 | 20.9 | | \\[ARC-c\\]\\[arc\\] | Accuracy | 25-shot | 51.7 | 61.6 | | \\[ARC-e\\]\\[arc\\] | Accuracy | 0-shot | 75.8 | 81.6 | | \\[WinoGrande\\]\\[winogrande\\] | Accuracy | 5-shot | 66.8 | 71.7 | | \\[BIG-Bench Hard\\]\\[bbh\\] | Accuracy | few-shot | 44.3 | 52.9 | | \\[DROP\\]\\[drop\\] | Token F1 score | 1-shot | 53.9 | 60.8 | \\[hellaswag\\]: https://arxiv.org/abs/1905.07830 \\[boolq\\]: https://arxiv.org/abs/1905.10044 \\[piqa\\]: https://arxiv.org/abs/1911.11641 \\[socialiqa\\]: https://arxiv.org/abs/1904.09728 \\[triviaqa\\]: https://arxiv.org/abs/1705.03551 \\[naturalq\\]: https://github.com/google-research-datasets/natural-questions \\[arc\\]: https://arxiv.org/abs/1911.01547 \\[winogrande\\]: https://arxiv.org/abs/1907.10641 \\[bbh\\]: https://paperswithcode.com/dataset/bbh \\[drop\\]: https://arxiv.org/abs/1903.00161 #### Multilingual | Benchmark | Metric | n-shot | E2B IT | E4B IT | | ------------------------------------|-------------------------|----------|:--------:|:--------:| | \\[MGSM\\]\\[mgsm\\] | Accuracy | 0-shot | 53.1 | 60.7 | | \\[WMT24++\\]\\[wmt24pp\\] (ChrF) | Character-level F-score | 0-shot | 42.7 | 50.1 | | \\[Include\\]\\[include\\] | Accuracy | 0-shot | 38.6 | 57.2 | | \\[MMLU\\]\\[mmlu\\] (ProX) | Accuracy | 0-shot | 8.1 | 19.9 | | \\[OpenAI MMLU\\]\\[openai-mmlu\\] | Accuracy | 0-shot | 22.3 | 35.6 | | \\[Global-MMLU\\]\\[global-mmlu\\] | Accuracy | 0-shot | 55.1 | 60.3 | | \\[ECLeKTic\\]\\[eclektic\\] | ECLeKTic score | 0-shot | 2.5 | 1.9 | \\[mgsm\\]: https://arxiv.org/abs/2210.03057 \\[wmt24pp\\]: https://arxiv.org/abs/2502.12404v1 \\[include\\]:https://arxiv.org/abs/2411.19799 \\[mmlu\\]: https://arxiv.org/abs/2009.03300 \\[openai-mmlu\\]: https://huggingface.co/datasets/openai/MMMLU \\[global-mmlu\\]: https://huggingface.co/datasets/CohereLabs/Global-MMLU \\[eclektic\\]: https://arxiv.org/abs/2502.21228 #### STEM and code | Benchmark | Metric | n-shot | E2B IT | E4B IT | | ------------------------------------|--------------------------|----------|:--------:|:--------:| | \\[GPQA\\]\\[gpqa\\] Diamond | RelaxedAccuracy/accuracy | 0-shot | 24.8 | 23.7 | | \\[LiveCodeBench\\]\\[lcb\\] v5 | pass@1 | 0-shot | 18.6 | 25.7 | | Codegolf v2.2 | pass@1 | 0-shot | 11.0 | 16.8 | | \\[AIME 2025\\]\\[aime-2025\\] | Accuracy | 0-shot | 6.7 | 11.6 | \\[gpqa\\]: https://arxiv.org/abs/2311.12022 \\[lcb\\]: https://arxiv.org/abs/2403.07974 \\[aime-2025\\]: https://www.vals.ai/benchmarks/aime-2025-05-09 #### Additional benchmarks | Benchmark | Metric | n-shot | E2B IT | E4B IT | | ------------------------------------ |------------|----------|:--------:|:--------:| | \\[MMLU\\]\\[mmlu\\] | Accuracy | 0-shot | 60.1 | 64.9 | | \\[MBPP\\]\\[mbpp\\] | pass@1 | 3-shot | 56.6 | 63.6 | | \\[HumanEval\\]\\[humaneval\\] | pass@1 | 0-shot | 66.5 | 75.0 | | \\[LiveCodeBench\\]\\[lcb\\] | pass@1 | 0-shot | 13.2 | 13.2 | | HiddenMath | Accuracy | 0-shot | 27.7 | 37.7 | | \\[Global-MMLU-Lite\\]\\[global-mmlu-lite\\] | Accuracy | 0-shot | 59.0 | 64.5 | | \\[MMLU\\]\\[mmlu\\] (Pro) | Accuracy | 0-shot | 40.5 | 50.6 | \\[gpqa\\]: https://arxiv.org/abs/2311.12022 \\[mbpp\\]: https://arxiv.org/abs/2108.07732 \\[humaneval\\]: https://arxiv.org/abs/2107.03374 \\[lcb\\]: https://arxiv.org/abs/2403.07974 \\[global-mmlu-lite\\]: https://huggingface.co/datasets/CohereForAI/Global-MMLU-Lite ## Usage and Limitations These models have certain limitations that users should be aware of. ### Intended Usage Open generative models have a wide range of applications across various industries and domains. The following list of potential uses is not comprehensive. The purpose of this list is to provide contextual information about the possible use-cases that the model creators considered as part of model training and development. - Content Creation and Communication - \\*\\*Text Generation\\*\\*: Generate creative text formats such as poems, scripts, code, marketing copy, and email drafts. - \\*\\*Chatbots and Conversational AI\\*\\*: Power conversational interfaces for customer service, virtual assistants, or interactive applications. - \\*\\*Text Summarization\\*\\*: Generate concise summaries of a text corpus, research papers, or reports. - \\*\\*Image Data Extraction\\*\\*: Extract, interpret, and summarize visual data for text communications. - \\*\\*Audio Data Extraction\\*\\*: Transcribe spoken language, translate speech to text in other languages, and analyze sound-based data. - Research and Education - \\*\\*Natural Language Processing (NLP) and generative model Research\\*\\*: These models can serve as a foundation for researchers to experiment with generative models and NLP techniques, develop algorithms, and contribute to the advancement of the field. - \\*\\*Language Learning Tools\\*\\*: Support interactive language learning experiences, aiding in grammar correction or providing writing practice. - \\*\\*Knowledge Exploration\\*\\*: Assist researchers in exploring large bodies of data by generating summaries or answering questions about specific topics. ## Ethics and Safety Ethics and safety evaluation approach and results. ### Evaluation Approach Our evaluation methods include structured evaluations and internal red-teaming testing of relevant content policies. Red-teaming was conducted by a number of different teams, each with different goals and human evaluation metrics. These models were evaluated against a number of different categories relevant to ethics and safety, including: - \\*\\*Child Safety\\*\\*: Evaluation of text-to-text and image to text prompts covering child safety policies, including child sexual abuse and exploitation. - \\*\\*Content Safety:\\*\\* Evaluation of text-to-text and image to text prompts covering safety policies including, harassment, violence and gore, and hate speech. - \\*\\*Representational Harms\\*\\*: Evaluation of text-to-text and image to text prompts covering safety policies including bias, stereotyping, and harmful associations or inaccuracies. In addition to development level evaluations, we conduct \"assurance evaluations\" which are our 'arms-length' internal evaluations for responsibility governance decision making. They are conducted separately from the model development team, to inform decision making about release. High level findings are fed back to the model team, but prompt sets are held-out to prevent overfitting and preserve the results' ability to inform decision making. Notable assurance evaluation results are reported to our Responsibility & Safety Council as part of release review. ### Evaluation Results For all areas of safety testing, we saw safe levels of performance across the categories of child safety, content safety, and representational harms relative to previous Gemma models. All testing was conducted without safety filters to evaluate the model capabilities and behaviors. For text-to-text, image-to-text, and audio-to-text, and across all model sizes, the model produced minimal policy violations, and showed significant improvements over previous Gemma models' performance with respect to high severity violations. A limitation of our evaluations was they included primarily English language prompts. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "gemma3n:latest",
        "size": "gemma3n:latest",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e2b",
        "size": "gemma3n:e2b",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e4b",
        "size": "gemma3n:e4b",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e2b-it-q4_K_M",
        "size": "gemma3n:e2b-it-q4_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e2b-it-q8_0",
        "size": "gemma3n:e2b-it-q8_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e2b-it-fp16",
        "size": "gemma3n:e2b-it-fp16",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e4b-it-q4_K_M",
        "size": "gemma3n:e4b-it-q4_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e4b-it-q8_0",
        "size": "gemma3n:e4b-it-q8_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "gemma3n:e4b-it-fp16",
        "size": "gemma3n:e4b-it-fp16",
        "updated": "Text input • \n                    2 months ago"
      }
    ]
  },
  {
    "name": "granite3.1-moe",
    "link": "https://ollama.com/library/granite3.1-moe",
    "description": "The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage.",
    "pullCount": "434.4K",
    "updated": "7 months ago",
    "size": [
      "1b",
      "3b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n## Granite mixture of experts models\n\nThe IBM Granite **1B and 3B models** are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage.\n\nThe models are trained on over 10 trillion tokens of data, the Granite MoE models are ideal for deployment in on-device applications or situations requiring instantaneous inference.\n\n### Parameter Sizes\n\n**1B:**\n\n`ollama run granite3.1-moe:1b`\n\n**3B:**\n\n`ollama run granite3.1-moe:3b`\n\n### Supported Languages\n\nEnglish, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified)\n\n### Capabilities\n\n* Summarization\n* Text classification\n* Text extraction\n* Question-answering\n* Retrieval Augmented Generation (RAG)\n* Code related tasks\n* Function-calling tasks\n* Multilingual dialog use cases\n* Long-context tasks including long document/meeting summarization, long document QA, etc.\n\n## Granite dense models\n\nThe Granite dense models are available in **2B and 8B** parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.\n\n[See model page](https://ollama.com/library/granite3-dense)\n\n## Learn more\n\n* **Developers:** IBM Research\n* **GitHub Repository:** [ibm-granite/granite-language-models](https://github.com/ibm-granite/granite-3.1-language-models)\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: December 18th, 2024\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\nWrite Preview \n\n\\## Granite mixture of experts models The IBM Granite \\*\\*1B and 3B models\\*\\* are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage. The models are trained on over 10 trillion tokens of data, the Granite MoE models are ideal for deployment in on-device applications or situations requiring instantaneous inference. ### Parameter Sizes \\*\\*1B:\\*\\* \\`ollama run granite3.1-moe:1b\\` \\*\\*3B:\\*\\* \\`ollama run granite3.1-moe:3b\\` ### Supported Languages English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified) ### Capabilities \\* Summarization \\* Text classification \\* Text extraction \\* Question-answering \\* Retrieval Augmented Generation (RAG) \\* Code related tasks \\* Function-calling tasks \\* Multilingual dialog use cases \\* Long-context tasks including long document/meeting summarization, long document QA, etc. ## Granite dense models The Granite dense models are available in \\*\\*2B and 8B\\*\\* parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. \\[See model page\\](https://ollama.com/library/granite3-dense) ## Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*GitHub Repository:\\*\\* \\[ibm-granite/granite-language-models\\](https://github.com/ibm-granite/granite-3.1-language-models) - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: December 18th, 2024 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0). \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3.1-moe:latest",
        "size": "granite3.1-moe:latest",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b",
        "size": "granite3.1-moe:1b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-moe:3b",
        "size": "granite3.1-moe:3b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q2_K",
        "size": "granite3.1-moe:1b-instruct-q2_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q3_K_S",
        "size": "granite3.1-moe:1b-instruct-q3_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q3_K_M",
        "size": "granite3.1-moe:1b-instruct-q3_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q3_K_L",
        "size": "granite3.1-moe:1b-instruct-q3_K_L",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q4_0",
        "size": "granite3.1-moe:1b-instruct-q4_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q4_1",
        "size": "granite3.1-moe:1b-instruct-q4_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q4_K_S",
        "size": "granite3.1-moe:1b-instruct-q4_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q4_K_M",
        "size": "granite3.1-moe:1b-instruct-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q5_0",
        "size": "granite3.1-moe:1b-instruct-q5_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q5_1",
        "size": "granite3.1-moe:1b-instruct-q5_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q5_K_S",
        "size": "granite3.1-moe:1b-instruct-q5_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q5_K_M",
        "size": "granite3.1-moe:1b-instruct-q5_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q6_K",
        "size": "granite3.1-moe:1b-instruct-q6_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-q8_0",
        "size": "granite3.1-moe:1b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-moe:1b-instruct-fp16",
        "size": "granite3.1-moe:1b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q2_K",
        "size": "granite3.1-moe:3b-instruct-q2_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q3_K_S",
        "size": "granite3.1-moe:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q3_K_M",
        "size": "granite3.1-moe:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q3_K_L",
        "size": "granite3.1-moe:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q4_0",
        "size": "granite3.1-moe:3b-instruct-q4_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q4_1",
        "size": "granite3.1-moe:3b-instruct-q4_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q4_K_S",
        "size": "granite3.1-moe:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q4_K_M",
        "size": "granite3.1-moe:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q5_0",
        "size": "granite3.1-moe:3b-instruct-q5_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q5_1",
        "size": "granite3.1-moe:3b-instruct-q5_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q5_K_S",
        "size": "granite3.1-moe:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q5_K_M",
        "size": "granite3.1-moe:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q6_K",
        "size": "granite3.1-moe:3b-instruct-q6_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-q8_0",
        "size": "granite3.1-moe:3b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-moe:3b-instruct-fp16",
        "size": "granite3.1-moe:3b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "smollm",
    "link": "https://ollama.com/library/smollm",
    "description": "🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on a new high-quality dataset.",
    "pullCount": "432.1K",
    "updated": "1 year ago",
    "size": [
      "135m360m1.7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/smollm/50a4746f-b96d-4948-aa52-7ff06524f485)\n\nSmolLM is a series of small language models available in three sizes: 135M, 360M, and 1.7B parameters.\n\n## References\n\n[Blog post](https://huggingface.co/blog/smollm)\n\n[Hugging Face](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/smollm/50a4746f-b96d-4948-aa52-7ff06524f485\" width=\"512\" /> SmolLM is a series of small language models available in three sizes: 135M, 360M, and 1.7B parameters. ## References \\[Blog post\\](https://huggingface.co/blog/smollm) \\[Hugging Face\\](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "smollm:latest",
        "size": "smollm:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m",
        "size": "smollm:135m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m",
        "size": "smollm:360m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b",
        "size": "smollm:1.7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q2_K",
        "size": "smollm:135m-base-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q3_K_S",
        "size": "smollm:135m-base-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q3_K_M",
        "size": "smollm:135m-base-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q3_K_L",
        "size": "smollm:135m-base-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q4_0",
        "size": "smollm:135m-base-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q4_1",
        "size": "smollm:135m-base-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q4_K_S",
        "size": "smollm:135m-base-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q4_K_M",
        "size": "smollm:135m-base-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q5_0",
        "size": "smollm:135m-base-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q5_1",
        "size": "smollm:135m-base-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q5_K_S",
        "size": "smollm:135m-base-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q5_K_M",
        "size": "smollm:135m-base-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q6_K",
        "size": "smollm:135m-base-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-q8_0",
        "size": "smollm:135m-base-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-base-v0.2-fp16",
        "size": "smollm:135m-base-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q2_K",
        "size": "smollm:135m-instruct-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q3_K_S",
        "size": "smollm:135m-instruct-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q3_K_M",
        "size": "smollm:135m-instruct-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q3_K_L",
        "size": "smollm:135m-instruct-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q4_0",
        "size": "smollm:135m-instruct-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q4_1",
        "size": "smollm:135m-instruct-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q4_K_S",
        "size": "smollm:135m-instruct-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q4_K_M",
        "size": "smollm:135m-instruct-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q5_0",
        "size": "smollm:135m-instruct-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q5_1",
        "size": "smollm:135m-instruct-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q5_K_S",
        "size": "smollm:135m-instruct-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q5_K_M",
        "size": "smollm:135m-instruct-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q6_K",
        "size": "smollm:135m-instruct-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-q8_0",
        "size": "smollm:135m-instruct-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:135m-instruct-v0.2-fp16",
        "size": "smollm:135m-instruct-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q2_K",
        "size": "smollm:360m-base-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q3_K_S",
        "size": "smollm:360m-base-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q3_K_M",
        "size": "smollm:360m-base-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q3_K_L",
        "size": "smollm:360m-base-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q4_0",
        "size": "smollm:360m-base-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q4_1",
        "size": "smollm:360m-base-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q4_K_S",
        "size": "smollm:360m-base-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q4_K_M",
        "size": "smollm:360m-base-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q5_0",
        "size": "smollm:360m-base-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q5_1",
        "size": "smollm:360m-base-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q5_K_S",
        "size": "smollm:360m-base-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q5_K_M",
        "size": "smollm:360m-base-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q6_K",
        "size": "smollm:360m-base-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-q8_0",
        "size": "smollm:360m-base-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-base-v0.2-fp16",
        "size": "smollm:360m-base-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q2_K",
        "size": "smollm:360m-instruct-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q3_K_S",
        "size": "smollm:360m-instruct-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q3_K_M",
        "size": "smollm:360m-instruct-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q3_K_L",
        "size": "smollm:360m-instruct-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q4_0",
        "size": "smollm:360m-instruct-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q4_1",
        "size": "smollm:360m-instruct-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q4_K_S",
        "size": "smollm:360m-instruct-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q4_K_M",
        "size": "smollm:360m-instruct-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q5_0",
        "size": "smollm:360m-instruct-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q5_1",
        "size": "smollm:360m-instruct-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q5_K_S",
        "size": "smollm:360m-instruct-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q5_K_M",
        "size": "smollm:360m-instruct-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q6_K",
        "size": "smollm:360m-instruct-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-q8_0",
        "size": "smollm:360m-instruct-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:360m-instruct-v0.2-fp16",
        "size": "smollm:360m-instruct-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q2_K",
        "size": "smollm:1.7b-base-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q3_K_S",
        "size": "smollm:1.7b-base-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q3_K_M",
        "size": "smollm:1.7b-base-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q3_K_L",
        "size": "smollm:1.7b-base-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q4_0",
        "size": "smollm:1.7b-base-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q4_1",
        "size": "smollm:1.7b-base-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q4_K_S",
        "size": "smollm:1.7b-base-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q4_K_M",
        "size": "smollm:1.7b-base-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q5_0",
        "size": "smollm:1.7b-base-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q5_1",
        "size": "smollm:1.7b-base-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q5_K_S",
        "size": "smollm:1.7b-base-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q5_K_M",
        "size": "smollm:1.7b-base-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q6_K",
        "size": "smollm:1.7b-base-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-q8_0",
        "size": "smollm:1.7b-base-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-base-v0.2-fp16",
        "size": "smollm:1.7b-base-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q2_K",
        "size": "smollm:1.7b-instruct-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q3_K_S",
        "size": "smollm:1.7b-instruct-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q3_K_M",
        "size": "smollm:1.7b-instruct-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q3_K_L",
        "size": "smollm:1.7b-instruct-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q4_0",
        "size": "smollm:1.7b-instruct-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q4_1",
        "size": "smollm:1.7b-instruct-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q4_K_S",
        "size": "smollm:1.7b-instruct-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q4_K_M",
        "size": "smollm:1.7b-instruct-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q5_0",
        "size": "smollm:1.7b-instruct-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q5_1",
        "size": "smollm:1.7b-instruct-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q5_K_S",
        "size": "smollm:1.7b-instruct-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q5_K_M",
        "size": "smollm:1.7b-instruct-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q6_K",
        "size": "smollm:1.7b-instruct-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-q8_0",
        "size": "smollm:1.7b-instruct-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "smollm:1.7b-instruct-v0.2-fp16",
        "size": "smollm:1.7b-instruct-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "granite3.3",
    "link": "https://ollama.com/library/granite3.3",
    "description": "IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.",
    "pullCount": "424.2K",
    "updated": "4 months ago",
    "size": [
      "2b",
      "8b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/granite3.2/90c5e567-0004-425c-a17a-1b846c2b5d3d)\n\n## Granite 3.3\n\nThe IBM Granite **2B and 8B models** are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities. These models deliver significant gains on benchmarks for measuring generic performance including AlpacaEval-2.0 and Arena-Hard, and improvements in mathematics, coding, and instruction following. They also supports Fill-in-the-Middle (FIM) for code completion tasks and structured reasoning.\n\n### Parameter Sizes\n\n**2B:**\n\n`ollama run granite3.3:2b`\n\n**8B:**\n\n`ollama run granite3.3:8b`\n\n### Supported Languages\n\nEnglish, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. However, users may finetune this Granite model for languages beyond these 12 languages.\n\n### Intended Use\n\nThese models are designed to handle general instruction-following tasks and can be integrated into AI assistants across various domains, including business applications.\n\n### Capabilities\n\n* Thinking\n* Summarization\n* Text classification\n* Text extraction\n* Question-answering\n* Retrieval Augmented Generation (RAG)\n* Code related tasks\n* Function-calling tasks\n* Multilingual dialog use cases\n* Fill-in-the-middle\n* Long-context tasks including long document/meeting summarization, long document QA, etc.\n\n### Thinking\n\nTo enable thinking, add a message with “role”: “control” and set “content” to “thinking”. For example:\n\n```\n{\n    \"messages\": [\n        {\"role\": \"control\", \"content\": \"thinking\"},\n        {\"role\": \"user\", \"content\": \"How do I get to the airport if my car won't start?\"}\n    ]\n}\n\n```\n\n## Learn more\n\n* **Developers:** IBM Research\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: April 16th, 2025\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\nWrite Preview \n\n<img src=\"/assets/library/granite3.2/90c5e567-0004-425c-a17a-1b846c2b5d3d\" width=\"600\" /> ## Granite 3.3 The IBM Granite \\*\\*2B and 8B models\\*\\* are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities. These models deliver significant gains on benchmarks for measuring generic performance including AlpacaEval-2.0 and Arena-Hard, and improvements in mathematics, coding, and instruction following. They also supports Fill-in-the-Middle (FIM) for code completion tasks and structured reasoning. ### Parameter Sizes \\*\\*2B:\\*\\* \\`ollama run granite3.3:2b\\` \\*\\*8B:\\*\\* \\`ollama run granite3.3:8b\\` ### Supported Languages English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. However, users may finetune this Granite model for languages beyond these 12 languages. ### Intended Use These models are designed to handle general instruction-following tasks and can be integrated into AI assistants across various domains, including business applications. ### Capabilities \\* Thinking \\* Summarization \\* Text classification \\* Text extraction \\* Question-answering \\* Retrieval Augmented Generation (RAG) \\* Code related tasks \\* Function-calling tasks \\* Multilingual dialog use cases \\* Fill-in-the-middle \\* Long-context tasks including long document/meeting summarization, long document QA, etc. ### Thinking To enable thinking, add a message with \"role\": \"control\" and set \"content\" to \"thinking\". For example: \\`\\`\\` { \"messages\": \\[ {\"role\": \"control\", \"content\": \"thinking\"}, {\"role\": \"user\", \"content\": \"How do I get to the airport if my car won't start?\"} \\] } \\`\\`\\` ## Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: April 16th, 2025 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3.3:latest",
        "size": "granite3.3:latest",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "granite3.3:2b",
        "size": "granite3.3:2b",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "granite3.3:8b",
        "size": "granite3.3:8b",
        "updated": "Text input • \n                    4 months ago"
      }
    ]
  },
  {
    "name": "codestral",
    "link": "https://ollama.com/library/codestral",
    "description": "Codestral is Mistral AI’s first-ever code model designed for code generation tasks.",
    "pullCount": "423.8K",
    "updated": "1 year ago",
    "size": [
      "22b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n# Codestral\n\n![Codestral Hello World](https://ollama.com/assets/mchiang0610/test1/76bfd7f0-fccd-431b-95fe-dddf5a422dcf)\n\nCodestral is Mistral AI’s first-ever code model designed for code generation tasks. It is a 22B model.\n\n### Fluent in 80+ programming languages\n\nCodestral is trained on a dataset of over 80 programming languages, including Python, Java, C, C++, JavaScript, Swift, Fortran and Bash.\n\nThe model can complete coding functions, write tests, and complete any partial code using a fill-in-the-middle mechanism.\n\n### Benchmarks\n\n![With its larger context window of 32k (compared to 4k, 8k or 16k for competitors), Codestral outperforms all other models in RepoBench, a long-range eval for code generation](https://ollama.com/assets/mchiang0610/test1/f5ea9604-669b-4de0-957d-41245e33636c)\n\n![Benchmarks](https://ollama.com/assets/mchiang0610/test1/e42a01d3-4f36-4d60-a0c8-74ad10159cdd)\n\n![FIM benchmarks](https://ollama.com/assets/mchiang0610/test1/8ca203e2-7bfd-4081-98c8-1ecc3cc46ef8)\n\n### Reference\n\n[Mistral AI - Codestral: Hello, World](https://mistral.ai/news/codestral/)\n\nWrite Preview \n\n\\# Codestral !\\[Codestral Hello World\\](https://ollama.com/assets/mchiang0610/test1/76bfd7f0-fccd-431b-95fe-dddf5a422dcf) Codestral is Mistral AI's first-ever code model designed for code generation tasks. It is a 22B model. ### Fluent in 80+ programming languages Codestral is trained on a dataset of over 80 programming languages, including Python, Java, C, C++, JavaScript, Swift, Fortran and Bash. The model can complete coding functions, write tests, and complete any partial code using a fill-in-the-middle mechanism. ### Benchmarks !\\[With its larger context window of 32k (compared to 4k, 8k or 16k for competitors), Codestral outperforms all other models in RepoBench, a long-range eval for code generation\\](https://ollama.com/assets/mchiang0610/test1/f5ea9604-669b-4de0-957d-41245e33636c) !\\[Benchmarks\\](https://ollama.com/assets/mchiang0610/test1/e42a01d3-4f36-4d60-a0c8-74ad10159cdd) !\\[FIM benchmarks\\](https://ollama.com/assets/mchiang0610/test1/8ca203e2-7bfd-4081-98c8-1ecc3cc46ef8) ### Reference \\[Mistral AI - Codestral: Hello, World\\](https://mistral.ai/news/codestral/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codestral:latest",
        "size": "codestral:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:v0.1",
        "size": "codestral:v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b",
        "size": "codestral:22b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q2_K",
        "size": "codestral:22b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q3_K_S",
        "size": "codestral:22b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q3_K_M",
        "size": "codestral:22b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q3_K_L",
        "size": "codestral:22b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q4_0",
        "size": "codestral:22b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q4_1",
        "size": "codestral:22b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q4_K_S",
        "size": "codestral:22b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q4_K_M",
        "size": "codestral:22b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q5_0",
        "size": "codestral:22b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q5_1",
        "size": "codestral:22b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q5_K_S",
        "size": "codestral:22b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q5_K_M",
        "size": "codestral:22b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q6_K",
        "size": "codestral:22b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codestral:22b-v0.1-q8_0",
        "size": "codestral:22b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "dolphin-llama3",
    "link": "https://ollama.com/library/dolphin-llama3",
    "description": "Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills.",
    "pullCount": "415.9K",
    "updated": "1 year ago",
    "size": [
      "8b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n# 🐬 Dolphin 2.9 Llama 3\n\nDolphin-2.9 has a variety of instruction, conversational, and coding skills. It also has initial agentic abilities and supports function calling.\n\nDolphin is [uncensored](https://erichartford.com/uncensored-models). The dataset has been filtered to remove alignment and bias. This makes the model more compliant.\n\nCurated and trained by Eric Hartford, Lucas Atkins, and Fernando Fernandes, and Cognitive Computations.\n\n## Sizes\n\n* `dolphin-llama3:8b`\n* `dolphin-llama3:70b`\n\n## 256K Context Window\n\n> Note: using a 256k context window requires at least 64GB of memory.\n\nDolphin Llama 3 also has a 256k context window version. To extend the context window use:\n\nAPI\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"dolphin-llama3:8b-256k\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"options\": {\n    \"num_ctx\": 256000\n  }\n}'\n\n```\n\nCLI\n\n```\nollama run dolphin-llama3:8b-256k\n>>> /set parameter num_ctx 256000\n\n```\n\n## References\n\n[HuggingFace](https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b)\n\nWrite Preview \n\n\\# 🐬 Dolphin 2.9 Llama 3 Dolphin-2.9 has a variety of instruction, conversational, and coding skills. It also has initial agentic abilities and supports function calling. Dolphin is \\[uncensored\\](https://erichartford.com/uncensored-models). The dataset has been filtered to remove alignment and bias. This makes the model more compliant. Curated and trained by Eric Hartford, Lucas Atkins, and Fernando Fernandes, and Cognitive Computations. ## Sizes \\* \\`dolphin-llama3:8b\\` \\* \\`dolphin-llama3:70b\\` ## 256K Context Window > Note: using a 256k context window requires at least 64GB of memory. Dolphin Llama 3 also has a 256k context window version. To extend the context window use: <sub>API</sub> \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"dolphin-llama3:8b-256k\", \"prompt\": \"Why is the sky blue?\", \"options\": { \"num\\_ctx\": 256000 } }' \\`\\`\\` <sub>CLI</sub> \\`\\`\\` ollama run dolphin-llama3:8b-256k >>> /set parameter num\\_ctx 256000 \\`\\`\\` ## References \\[HuggingFace\\](https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dolphin-llama3:latest",
        "size": "dolphin-llama3:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:v2.9",
        "size": "dolphin-llama3:v2.9",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b",
        "size": "dolphin-llama3:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b",
        "size": "dolphin-llama3:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k",
        "size": "dolphin-llama3:8b-256k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9",
        "size": "dolphin-llama3:8b-256k-v2.9",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q2_K",
        "size": "dolphin-llama3:8b-256k-v2.9-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q3_K_S",
        "size": "dolphin-llama3:8b-256k-v2.9-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q3_K_M",
        "size": "dolphin-llama3:8b-256k-v2.9-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q3_K_L",
        "size": "dolphin-llama3:8b-256k-v2.9-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q4_0",
        "size": "dolphin-llama3:8b-256k-v2.9-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q4_1",
        "size": "dolphin-llama3:8b-256k-v2.9-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q4_K_S",
        "size": "dolphin-llama3:8b-256k-v2.9-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q4_K_M",
        "size": "dolphin-llama3:8b-256k-v2.9-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q5_0",
        "size": "dolphin-llama3:8b-256k-v2.9-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q5_1",
        "size": "dolphin-llama3:8b-256k-v2.9-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q5_K_S",
        "size": "dolphin-llama3:8b-256k-v2.9-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q5_K_M",
        "size": "dolphin-llama3:8b-256k-v2.9-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q6_K",
        "size": "dolphin-llama3:8b-256k-v2.9-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-q8_0",
        "size": "dolphin-llama3:8b-256k-v2.9-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-256k-v2.9-fp16",
        "size": "dolphin-llama3:8b-256k-v2.9-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9",
        "size": "dolphin-llama3:8b-v2.9",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q2_K",
        "size": "dolphin-llama3:8b-v2.9-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q3_K_S",
        "size": "dolphin-llama3:8b-v2.9-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q3_K_M",
        "size": "dolphin-llama3:8b-v2.9-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q3_K_L",
        "size": "dolphin-llama3:8b-v2.9-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q4_0",
        "size": "dolphin-llama3:8b-v2.9-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q4_1",
        "size": "dolphin-llama3:8b-v2.9-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q4_K_S",
        "size": "dolphin-llama3:8b-v2.9-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q4_K_M",
        "size": "dolphin-llama3:8b-v2.9-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q5_0",
        "size": "dolphin-llama3:8b-v2.9-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q5_1",
        "size": "dolphin-llama3:8b-v2.9-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q5_K_S",
        "size": "dolphin-llama3:8b-v2.9-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q5_K_M",
        "size": "dolphin-llama3:8b-v2.9-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q6_K",
        "size": "dolphin-llama3:8b-v2.9-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-q8_0",
        "size": "dolphin-llama3:8b-v2.9-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:8b-v2.9-fp16",
        "size": "dolphin-llama3:8b-v2.9-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9",
        "size": "dolphin-llama3:70b-v2.9",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q2_K",
        "size": "dolphin-llama3:70b-v2.9-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q3_K_S",
        "size": "dolphin-llama3:70b-v2.9-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q3_K_M",
        "size": "dolphin-llama3:70b-v2.9-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q3_K_L",
        "size": "dolphin-llama3:70b-v2.9-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q4_0",
        "size": "dolphin-llama3:70b-v2.9-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q4_1",
        "size": "dolphin-llama3:70b-v2.9-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q4_K_S",
        "size": "dolphin-llama3:70b-v2.9-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q4_K_M",
        "size": "dolphin-llama3:70b-v2.9-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q5_0",
        "size": "dolphin-llama3:70b-v2.9-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q5_1",
        "size": "dolphin-llama3:70b-v2.9-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q5_K_S",
        "size": "dolphin-llama3:70b-v2.9-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q5_K_M",
        "size": "dolphin-llama3:70b-v2.9-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q6_K",
        "size": "dolphin-llama3:70b-v2.9-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-q8_0",
        "size": "dolphin-llama3:70b-v2.9-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-llama3:70b-v2.9-fp16",
        "size": "dolphin-llama3:70b-v2.9-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "wizardlm2",
    "link": "https://ollama.com/library/wizardlm2",
    "description": "State of the art large language model from Microsoft AI with improved performance on complex chat, multilingual, reasoning and agent use cases.",
    "pullCount": "409.7K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "8x22b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nWizardLM-2 is a next generation state-of-the-art large language model with improved performance on complex chat, multilingual, reasoning and agent use cases. This family includes three cutting-edge models:\n\n* `wizardlm2:7b`: fastest model, comparable performance with 10x larger open-source models.\n* `wizardlm2:8x22b`: the most advanced model, and the best opensource LLM in Microsoft’s internal evaluation on highly complex tasks.\n* `wizardlm2:70b`: model with top-tier reasoning capabilities for its size (coming soon)\n\n## References\n\n[Blog Post](https://wizardlm.github.io/WizardLM2/)\n\n[HuggingFace](https://huggingface.co/collections/microsoft/wizardlm-661d403f71e6c8257dbd598a)\n\nWrite Preview \n\nWizardLM-2 is a next generation state-of-the-art large language model with improved performance on complex chat, multilingual, reasoning and agent use cases. This family includes three cutting-edge models: \\* \\`wizardlm2:7b\\`: fastest model, comparable performance with 10x larger open-source models. \\* \\`wizardlm2:8x22b\\`: the most advanced model, and the best opensource LLM in Microsoft's internal evaluation on highly complex tasks. \\* \\`wizardlm2:70b\\`: model with top-tier reasoning capabilities for its size (coming soon) ## References \\[Blog Post\\](https://wizardlm.github.io/WizardLM2/) \\[HuggingFace\\](https://huggingface.co/collections/microsoft/wizardlm-661d403f71e6c8257dbd598a) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizardlm2:latest",
        "size": "wizardlm2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b",
        "size": "wizardlm2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:8x22b",
        "size": "wizardlm2:8x22b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q2_K",
        "size": "wizardlm2:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q3_K_S",
        "size": "wizardlm2:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q3_K_M",
        "size": "wizardlm2:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q3_K_L",
        "size": "wizardlm2:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q4_0",
        "size": "wizardlm2:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q4_1",
        "size": "wizardlm2:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q4_K_S",
        "size": "wizardlm2:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q4_K_M",
        "size": "wizardlm2:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q5_0",
        "size": "wizardlm2:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q5_1",
        "size": "wizardlm2:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q5_K_S",
        "size": "wizardlm2:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q5_K_M",
        "size": "wizardlm2:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q6_K",
        "size": "wizardlm2:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-q8_0",
        "size": "wizardlm2:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:7b-fp16",
        "size": "wizardlm2:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:8x22b-q2_K",
        "size": "wizardlm2:8x22b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:8x22b-q4_0",
        "size": "wizardlm2:8x22b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:8x22b-q8_0",
        "size": "wizardlm2:8x22b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm2:8x22b-fp16",
        "size": "wizardlm2:8x22b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "phi4-reasoning",
    "link": "https://ollama.com/library/phi4-reasoning",
    "description": "Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.",
    "pullCount": "392.6K",
    "updated": "4 months ago",
    "size": [
      "14b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nPhi 4 reasoning and reasoning plus models are 14 billion parameter models that rival much larger models on complex reasoning tasks.\n\nPhi 4 reasoning model is trained via supervised fine-tuning of Phi 4 on carefully curated reasoning demonstrations from OpenAI’s o3-mini. This model demonstrates meticulous data curation and high quality synthetic datasets allow smaller models to compete with larger counterparts.\n\nPhi 4 reasoning plus model builds on top of Phi 4 reasoning, and is further trained with reinforcement learning to deliver higher accuracy.\n\n### Models\n\n**Phi 4 reasoning**\n\n```\nollama run phi4-reasoning\n\n```\n\n**Phi 4 reasoning plus**\n\n```\nollama run phi4-reasoning:plus\n\n```\n\n### Benchmarks\n\n![image.png](/assets/library/phi4-reasoning/6df829cd-a2e5-4a25-906b-29de63e072df)\n\n Phi-4-reasoning performance across representative reasoning benchmarks spanning mathematical and scientific reasoning. We illustrate the performance gains from reasoning-focused post-training of Phi-4 via Phi-4-reasoning (SFT) and Phi-4-reasoning-plus (SFT+RL), alongside a representative set of baselines from two model families: open-weight models from DeepSeek including DeepSeek R1 (671B Mixture-of-Experts) and its distilled dense variant DeepSeek-R1 Distill Llama 70B, and OpenAI’s proprietary frontier models o1-mini and o3-mini. Phi-4-reasoning and Phi-4-reasoning-plus consistently outperform the base model Phi-4 by significant margins, exceed DeepSeek-R1 Distill Llama 70B (5x larger) and demonstrate competitive performance against significantly larger models such as Deepseek-R1.\n\n![image.png](/assets/library/phi4-reasoning/b4500c73-f2bf-4558-8391-b58e63c5ce8c)\n\nAccuracy of models across general-purpose benchmarks for: long input context QA (FlenQA), instruction following (IFEval), Coding (HumanEvalPlus), knowledge & language understanding (MMLUPro), safety detection (ToxiGen), and other general skills (ArenaHard and PhiBench).\n\n## References\n\n[Blog post ](https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/)\n\nWrite Preview \n\nPhi 4 reasoning and reasoning plus models are 14 billion parameter models that rival much larger models on complex reasoning tasks. Phi 4 reasoning model is trained via supervised fine-tuning of Phi 4 on carefully curated reasoning demonstrations from OpenAI's o3-mini. This model demonstrates meticulous data curation and high quality synthetic datasets allow smaller models to compete with larger counterparts. Phi 4 reasoning plus model builds on top of Phi 4 reasoning, and is further trained with reinforcement learning to deliver higher accuracy. ### Models \\*\\*Phi 4 reasoning\\*\\* \\`\\`\\` ollama run phi4-reasoning \\`\\`\\` \\*\\*Phi 4 reasoning plus\\*\\* \\`\\`\\` ollama run phi4-reasoning:plus \\`\\`\\` ### Benchmarks !\\[image.png\\](/assets/library/phi4-reasoning/6df829cd-a2e5-4a25-906b-29de63e072df) <small> Phi-4-reasoning performance across representative reasoning benchmarks spanning mathematical and scientific reasoning. We illustrate the performance gains from reasoning-focused post-training of Phi-4 via Phi-4-reasoning (SFT) and Phi-4-reasoning-plus (SFT+RL), alongside a representative set of baselines from two model families: open-weight models from DeepSeek including DeepSeek R1 (671B Mixture-of-Experts) and its distilled dense variant DeepSeek-R1 Distill Llama 70B, and OpenAI’s proprietary frontier models o1-mini and o3-mini. Phi-4-reasoning and Phi-4-reasoning-plus consistently outperform the base model Phi-4 by significant margins, exceed DeepSeek-R1 Distill Llama 70B (5x larger) and demonstrate competitive performance against significantly larger models such as Deepseek-R1.</small> !\\[image.png\\](/assets/library/phi4-reasoning/b4500c73-f2bf-4558-8391-b58e63c5ce8c) <small>Accuracy of models across general-purpose benchmarks for: long input context QA (FlenQA), instruction following (IFEval), Coding (HumanEvalPlus), knowledge & language understanding (MMLUPro), safety detection (ToxiGen), and other general skills (ArenaHard and PhiBench). </small> ## References \\[Blog post \\](https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi4-reasoning:latest",
        "size": "phi4-reasoning:latest",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:plus",
        "size": "phi4-reasoning:plus",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b",
        "size": "phi4-reasoning:14b",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b-plus-q4_K_M",
        "size": "phi4-reasoning:14b-plus-q4_K_M",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b-plus-q8_0",
        "size": "phi4-reasoning:14b-plus-q8_0",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b-plus-fp16",
        "size": "phi4-reasoning:14b-plus-fp16",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b-q4_K_M",
        "size": "phi4-reasoning:14b-q4_K_M",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b-q8_0",
        "size": "phi4-reasoning:14b-q8_0",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-reasoning:14b-fp16",
        "size": "phi4-reasoning:14b-fp16",
        "updated": "Text input • \n                    4 months ago"
      }
    ]
  },
  {
    "name": "dolphin-mistral",
    "link": "https://ollama.com/library/dolphin-mistral",
    "description": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
    "pullCount": "390.9K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/c65aad4e-7a58-4645-97f2-5e8ca158275f)\n\nThe Dolphin model by Eric Hartford, based on [Mistral](https://ollama.ai/library/mistral) version 0.2 released in March 2024\\. This model is uncensored, available for both commercial and non-commercial use, and excels at coding.\n\n## Versions\n\n| Tag         | Date       | Notes                                                                                                             |\n| ----------- | ---------- | ----------------------------------------------------------------------------------------------------------------- |\n| v2.8 latest | 03/31/2024 | Based on Mistral 0.2 with support for a context window of 32K tokens.                                             |\n| v2.6        | 12/27/2023 | Fixed a training configuration issue that improved quality, and improvements to the training dataset for empathy. |\n| v2.2.1      | 10/30/2023 | This is a checkpoint release, to fix overfit training                                                             |\n| v2.2        | 10/29/2023 | Added conversation and empathy data.                                                                              |\n| v2.1        | 10/11/2023 | Enhanced with the airoboros dataset.                                                                              |\n| v2.0        | 10/2/2023  | Initial release of the model.                                                                                     |\n\n## References\n\n[HuggingFace](https://huggingface.co/cognitivecomputations)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/c65aad4e-7a58-4645-97f2-5e8ca158275f\" width=\"280\" /> The Dolphin model by Eric Hartford, based on \\[Mistral\\](https://ollama.ai/library/mistral) version 0.2 released in March 2024\\. This model is uncensored, available for both commercial and non-commercial use, and excels at coding. ## Versions | Tag | Date | Notes | | --------------- | ---------- | ----------------------------------------------------------------------------------------------------------------- | | \\`v2.8\\` \\`latest\\` | 03/31/2024 | Based on Mistral 0.2 with support for a context window of 32K tokens. | | \\`v2.6\\` | 12/27/2023 | Fixed a training configuration issue that improved quality, and improvements to the training dataset for empathy. | | \\`v2.2.1\\` | 10/30/2023 | This is a checkpoint release, to fix overfit training | | \\`v2.2\\` | 10/29/2023 | Added conversation and empathy data. | | \\`v2.1\\` | 10/11/2023 | Enhanced with the airoboros dataset. | | \\`v2.0\\` | 10/2/2023 | Initial release of the model. | ## References \\[HuggingFace\\](https://huggingface.co/cognitivecomputations) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dolphin-mistral:latest",
        "size": "dolphin-mistral:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:v2",
        "size": "dolphin-mistral:v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:v2.1",
        "size": "dolphin-mistral:v2.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:v2.2",
        "size": "dolphin-mistral:v2.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:v2.2.1",
        "size": "dolphin-mistral:v2.2.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:v2.6",
        "size": "dolphin-mistral:v2.6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:v2.8",
        "size": "dolphin-mistral:v2.8",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b",
        "size": "dolphin-mistral:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2",
        "size": "dolphin-mistral:7b-v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q2_K",
        "size": "dolphin-mistral:7b-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q3_K_S",
        "size": "dolphin-mistral:7b-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q3_K_M",
        "size": "dolphin-mistral:7b-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q3_K_L",
        "size": "dolphin-mistral:7b-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q4_0",
        "size": "dolphin-mistral:7b-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q4_1",
        "size": "dolphin-mistral:7b-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q4_K_S",
        "size": "dolphin-mistral:7b-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q4_K_M",
        "size": "dolphin-mistral:7b-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q5_0",
        "size": "dolphin-mistral:7b-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q5_1",
        "size": "dolphin-mistral:7b-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q5_K_S",
        "size": "dolphin-mistral:7b-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q5_K_M",
        "size": "dolphin-mistral:7b-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q6_K",
        "size": "dolphin-mistral:7b-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-q8_0",
        "size": "dolphin-mistral:7b-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2-fp16",
        "size": "dolphin-mistral:7b-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1",
        "size": "dolphin-mistral:7b-v2.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q2_K",
        "size": "dolphin-mistral:7b-v2.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q3_K_S",
        "size": "dolphin-mistral:7b-v2.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q3_K_M",
        "size": "dolphin-mistral:7b-v2.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q3_K_L",
        "size": "dolphin-mistral:7b-v2.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q4_0",
        "size": "dolphin-mistral:7b-v2.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q4_1",
        "size": "dolphin-mistral:7b-v2.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q4_K_S",
        "size": "dolphin-mistral:7b-v2.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q4_K_M",
        "size": "dolphin-mistral:7b-v2.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q5_0",
        "size": "dolphin-mistral:7b-v2.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q5_1",
        "size": "dolphin-mistral:7b-v2.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q5_K_S",
        "size": "dolphin-mistral:7b-v2.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q5_K_M",
        "size": "dolphin-mistral:7b-v2.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q6_K",
        "size": "dolphin-mistral:7b-v2.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-q8_0",
        "size": "dolphin-mistral:7b-v2.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.1-fp16",
        "size": "dolphin-mistral:7b-v2.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2",
        "size": "dolphin-mistral:7b-v2.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q2_K",
        "size": "dolphin-mistral:7b-v2.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q3_K_S",
        "size": "dolphin-mistral:7b-v2.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q3_K_M",
        "size": "dolphin-mistral:7b-v2.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q3_K_L",
        "size": "dolphin-mistral:7b-v2.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q4_0",
        "size": "dolphin-mistral:7b-v2.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q4_1",
        "size": "dolphin-mistral:7b-v2.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q4_K_S",
        "size": "dolphin-mistral:7b-v2.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q4_K_M",
        "size": "dolphin-mistral:7b-v2.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q5_0",
        "size": "dolphin-mistral:7b-v2.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q5_1",
        "size": "dolphin-mistral:7b-v2.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q5_K_S",
        "size": "dolphin-mistral:7b-v2.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q5_K_M",
        "size": "dolphin-mistral:7b-v2.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q6_K",
        "size": "dolphin-mistral:7b-v2.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-q8_0",
        "size": "dolphin-mistral:7b-v2.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2-fp16",
        "size": "dolphin-mistral:7b-v2.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1",
        "size": "dolphin-mistral:7b-v2.2.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q2_K",
        "size": "dolphin-mistral:7b-v2.2.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q3_K_S",
        "size": "dolphin-mistral:7b-v2.2.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q3_K_M",
        "size": "dolphin-mistral:7b-v2.2.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q3_K_L",
        "size": "dolphin-mistral:7b-v2.2.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q4_0",
        "size": "dolphin-mistral:7b-v2.2.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q4_1",
        "size": "dolphin-mistral:7b-v2.2.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q4_K_S",
        "size": "dolphin-mistral:7b-v2.2.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q4_K_M",
        "size": "dolphin-mistral:7b-v2.2.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q5_0",
        "size": "dolphin-mistral:7b-v2.2.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q5_1",
        "size": "dolphin-mistral:7b-v2.2.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q5_K_S",
        "size": "dolphin-mistral:7b-v2.2.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q5_K_M",
        "size": "dolphin-mistral:7b-v2.2.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q6_K",
        "size": "dolphin-mistral:7b-v2.2.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-q8_0",
        "size": "dolphin-mistral:7b-v2.2.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.2.1-fp16",
        "size": "dolphin-mistral:7b-v2.2.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6",
        "size": "dolphin-mistral:7b-v2.6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q2_K",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q2_K",
        "size": "dolphin-mistral:7b-v2.6-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q3_K_S",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q3_K_S",
        "size": "dolphin-mistral:7b-v2.6-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q3_K_M",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q3_K_M",
        "size": "dolphin-mistral:7b-v2.6-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q3_K_L",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q3_K_L",
        "size": "dolphin-mistral:7b-v2.6-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q4_0",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q4_0",
        "size": "dolphin-mistral:7b-v2.6-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q4_1",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q4_1",
        "size": "dolphin-mistral:7b-v2.6-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q4_K_S",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q4_K_S",
        "size": "dolphin-mistral:7b-v2.6-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q4_K_M",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q4_K_M",
        "size": "dolphin-mistral:7b-v2.6-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q5_0",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q5_0",
        "size": "dolphin-mistral:7b-v2.6-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q5_1",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q5_1",
        "size": "dolphin-mistral:7b-v2.6-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q5_K_S",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q5_K_S",
        "size": "dolphin-mistral:7b-v2.6-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q5_K_M",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q5_K_M",
        "size": "dolphin-mistral:7b-v2.6-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q6_K",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q6_K",
        "size": "dolphin-mistral:7b-v2.6-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-q8_0",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-q8_0",
        "size": "dolphin-mistral:7b-v2.6-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-dpo-laser-fp16",
        "size": "dolphin-mistral:7b-v2.6-dpo-laser-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.6-fp16",
        "size": "dolphin-mistral:7b-v2.6-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8",
        "size": "dolphin-mistral:7b-v2.8",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q2_K",
        "size": "dolphin-mistral:7b-v2.8-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q3_K_S",
        "size": "dolphin-mistral:7b-v2.8-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q3_K_M",
        "size": "dolphin-mistral:7b-v2.8-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q3_K_L",
        "size": "dolphin-mistral:7b-v2.8-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q4_0",
        "size": "dolphin-mistral:7b-v2.8-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q4_1",
        "size": "dolphin-mistral:7b-v2.8-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q4_K_S",
        "size": "dolphin-mistral:7b-v2.8-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q4_K_M",
        "size": "dolphin-mistral:7b-v2.8-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q5_0",
        "size": "dolphin-mistral:7b-v2.8-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q5_1",
        "size": "dolphin-mistral:7b-v2.8-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q5_K_S",
        "size": "dolphin-mistral:7b-v2.8-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q5_K_M",
        "size": "dolphin-mistral:7b-v2.8-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q6_K",
        "size": "dolphin-mistral:7b-v2.8-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-q8_0",
        "size": "dolphin-mistral:7b-v2.8-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-mistral:7b-v2.8-fp16",
        "size": "dolphin-mistral:7b-v2.8-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "cogito",
    "link": "https://ollama.com/library/cogito",
    "description": "Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that outperform the best available open models of the same size, including counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks.",
    "pullCount": "354K",
    "updated": "5 months ago",
    "size": [
      "3b",
      "8b",
      "14b",
      "32b",
      "70b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/cogito/44ceefc5-6a71-4d18-958e-21d45d309b18)\n\nThe Cogito v1 Preview LLMs are instruction tuned generative models (text in/text out). All models are released under an open license for commercial use.\n\n* Cogito models are hybrid reasoning models. Each model can answer directly (standard LLM), or self-reflect before answering (like reasoning models).\n* The LLMs are trained using **Iterated Distillation and Amplification (IDA)** \\- an scalable and efficient alignment strategy for superintelligence using iterative self-improvement.\n* The models have been optimized for coding, STEM, instruction following and general helpfulness, and have significantly higher multilingual, coding and tool calling capabilities than size equivalent counterparts.  \n   * In both standard and reasoning modes, Cogito v1-preview models outperform their size equivalent counterparts on common industry benchmarks.\n* Each model is trained in over 30 languages and supports a context length of 128k.\n\n## Extended thinking\n\nTo enable extended thinking, include `Enable deep thinking subroutine.` in the system prompt:\n\n```\n/set system \"\"\"Enable deep thinking subroutine.\"\"\"\n\n```\n\nOr via the API:\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"cogito\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"Enable deep thinking subroutine.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"How many letter Rs are in the word Strawberry?\"\n    }\n  ]\n}'\n\n```\n\n## Sizes\n\n#### 3B\n\n```\nollama run cogito:3b\n\n```\n\n#### 8B\n\n```\nollama run cogito:8b\n\n```\n\n#### 14B\n\n```\nollama run cogito:14b\n\n```\n\n#### 32B\n\n```\nollama run cogito:32b\n\n```\n\n#### 70B\n\n```\nollama run cogito:70b\n\n```\n\n## Benchmarks\n\n### Smaller models - 3B and 8B\n\n#### 3B performance\n\n![3b.webp](/assets/library/cogito/b3f444f7-91a6-4bd4-a395-a515060752b9)\n\n#### 8B performance\n\n![8b.webp](/assets/library/cogito/e2cc899a-0f9f-48c5-a530-e941576bd67a)\n\n#### 3B tool calling\n\n![3b-toolcalling.webp](/assets/library/cogito/53992b0e-9226-4fff-ba70-9ffd7f980f2f)\n\n### Medium models - 14B and 32B\n\n#### 14B\n\n![14b.webp](/assets/library/cogito/c32b8f91-3b00-457a-ad54-feab83d1decf)\n\n#### 32B\n\n![32b.webp](/assets/library/cogito/bc5ea441-1fb8-4bf6-b4de-9093b0e74426)\n\n### Larger models - 70B\n\n![70b.webp](/assets/library/cogito/139c3df7-bdc5-4497-aa51-cddb7eccaca9)\n\n## References\n\n[Blog post](https://www.deepcogito.com/research/cogito-v1-preview)\n\n[Hugging Face](https://huggingface.co/collections/deepcogito/cogito-v1-preview-67eb105721081abe4ce2ee53)\n\nWrite Preview \n\n<img src=\"/assets/library/cogito/44ceefc5-6a71-4d18-958e-21d45d309b18\" width=\"320\" /> The Cogito v1 Preview LLMs are instruction tuned generative models (text in/text out). All models are released under an open license for commercial use. - Cogito models are hybrid reasoning models. Each model can answer directly (standard LLM), or self-reflect before answering (like reasoning models). - The LLMs are trained using \\*\\*Iterated Distillation and Amplification (IDA)\\*\\* - an scalable and efficient alignment strategy for superintelligence using iterative self-improvement. - The models have been optimized for coding, STEM, instruction following and general helpfulness, and have significantly higher multilingual, coding and tool calling capabilities than size equivalent counterparts. - In both standard and reasoning modes, Cogito v1-preview models outperform their size equivalent counterparts on common industry benchmarks. - Each model is trained in over 30 languages and supports a context length of 128k. ## Extended thinking To enable extended thinking, include \\`Enable deep thinking subroutine.\\` in the system prompt: \\`\\`\\` /set system \"\"\"Enable deep thinking subroutine.\"\"\" \\`\\`\\` Or via the API: \\`\\`\\` curl http://localhost:11434/api/chat -d '{ \"model\": \"cogito\", \"messages\": \\[ { \"role\": \"system\", \"content\": \"Enable deep thinking subroutine.\" }, { \"role\": \"user\", \"content\": \"How many letter Rs are in the word Strawberry?\" } \\] }' \\`\\`\\` ## Sizes #### 3B \\`\\`\\` ollama run cogito:3b \\`\\`\\` #### 8B \\`\\`\\` ollama run cogito:8b \\`\\`\\` #### 14B \\`\\`\\` ollama run cogito:14b \\`\\`\\` #### 32B \\`\\`\\` ollama run cogito:32b \\`\\`\\` #### 70B \\`\\`\\` ollama run cogito:70b \\`\\`\\` ## Benchmarks ### Smaller models - 3B and 8B #### 3B performance !\\[3b.webp\\](/assets/library/cogito/b3f444f7-91a6-4bd4-a395-a515060752b9) #### 8B performance !\\[8b.webp\\](/assets/library/cogito/e2cc899a-0f9f-48c5-a530-e941576bd67a) #### 3B tool calling !\\[3b-toolcalling.webp\\](/assets/library/cogito/53992b0e-9226-4fff-ba70-9ffd7f980f2f) ### Medium models - 14B and 32B #### 14B !\\[14b.webp\\](/assets/library/cogito/c32b8f91-3b00-457a-ad54-feab83d1decf) #### 32B !\\[32b.webp\\](/assets/library/cogito/bc5ea441-1fb8-4bf6-b4de-9093b0e74426) ### Larger models - 70B !\\[70b.webp\\](/assets/library/cogito/139c3df7-bdc5-4497-aa51-cddb7eccaca9) ## References \\[Blog post\\](https://www.deepcogito.com/research/cogito-v1-preview) \\[Hugging Face\\](https://huggingface.co/collections/deepcogito/cogito-v1-preview-67eb105721081abe4ce2ee53) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "cogito:latest",
        "size": "cogito:latest",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:3b",
        "size": "cogito:3b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:8b",
        "size": "cogito:8b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:14b",
        "size": "cogito:14b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:32b",
        "size": "cogito:32b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:70b",
        "size": "cogito:70b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:3b-v1-preview-llama-q4_K_M",
        "size": "cogito:3b-v1-preview-llama-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:3b-v1-preview-llama-q8_0",
        "size": "cogito:3b-v1-preview-llama-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:3b-v1-preview-llama-fp16",
        "size": "cogito:3b-v1-preview-llama-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:8b-v1-preview-llama-q4_K_M",
        "size": "cogito:8b-v1-preview-llama-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:8b-v1-preview-llama-q8_0",
        "size": "cogito:8b-v1-preview-llama-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:14b-v1-preview-qwen-q4_K_M",
        "size": "cogito:14b-v1-preview-qwen-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:14b-v1-preview-qwen-q8_0",
        "size": "cogito:14b-v1-preview-qwen-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:14b-v1-preview-qwen-fp16",
        "size": "cogito:14b-v1-preview-qwen-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:32b-v1-preview-qwen-q4_K_M",
        "size": "cogito:32b-v1-preview-qwen-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:32b-v1-preview-qwen-q8_0",
        "size": "cogito:32b-v1-preview-qwen-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:32b-v1-preview-qwen-fp16",
        "size": "cogito:32b-v1-preview-qwen-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:70b-v1-preview-llama-q4_K_M",
        "size": "cogito:70b-v1-preview-llama-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:70b-v1-preview-llama-q8_0",
        "size": "cogito:70b-v1-preview-llama-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "cogito:70b-v1-preview-llama-fp16",
        "size": "cogito:70b-v1-preview-llama-fp16",
        "updated": "Text input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "magistral",
    "link": "https://ollama.com/library/magistral",
    "description": "Magistral is a small, efficient reasoning model with 24B parameters.",
    "pullCount": "341.5K",
    "updated": "2 months ago",
    "size": [
      "24b"
    ],
    "capabilities": "toolsthinking",
    "readme": "## Readme\n\n![](/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e)\n\nMagistral is the first reasoning model by Mistral AI, excelling in domain-specific, transparent, and multilingual reasoning.\n\n![magistral small comparison to medium](/assets/library/magistral/c57cd779-0588-4d74-9f48-89ba50f7a565)\n\n![magistral small](/assets/library/magistral/fe972176-2881-42bc-bbd8-90a079188aa9)\n\n### Key features\n\n* **Reasoning:** Capable of long chains of reasoning traces before providing an answer.\n* **Multilingual:** Supports dozens of languages, including English, French, German, Greek, Hindi, Indonesian, Italian, Japanese, Korean, Malay, Nepali, Polish, Portuguese, Romanian, Russian, Serbian, Spanish, Swedish, Turkish, Ukrainian, Vietnamese, Arabic, Bengali, Chinese, and Farsi.\n* **Apache 2.0 License:** Open license allowing usage and modification for both commercial and non-commercial purposes.\n* **Context Window:** A 128k context window, **but** performance might degrade past **40k**. Hence we recommend setting the maximum model length to 40k.\n\nMagistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling — this model solves multi-step challenges where transparency and precision are critical.\n\n#### Business strategy and operations.\n\nBuilding on our flagship [models](https://mistral.ai/models), Magistral is designed for research, strategic planning, operational optimization, and data-driven decision making — whether executing risk assessment and modelling with multiple factors, or calculating optimal delivery windows under constraints.\n\n#### Regulated industries and sectors.\n\nLegal, finance, healthcare, and government professionals get traceable reasoning that meets compliance requirements. Every conclusion can be traced back through its logical steps, providing auditability for high-stakes environments with domain-specialized AI.\n\n#### Systems, software, and data engineering.\n\nMagistral enhances coding and development use cases: compared to non-reasoning models, it significantly improves project planning, backend architecture, frontend design, and data engineering through sequenced, multi-step actions involving external tools or API.\n\n#### Content and communication.\n\nOur early tests indicated that Magistral is an excellent creative companion. We highly recommend it for creative writing and storytelling, with the model capable of producing coherent or — if needed — delightfully eccentric copy.\n\n### Reference\n\n* [Magistral paper](https://mistral.ai/static/research/magistral.pdf)\n* [Blog post](https://mistral.ai/news/magistral)\n\nWrite Preview \n\n<img src=\"/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e\" width=\"120\" /> Magistral is the first reasoning model by Mistral AI, excelling in domain-specific, transparent, and multilingual reasoning. !\\[magistral small comparison to medium\\](/assets/library/magistral/c57cd779-0588-4d74-9f48-89ba50f7a565) !\\[magistral small\\](/assets/library/magistral/fe972176-2881-42bc-bbd8-90a079188aa9) ### Key features - \\*\\*Reasoning:\\*\\* Capable of long chains of reasoning traces before providing an answer. - \\*\\*Multilingual:\\*\\* Supports dozens of languages, including English, French, German, Greek, Hindi, Indonesian, Italian, Japanese, Korean, Malay, Nepali, Polish, Portuguese, Romanian, Russian, Serbian, Spanish, Swedish, Turkish, Ukrainian, Vietnamese, Arabic, Bengali, Chinese, and Farsi. - \\*\\*Apache 2.0 License:\\*\\* Open license allowing usage and modification for both commercial and non-commercial purposes. - \\*\\*Context Window:\\*\\* A 128k context window, \\*\\*but\\*\\* performance might degrade past \\*\\*40k\\*\\*. Hence we recommend setting the maximum model length to 40k. Magistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling — this model solves multi-step challenges where transparency and precision are critical. #### Business strategy and operations. Building on our flagship \\[models\\](https://mistral.ai/models), Magistral is designed for research, strategic planning, operational optimization, and data-driven decision making — whether executing risk assessment and modelling with multiple factors, or calculating optimal delivery windows under constraints. #### Regulated industries and sectors. Legal, finance, healthcare, and government professionals get traceable reasoning that meets compliance requirements. Every conclusion can be traced back through its logical steps, providing auditability for high-stakes environments with domain-specialized AI. #### Systems, software, and data engineering. Magistral enhances coding and development use cases: compared to non-reasoning models, it significantly improves project planning, backend architecture, frontend design, and data engineering through sequenced, multi-step actions involving external tools or API. #### Content and communication. Our early tests indicated that Magistral is an excellent creative companion. We highly recommend it for creative writing and storytelling, with the model capable of producing coherent or — if needed — delightfully eccentric copy. ### Reference - \\[Magistral paper\\](https://mistral.ai/static/research/magistral.pdf) - \\[Blog post\\](https://mistral.ai/news/magistral) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "magistral:latest",
        "size": "magistral:latest",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "magistral:24b",
        "size": "magistral:24b",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "magistral:24b-small-2506-q4_K_M",
        "size": "magistral:24b-small-2506-q4_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "magistral:24b-small-2506-q8_0",
        "size": "magistral:24b-small-2506-q8_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "magistral:24b-small-2506-fp16",
        "size": "magistral:24b-small-2506-fp16",
        "updated": "Text input • \n                    2 months ago"
      }
    ]
  },
  {
    "name": "command-r",
    "link": "https://ollama.com/library/command-r",
    "description": "Command R is a Large Language Model optimized for conversational interaction and long context tasks.",
    "pullCount": "339.4K",
    "updated": "1 year ago",
    "size": [
      "35b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/0f8ef1fc-f0ba-4e69-b171-36c387aa5349)\n\nCommand R is a generative model optimized for long context tasks such as retrieval-augmented generation (RAG) and using external APIs and tools. As a model built for companies to implement at scale, Command R boasts:\n\n* Strong accuracy on RAG and Tool Use\n* Low latency, and high throughput\n* Longer 128k context\n* Strong capabilities across 10 key languages\n\nThere are currently two versions of Command R:\n\n* Original release tagged **v0.1**\n* August 2024 update tagged **08-2024**\n\n## References\n\n* [Blog Post](https://txt.cohere.com/command-r/)\n* [Hugging Face](https://huggingface.co/CohereForAI/c4ai-command-r-v01)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/0f8ef1fc-f0ba-4e69-b171-36c387aa5349\" width=\"480\" /> Command R is a generative model optimized for long context tasks such as retrieval-augmented generation (RAG) and using external APIs and tools. As a model built for companies to implement at scale, Command R boasts: - Strong accuracy on RAG and Tool Use - Low latency, and high throughput - Longer 128k context - Strong capabilities across 10 key languages There are currently two versions of Command R: - Original release tagged \\*\\*v0.1\\*\\* - August 2024 update tagged \\*\\*08-2024\\*\\* ## References - \\[Blog Post\\](https://txt.cohere.com/command-r/) - \\[Hugging Face\\](https://huggingface.co/CohereForAI/c4ai-command-r-v01) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "command-r:latest",
        "size": "command-r:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:v0.1",
        "size": "command-r:v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b",
        "size": "command-r:35b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q2_K",
        "size": "command-r:35b-08-2024-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q3_K_S",
        "size": "command-r:35b-08-2024-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q3_K_M",
        "size": "command-r:35b-08-2024-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q3_K_L",
        "size": "command-r:35b-08-2024-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q4_0",
        "size": "command-r:35b-08-2024-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q4_1",
        "size": "command-r:35b-08-2024-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q4_K_S",
        "size": "command-r:35b-08-2024-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q4_K_M",
        "size": "command-r:35b-08-2024-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q5_0",
        "size": "command-r:35b-08-2024-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q5_1",
        "size": "command-r:35b-08-2024-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q5_K_S",
        "size": "command-r:35b-08-2024-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q5_K_M",
        "size": "command-r:35b-08-2024-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q6_K",
        "size": "command-r:35b-08-2024-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-q8_0",
        "size": "command-r:35b-08-2024-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-08-2024-fp16",
        "size": "command-r:35b-08-2024-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q2_K",
        "size": "command-r:35b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q3_K_S",
        "size": "command-r:35b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q3_K_M",
        "size": "command-r:35b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q3_K_L",
        "size": "command-r:35b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q4_0",
        "size": "command-r:35b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q4_1",
        "size": "command-r:35b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q4_K_S",
        "size": "command-r:35b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q4_K_M",
        "size": "command-r:35b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q5_1",
        "size": "command-r:35b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q5_K_S",
        "size": "command-r:35b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q5_K_M",
        "size": "command-r:35b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q6_K",
        "size": "command-r:35b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-q8_0",
        "size": "command-r:35b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r:35b-v0.1-fp16",
        "size": "command-r:35b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "qwen3-coder",
    "link": "https://ollama.com/library/qwen3-coder",
    "description": "Alibaba's performant long context models for agentic and coding tasks.",
    "pullCount": "337.9K",
    "updated": "2 weeks ago",
    "size": [
      "30b",
      "480b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![Qwen 3 logo](/assets/library/qwen3/a5541098-87ba-4184-a5af-2b63312c2522) **Qwen3-Coder** is the most agentic code model to date in the Qwen series.\n\n### Overview\n\n`qwen3-coder:30b` offers 30B total parameters with only 3.3B activated, delivering strong performance while maintaining efficiency.\n\n* Exceptional agentic capabilities for real-world software engineering tasks through advanced long-horizon reinforcement learning on SWE-Bench and similar benchmarks.\n* Long context support with 256K tokens natively and up to 1M tokens using extrapolation methods, optimized for repository-scale understanding.\n* Scaled pretraining on 7.5T tokens (70% code ratio) while preserving strong general and mathematical abilities.\n* Execution-driven reinforcement learning that significantly boosts code execution success rates across diverse real-world coding tasks.\n\n![image.png](/assets/library/qwen3-coder/52070971-5a66-4947-90a0-5e983a5809e7)\n\n### Reference\n\n* [Blog](https://qwenlm.github.io/blog/qwen3-coder/)\n\nWrite Preview \n\n!\\[Qwen 3 logo\\](/assets/library/qwen3/a5541098-87ba-4184-a5af-2b63312c2522) \\*\\*Qwen3-Coder\\*\\* is the most agentic code model to date in the Qwen series. ### Overview \\`qwen3-coder:30b\\` offers 30B total parameters with only 3.3B activated, delivering strong performance while maintaining efficiency. - Exceptional agentic capabilities for real-world software engineering tasks through advanced long-horizon reinforcement learning on SWE-Bench and similar benchmarks. - Long context support with 256K tokens natively and up to 1M tokens using extrapolation methods, optimized for repository-scale understanding. - Scaled pretraining on 7.5T tokens (70% code ratio) while preserving strong general and mathematical abilities. - Execution-driven reinforcement learning that significantly boosts code execution success rates across diverse real-world coding tasks. !\\[image.png\\](/assets/library/qwen3-coder/52070971-5a66-4947-90a0-5e983a5809e7) ### Reference - \\[Blog\\](https://qwenlm.github.io/blog/qwen3-coder/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen3-coder:latest",
        "size": "qwen3-coder:latest",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3-coder:30b",
        "size": "qwen3-coder:30b",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3-coder:480b",
        "size": "qwen3-coder:480b",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "qwen3-coder:30b-a3b-q4_K_M",
        "size": "qwen3-coder:30b-a3b-q4_K_M",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3-coder:30b-a3b-q8_0",
        "size": "qwen3-coder:30b-a3b-q8_0",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3-coder:30b-a3b-fp16",
        "size": "qwen3-coder:30b-a3b-fp16",
        "updated": "Text input • \n                    1 month ago"
      },
      {
        "name": "qwen3-coder:480b-a35b-q4_K_M",
        "size": "qwen3-coder:480b-a35b-q4_K_M",
        "updated": "Text input • \n                    3 weeks ago"
      },
      {
        "name": "qwen3-coder:480b-a35b-q8_0",
        "size": "qwen3-coder:480b-a35b-q8_0",
        "updated": "Text input • \n                    2 weeks ago"
      },
      {
        "name": "qwen3-coder:480b-a35b-fp16",
        "size": "qwen3-coder:480b-a35b-fp16",
        "updated": "Text input • \n                    1 month ago"
      }
    ]
  },
  {
    "name": "phi4-mini",
    "link": "https://ollama.com/library/phi4-mini",
    "description": "Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.",
    "pullCount": "334.6K",
    "updated": "6 months ago",
    "size": [
      "3.8b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n> Note: this model requires [Ollama 0.5.13](https://github.com/ollama/ollama/releases/tag/v0.5.13) or later.\n\n![](https://ollama.com/assets/library/phi3.5/dbf19a17-e3fd-46b6-a059-e6b4f1fae59f)\n\nPhi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures.\n\n## Primary use cases\n\nThe model is intended for broad multilingual commercial and research use. The model provides uses for general purpose AI systems and applications which require:\n\n* Memory/compute constrained environments\n* Latency bound scenarios\n* Strong reasoning (especially math and logic).\n* The model is designed to accelerate research on language and multimodal models, for use as a building block for generative AI powered features.\n\n## References\n\n[Hugging Face](https://huggingface.co/microsoft/Phi-4-mini-instruct)\n\n[Blog post](https://techcommunity.microsoft.com/blog/educatordeveloperblog/welcome-to-the-new-phi-4-models---microsoft-phi-4-mini--phi-4-multimodal/4386037)\n\nWrite Preview \n\n\\> Note: this model requires \\[Ollama 0.5.13\\](https://github.com/ollama/ollama/releases/tag/v0.5.13) or later. <img src=\"https://ollama.com/assets/library/phi3.5/dbf19a17-e3fd-46b6-a059-e6b4f1fae59f\" width=\"320\" /> Phi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures. ## Primary use cases The model is intended for broad multilingual commercial and research use. The model provides uses for general purpose AI systems and applications which require: - Memory/compute constrained environments - Latency bound scenarios - Strong reasoning (especially math and logic). - The model is designed to accelerate research on language and multimodal models, for use as a building block for generative AI powered features. ## References \\[Hugging Face\\](https://huggingface.co/microsoft/Phi-4-mini-instruct) \\[Blog post\\](https://techcommunity.microsoft.com/blog/educatordeveloperblog/welcome-to-the-new-phi-4-models---microsoft-phi-4-mini--phi-4-multimodal/4386037) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi4-mini:latest",
        "size": "phi4-mini:latest",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "phi4-mini:3.8b",
        "size": "phi4-mini:3.8b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "phi4-mini:3.8b-q4_K_M",
        "size": "phi4-mini:3.8b-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "phi4-mini:3.8b-q8_0",
        "size": "phi4-mini:3.8b-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "phi4-mini:3.8b-fp16",
        "size": "phi4-mini:3.8b-fp16",
        "updated": "Text input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "hermes3",
    "link": "https://ollama.com/library/hermes3",
    "description": "Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous Research",
    "pullCount": "333.3K",
    "updated": "8 months ago",
    "size": [
      "3b",
      "8b",
      "70b",
      "405b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![image.png](https://ollama.com/assets/library/hermes3/e8584a99-0cf4-4d0a-9032-3af2fd7db91d)\n\nHermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nThe ethos of the Hermes series of models is focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\n**Hermes 3** series contains four models: **3B**, **8B**, **70B**, and **405B**\n\n## References:\n\n* [Hermes 3 Technical Report](https://arxiv.org/abs/2408.11857)\n* [Hugging Face](https://huggingface.co/collections/NousResearch/hermes-3-66bd6c01399b14b08fe335ea)\n\nWrite Preview \n\n!\\[image.png\\](https://ollama.com/assets/library/hermes3/e8584a99-0cf4-4d0a-9032-3af2fd7db91d) Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board. The ethos of the Hermes series of models is focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user. The Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills. \\*\\*Hermes 3\\*\\* series contains four models: \\*\\*3B\\*\\*, \\*\\*8B\\*\\*, \\*\\*70B\\*\\*, and \\*\\*405B\\*\\* ## References: \\* \\[Hermes 3 Technical Report\\](https://arxiv.org/abs/2408.11857) \\* \\[Hugging Face\\](https://huggingface.co/collections/NousResearch/hermes-3-66bd6c01399b14b08fe335ea) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "hermes3:latest",
        "size": "hermes3:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b",
        "size": "hermes3:3b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b",
        "size": "hermes3:8b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:70b",
        "size": "hermes3:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:405b",
        "size": "hermes3:405b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q2_K",
        "size": "hermes3:3b-llama3.2-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q3_K_S",
        "size": "hermes3:3b-llama3.2-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q3_K_M",
        "size": "hermes3:3b-llama3.2-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q3_K_L",
        "size": "hermes3:3b-llama3.2-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q4_0",
        "size": "hermes3:3b-llama3.2-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q4_1",
        "size": "hermes3:3b-llama3.2-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q4_K_S",
        "size": "hermes3:3b-llama3.2-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q4_K_M",
        "size": "hermes3:3b-llama3.2-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q5_0",
        "size": "hermes3:3b-llama3.2-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q5_1",
        "size": "hermes3:3b-llama3.2-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q5_K_S",
        "size": "hermes3:3b-llama3.2-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q5_K_M",
        "size": "hermes3:3b-llama3.2-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q6_K",
        "size": "hermes3:3b-llama3.2-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-q8_0",
        "size": "hermes3:3b-llama3.2-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:3b-llama3.2-fp16",
        "size": "hermes3:3b-llama3.2-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q2_K",
        "size": "hermes3:8b-llama3.1-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q3_K_S",
        "size": "hermes3:8b-llama3.1-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q3_K_M",
        "size": "hermes3:8b-llama3.1-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q3_K_L",
        "size": "hermes3:8b-llama3.1-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q4_0",
        "size": "hermes3:8b-llama3.1-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q4_1",
        "size": "hermes3:8b-llama3.1-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q4_K_S",
        "size": "hermes3:8b-llama3.1-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q4_K_M",
        "size": "hermes3:8b-llama3.1-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q5_0",
        "size": "hermes3:8b-llama3.1-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q5_1",
        "size": "hermes3:8b-llama3.1-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q5_K_S",
        "size": "hermes3:8b-llama3.1-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q5_K_M",
        "size": "hermes3:8b-llama3.1-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q6_K",
        "size": "hermes3:8b-llama3.1-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-q8_0",
        "size": "hermes3:8b-llama3.1-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:8b-llama3.1-fp16",
        "size": "hermes3:8b-llama3.1-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q2_K",
        "size": "hermes3:70b-llama3.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q3_K_S",
        "size": "hermes3:70b-llama3.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q3_K_M",
        "size": "hermes3:70b-llama3.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q3_K_L",
        "size": "hermes3:70b-llama3.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q4_0",
        "size": "hermes3:70b-llama3.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q4_1",
        "size": "hermes3:70b-llama3.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q4_K_S",
        "size": "hermes3:70b-llama3.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q4_K_M",
        "size": "hermes3:70b-llama3.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q5_0",
        "size": "hermes3:70b-llama3.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q5_1",
        "size": "hermes3:70b-llama3.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q5_K_S",
        "size": "hermes3:70b-llama3.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q5_K_M",
        "size": "hermes3:70b-llama3.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q6_K",
        "size": "hermes3:70b-llama3.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-q8_0",
        "size": "hermes3:70b-llama3.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:70b-llama3.1-fp16",
        "size": "hermes3:70b-llama3.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q2_K",
        "size": "hermes3:405b-llama3.1-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q3_K_S",
        "size": "hermes3:405b-llama3.1-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q3_K_M",
        "size": "hermes3:405b-llama3.1-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q3_K_L",
        "size": "hermes3:405b-llama3.1-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q4_0",
        "size": "hermes3:405b-llama3.1-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q4_1",
        "size": "hermes3:405b-llama3.1-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q4_K_S",
        "size": "hermes3:405b-llama3.1-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q4_K_M",
        "size": "hermes3:405b-llama3.1-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q5_0",
        "size": "hermes3:405b-llama3.1-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q5_1",
        "size": "hermes3:405b-llama3.1-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q5_K_S",
        "size": "hermes3:405b-llama3.1-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q5_K_M",
        "size": "hermes3:405b-llama3.1-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q6_K",
        "size": "hermes3:405b-llama3.1-q6_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-q8_0",
        "size": "hermes3:405b-llama3.1-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "hermes3:405b-llama3.1-fp16",
        "size": "hermes3:405b-llama3.1-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "phi3.5",
    "link": "https://ollama.com/library/phi3.5",
    "description": "A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.",
    "pullCount": "321.2K",
    "updated": "1 year ago",
    "size": [
      "3.8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/phi3.5/dbf19a17-e3fd-46b6-a059-e6b4f1fae59f)\n\nPhi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites with a focus on very high-quality, reasoning dense data.\n\nThe model belongs to the Phi-3 model family and supports 128K token context length. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures.\n\n### Long Context\n\nPhi-3.5-mini supports 128K context length, therefore the model is capable of several long context tasks including long document/meeting summarization, long document QA, long document information retrieval.\n\n## References\n\n[Hugging Face](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/phi3.5/dbf19a17-e3fd-46b6-a059-e6b4f1fae59f\" width=\"320\" /> Phi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family and supports 128K token context length. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures. ### Long Context Phi-3.5-mini supports 128K context length, therefore the model is capable of several long context tasks including long document/meeting summarization, long document QA, long document information retrieval. ## References \\[Hugging Face\\](https://huggingface.co/microsoft/Phi-3.5-mini-instruct) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi3.5:latest",
        "size": "phi3.5:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b",
        "size": "phi3.5:3.8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q2_K",
        "size": "phi3.5:3.8b-mini-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q3_K_S",
        "size": "phi3.5:3.8b-mini-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q3_K_M",
        "size": "phi3.5:3.8b-mini-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q3_K_L",
        "size": "phi3.5:3.8b-mini-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q4_0",
        "size": "phi3.5:3.8b-mini-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q4_1",
        "size": "phi3.5:3.8b-mini-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q4_K_S",
        "size": "phi3.5:3.8b-mini-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q4_K_M",
        "size": "phi3.5:3.8b-mini-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q5_0",
        "size": "phi3.5:3.8b-mini-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q5_1",
        "size": "phi3.5:3.8b-mini-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q5_K_S",
        "size": "phi3.5:3.8b-mini-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q5_K_M",
        "size": "phi3.5:3.8b-mini-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q6_K",
        "size": "phi3.5:3.8b-mini-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-q8_0",
        "size": "phi3.5:3.8b-mini-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phi3.5:3.8b-mini-instruct-fp16",
        "size": "phi3.5:3.8b-mini-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "devstral",
    "link": "https://ollama.com/library/devstral",
    "description": "Devstral: the best open source model for coding agents",
    "pullCount": "320.9K",
    "updated": "2 months ago",
    "size": [
      "24b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e)\n\n**Devstral** is an agentic LLM for software engineering tasks built under a collaboration between [Mistral AI](https://mistral.ai/) and [All Hands AI](https://www.all-hands.dev/) 🙌. Devstral excels at using tools to explore codebases, editing multiple files and power software engineering agents. The model achieves remarkable performance on SWE-bench which positionates it as the #1 open source model.\n\nIt is finetuned from Mistral Small 3.1, therefore it has a long context window of up to 128k tokens. As a coding agent, Devstral is text-only and before fine-tuning from `Mistral-Small-3.1` the vision encoder was removed.\n\n![agentic performance](/assets/library/devstral/a1ff4c01-fedd-4ce1-ad70-2dacb674add1)\n\n### Key Features:\n\n* **Agentic coding**: Devstral is designed to excel at agentic coding tasks, making it a great choice for software engineering agents.\n* **Lightweight**: with its compact size of just 24 billion parameters, Devstral is light enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it an appropriate model for local deployment and on-device use.\n* **Apache 2.0 License**: Open license allowing usage and modification for both commercial and non-commercial purposes.\n* **Context Window**: A 128k context window.\n\n### SWE-Bench\n\nDevstral achieves a score of **46.8% on SWE-Bench Verified**, outperforming prior open-source state-of-the-art by 6%.\n\n| Model            | Scaffold           | SWE-Bench Verified (%) |\n| ---------------- | ------------------ | ---------------------- |\n| Devstral         | OpenHands Scaffold | **46.8**               |\n| GPT-4.1-mini     | OpenAI Scaffold    | 23.6                   |\n| Claude 3.5 Haiku | Anthropic Scaffold | 40.6                   |\n| SWE-smith-LM 32B | SWE-agent Scaffold | 40.2                   |\n\nWhen evaluated under the same test scaffold (OpenHands, provided by All Hands AI 🙌), Devstral exceeds far larger models such as Deepseek-V3-0324 and Qwen3 232B-A22B.\n\nIn the chart below, we also compare Devstral to closed and open models evaluated under any scaffold (including ones custom for the model). Here, we find that Devstral achieves substantially better performance than a number of closed-source alternatives. For example, Devstral surpasses the recent GPT-4.1-mini by over 20%.\n\n![Devstral comparison](/assets/library/devstral/c78b6b7a-52d5-4b1f-9657-abdcb8369ef5)\n\n### Reference\n\n[Blog](https://mistral.ai/news/devstral)\n\nWrite Preview \n\n<img src=\"/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e\" width=\"120\" /> \\*\\*Devstral\\*\\* is an agentic LLM for software engineering tasks built under a collaboration between \\[Mistral AI\\](https://mistral.ai/) and \\[All Hands AI\\](https://www.all-hands.dev/) 🙌. Devstral excels at using tools to explore codebases, editing multiple files and power software engineering agents. The model achieves remarkable performance on SWE-bench which positionates it as the #1 open source model. It is finetuned from Mistral Small 3.1, therefore it has a long context window of up to 128k tokens. As a coding agent, Devstral is text-only and before fine-tuning from \\`Mistral-Small-3.1\\` the vision encoder was removed. !\\[agentic performance\\](/assets/library/devstral/a1ff4c01-fedd-4ce1-ad70-2dacb674add1) ### Key Features: - \\*\\*Agentic coding\\*\\*: Devstral is designed to excel at agentic coding tasks, making it a great choice for software engineering agents. - \\*\\*Lightweight\\*\\*: with its compact size of just 24 billion parameters, Devstral is light enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it an appropriate model for local deployment and on-device use. - \\*\\*Apache 2.0 License\\*\\*: Open license allowing usage and modification for both commercial and non-commercial purposes. - \\*\\*Context Window\\*\\*: A 128k context window. ### SWE-Bench Devstral achieves a score of \\*\\*46.8% on SWE-Bench Verified\\*\\*, outperforming prior open-source state-of-the-art by 6%. | Model | Scaffold | SWE-Bench Verified (%) | |------------------|--------------------|------------------------| | Devstral | OpenHands Scaffold | \\*\\*46.8\\*\\* | | GPT-4.1-mini | OpenAI Scaffold | 23.6 | | Claude 3.5 Haiku | Anthropic Scaffold | 40.6 | | SWE-smith-LM 32B | SWE-agent Scaffold | 40.2 | When evaluated under the same test scaffold (OpenHands, provided by All Hands AI 🙌), Devstral exceeds far larger models such as Deepseek-V3-0324 and Qwen3 232B-A22B. In the chart below, we also compare Devstral to closed and open models evaluated under any scaffold (including ones custom for the model). Here, we find that Devstral achieves substantially better performance than a number of closed-source alternatives. For example, Devstral surpasses the recent GPT-4.1-mini by over 20%. !\\[Devstral comparison\\](/assets/library/devstral/c78b6b7a-52d5-4b1f-9657-abdcb8369ef5) ### Reference \\[Blog\\](https://mistral.ai/news/devstral) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "devstral:latest",
        "size": "devstral:latest",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "devstral:24b",
        "size": "devstral:24b",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "devstral:24b-small-2505-q4_K_M",
        "size": "devstral:24b-small-2505-q4_K_M",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "devstral:24b-small-2505-q8_0",
        "size": "devstral:24b-small-2505-q8_0",
        "updated": "Text input • \n                    2 months ago"
      },
      {
        "name": "devstral:24b-small-2505-fp16",
        "size": "devstral:24b-small-2505-fp16",
        "updated": "Text input • \n                    2 months ago"
      }
    ]
  },
  {
    "name": "yi",
    "link": "https://ollama.com/library/yi",
    "description": "Yi 1.5 is a high-performing, bilingual language model.",
    "pullCount": "296.8K",
    "updated": "1 year ago",
    "size": [
      "6b",
      "9b",
      "34b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![yi](https://github.com/jmorganca/ollama/assets/251292/ac83ff77-b8aa-4dae-a619-d9603ef2edaa)\n\nYi is a series of large language models trained on a high-quality corpus of 3 trillion tokens that support both the English and Chinese languages.\n\n## References\n\n[HuggingFace](https://huggingface.co/01-ai/Yi-34B)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/ac83ff77-b8aa-4dae-a619-d9603ef2edaa\" alt=\"yi\" width=\"200\" /> Yi is a series of large language models trained on a high-quality corpus of 3 trillion tokens that support both the English and Chinese languages. ## References \\[HuggingFace\\](https://huggingface.co/01-ai/Yi-34B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "yi:latest",
        "size": "yi:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:v1.5",
        "size": "yi:v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b",
        "size": "yi:6b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b",
        "size": "yi:9b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b",
        "size": "yi:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k",
        "size": "yi:6b-200k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q2_K",
        "size": "yi:6b-200k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q3_K_S",
        "size": "yi:6b-200k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q3_K_M",
        "size": "yi:6b-200k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q3_K_L",
        "size": "yi:6b-200k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q4_0",
        "size": "yi:6b-200k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q4_1",
        "size": "yi:6b-200k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q4_K_S",
        "size": "yi:6b-200k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q4_K_M",
        "size": "yi:6b-200k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q5_0",
        "size": "yi:6b-200k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q5_1",
        "size": "yi:6b-200k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q5_K_S",
        "size": "yi:6b-200k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q5_K_M",
        "size": "yi:6b-200k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q6_K",
        "size": "yi:6b-200k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-q8_0",
        "size": "yi:6b-200k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-200k-fp16",
        "size": "yi:6b-200k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat",
        "size": "yi:6b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q2_K",
        "size": "yi:6b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q2_K",
        "size": "yi:6b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q3_K_S",
        "size": "yi:6b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q3_K_S",
        "size": "yi:6b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q3_K_M",
        "size": "yi:6b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q3_K_M",
        "size": "yi:6b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q3_K_L",
        "size": "yi:6b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q3_K_L",
        "size": "yi:6b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q4_0",
        "size": "yi:6b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q4_0",
        "size": "yi:6b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q4_1",
        "size": "yi:6b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q4_1",
        "size": "yi:6b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q4_K_S",
        "size": "yi:6b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q4_K_S",
        "size": "yi:6b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q4_K_M",
        "size": "yi:6b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q4_K_M",
        "size": "yi:6b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q5_0",
        "size": "yi:6b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q5_0",
        "size": "yi:6b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q5_1",
        "size": "yi:6b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q5_1",
        "size": "yi:6b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q5_K_S",
        "size": "yi:6b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q5_K_S",
        "size": "yi:6b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q5_K_M",
        "size": "yi:6b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q5_K_M",
        "size": "yi:6b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q6_K",
        "size": "yi:6b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q6_K",
        "size": "yi:6b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-q8_0",
        "size": "yi:6b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-q8_0",
        "size": "yi:6b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-fp16",
        "size": "yi:6b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-chat-v1.5-fp16",
        "size": "yi:6b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5",
        "size": "yi:6b-v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q2_K",
        "size": "yi:6b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q3_K_S",
        "size": "yi:6b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q3_K_M",
        "size": "yi:6b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q3_K_L",
        "size": "yi:6b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q4_0",
        "size": "yi:6b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q4_1",
        "size": "yi:6b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q4_K_S",
        "size": "yi:6b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q4_K_M",
        "size": "yi:6b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q5_0",
        "size": "yi:6b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q5_1",
        "size": "yi:6b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q5_K_S",
        "size": "yi:6b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q5_K_M",
        "size": "yi:6b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q6_K",
        "size": "yi:6b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-q8_0",
        "size": "yi:6b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-v1.5-fp16",
        "size": "yi:6b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q2_K",
        "size": "yi:6b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q3_K_S",
        "size": "yi:6b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q3_K_M",
        "size": "yi:6b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q3_K_L",
        "size": "yi:6b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q4_0",
        "size": "yi:6b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q4_1",
        "size": "yi:6b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q4_K_S",
        "size": "yi:6b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q4_K_M",
        "size": "yi:6b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q5_0",
        "size": "yi:6b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q5_1",
        "size": "yi:6b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q5_K_S",
        "size": "yi:6b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q5_K_M",
        "size": "yi:6b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q6_K",
        "size": "yi:6b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-q8_0",
        "size": "yi:6b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:6b-fp16",
        "size": "yi:6b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat",
        "size": "yi:9b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q2_K",
        "size": "yi:9b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q3_K_S",
        "size": "yi:9b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q3_K_M",
        "size": "yi:9b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q3_K_L",
        "size": "yi:9b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q4_0",
        "size": "yi:9b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q4_1",
        "size": "yi:9b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q4_K_S",
        "size": "yi:9b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q4_K_M",
        "size": "yi:9b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q5_0",
        "size": "yi:9b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q5_1",
        "size": "yi:9b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q5_K_S",
        "size": "yi:9b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q5_K_M",
        "size": "yi:9b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q6_K",
        "size": "yi:9b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-q8_0",
        "size": "yi:9b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-chat-v1.5-fp16",
        "size": "yi:9b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5",
        "size": "yi:9b-v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q2_K",
        "size": "yi:9b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q3_K_S",
        "size": "yi:9b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q3_K_M",
        "size": "yi:9b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q3_K_L",
        "size": "yi:9b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q4_0",
        "size": "yi:9b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q4_1",
        "size": "yi:9b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q4_K_S",
        "size": "yi:9b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q4_K_M",
        "size": "yi:9b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q5_0",
        "size": "yi:9b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q5_1",
        "size": "yi:9b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q5_K_S",
        "size": "yi:9b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q5_K_M",
        "size": "yi:9b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q6_K",
        "size": "yi:9b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-q8_0",
        "size": "yi:9b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:9b-v1.5-fp16",
        "size": "yi:9b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat",
        "size": "yi:34b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q2_K",
        "size": "yi:34b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q2_K",
        "size": "yi:34b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q3_K_S",
        "size": "yi:34b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q3_K_S",
        "size": "yi:34b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q3_K_M",
        "size": "yi:34b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q3_K_M",
        "size": "yi:34b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q3_K_L",
        "size": "yi:34b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q3_K_L",
        "size": "yi:34b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q4_0",
        "size": "yi:34b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q4_0",
        "size": "yi:34b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q4_1",
        "size": "yi:34b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q4_1",
        "size": "yi:34b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q4_K_S",
        "size": "yi:34b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q4_K_S",
        "size": "yi:34b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q4_K_M",
        "size": "yi:34b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q4_K_M",
        "size": "yi:34b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q5_0",
        "size": "yi:34b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q5_0",
        "size": "yi:34b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q5_1",
        "size": "yi:34b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q5_1",
        "size": "yi:34b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q5_K_S",
        "size": "yi:34b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q5_K_S",
        "size": "yi:34b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q5_K_M",
        "size": "yi:34b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q5_K_M",
        "size": "yi:34b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q6_K",
        "size": "yi:34b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q6_K",
        "size": "yi:34b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-q8_0",
        "size": "yi:34b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-q8_0",
        "size": "yi:34b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-fp16",
        "size": "yi:34b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-chat-v1.5-fp16",
        "size": "yi:34b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5",
        "size": "yi:34b-v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q2_K",
        "size": "yi:34b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q3_K_S",
        "size": "yi:34b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q3_K_M",
        "size": "yi:34b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q3_K_L",
        "size": "yi:34b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q4_0",
        "size": "yi:34b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q4_1",
        "size": "yi:34b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q4_K_S",
        "size": "yi:34b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q4_K_M",
        "size": "yi:34b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q5_0",
        "size": "yi:34b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q5_1",
        "size": "yi:34b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q5_K_S",
        "size": "yi:34b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q5_K_M",
        "size": "yi:34b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q6_K",
        "size": "yi:34b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-q8_0",
        "size": "yi:34b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-v1.5-fp16",
        "size": "yi:34b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q2_K",
        "size": "yi:34b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q3_K_S",
        "size": "yi:34b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q3_K_M",
        "size": "yi:34b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q3_K_L",
        "size": "yi:34b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q4_0",
        "size": "yi:34b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q4_1",
        "size": "yi:34b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q4_K_S",
        "size": "yi:34b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q4_K_M",
        "size": "yi:34b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q5_0",
        "size": "yi:34b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q5_1",
        "size": "yi:34b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q5_K_S",
        "size": "yi:34b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi:34b-q6_K",
        "size": "yi:34b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "zephyr",
    "link": "https://ollama.com/library/zephyr",
    "description": "Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models that are trained to act as helpful assistants.",
    "pullCount": "286K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "141b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/8dab1157-909a-455b-a5c4-f7c31e9bcf0e)\n\nZephyr is a series of language models that are trained to act as helpful assistants. Zephyr 141B-A35B is the latest model in the series, and is a fine-tuned version of [Mixtral 8x22b](https://ollama.com/library/mixtral:8x22b).\n\n## Sizes\n\n* `zephyr:141b`: A Mixture of Experts (MoE) model with 141B total parameters and 35B active parameters.\n* `zephyr:7b`: The original Zephyr model\n\n## Source:\n\n* [HuggingFace](https://huggingface.co/HuggingFaceH4)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/8dab1157-909a-455b-a5c4-f7c31e9bcf0e\" width=\"400\" /> Zephyr is a series of language models that are trained to act as helpful assistants. Zephyr 141B-A35B is the latest model in the series, and is a fine-tuned version of \\[Mixtral 8x22b\\](https://ollama.com/library/mixtral:8x22b). ## Sizes \\* \\`zephyr:141b\\`: A Mixture of Experts (MoE) model with 141B total parameters and 35B active parameters. \\* \\`zephyr:7b\\`: The original Zephyr model ## Source: \\* \\[HuggingFace\\](https://huggingface.co/HuggingFaceH4) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "zephyr:latest",
        "size": "zephyr:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b",
        "size": "zephyr:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:141b",
        "size": "zephyr:141b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha",
        "size": "zephyr:7b-alpha",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q2_K",
        "size": "zephyr:7b-alpha-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q3_K_S",
        "size": "zephyr:7b-alpha-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q3_K_M",
        "size": "zephyr:7b-alpha-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q3_K_L",
        "size": "zephyr:7b-alpha-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q4_0",
        "size": "zephyr:7b-alpha-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q4_1",
        "size": "zephyr:7b-alpha-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q4_K_S",
        "size": "zephyr:7b-alpha-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q4_K_M",
        "size": "zephyr:7b-alpha-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q5_0",
        "size": "zephyr:7b-alpha-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q5_1",
        "size": "zephyr:7b-alpha-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q5_K_S",
        "size": "zephyr:7b-alpha-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q5_K_M",
        "size": "zephyr:7b-alpha-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q6_K",
        "size": "zephyr:7b-alpha-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-q8_0",
        "size": "zephyr:7b-alpha-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-alpha-fp16",
        "size": "zephyr:7b-alpha-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta",
        "size": "zephyr:7b-beta",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q2_K",
        "size": "zephyr:7b-beta-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q3_K_S",
        "size": "zephyr:7b-beta-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q3_K_M",
        "size": "zephyr:7b-beta-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q3_K_L",
        "size": "zephyr:7b-beta-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q4_0",
        "size": "zephyr:7b-beta-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q4_1",
        "size": "zephyr:7b-beta-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q4_K_S",
        "size": "zephyr:7b-beta-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q4_K_M",
        "size": "zephyr:7b-beta-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q5_0",
        "size": "zephyr:7b-beta-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q5_1",
        "size": "zephyr:7b-beta-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q5_K_S",
        "size": "zephyr:7b-beta-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q5_K_M",
        "size": "zephyr:7b-beta-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q6_K",
        "size": "zephyr:7b-beta-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-q8_0",
        "size": "zephyr:7b-beta-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:7b-beta-fp16",
        "size": "zephyr:7b-beta-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:141b-v0.1",
        "size": "zephyr:141b-v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:141b-v0.1-q2_K",
        "size": "zephyr:141b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:141b-v0.1-q4_0",
        "size": "zephyr:141b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:141b-v0.1-q8_0",
        "size": "zephyr:141b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "zephyr:141b-v0.1-fp16",
        "size": "zephyr:141b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepscaler",
    "link": "https://ollama.com/library/deepscaler",
    "description": "A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI’s o1-preview with just 1.5B parameters on popular math evaluations.",
    "pullCount": "283.6K",
    "updated": "6 months ago",
    "size": [
      "1.5b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n# DeepScaleR\n\n🚀 Democratizing Reinforcement Learning for LLMs 🌟\n\nDeepScaleR-1.5B-Preview is a language model fine-tuned from DeepSeek-R1-Distilled-Qwen-1.5B using distributed reinforcement learning (RL) to scale up to long context lengths. The model achieves 43.1% Pass@1 accuracy on AIME 2024, representing a 15% improvement over the base model (28.8%) and surpassing OpenAI’s O1-Preview performance with just 1.5B parameters.\n\n| Model                         | AIME 2024 | MATH 500 | AMC 2023 | Minerva Math | Olympiad Bench | Avg.     |\n| ----------------------------- | --------- | -------- | -------- | ------------ | -------------- | -------- |\n| **DeepScaleR-1.5B-Preview**   | **43.1**  | **87.8** | **73.6** | **30.2**     | **50.0**       | **57.0** |\n| DeepSeek-R1-Distill-Qwen-1.5B | 28.8      | 82.8     | 62.9     | 26.5         | 43.3           | 48.9     |\n| O1-Preview                    | 40.0      | 81.4     | \\-       | \\-           | \\-             | \\-       |\n\n![image.png](/assets/library/deepscaler/c8dcb4f4-481a-4fea-89a9-168cdd1f48fe)\n\n### Data\n\nOur training dataset consists of approximately 40,000 unique problem-answer pairs compiled from:\n\n* AIME problems (1984-2023)\n* AMC problems (prior to 2023)\n* Omni-MATH dataset\n* Still dataset\n\n### Evaluation\n\nWe evaluate our model on competition-level mathematics benchmarks, including AIME 2024, AMC 2023, MATH-500, Minerva Math, and OlympiadBench. Below, Pass@1 accuracy is reported, averaged over 16 samples for each problem.\n\n| **Model**                     | **AIME 2024** | **MATH 500** | **AMC 2023** | **Minerva Math** | **OlympiadBench** | **Avg.** |\n| ----------------------------- | ------------- | ------------ | ------------ | ---------------- | ----------------- | -------- |\n| Qwen-2.5-Math-7B-Instruct     | 13.3          | 79.8         | 50.6         | 34.6             | 40.7              | 43.8     |\n| rStar-Math-7B                 | 26.7          | 78.4         | 47.5         | \\-               | 47.1              | \\-       |\n| Eurus-2-7B-PRIME              | 26.7          | 79.2         | 57.8         | 38.6             | 42.1              | 48.9     |\n| Qwen2.5-7B-SimpleRL           | 26.7          | 82.4         | 62.5         | **39.7**         | 43.3              | 50.9     |\n| DeepSeek-R1-Distill-Qwen-1.5B | 28.8          | 82.8         | 62.9         | 26.5             | 43.3              | 48.9     |\n| Still-1.5B                    | 32.5          | 84.4         | 66.7         | 29.0             | 45.4              | 51.6     |\n| **DeepScaleR-1.5B-Preview**   | **43.1**      | **87.8**     | **73.6**     | 30.2             | **50.0**          | **57.0** |\n| O1-Preview                    | 40.0          | 81.4         | \\-           | \\-               | \\-                | \\-       |\n\nWe compare DeepScaleR with the base DeepSeek model we use, as well as recent academic works exploring RL for reasoning tasks. DeepScaleR significantly outperforms the base model across all benchmarks, achieving a 14.4% absolute gain on AIME2024 and an 8.1% overall improvement. Additionally, DeepScaleR surpasses recent academic works such as rSTAR, Prime, and SimpleRL, which are finetuned from 7B models. DeepScaleR achieves O1-preview-level performance with only 1.5B parameters—a remarkable efficiency gain.\n\n![image.png](/assets/library/deepscaler/afbe7f8e-04db-4350-ab39-352c023a6218)\n\n## References\n\n[Article](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2)\n\n[GitHub](https://github.com/agentica-project/deepscaler)\n\n[Hugging Face](https://huggingface.co/agentica-org/DeepScaleR-1.5B-Preview)\n\nWrite Preview \n\n\\# DeepScaleR 🚀 Democratizing Reinforcement Learning for LLMs 🌟 DeepScaleR-1.5B-Preview is a language model fine-tuned from DeepSeek-R1-Distilled-Qwen-1.5B using distributed reinforcement learning (RL) to scale up to long context lengths. The model achieves 43.1% Pass@1 accuracy on AIME 2024, representing a 15% improvement over the base model (28.8%) and surpassing OpenAI's O1-Preview performance with just 1.5B parameters. | Model | AIME 2024 | MATH 500 | AMC 2023 | Minerva Math | Olympiad Bench | Avg. | | --- | --- | --- | --- | --- | --- | --- | | \\*\\*DeepScaleR-1.5B-Preview\\*\\* | \\*\\*43.1\\*\\* | \\*\\*87.8\\*\\* | \\*\\*73.6\\*\\* | \\*\\*30.2\\*\\* | \\*\\*50.0\\*\\* | \\*\\*57.0\\*\\* | | DeepSeek-R1-Distill-Qwen-1.5B | 28.8 | 82.8 | 62.9 | 26.5 | 43.3 | 48.9 | | O1-Preview | 40.0 | 81.4 | - | - | - | - | !\\[image.png\\](/assets/library/deepscaler/c8dcb4f4-481a-4fea-89a9-168cdd1f48fe) ### Data Our training dataset consists of approximately 40,000 unique problem-answer pairs compiled from: - AIME problems (1984-2023) - AMC problems (prior to 2023) - Omni-MATH dataset - Still dataset ### Evaluation We evaluate our model on competition-level mathematics benchmarks, including AIME 2024, AMC 2023, MATH-500, Minerva Math, and OlympiadBench. Below, Pass@1 accuracy is reported, averaged over 16 samples for each problem. | \\*\\*Model\\*\\* | \\*\\*AIME 2024\\*\\* | \\*\\*MATH 500\\*\\* | \\*\\*AMC 2023\\*\\* | \\*\\*Minerva Math\\*\\* | \\*\\*OlympiadBench\\*\\* | \\*\\*Avg.\\*\\* | | --- | --- | --- | --- | --- | --- | --- | | Qwen-2.5-Math-7B-Instruct | 13.3 | 79.8 | 50.6 | 34.6 | 40.7 | 43.8 | | rStar-Math-7B | 26.7 | 78.4 | 47.5 | - | 47.1 | - | | Eurus-2-7B-PRIME | 26.7 | 79.2 | 57.8 | 38.6 | 42.1 | 48.9 | | Qwen2.5-7B-SimpleRL | 26.7 | 82.4 | 62.5 | \\*\\*39.7\\*\\* | 43.3 | 50.9 | | DeepSeek-R1-Distill-Qwen-1.5B | 28.8 | 82.8 | 62.9 | 26.5 | 43.3 | 48.9 | | Still-1.5B | 32.5 | 84.4 | 66.7 | 29.0 | 45.4 | 51.6 | | \\*\\*DeepScaleR-1.5B-Preview\\*\\* | \\*\\*43.1\\*\\* | \\*\\*87.8\\*\\* | \\*\\*73.6\\*\\* | 30.2 | \\*\\*50.0\\*\\* | \\*\\*57.0\\*\\* | | O1-Preview | 40.0 | 81.4 | - | - | - | - | We compare DeepScaleR with the base DeepSeek model we use, as well as recent academic works exploring RL for reasoning tasks. DeepScaleR significantly outperforms the base model across all benchmarks, achieving a 14.4% absolute gain on AIME2024 and an 8.1% overall improvement. Additionally, DeepScaleR surpasses recent academic works such as rSTAR, Prime, and SimpleRL, which are finetuned from 7B models. DeepScaleR achieves O1-preview-level performance with only 1.5B parameters—a remarkable efficiency gain. !\\[image.png\\](/assets/library/deepscaler/afbe7f8e-04db-4350-ab39-352c023a6218) ## References \\[Article\\](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2) \\[GitHub\\](https://github.com/agentica-project/deepscaler) \\[Hugging Face\\](https://huggingface.co/agentica-org/DeepScaleR-1.5B-Preview) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepscaler:latest",
        "size": "deepscaler:latest",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "deepscaler:1.5b",
        "size": "deepscaler:1.5b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "deepscaler:1.5b-preview-q4_K_M",
        "size": "deepscaler:1.5b-preview-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "deepscaler:1.5b-preview-q8_0",
        "size": "deepscaler:1.5b-preview-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "deepscaler:1.5b-preview-fp16",
        "size": "deepscaler:1.5b-preview-fp16",
        "updated": "Text input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "dolphin-phi",
    "link": "https://ollama.com/library/dolphin-phi",
    "description": "2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research.",
    "pullCount": "277.9K",
    "updated": "1 year ago",
    "size": [
      "2.7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/c65aad4e-7a58-4645-97f2-5e8ca158275f)\n\nDolphin Phi 2.6 is an uncensored model based on the 2.7B [Phi](https://ollama.ai/library/phi) model by Microsoft Research, using similar datasets as other versions of this model such as [Dolphin Mixtral](https://ollama.ai/library/dolphin-mixtral).\n\nIt was created by [Eric Hartford](https://erichartford.com/) and Cognitive Computations.\n\n## References\n\n[HuggingFace](https://huggingface.co/cognitivecomputations/dolphin-2%5F6-phi-2)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/c65aad4e-7a58-4645-97f2-5e8ca158275f\" width=\"280\" /> Dolphin Phi 2.6 is an uncensored model based on the 2.7B \\[Phi\\](https://ollama.ai/library/phi) model by Microsoft Research, using similar datasets as other versions of this model such as \\[Dolphin Mixtral\\](https://ollama.ai/library/dolphin-mixtral). It was created by \\[Eric Hartford\\](https://erichartford.com/) and Cognitive Computations. ## References \\[HuggingFace\\](https://huggingface.co/cognitivecomputations/dolphin-2\\_6-phi-2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dolphin-phi:latest",
        "size": "dolphin-phi:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b",
        "size": "dolphin-phi:2.7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6",
        "size": "dolphin-phi:2.7b-v2.6",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q2_K",
        "size": "dolphin-phi:2.7b-v2.6-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q3_K_S",
        "size": "dolphin-phi:2.7b-v2.6-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q3_K_M",
        "size": "dolphin-phi:2.7b-v2.6-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q3_K_L",
        "size": "dolphin-phi:2.7b-v2.6-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q4_0",
        "size": "dolphin-phi:2.7b-v2.6-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q4_K_S",
        "size": "dolphin-phi:2.7b-v2.6-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q4_K_M",
        "size": "dolphin-phi:2.7b-v2.6-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q5_0",
        "size": "dolphin-phi:2.7b-v2.6-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q5_K_S",
        "size": "dolphin-phi:2.7b-v2.6-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q5_K_M",
        "size": "dolphin-phi:2.7b-v2.6-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q6_K",
        "size": "dolphin-phi:2.7b-v2.6-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphin-phi:2.7b-v2.6-q8_0",
        "size": "dolphin-phi:2.7b-v2.6-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "granite3.2-vision",
    "link": "https://ollama.com/library/granite3.2-vision",
    "description": "A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.",
    "pullCount": "277.8K",
    "updated": "6 months ago",
    "size": [
      "2b"
    ],
    "capabilities": "visiontools",
    "readme": "## Readme\n\n> Note: this model requires [Ollama 0.5.13](https://github.com/ollama/ollama/releases/tag/v0.5.13).\n\nA compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. The model was trained on a meticulously curated instruction-following dataset, comprising diverse public datasets and synthetic datasets tailored to support a wide range of document understanding and general image tasks. It was trained by fine-tuning a Granite large language model with both image and text modalities.\n\n## References\n\n[Hugging Face](https://huggingface.co/ibm-granite/granite-vision-3.2-2b)\n\nWrite Preview \n\n\\> Note: this model requires \\[Ollama 0.5.13\\](https://github.com/ollama/ollama/releases/tag/v0.5.13). A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. The model was trained on a meticulously curated instruction-following dataset, comprising diverse public datasets and synthetic datasets tailored to support a wide range of document understanding and general image tasks. It was trained by fine-tuning a Granite large language model with both image and text modalities. ## References \\[Hugging Face\\](https://huggingface.co/ibm-granite/granite-vision-3.2-2b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3.2-vision:latest",
        "size": "granite3.2-vision:latest",
        "updated": "Text, Image input • \n                    6 months ago"
      },
      {
        "name": "granite3.2-vision:2b",
        "size": "granite3.2-vision:2b",
        "updated": "Text, Image input • \n                    6 months ago"
      },
      {
        "name": "granite3.2-vision:2b-q4_K_M",
        "size": "granite3.2-vision:2b-q4_K_M",
        "updated": "Text, Image input • \n                    6 months ago"
      },
      {
        "name": "granite3.2-vision:2b-q8_0",
        "size": "granite3.2-vision:2b-q8_0",
        "updated": "Text, Image input • \n                    6 months ago"
      },
      {
        "name": "granite3.2-vision:2b-fp16",
        "size": "granite3.2-vision:2b-fp16",
        "updated": "Text, Image input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "deepcoder",
    "link": "https://ollama.com/library/deepcoder",
    "description": "DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.",
    "pullCount": "275.5K",
    "updated": "5 months ago",
    "size": [
      "1.5b",
      "14b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/deepcoder/7e57e9ba-4b82-4a7a-82f6-3ce9d4cba1c8)\n\nThrough a joint collaboration between the Agentica team and Together AI, DeepCoder-14B-Preview is a code reasoning model finetuned from Deepseek-R1-Distilled-Qwen-14B via distributed RL. It achieves an impressive 60.6% Pass@1 accuracy on LiveCodeBench (+8% improvement), matching the performance of `o3-mini-2025-01-031` (Low) and `o1-2024-12-17` with just 14B parameters\n\n## Evaluation\n\n| **Model**                        | LCB (v5)(8/1/24-2/1/25) | Codeforces Rating | Codeforces Percentile | HumanEval+ |\n| -------------------------------- | ----------------------- | ----------------- | --------------------- | ---------- |\n| **DeepCoder-14B-Preview**        | **_60.6_**              | **_1936_**        | **_95.3_**            | **_92.6_** |\n| **DeepSeek-R1-Distill-Qwen-14B** | 53.0                    | 1791              | 92.7                  | 92.0       |\n| **O1-2024-12-17 (Low)**          | 59.5                    | **1991**          | **96.1**              | 90.8       |\n| **O3-Mini-2025-1-31 (Low)**      | **60.9**                | 1918              | 94.9                  | 92.6       |\n| **O1-Preview**                   | 42.7                    | 1658              | 88.5                  | 89         |\n| **Deepseek-R1**                  | 62.8                    | 1948              | 95.4                  | 92.6       |\n| **Llama-4-Behemoth**             | 49.4                    | \\-                | \\-                    | \\-         |\n\n## References\n\n[Blog post](https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51)\n\nWrite Preview \n\n<img src=\"/assets/library/deepcoder/7e57e9ba-4b82-4a7a-82f6-3ce9d4cba1c8\" width=\"100\" /> Through a joint collaboration between the Agentica team and Together AI, DeepCoder-14B-Preview is a code reasoning model finetuned from Deepseek-R1-Distilled-Qwen-14B via distributed RL. It achieves an impressive 60.6% Pass@1 accuracy on LiveCodeBench (+8% improvement), matching the performance of \\`o3-mini-2025-01-031\\` (Low) and \\`o1-2024-12-17\\` with just 14B parameters ## Evaluation | \\*\\*Model\\*\\* | LCB (v5)(8/1/24-2/1/25) | Codeforces Rating | Codeforces Percentile | HumanEval+ | | --- | --- | --- | --- | --- | | \\*\\*DeepCoder-14B-Preview\\*\\* | \\*\\*\\*60.6\\*\\*\\* | \\*\\*\\*1936\\*\\*\\* | \\*\\*\\*95.3\\*\\*\\* | \\*\\*\\*92.6\\*\\*\\* | | \\*\\*DeepSeek-R1-Distill-Qwen-14B\\*\\* | 53.0 | 1791 | 92.7 | 92.0 | | \\*\\*O1-2024-12-17 (Low)\\*\\* | 59.5 | \\*\\*1991\\*\\* | \\*\\*96.1\\*\\* | 90.8 | | \\*\\*O3-Mini-2025-1-31 (Low)\\*\\* | \\*\\*60.9\\*\\* | 1918 | 94.9 | 92.6 | | \\*\\*O1-Preview\\*\\* | 42.7 | 1658 | 88.5 | 89 | | \\*\\*Deepseek-R1\\*\\* | 62.8 | 1948 | 95.4 | 92.6 | | \\*\\*Llama-4-Behemoth\\*\\* | 49.4 | - | - | - | ## References \\[Blog post\\](https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepcoder:latest",
        "size": "deepcoder:latest",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:1.5b",
        "size": "deepcoder:1.5b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:14b",
        "size": "deepcoder:14b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:1.5b-preview-q4_K_M",
        "size": "deepcoder:1.5b-preview-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:1.5b-preview-q8_0",
        "size": "deepcoder:1.5b-preview-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:1.5b-preview-fp16",
        "size": "deepcoder:1.5b-preview-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:14b-preview-q4_K_M",
        "size": "deepcoder:14b-preview-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:14b-preview-q8_0",
        "size": "deepcoder:14b-preview-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "deepcoder:14b-preview-fp16",
        "size": "deepcoder:14b-preview-fp16",
        "updated": "Text input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "mistral-small3.1",
    "link": "https://ollama.com/library/mistral-small3.1",
    "description": "Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.",
    "pullCount": "255.2K",
    "updated": "5 months ago",
    "size": [
      "24b"
    ],
    "capabilities": "visiontools",
    "readme": "## Readme\n\n> Note: this model requires Ollama 0.6.5 or higher. [Download Ollama](https://ollama.com/download)\n\n![](/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e)\n\nBuilding on [Mistral Small 3](https://ollama.com/library/mistral-small), this new model comes with improved text performance, multimodal understanding, and an expanded context window of up to 128k tokens. The model outperforms comparable models like Gemma 3 and GPT-4o Mini, while delivering inference speeds of 150 tokens per second.\n\nMistral Small 3.1 is released under an Apache 2.0 license.\n\n## Key features and capabilities\n\n* Lightweight: Mistral Small 3.1 can run on a single RTX 4090 or a Mac with 32GB RAM. This makes it a great fit for on-device use cases.\n* Fast-response conversational assistance: Ideal for virtual assistants and other applications where quick, accurate responses are essential.\n* Low-latency function calling: Capable of rapid function execution within automated or agentic workflows\n* Fine-tuning for specialized domains: Mistral Small 3.1 can be fine-tuned to specialize in specific domains, creating accurate subject matter experts. This is particularly useful in fields like legal advice, medical diagnostics, and technical support.\n* Foundation for advanced reasoning: We continue to be impressed by how the community builds on top of open Mistral models. Just in the last few weeks, we have seen several excellent reasoning models built on Mistral Small 3, such as the DeepHermes 24B by Nous Research. To that end, we are releasing both base and instruct checkpoints for Mistral Small 3.1 to enable further downstream customization of the model.\n\n## References\n\n[Blog post](https://mistral.ai/news/mistral-small-3-1)\n\nWrite Preview \n\n\\> Note: this model requires Ollama 0.6.5 or higher. \\[Download Ollama\\](https://ollama.com/download) <img src=\"/assets/library/mistral-small3.1/88f81c26-7028-4f08-b906-92b873d5536e\" width=\"120\" /> Building on \\[Mistral Small 3\\](https://ollama.com/library/mistral-small), this new model comes with improved text performance, multimodal understanding, and an expanded context window of up to 128k tokens. The model outperforms comparable models like Gemma 3 and GPT-4o Mini, while delivering inference speeds of 150 tokens per second. Mistral Small 3.1 is released under an Apache 2.0 license. ## Key features and capabilities \\* Lightweight: Mistral Small 3.1 can run on a single RTX 4090 or a Mac with 32GB RAM. This makes it a great fit for on-device use cases. \\* Fast-response conversational assistance: Ideal for virtual assistants and other applications where quick, accurate responses are essential. \\* Low-latency function calling: Capable of rapid function execution within automated or agentic workflows \\* Fine-tuning for specialized domains: Mistral Small 3.1 can be fine-tuned to specialize in specific domains, creating accurate subject matter experts. This is particularly useful in fields like legal advice, medical diagnostics, and technical support. \\* Foundation for advanced reasoning: We continue to be impressed by how the community builds on top of open Mistral models. Just in the last few weeks, we have seen several excellent reasoning models built on Mistral Small 3, such as the DeepHermes 24B by Nous Research. To that end, we are releasing both base and instruct checkpoints for Mistral Small 3.1 to enable further downstream customization of the model. ## References \\[Blog post\\](https://mistral.ai/news/mistral-small-3-1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral-small3.1:latest",
        "size": "mistral-small3.1:latest",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "mistral-small3.1:24b",
        "size": "mistral-small3.1:24b",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "mistral-small3.1:24b-instruct-2503-q4_K_M",
        "size": "mistral-small3.1:24b-instruct-2503-q4_K_M",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "mistral-small3.1:24b-instruct-2503-q8_0",
        "size": "mistral-small3.1:24b-instruct-2503-q8_0",
        "updated": "Text, Image input • \n                    5 months ago"
      },
      {
        "name": "mistral-small3.1:24b-instruct-2503-fp16",
        "size": "mistral-small3.1:24b-instruct-2503-fp16",
        "updated": "Text, Image input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "mistral-large",
    "link": "https://ollama.com/library/mistral-large",
    "description": "Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages.",
    "pullCount": "254.5K",
    "updated": "9 months ago",
    "size": [
      "123b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/mistral-large/1b9ab956-d5ea-4927-a54a-3f969021d3db)\n\nMistral-Large-Instruct-2411 is an advanced dense Large Language Model (LLM) of 123B parameters with state-of-the-art reasoning, knowledge and coding capabilities.\n\n### Key features\n\n* Multi-lingual by design: Dozens of languages supported, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch and Polish.\n* Proficient in coding: Trained on 80+ coding languages such as Python, Java, C, C++, JavacScript, and Bash. Also trained on more specific languages such as Swift and Fortran.\n* Agentic-centric: Best-in-class agentic capabilities with native function calling and JSON outputting.\n* Advanced Reasoning: State-of-the-art mathematical and reasoning capabilities.\n* Mistral Research License: Allows usage and modification for research and non-commercial usages.\n* Large Context: A large 128k context window.\n\n## References\n\n[Blog post](https://mistral.ai/news/mistral-large-2407/)\n\n[Hugging Face](https://huggingface.co/mistralai/Mistral-Large-Instruct-2411)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/mistral-large/1b9ab956-d5ea-4927-a54a-3f969021d3db\" width=\"320\" /> Mistral-Large-Instruct-2411 is an advanced dense Large Language Model (LLM) of 123B parameters with state-of-the-art reasoning, knowledge and coding capabilities. ### Key features \\* Multi-lingual by design: Dozens of languages supported, including English, French, German, Spanish, Italian, Chinese, Japanese, Korean, Portuguese, Dutch and Polish. \\* Proficient in coding: Trained on 80+ coding languages such as Python, Java, C, C++, JavacScript, and Bash. Also trained on more specific languages such as Swift and Fortran. \\* Agentic-centric: Best-in-class agentic capabilities with native function calling and JSON outputting. \\* Advanced Reasoning: State-of-the-art mathematical and reasoning capabilities. \\* Mistral Research License: Allows usage and modification for research and non-commercial usages. \\* Large Context: A large 128k context window. ## References \\[Blog post\\](https://mistral.ai/news/mistral-large-2407/) \\[Hugging Face\\](https://huggingface.co/mistralai/Mistral-Large-Instruct-2411) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral-large:latest",
        "size": "mistral-large:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b",
        "size": "mistral-large:123b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q2_K",
        "size": "mistral-large:123b-instruct-2407-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q3_K_S",
        "size": "mistral-large:123b-instruct-2407-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q3_K_M",
        "size": "mistral-large:123b-instruct-2407-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q3_K_L",
        "size": "mistral-large:123b-instruct-2407-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q4_0",
        "size": "mistral-large:123b-instruct-2407-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q4_1",
        "size": "mistral-large:123b-instruct-2407-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q4_K_S",
        "size": "mistral-large:123b-instruct-2407-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q4_K_M",
        "size": "mistral-large:123b-instruct-2407-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q5_0",
        "size": "mistral-large:123b-instruct-2407-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q5_1",
        "size": "mistral-large:123b-instruct-2407-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q5_K_S",
        "size": "mistral-large:123b-instruct-2407-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q5_K_M",
        "size": "mistral-large:123b-instruct-2407-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q6_K",
        "size": "mistral-large:123b-instruct-2407-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-q8_0",
        "size": "mistral-large:123b-instruct-2407-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2407-fp16",
        "size": "mistral-large:123b-instruct-2407-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q2_K",
        "size": "mistral-large:123b-instruct-2411-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q3_K_S",
        "size": "mistral-large:123b-instruct-2411-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q3_K_M",
        "size": "mistral-large:123b-instruct-2411-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q3_K_L",
        "size": "mistral-large:123b-instruct-2411-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q4_0",
        "size": "mistral-large:123b-instruct-2411-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q4_1",
        "size": "mistral-large:123b-instruct-2411-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q4_K_S",
        "size": "mistral-large:123b-instruct-2411-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q4_K_M",
        "size": "mistral-large:123b-instruct-2411-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q5_0",
        "size": "mistral-large:123b-instruct-2411-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q5_1",
        "size": "mistral-large:123b-instruct-2411-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q5_K_S",
        "size": "mistral-large:123b-instruct-2411-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q5_K_M",
        "size": "mistral-large:123b-instruct-2411-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q6_K",
        "size": "mistral-large:123b-instruct-2411-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-q8_0",
        "size": "mistral-large:123b-instruct-2411-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "mistral-large:123b-instruct-2411-fp16",
        "size": "mistral-large:123b-instruct-2411-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "mistral-small3.2",
    "link": "https://ollama.com/library/mistral-small3.2",
    "description": "An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.",
    "pullCount": "250.5K",
    "updated": "2 months ago",
    "size": [
      "24b"
    ],
    "capabilities": "visiontools",
    "readme": "## Readme\n\n![](/assets/library/mistral-small3.2/cec4138e-e20c-4d5b-910f-56f8647dbda1)\n\nMistral-Small-3.2-24B-Instruct-2506 is a minor update of Mistral-Small-3.1-24B-Instruct-2503.\n\nSmall-3.2 improves in the following categories:\n\n* **Instruction following**: Small-3.2 is better at following precise instructions\n* **Repetition errors**: Small-3.2 produces less infinite generations or repetitive answers\n* **Function calling**: Small-3.2’s function calling template is more robust (see here and examples)\n\nIn all other categories Small-3.2 should match or slightly improve compared to Mistral-Small-3.1-24B-Instruct-2503.\n\n## References\n\n[Hugging Face](https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506)\n\nWrite Preview \n\n<img src=\"/assets/library/mistral-small3.2/cec4138e-e20c-4d5b-910f-56f8647dbda1\" width=\"140\" /> Mistral-Small-3.2-24B-Instruct-2506 is a minor update of Mistral-Small-3.1-24B-Instruct-2503\\. Small-3.2 improves in the following categories: \\* \\*\\*Instruction following\\*\\*: Small-3.2 is better at following precise instructions \\* \\*\\*Repetition errors\\*\\*: Small-3.2 produces less infinite generations or repetitive answers \\* \\*\\*Function calling\\*\\*: Small-3.2's function calling template is more robust (see here and examples) In all other categories Small-3.2 should match or slightly improve compared to Mistral-Small-3.1-24B-Instruct-2503\\. ## References \\[Hugging Face\\](https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral-small3.2:latest",
        "size": "mistral-small3.2:latest",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "mistral-small3.2:24b",
        "size": "mistral-small3.2:24b",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "mistral-small3.2:24b-instruct-2506-q4_K_M",
        "size": "mistral-small3.2:24b-instruct-2506-q4_K_M",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "mistral-small3.2:24b-instruct-2506-q8_0",
        "size": "mistral-small3.2:24b-instruct-2506-q8_0",
        "updated": "Text, Image input • \n                    2 months ago"
      },
      {
        "name": "mistral-small3.2:24b-instruct-2506-fp16",
        "size": "mistral-small3.2:24b-instruct-2506-fp16",
        "updated": "Text, Image input • \n                    2 months ago"
      }
    ]
  },
  {
    "name": "moondream",
    "link": "https://ollama.com/library/moondream",
    "description": "moondream2 is a small vision language model designed to run efficiently on edge devices.",
    "pullCount": "248K",
    "updated": "1 year ago",
    "size": [
      "1.8b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n# 🌔 moondream 2\n\n> Moondream 2 requires Ollama 0.1.33 or later\n\n_“a tiny vision language model that kicks ass and runs anywhere”_\n\n### Limitations\n\n* The model may generate inaccurate statements, and struggle to understand intricate or nuanced instructions.\n* The model may not be free from societal biases. Users should be aware of this and exercise caution and critical thinking when using the model.\n* The model may generate offensive, inappropriate, or hurtful content if it is prompted to do so.\n\n## References\n\n[GitHub](https://github.com/vikhyat/moondream)\n\n[Hugging Face](https://huggingface.co/vikhyatk/moondream2)\n\nWrite Preview \n\n\\# 🌔 moondream 2 > Moondream 2 requires Ollama 0.1.33 or later \\_\"a tiny vision language model that kicks ass and runs anywhere\"\\_ ### Limitations \\* The model may generate inaccurate statements, and struggle to understand intricate or nuanced instructions. \\* The model may not be free from societal biases. Users should be aware of this and exercise caution and critical thinking when using the model. \\* The model may generate offensive, inappropriate, or hurtful content if it is prompted to do so. ## References \\[GitHub\\](https://github.com/vikhyat/moondream) \\[Hugging Face\\](https://huggingface.co/vikhyatk/moondream2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "moondream:latest",
        "size": "moondream:latest",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:v2",
        "size": "moondream:v2",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b",
        "size": "moondream:1.8b",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q2_K",
        "size": "moondream:1.8b-v2-q2_K",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q3_K_S",
        "size": "moondream:1.8b-v2-q3_K_S",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q3_K_M",
        "size": "moondream:1.8b-v2-q3_K_M",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q3_K_L",
        "size": "moondream:1.8b-v2-q3_K_L",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q4_0",
        "size": "moondream:1.8b-v2-q4_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q4_1",
        "size": "moondream:1.8b-v2-q4_1",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q4_K_S",
        "size": "moondream:1.8b-v2-q4_K_S",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q4_K_M",
        "size": "moondream:1.8b-v2-q4_K_M",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q5_0",
        "size": "moondream:1.8b-v2-q5_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q5_1",
        "size": "moondream:1.8b-v2-q5_1",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q5_K_S",
        "size": "moondream:1.8b-v2-q5_K_S",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q5_K_M",
        "size": "moondream:1.8b-v2-q5_K_M",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q6_K",
        "size": "moondream:1.8b-v2-q6_K",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-q8_0",
        "size": "moondream:1.8b-v2-q8_0",
        "updated": "Text, Image input • \n                    1 year ago"
      },
      {
        "name": "moondream:1.8b-v2-fp16",
        "size": "moondream:1.8b-v2-fp16",
        "updated": "Text, Image input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "wizard-vicuna-uncensored",
    "link": "https://ollama.com/library/wizard-vicuna-uncensored",
    "description": "Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford.",
    "pullCount": "239.6K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "30b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nWizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford. The models were trained against LLaMA-7B with a subset of the dataset, responses that contained alignment / moralizing were removed.\n\n## Get started with Wizard Vicuna Uncensored\n\nThe model used in the example below is the Wizard Vicuna Uncensored model, with 7b parameters, which is a general-use model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"wizard-vicuna-uncensored\",\n  \"prompt\":\"Who made Rose promise that she would never let go?\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run wizard-vicuna-uncensored`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull wizard-vicuna-uncensored`\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 13b models generally require at least 16GB of RAM\n* 30b models generally require at least 32GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n| **Aliases**          |\n| -------------------- |\n| latest, 7b, 7b-q4\\_0 |\n| 13b, 13b-q4\\_0       |\n| 30b, 30b-q4\\_0       |\n\n## Model source\n\n**Wizard Vicuna Uncensored source on Ollama**\n\n7b parameters original source:[Eric Hartford](https://huggingface.co/ehartford/Wizard-Vicuna-7B-Uncensored)\n\n13b parameters original source:[Eric Hartford](https://huggingface.co/ehartford/Wizard-Vicuna-13B-Uncensored)\n\n30b parameters original source:[Eric Hartford](https://huggingface.co/ehartford/Wizard-Vicuna-30B-Uncensored)\n\nWrite Preview \n\nWizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford. The models were trained against LLaMA-7B with a subset of the dataset, responses that contained alignment / moralizing were removed. ## Get started with Wizard Vicuna Uncensored The model used in the example below is the Wizard Vicuna Uncensored model, with 7b parameters, which is a general-use model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"wizard-vicuna-uncensored\", \"prompt\":\"Who made Rose promise that she would never let go?\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run wizard-vicuna-uncensored\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull wizard-vicuna-uncensored\\` ## Memory requirements - 7b models generally require at least 8GB of RAM - 13b models generally require at least 16GB of RAM - 30b models generally require at least 32GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. | \\*\\*Aliases\\*\\* | | --- | | latest, 7b, 7b-q4\\_0 | | 13b, 13b-q4\\_0 | | 30b, 30b-q4\\_0 | ## Model source \\*\\*Wizard Vicuna Uncensored source on Ollama\\*\\* 7b parameters original source: \\[Eric Hartford\\](https://huggingface.co/ehartford/Wizard-Vicuna-7B-Uncensored) 13b parameters original source: \\[Eric Hartford\\](https://huggingface.co/ehartford/Wizard-Vicuna-13B-Uncensored) 30b parameters original source: \\[Eric Hartford\\](https://huggingface.co/ehartford/Wizard-Vicuna-30B-Uncensored) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizard-vicuna-uncensored:latest",
        "size": "wizard-vicuna-uncensored:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b",
        "size": "wizard-vicuna-uncensored:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b",
        "size": "wizard-vicuna-uncensored:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b",
        "size": "wizard-vicuna-uncensored:30b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q2_K",
        "size": "wizard-vicuna-uncensored:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q3_K_S",
        "size": "wizard-vicuna-uncensored:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q3_K_M",
        "size": "wizard-vicuna-uncensored:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q3_K_L",
        "size": "wizard-vicuna-uncensored:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q4_0",
        "size": "wizard-vicuna-uncensored:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q4_1",
        "size": "wizard-vicuna-uncensored:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q4_K_S",
        "size": "wizard-vicuna-uncensored:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q4_K_M",
        "size": "wizard-vicuna-uncensored:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q5_0",
        "size": "wizard-vicuna-uncensored:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q5_1",
        "size": "wizard-vicuna-uncensored:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q5_K_S",
        "size": "wizard-vicuna-uncensored:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q5_K_M",
        "size": "wizard-vicuna-uncensored:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q6_K",
        "size": "wizard-vicuna-uncensored:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-q8_0",
        "size": "wizard-vicuna-uncensored:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:7b-fp16",
        "size": "wizard-vicuna-uncensored:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q2_K",
        "size": "wizard-vicuna-uncensored:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q3_K_S",
        "size": "wizard-vicuna-uncensored:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q3_K_M",
        "size": "wizard-vicuna-uncensored:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q3_K_L",
        "size": "wizard-vicuna-uncensored:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q4_0",
        "size": "wizard-vicuna-uncensored:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q4_1",
        "size": "wizard-vicuna-uncensored:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q4_K_S",
        "size": "wizard-vicuna-uncensored:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q4_K_M",
        "size": "wizard-vicuna-uncensored:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q5_0",
        "size": "wizard-vicuna-uncensored:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q5_1",
        "size": "wizard-vicuna-uncensored:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q5_K_S",
        "size": "wizard-vicuna-uncensored:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q5_K_M",
        "size": "wizard-vicuna-uncensored:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q6_K",
        "size": "wizard-vicuna-uncensored:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-q8_0",
        "size": "wizard-vicuna-uncensored:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:13b-fp16",
        "size": "wizard-vicuna-uncensored:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q2_K",
        "size": "wizard-vicuna-uncensored:30b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q3_K_S",
        "size": "wizard-vicuna-uncensored:30b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q3_K_M",
        "size": "wizard-vicuna-uncensored:30b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q3_K_L",
        "size": "wizard-vicuna-uncensored:30b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q4_0",
        "size": "wizard-vicuna-uncensored:30b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q4_1",
        "size": "wizard-vicuna-uncensored:30b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q4_K_S",
        "size": "wizard-vicuna-uncensored:30b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q4_K_M",
        "size": "wizard-vicuna-uncensored:30b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q5_0",
        "size": "wizard-vicuna-uncensored:30b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q5_1",
        "size": "wizard-vicuna-uncensored:30b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q5_K_S",
        "size": "wizard-vicuna-uncensored:30b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q5_K_M",
        "size": "wizard-vicuna-uncensored:30b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q6_K",
        "size": "wizard-vicuna-uncensored:30b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-q8_0",
        "size": "wizard-vicuna-uncensored:30b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna-uncensored:30b-fp16",
        "size": "wizard-vicuna-uncensored:30b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "granite-code",
    "link": "https://ollama.com/library/granite-code",
    "description": "A family of open foundation models by IBM for Code Intelligence",
    "pullCount": "237.6K",
    "updated": "1 year ago",
    "size": [
      "3b",
      "8b",
      "20b",
      "34b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![image.png](https://ollama.com/assets/library/granite-code/e28e37cc-af1b-47d7-bd85-6154b0cf26be)\n\nGranite Code is a family of decoder-only code model designed for code generative tasks (e.g. code generation, code explanation, code fixing, etc.).\n\n## Parameter Sizes\n\n* 34B Parameters `ollama run granite-code:34b`\n* 20B Parameters `ollama run granite-code:20b`\n* 8B Parameters (with 128K context window) `ollama run granite-code:8b`\n* 3B Parameters (with 128K context window) `ollama run granite-code:3b`\n\n## Resources\n\n* [Hugging Face](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330)\n* [Paper](https://arxiv.org/abs/2405.04324)\n\nWrite Preview \n\n!\\[image.png\\](https://ollama.com/assets/library/granite-code/e28e37cc-af1b-47d7-bd85-6154b0cf26be) Granite Code is a family of decoder-only code model designed for code generative tasks (e.g. code generation, code explanation, code fixing, etc.). ## Parameter Sizes \\* 34B Parameters \\`ollama run granite-code:34b\\` \\* 20B Parameters \\`ollama run granite-code:20b\\` \\* 8B Parameters (with 128K context window) \\`ollama run granite-code:8b\\` \\* 3B Parameters (with 128K context window) \\`ollama run granite-code:3b\\` ## Resources \\* \\[Hugging Face\\](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330) \\* \\[Paper\\](https://arxiv.org/abs/2405.04324) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite-code:latest",
        "size": "granite-code:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b",
        "size": "granite-code:3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b",
        "size": "granite-code:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b",
        "size": "granite-code:20b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b",
        "size": "granite-code:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base",
        "size": "granite-code:3b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q2_K",
        "size": "granite-code:3b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q3_K_S",
        "size": "granite-code:3b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q3_K_M",
        "size": "granite-code:3b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q3_K_L",
        "size": "granite-code:3b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q4_0",
        "size": "granite-code:3b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q4_1",
        "size": "granite-code:3b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q4_K_S",
        "size": "granite-code:3b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q4_K_M",
        "size": "granite-code:3b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q5_0",
        "size": "granite-code:3b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q5_1",
        "size": "granite-code:3b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q5_K_S",
        "size": "granite-code:3b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q5_K_M",
        "size": "granite-code:3b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q6_K",
        "size": "granite-code:3b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-q8_0",
        "size": "granite-code:3b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-base-fp16",
        "size": "granite-code:3b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct",
        "size": "granite-code:3b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q2_K",
        "size": "granite-code:3b-instruct-128k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q2_K",
        "size": "granite-code:3b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q3_K_S",
        "size": "granite-code:3b-instruct-128k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q3_K_S",
        "size": "granite-code:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q3_K_M",
        "size": "granite-code:3b-instruct-128k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q3_K_M",
        "size": "granite-code:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q3_K_L",
        "size": "granite-code:3b-instruct-128k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q3_K_L",
        "size": "granite-code:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q4_0",
        "size": "granite-code:3b-instruct-128k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q4_0",
        "size": "granite-code:3b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q4_1",
        "size": "granite-code:3b-instruct-128k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q4_1",
        "size": "granite-code:3b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q4_K_S",
        "size": "granite-code:3b-instruct-128k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q4_K_S",
        "size": "granite-code:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q4_K_M",
        "size": "granite-code:3b-instruct-128k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q4_K_M",
        "size": "granite-code:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q5_0",
        "size": "granite-code:3b-instruct-128k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q5_0",
        "size": "granite-code:3b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q5_1",
        "size": "granite-code:3b-instruct-128k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q5_1",
        "size": "granite-code:3b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q5_K_S",
        "size": "granite-code:3b-instruct-128k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q5_K_S",
        "size": "granite-code:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q5_K_M",
        "size": "granite-code:3b-instruct-128k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q5_K_M",
        "size": "granite-code:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q6_K",
        "size": "granite-code:3b-instruct-128k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q6_K",
        "size": "granite-code:3b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-q8_0",
        "size": "granite-code:3b-instruct-128k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-q8_0",
        "size": "granite-code:3b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-128k-fp16",
        "size": "granite-code:3b-instruct-128k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:3b-instruct-fp16",
        "size": "granite-code:3b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base",
        "size": "granite-code:8b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q2_K",
        "size": "granite-code:8b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q3_K_S",
        "size": "granite-code:8b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q3_K_M",
        "size": "granite-code:8b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q3_K_L",
        "size": "granite-code:8b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q4_0",
        "size": "granite-code:8b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q4_1",
        "size": "granite-code:8b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q4_K_S",
        "size": "granite-code:8b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q4_K_M",
        "size": "granite-code:8b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q5_0",
        "size": "granite-code:8b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q5_1",
        "size": "granite-code:8b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q5_K_S",
        "size": "granite-code:8b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q5_K_M",
        "size": "granite-code:8b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q6_K",
        "size": "granite-code:8b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-q8_0",
        "size": "granite-code:8b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-base-fp16",
        "size": "granite-code:8b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct",
        "size": "granite-code:8b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q2_K",
        "size": "granite-code:8b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q3_K_S",
        "size": "granite-code:8b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q3_K_M",
        "size": "granite-code:8b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q3_K_L",
        "size": "granite-code:8b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-128k-q4_0",
        "size": "granite-code:8b-instruct-128k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q4_0",
        "size": "granite-code:8b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-128k-q4_1",
        "size": "granite-code:8b-instruct-128k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q4_1",
        "size": "granite-code:8b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q4_K_S",
        "size": "granite-code:8b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q4_K_M",
        "size": "granite-code:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q5_0",
        "size": "granite-code:8b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q5_1",
        "size": "granite-code:8b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q5_K_S",
        "size": "granite-code:8b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q5_K_M",
        "size": "granite-code:8b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q6_K",
        "size": "granite-code:8b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-q8_0",
        "size": "granite-code:8b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:8b-instruct-fp16",
        "size": "granite-code:8b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base",
        "size": "granite-code:20b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q2_K",
        "size": "granite-code:20b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q3_K_S",
        "size": "granite-code:20b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q3_K_M",
        "size": "granite-code:20b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q3_K_L",
        "size": "granite-code:20b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q4_0",
        "size": "granite-code:20b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q4_1",
        "size": "granite-code:20b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q4_K_S",
        "size": "granite-code:20b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q4_K_M",
        "size": "granite-code:20b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q5_0",
        "size": "granite-code:20b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q5_1",
        "size": "granite-code:20b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q5_K_S",
        "size": "granite-code:20b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q5_K_M",
        "size": "granite-code:20b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q6_K",
        "size": "granite-code:20b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-q8_0",
        "size": "granite-code:20b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-base-fp16",
        "size": "granite-code:20b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct",
        "size": "granite-code:20b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q2_K",
        "size": "granite-code:20b-instruct-8k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q2_K",
        "size": "granite-code:20b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q3_K_S",
        "size": "granite-code:20b-instruct-8k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q3_K_S",
        "size": "granite-code:20b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q3_K_M",
        "size": "granite-code:20b-instruct-8k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q3_K_M",
        "size": "granite-code:20b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q3_K_L",
        "size": "granite-code:20b-instruct-8k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q3_K_L",
        "size": "granite-code:20b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q4_0",
        "size": "granite-code:20b-instruct-8k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q4_0",
        "size": "granite-code:20b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q4_1",
        "size": "granite-code:20b-instruct-8k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q4_1",
        "size": "granite-code:20b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q4_K_S",
        "size": "granite-code:20b-instruct-8k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q4_K_S",
        "size": "granite-code:20b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q4_K_M",
        "size": "granite-code:20b-instruct-8k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q4_K_M",
        "size": "granite-code:20b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q5_0",
        "size": "granite-code:20b-instruct-8k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q5_0",
        "size": "granite-code:20b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q5_1",
        "size": "granite-code:20b-instruct-8k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q5_1",
        "size": "granite-code:20b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q5_K_S",
        "size": "granite-code:20b-instruct-8k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q5_K_S",
        "size": "granite-code:20b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q5_K_M",
        "size": "granite-code:20b-instruct-8k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q5_K_M",
        "size": "granite-code:20b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q6_K",
        "size": "granite-code:20b-instruct-8k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q6_K",
        "size": "granite-code:20b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-q8_0",
        "size": "granite-code:20b-instruct-8k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-q8_0",
        "size": "granite-code:20b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:20b-instruct-8k-fp16",
        "size": "granite-code:20b-instruct-8k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base",
        "size": "granite-code:34b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q2_K",
        "size": "granite-code:34b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q3_K_S",
        "size": "granite-code:34b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q3_K_M",
        "size": "granite-code:34b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q3_K_L",
        "size": "granite-code:34b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q4_0",
        "size": "granite-code:34b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q4_1",
        "size": "granite-code:34b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q4_K_S",
        "size": "granite-code:34b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q4_K_M",
        "size": "granite-code:34b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q5_0",
        "size": "granite-code:34b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q5_1",
        "size": "granite-code:34b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q5_K_S",
        "size": "granite-code:34b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q5_K_M",
        "size": "granite-code:34b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q6_K",
        "size": "granite-code:34b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-base-q8_0",
        "size": "granite-code:34b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct",
        "size": "granite-code:34b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q2_K",
        "size": "granite-code:34b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q3_K_S",
        "size": "granite-code:34b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q3_K_M",
        "size": "granite-code:34b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q3_K_L",
        "size": "granite-code:34b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q4_0",
        "size": "granite-code:34b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q4_1",
        "size": "granite-code:34b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q4_K_S",
        "size": "granite-code:34b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q4_K_M",
        "size": "granite-code:34b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q5_0",
        "size": "granite-code:34b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q5_1",
        "size": "granite-code:34b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q5_K_S",
        "size": "granite-code:34b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q5_K_M",
        "size": "granite-code:34b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q6_K",
        "size": "granite-code:34b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "granite-code:34b-instruct-q8_0",
        "size": "granite-code:34b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "starcoder",
    "link": "https://ollama.com/library/starcoder",
    "description": "StarCoder is a code generation model trained on 80+ programming languages.",
    "pullCount": "220.3K",
    "updated": "1 year ago",
    "size": [
      "1b",
      "3b",
      "7b",
      "15b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/1bf014aa-cde3-4f9d-88df-81773106b1dd)\n\nStarCoder models are trained on GitHub code with over 80+ programming languages.\n\n## Example prompt\n\n```\ndef print_hello_world():\n\n```\n\n## Example response\n\n```\n    print(\"Hello world\")\n\n```\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/1bf014aa-cde3-4f9d-88df-81773106b1dd\" width=\"400\" /> StarCoder models are trained on GitHub code with over 80+ programming languages. ## Example prompt \\`\\`\\` def print\\_hello\\_world(): \\`\\`\\` ## Example response \\`\\`\\` print(\"Hello world\") \\`\\`\\` \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "starcoder:latest",
        "size": "starcoder:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b",
        "size": "starcoder:1b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b",
        "size": "starcoder:3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b",
        "size": "starcoder:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b",
        "size": "starcoder:15b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base",
        "size": "starcoder:1b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q2_K",
        "size": "starcoder:1b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q3_K_S",
        "size": "starcoder:1b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q3_K_M",
        "size": "starcoder:1b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q3_K_L",
        "size": "starcoder:1b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q4_0",
        "size": "starcoder:1b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q4_1",
        "size": "starcoder:1b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q4_K_S",
        "size": "starcoder:1b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q4_K_M",
        "size": "starcoder:1b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q5_0",
        "size": "starcoder:1b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q5_1",
        "size": "starcoder:1b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q5_K_S",
        "size": "starcoder:1b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q5_K_M",
        "size": "starcoder:1b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q6_K",
        "size": "starcoder:1b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-q8_0",
        "size": "starcoder:1b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:1b-base-fp16",
        "size": "starcoder:1b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base",
        "size": "starcoder:3b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q2_K",
        "size": "starcoder:3b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q3_K_S",
        "size": "starcoder:3b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q3_K_M",
        "size": "starcoder:3b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q3_K_L",
        "size": "starcoder:3b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q4_0",
        "size": "starcoder:3b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q4_1",
        "size": "starcoder:3b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q4_K_S",
        "size": "starcoder:3b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q4_K_M",
        "size": "starcoder:3b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q5_0",
        "size": "starcoder:3b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q5_1",
        "size": "starcoder:3b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q5_K_S",
        "size": "starcoder:3b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q5_K_M",
        "size": "starcoder:3b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q6_K",
        "size": "starcoder:3b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-q8_0",
        "size": "starcoder:3b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:3b-base-fp16",
        "size": "starcoder:3b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base",
        "size": "starcoder:7b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q2_K",
        "size": "starcoder:7b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q3_K_S",
        "size": "starcoder:7b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q3_K_M",
        "size": "starcoder:7b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q3_K_L",
        "size": "starcoder:7b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q4_0",
        "size": "starcoder:7b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q4_1",
        "size": "starcoder:7b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q4_K_S",
        "size": "starcoder:7b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q4_K_M",
        "size": "starcoder:7b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q5_0",
        "size": "starcoder:7b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q5_1",
        "size": "starcoder:7b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q5_K_S",
        "size": "starcoder:7b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q5_K_M",
        "size": "starcoder:7b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q6_K",
        "size": "starcoder:7b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-q8_0",
        "size": "starcoder:7b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:7b-base-fp16",
        "size": "starcoder:7b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base",
        "size": "starcoder:15b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q2_K",
        "size": "starcoder:15b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q3_K_S",
        "size": "starcoder:15b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q3_K_M",
        "size": "starcoder:15b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q3_K_L",
        "size": "starcoder:15b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q4_0",
        "size": "starcoder:15b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q4_1",
        "size": "starcoder:15b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q4_K_S",
        "size": "starcoder:15b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q4_K_M",
        "size": "starcoder:15b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q5_0",
        "size": "starcoder:15b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q5_1",
        "size": "starcoder:15b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q5_K_S",
        "size": "starcoder:15b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q5_K_M",
        "size": "starcoder:15b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q6_K",
        "size": "starcoder:15b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-q8_0",
        "size": "starcoder:15b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-base-fp16",
        "size": "starcoder:15b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus",
        "size": "starcoder:15b-plus",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q2_K",
        "size": "starcoder:15b-plus-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q3_K_S",
        "size": "starcoder:15b-plus-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q3_K_M",
        "size": "starcoder:15b-plus-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q3_K_L",
        "size": "starcoder:15b-plus-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q4_0",
        "size": "starcoder:15b-plus-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q4_1",
        "size": "starcoder:15b-plus-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q4_K_S",
        "size": "starcoder:15b-plus-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q4_K_M",
        "size": "starcoder:15b-plus-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q5_0",
        "size": "starcoder:15b-plus-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q5_1",
        "size": "starcoder:15b-plus-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q5_K_S",
        "size": "starcoder:15b-plus-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q5_K_M",
        "size": "starcoder:15b-plus-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q6_K",
        "size": "starcoder:15b-plus-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-q8_0",
        "size": "starcoder:15b-plus-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-plus-fp16",
        "size": "starcoder:15b-plus-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q2_K",
        "size": "starcoder:15b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q3_K_S",
        "size": "starcoder:15b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q3_K_M",
        "size": "starcoder:15b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q3_K_L",
        "size": "starcoder:15b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q4_0",
        "size": "starcoder:15b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q4_1",
        "size": "starcoder:15b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q4_K_S",
        "size": "starcoder:15b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q4_K_M",
        "size": "starcoder:15b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q5_0",
        "size": "starcoder:15b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q5_1",
        "size": "starcoder:15b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q5_K_S",
        "size": "starcoder:15b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q5_K_M",
        "size": "starcoder:15b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q6_K",
        "size": "starcoder:15b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-q8_0",
        "size": "starcoder:15b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starcoder:15b-fp16",
        "size": "starcoder:15b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepseek-llm",
    "link": "https://ollama.com/library/deepseek-llm",
    "description": "An advanced language model crafted with 2 trillion bilingual tokens.",
    "pullCount": "201.5K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "67b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/0e62c3d2-6b1d-408a-a44d-273fc72697e6)\n\nDeepSeek LLM is an advanced language model available in both 7 billion and 67 billion parameters. Both a `chat` and `base` variation are available.\n\n![](https://github.com/jmorganca/ollama/assets/3325447/c74a21e9-1eb9-4036-9f83-6c3a027134c4)\n\n* Superior General Capabilities: DeepSeek LLM 67B Base outperforms Llama2 70B Base in areas such as reasoning, coding, math, and Chinese comprehension.\n* Proficient in Coding and Math: DeepSeek LLM 67B Chat exhibits outstanding performance in coding (using the HumanEval benchmark) and mathematics (using the GSM8K benchmark).\n\n## References\n\n[GitHub](https://github.com/deepseek-ai/deepseek-LLM)\n\n[HuggingFace](https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/0e62c3d2-6b1d-408a-a44d-273fc72697e6\" width=\"240\" /> DeepSeek LLM is an advanced language model available in both 7 billion and 67 billion parameters. Both a \\`chat\\` and \\`base\\` variation are available. <img src=\"https://github.com/jmorganca/ollama/assets/3325447/c74a21e9-1eb9-4036-9f83-6c3a027134c4\" width=\"500\" /> \\* Superior General Capabilities: DeepSeek LLM 67B Base outperforms Llama2 70B Base in areas such as reasoning, coding, math, and Chinese comprehension. \\* Proficient in Coding and Math: DeepSeek LLM 67B Chat exhibits outstanding performance in coding (using the HumanEval benchmark) and mathematics (using the GSM8K benchmark). ## References \\[GitHub\\](https://github.com/deepseek-ai/deepseek-LLM) \\[HuggingFace\\](https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-llm:latest",
        "size": "deepseek-llm:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b",
        "size": "deepseek-llm:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b",
        "size": "deepseek-llm:67b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base",
        "size": "deepseek-llm:7b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q2_K",
        "size": "deepseek-llm:7b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q3_K_S",
        "size": "deepseek-llm:7b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q3_K_M",
        "size": "deepseek-llm:7b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q3_K_L",
        "size": "deepseek-llm:7b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q4_0",
        "size": "deepseek-llm:7b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q4_1",
        "size": "deepseek-llm:7b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q4_K_S",
        "size": "deepseek-llm:7b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q4_K_M",
        "size": "deepseek-llm:7b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q5_0",
        "size": "deepseek-llm:7b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q5_1",
        "size": "deepseek-llm:7b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q5_K_S",
        "size": "deepseek-llm:7b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q5_K_M",
        "size": "deepseek-llm:7b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q6_K",
        "size": "deepseek-llm:7b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-q8_0",
        "size": "deepseek-llm:7b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-base-fp16",
        "size": "deepseek-llm:7b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat",
        "size": "deepseek-llm:7b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q2_K",
        "size": "deepseek-llm:7b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q3_K_S",
        "size": "deepseek-llm:7b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q3_K_M",
        "size": "deepseek-llm:7b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q3_K_L",
        "size": "deepseek-llm:7b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q4_0",
        "size": "deepseek-llm:7b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q4_1",
        "size": "deepseek-llm:7b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q4_K_S",
        "size": "deepseek-llm:7b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q4_K_M",
        "size": "deepseek-llm:7b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q5_0",
        "size": "deepseek-llm:7b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q5_1",
        "size": "deepseek-llm:7b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q5_K_S",
        "size": "deepseek-llm:7b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q5_K_M",
        "size": "deepseek-llm:7b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q6_K",
        "size": "deepseek-llm:7b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-q8_0",
        "size": "deepseek-llm:7b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:7b-chat-fp16",
        "size": "deepseek-llm:7b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base",
        "size": "deepseek-llm:67b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q2_K",
        "size": "deepseek-llm:67b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q3_K_S",
        "size": "deepseek-llm:67b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q3_K_M",
        "size": "deepseek-llm:67b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q3_K_L",
        "size": "deepseek-llm:67b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q4_0",
        "size": "deepseek-llm:67b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q4_1",
        "size": "deepseek-llm:67b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q4_K_S",
        "size": "deepseek-llm:67b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q4_K_M",
        "size": "deepseek-llm:67b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q5_0",
        "size": "deepseek-llm:67b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q5_1",
        "size": "deepseek-llm:67b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q5_K_S",
        "size": "deepseek-llm:67b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q5_K_M",
        "size": "deepseek-llm:67b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q6_K",
        "size": "deepseek-llm:67b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-q8_0",
        "size": "deepseek-llm:67b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-base-fp16",
        "size": "deepseek-llm:67b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat",
        "size": "deepseek-llm:67b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q2_K",
        "size": "deepseek-llm:67b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q3_K_S",
        "size": "deepseek-llm:67b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q3_K_M",
        "size": "deepseek-llm:67b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q3_K_L",
        "size": "deepseek-llm:67b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q4_0",
        "size": "deepseek-llm:67b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q4_1",
        "size": "deepseek-llm:67b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q4_K_S",
        "size": "deepseek-llm:67b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q4_K_M",
        "size": "deepseek-llm:67b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q5_0",
        "size": "deepseek-llm:67b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q5_1",
        "size": "deepseek-llm:67b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-q5_K_S",
        "size": "deepseek-llm:67b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-llm:67b-chat-fp16",
        "size": "deepseek-llm:67b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "vicuna",
    "link": "https://ollama.com/library/vicuna",
    "description": "General use chat model based on Llama and Llama 2 with 2K to 16K context sizes.",
    "pullCount": "197.8K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "33b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nVicuna is a chat assistant model. It includes 3 different variants in 3 different sizes. v1.3 is trained by fine-tuning Llama and has a context size of 2048 tokens. v1.5 is trained by fine-tuning Llama 2 and has a context size of 2048 tokens. v1.5-16k is trained by fine-tuning Llama 2 and has a context size of 16k tokens. All three variants are trained using conversations collected from ShareGPT.\n\n## Example prompts\n\n```\nWhat is the meaning of life? Explain it in 5 paragraphs.\n\n```\n\n## References\n\n[HuggingFace](https://huggingface.co/lmsys)\n\nWrite Preview \n\nVicuna is a chat assistant model. It includes 3 different variants in 3 different sizes. v1.3 is trained by fine-tuning Llama and has a context size of 2048 tokens. v1.5 is trained by fine-tuning Llama 2 and has a context size of 2048 tokens. v1.5-16k is trained by fine-tuning Llama 2 and has a context size of 16k tokens. All three variants are trained using conversations collected from ShareGPT. ## Example prompts \\`\\`\\` What is the meaning of life? Explain it in 5 paragraphs. \\`\\`\\` ## References \\[HuggingFace\\](https://huggingface.co/lmsys) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "vicuna:latest",
        "size": "vicuna:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b",
        "size": "vicuna:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b",
        "size": "vicuna:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b",
        "size": "vicuna:33b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-16k",
        "size": "vicuna:7b-16k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q2_K",
        "size": "vicuna:7b-v1.5-16k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q2_K",
        "size": "vicuna:7b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q3_K_S",
        "size": "vicuna:7b-v1.5-16k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q3_K_S",
        "size": "vicuna:7b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q3_K_M",
        "size": "vicuna:7b-v1.5-16k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q3_K_M",
        "size": "vicuna:7b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q3_K_L",
        "size": "vicuna:7b-v1.5-16k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q3_K_L",
        "size": "vicuna:7b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q4_0",
        "size": "vicuna:7b-v1.5-16k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q4_0",
        "size": "vicuna:7b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q4_1",
        "size": "vicuna:7b-v1.5-16k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q4_1",
        "size": "vicuna:7b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q4_K_S",
        "size": "vicuna:7b-v1.5-16k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q4_K_S",
        "size": "vicuna:7b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q4_K_M",
        "size": "vicuna:7b-v1.5-16k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q4_K_M",
        "size": "vicuna:7b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q5_0",
        "size": "vicuna:7b-v1.5-16k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q5_0",
        "size": "vicuna:7b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q5_1",
        "size": "vicuna:7b-v1.5-16k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q5_1",
        "size": "vicuna:7b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q5_K_S",
        "size": "vicuna:7b-v1.5-16k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q5_K_S",
        "size": "vicuna:7b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q5_K_M",
        "size": "vicuna:7b-v1.5-16k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q5_K_M",
        "size": "vicuna:7b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q6_K",
        "size": "vicuna:7b-v1.5-16k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q6_K",
        "size": "vicuna:7b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-q8_0",
        "size": "vicuna:7b-v1.5-16k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-q8_0",
        "size": "vicuna:7b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-16k-fp16",
        "size": "vicuna:7b-v1.5-16k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-v1.5-fp16",
        "size": "vicuna:7b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q2_K",
        "size": "vicuna:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q3_K_S",
        "size": "vicuna:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q3_K_M",
        "size": "vicuna:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q3_K_L",
        "size": "vicuna:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q4_0",
        "size": "vicuna:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q4_1",
        "size": "vicuna:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q4_K_S",
        "size": "vicuna:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q4_K_M",
        "size": "vicuna:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q5_0",
        "size": "vicuna:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q5_1",
        "size": "vicuna:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q5_K_S",
        "size": "vicuna:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q5_K_M",
        "size": "vicuna:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q6_K",
        "size": "vicuna:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-q8_0",
        "size": "vicuna:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:7b-fp16",
        "size": "vicuna:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-16k",
        "size": "vicuna:13b-16k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q2_K",
        "size": "vicuna:13b-v1.5-16k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q2_K",
        "size": "vicuna:13b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q3_K_S",
        "size": "vicuna:13b-v1.5-16k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q3_K_S",
        "size": "vicuna:13b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q3_K_M",
        "size": "vicuna:13b-v1.5-16k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q3_K_M",
        "size": "vicuna:13b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q3_K_L",
        "size": "vicuna:13b-v1.5-16k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q3_K_L",
        "size": "vicuna:13b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q4_0",
        "size": "vicuna:13b-v1.5-16k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q4_0",
        "size": "vicuna:13b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q4_1",
        "size": "vicuna:13b-v1.5-16k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q4_1",
        "size": "vicuna:13b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q4_K_S",
        "size": "vicuna:13b-v1.5-16k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q4_K_S",
        "size": "vicuna:13b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q4_K_M",
        "size": "vicuna:13b-v1.5-16k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q4_K_M",
        "size": "vicuna:13b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q5_0",
        "size": "vicuna:13b-v1.5-16k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q5_0",
        "size": "vicuna:13b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q5_1",
        "size": "vicuna:13b-v1.5-16k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q5_1",
        "size": "vicuna:13b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q5_K_S",
        "size": "vicuna:13b-v1.5-16k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q5_K_S",
        "size": "vicuna:13b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q5_K_M",
        "size": "vicuna:13b-v1.5-16k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q5_K_M",
        "size": "vicuna:13b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q6_K",
        "size": "vicuna:13b-v1.5-16k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q6_K",
        "size": "vicuna:13b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-q8_0",
        "size": "vicuna:13b-v1.5-16k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-q8_0",
        "size": "vicuna:13b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-16k-fp16",
        "size": "vicuna:13b-v1.5-16k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-v1.5-fp16",
        "size": "vicuna:13b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q2_K",
        "size": "vicuna:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q3_K_S",
        "size": "vicuna:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q3_K_M",
        "size": "vicuna:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q3_K_L",
        "size": "vicuna:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q4_0",
        "size": "vicuna:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q4_1",
        "size": "vicuna:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q4_K_S",
        "size": "vicuna:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q4_K_M",
        "size": "vicuna:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q5_0",
        "size": "vicuna:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q5_1",
        "size": "vicuna:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q5_K_S",
        "size": "vicuna:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q5_K_M",
        "size": "vicuna:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q6_K",
        "size": "vicuna:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-q8_0",
        "size": "vicuna:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:13b-fp16",
        "size": "vicuna:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q2_K",
        "size": "vicuna:33b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q3_K_S",
        "size": "vicuna:33b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q3_K_M",
        "size": "vicuna:33b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q3_K_L",
        "size": "vicuna:33b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q4_0",
        "size": "vicuna:33b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q4_1",
        "size": "vicuna:33b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q4_K_S",
        "size": "vicuna:33b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q4_K_M",
        "size": "vicuna:33b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q5_0",
        "size": "vicuna:33b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q5_1",
        "size": "vicuna:33b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q5_K_S",
        "size": "vicuna:33b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q5_K_M",
        "size": "vicuna:33b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q6_K",
        "size": "vicuna:33b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-q8_0",
        "size": "vicuna:33b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "vicuna:33b-fp16",
        "size": "vicuna:33b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "openchat",
    "link": "https://ollama.com/library/openchat",
    "description": "A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106.",
    "pullCount": "195.3K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/b39cea20-f0e9-4f63-a5b1-fa0c2368c286)\n\nOpenChat is set of open-source language models, fine-tuned with C-RLFT: a strategy inspired by offline reinforcement learning.\n\nUpdated to OpenChat-3.5-1210, this new version of the model model excels at coding tasks and scores very high on many open-source LLM benchmarks.\n\n## References\n\n[GitHub](https://github.com/imoneoi/openchat)\n\n[HuggingFace](https://huggingface.co/openchat/openchat%5F3.5)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/b39cea20-f0e9-4f63-a5b1-fa0c2368c286\" width=\"260\" /> OpenChat is set of open-source language models, fine-tuned with C-RLFT: a strategy inspired by offline reinforcement learning. Updated to OpenChat-3.5-1210, this new version of the model model excels at coding tasks and scores very high on many open-source LLM benchmarks. ## References \\[GitHub\\](https://github.com/imoneoi/openchat) \\[HuggingFace\\](https://huggingface.co/openchat/openchat\\_3.5) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "openchat:latest",
        "size": "openchat:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b",
        "size": "openchat:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5",
        "size": "openchat:7b-v3.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106",
        "size": "openchat:7b-v3.5-0106",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q2_K",
        "size": "openchat:7b-v3.5-0106-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q2_K",
        "size": "openchat:7b-v3.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q3_K_S",
        "size": "openchat:7b-v3.5-0106-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q3_K_S",
        "size": "openchat:7b-v3.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q3_K_M",
        "size": "openchat:7b-v3.5-0106-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q3_K_M",
        "size": "openchat:7b-v3.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q3_K_L",
        "size": "openchat:7b-v3.5-0106-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q3_K_L",
        "size": "openchat:7b-v3.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q4_0",
        "size": "openchat:7b-v3.5-0106-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q4_0",
        "size": "openchat:7b-v3.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q4_1",
        "size": "openchat:7b-v3.5-0106-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q4_1",
        "size": "openchat:7b-v3.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q4_K_S",
        "size": "openchat:7b-v3.5-0106-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q4_K_S",
        "size": "openchat:7b-v3.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q4_K_M",
        "size": "openchat:7b-v3.5-0106-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q4_K_M",
        "size": "openchat:7b-v3.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q5_0",
        "size": "openchat:7b-v3.5-0106-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q5_0",
        "size": "openchat:7b-v3.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q5_1",
        "size": "openchat:7b-v3.5-0106-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q5_1",
        "size": "openchat:7b-v3.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q5_K_S",
        "size": "openchat:7b-v3.5-0106-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q5_K_M",
        "size": "openchat:7b-v3.5-0106-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q6_K",
        "size": "openchat:7b-v3.5-0106-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-q8_0",
        "size": "openchat:7b-v3.5-0106-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-0106-fp16",
        "size": "openchat:7b-v3.5-0106-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210",
        "size": "openchat:7b-v3.5-1210",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q2_K",
        "size": "openchat:7b-v3.5-1210-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q3_K_S",
        "size": "openchat:7b-v3.5-1210-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q3_K_M",
        "size": "openchat:7b-v3.5-1210-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q3_K_L",
        "size": "openchat:7b-v3.5-1210-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q4_0",
        "size": "openchat:7b-v3.5-1210-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q4_1",
        "size": "openchat:7b-v3.5-1210-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q4_K_S",
        "size": "openchat:7b-v3.5-1210-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q4_K_M",
        "size": "openchat:7b-v3.5-1210-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q5_0",
        "size": "openchat:7b-v3.5-1210-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q5_1",
        "size": "openchat:7b-v3.5-1210-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q5_K_S",
        "size": "openchat:7b-v3.5-1210-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q5_K_S",
        "size": "openchat:7b-v3.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q5_K_M",
        "size": "openchat:7b-v3.5-1210-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q5_K_M",
        "size": "openchat:7b-v3.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q6_K",
        "size": "openchat:7b-v3.5-1210-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q6_K",
        "size": "openchat:7b-v3.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-q8_0",
        "size": "openchat:7b-v3.5-1210-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-q8_0",
        "size": "openchat:7b-v3.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-1210-fp16",
        "size": "openchat:7b-v3.5-1210-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openchat:7b-v3.5-fp16",
        "size": "openchat:7b-v3.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "mistral-openorca",
    "link": "https://ollama.com/library/mistral-openorca",
    "description": "Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset.",
    "pullCount": "185.3K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/3325447/e2ab7f70-f708-4b59-83af-6cf48f7115b5)\n\nMistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset.\n\nHuggingFace Leaderboard evals place this model as leader for all models smaller than 30B at the release time, outperforming all other 7B and 13B models.\n\n## Usage\n\n### CLI\n\n```\nollama run mistral-openorca \"Why is the sky blue?\"\n\n```\n\n### API\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"mistral-openorca\",\n  \"prompt\": \"Why is the sky blue?\"\n}'\n\n```\n\n## More information\n\n* [HuggingFace repo](https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/3325447/e2ab7f70-f708-4b59-83af-6cf48f7115b5\" width=\"360\" /> Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset. HuggingFace Leaderboard evals place this model as leader for all models smaller than 30B at the release time, outperforming all other 7B and 13B models. ## Usage ### CLI \\`\\`\\` ollama run mistral-openorca \"Why is the sky blue?\" \\`\\`\\` ### API \\`\\`\\` curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"mistral-openorca\", \"prompt\": \"Why is the sky blue?\" }' \\`\\`\\` ## More information \\* \\[HuggingFace repo\\](https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistral-openorca:latest",
        "size": "mistral-openorca:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b",
        "size": "mistral-openorca:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q2_K",
        "size": "mistral-openorca:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q3_K_S",
        "size": "mistral-openorca:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q3_K_M",
        "size": "mistral-openorca:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q3_K_L",
        "size": "mistral-openorca:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q4_0",
        "size": "mistral-openorca:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q4_1",
        "size": "mistral-openorca:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q4_K_S",
        "size": "mistral-openorca:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q4_K_M",
        "size": "mistral-openorca:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q5_0",
        "size": "mistral-openorca:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q5_1",
        "size": "mistral-openorca:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q5_K_S",
        "size": "mistral-openorca:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q5_K_M",
        "size": "mistral-openorca:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q6_K",
        "size": "mistral-openorca:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-q8_0",
        "size": "mistral-openorca:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistral-openorca:7b-fp16",
        "size": "mistral-openorca:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepseek-v2",
    "link": "https://ollama.com/library/deepseek-v2",
    "description": "A strong, economical, and efficient Mixture-of-Experts language model.",
    "pullCount": "184.9K",
    "updated": "1 year ago",
    "size": [
      "16b",
      "236b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/deepseek-v2/9422627b-6d24-401b-8d49-5d316df9956b)\n\n> Note: this model requires [Ollama 0.1.40](https://github.com/ollama/ollama/releases/tag/v0.1.40).\n\nDeepSeek-V2 is a a strong Mixture-of-Experts (MoE) language model characterized by economical training and efficient inference.\n\nNote: this model is bilingual in English and Chinese.\n\nThe model comes in two sizes:\n\n* 16B Lite: `ollama run deepseek-v2:16b`\n* 236B: `ollama run deepseek-v2:236b`\n\n## References\n\n[GitHub](https://github.com/deepseek-ai/DeepSeek-V2)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/deepseek-v2/9422627b-6d24-401b-8d49-5d316df9956b\" width=\"320\" /> > Note: this model requires \\[Ollama 0.1.40\\](https://github.com/ollama/ollama/releases/tag/v0.1.40). DeepSeek-V2 is a a strong Mixture-of-Experts (MoE) language model characterized by economical training and efficient inference. Note: this model is bilingual in English and Chinese. The model comes in two sizes: \\* 16B Lite: \\`ollama run deepseek-v2:16b\\` \\* 236B: \\`ollama run deepseek-v2:236b\\` ## References \\[GitHub\\](https://github.com/deepseek-ai/DeepSeek-V2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-v2:latest",
        "size": "deepseek-v2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:lite",
        "size": "deepseek-v2:lite",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b",
        "size": "deepseek-v2:16b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b",
        "size": "deepseek-v2:236b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q2_K",
        "size": "deepseek-v2:16b-lite-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q3_K_S",
        "size": "deepseek-v2:16b-lite-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q3_K_M",
        "size": "deepseek-v2:16b-lite-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q3_K_L",
        "size": "deepseek-v2:16b-lite-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q4_0",
        "size": "deepseek-v2:16b-lite-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q4_1",
        "size": "deepseek-v2:16b-lite-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q4_K_S",
        "size": "deepseek-v2:16b-lite-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q4_K_M",
        "size": "deepseek-v2:16b-lite-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q5_0",
        "size": "deepseek-v2:16b-lite-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q5_1",
        "size": "deepseek-v2:16b-lite-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q5_K_S",
        "size": "deepseek-v2:16b-lite-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q5_K_M",
        "size": "deepseek-v2:16b-lite-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q6_K",
        "size": "deepseek-v2:16b-lite-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-q8_0",
        "size": "deepseek-v2:16b-lite-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:16b-lite-chat-fp16",
        "size": "deepseek-v2:16b-lite-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q2_K",
        "size": "deepseek-v2:236b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q3_K_S",
        "size": "deepseek-v2:236b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q3_K_M",
        "size": "deepseek-v2:236b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q3_K_L",
        "size": "deepseek-v2:236b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q4_0",
        "size": "deepseek-v2:236b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q4_1",
        "size": "deepseek-v2:236b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q4_K_S",
        "size": "deepseek-v2:236b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q4_K_M",
        "size": "deepseek-v2:236b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q5_0",
        "size": "deepseek-v2:236b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q5_1",
        "size": "deepseek-v2:236b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q5_K_S",
        "size": "deepseek-v2:236b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q5_K_M",
        "size": "deepseek-v2:236b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q6_K",
        "size": "deepseek-v2:236b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-q8_0",
        "size": "deepseek-v2:236b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "deepseek-v2:236b-chat-fp16",
        "size": "deepseek-v2:236b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "codegeex4",
    "link": "https://ollama.com/library/codegeex4",
    "description": "A versatile model for AI software development scenarios, including code completion.",
    "pullCount": "183.6K",
    "updated": "1 year ago",
    "size": [
      "9b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![logo.jpg](https://ollama.com/assets/library/codegeex4/b3a2d858-363f-4a6c-a9c7-056f74bc2910)\n\n> Note: this model requires [Ollama 0.2](https://github.com/ollama/ollama/releases/tag/v0.2.0) or later.\n\nCodeGeeX4 is an open multilingual code generation model continually trained on the [GLM-4-9B](https://ollama.com/library/glm4), significantly enhancing its code generation capabilities.\n\nCodeGeeX4-ALL-9B has achieved highly competitive performance on public benchmarks, such as BigCodeBench and NaturalCodeBench. It is currently the most powerful code generation model with less than 10B parameters, even surpassing much larger general-purpose models, achieving the best balance in terms of inference speed and model performance.\n\n# References\n\n[GitHub](https://github.com/THUDM/CodeGeeX4)\n\n[Hugging Face](https://huggingface.co/THUDM/codegeex4-all-9b)\n\nWrite Preview \n\n!\\[logo.jpg\\](https://ollama.com/assets/library/codegeex4/b3a2d858-363f-4a6c-a9c7-056f74bc2910) > Note: this model requires \\[Ollama 0.2\\](https://github.com/ollama/ollama/releases/tag/v0.2.0) or later. CodeGeeX4 is an open multilingual code generation model continually trained on the \\[GLM-4-9B\\](https://ollama.com/library/glm4), significantly enhancing its code generation capabilities. CodeGeeX4-ALL-9B has achieved highly competitive performance on public benchmarks, such as BigCodeBench and NaturalCodeBench. It is currently the most powerful code generation model with less than 10B parameters, even surpassing much larger general-purpose models, achieving the best balance in terms of inference speed and model performance. # References \\[GitHub\\](https://github.com/THUDM/CodeGeeX4) \\[Hugging Face\\](https://huggingface.co/THUDM/codegeex4-all-9b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codegeex4:latest",
        "size": "codegeex4:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b",
        "size": "codegeex4:9b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q2_K",
        "size": "codegeex4:9b-all-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q3_K_S",
        "size": "codegeex4:9b-all-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q3_K_M",
        "size": "codegeex4:9b-all-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q3_K_L",
        "size": "codegeex4:9b-all-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q4_0",
        "size": "codegeex4:9b-all-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q4_1",
        "size": "codegeex4:9b-all-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q4_K_S",
        "size": "codegeex4:9b-all-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q4_K_M",
        "size": "codegeex4:9b-all-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q5_0",
        "size": "codegeex4:9b-all-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q5_1",
        "size": "codegeex4:9b-all-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q5_K_S",
        "size": "codegeex4:9b-all-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q5_K_M",
        "size": "codegeex4:9b-all-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q6_K",
        "size": "codegeex4:9b-all-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-q8_0",
        "size": "codegeex4:9b-all-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codegeex4:9b-all-fp16",
        "size": "codegeex4:9b-all-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "openhermes",
    "link": "https://ollama.com/library/openhermes",
    "description": "OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets.",
    "pullCount": "181.2K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/3325447/abc656b5-6d3b-47ef-8d1c-c0445f780168)\n\nOpen Hermes 2 a Mistral 7B fine-tuned with fully open datasets. Matching 70B models on benchmarks, this model has strong multi-turn chat skills and system prompt capabilities. In total, the model was trained on 900,000 instructions, and surpasses all previous versions of Nous-Hermes 13B and below.\n\n### Versions\n\n| Tag         | Date       | Notes                                      |\n| ----------- | ---------- | ------------------------------------------ |\n| v2.5 latest | 11/02/2023 | Added \\~100k examples of Code Instructions |\n| v2          | 10/16/2023 | Initial release of Open Hermes 2           |\n\n## Usage\n\n### CLI\n\n```\nollama run openhermes\n\n```\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"openhermes\",\n  \"prompt\": \"Here is a story about llamas eating grass\"\n}'\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/3325447/abc656b5-6d3b-47ef-8d1c-c0445f780168\" width=\"320\" /> Open Hermes 2 a Mistral 7B fine-tuned with fully open datasets. Matching 70B models on benchmarks, this model has strong multi-turn chat skills and system prompt capabilities. In total, the model was trained on 900,000 instructions, and surpasses all previous versions of Nous-Hermes 13B and below. ### Versions | Tag | Date | Notes | | --------------- | ---------- | ----------------------------------------- | | \\`v2.5\\` \\`latest\\` | 11/02/2023 | Added \\~100k examples of Code Instructions | | \\`v2\\` | 10/16/2023 | Initial release of Open Hermes 2 | ## Usage ### CLI \\`\\`\\` ollama run openhermes \\`\\`\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"openhermes\", \"prompt\": \"Here is a story about llamas eating grass\" }' \\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "openhermes:latest",
        "size": "openhermes:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:v2",
        "size": "openhermes:v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:v2.5",
        "size": "openhermes:v2.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q2_K",
        "size": "openhermes:7b-mistral-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q3_K_S",
        "size": "openhermes:7b-mistral-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q3_K_M",
        "size": "openhermes:7b-mistral-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q3_K_L",
        "size": "openhermes:7b-mistral-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q4_0",
        "size": "openhermes:7b-mistral-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q4_1",
        "size": "openhermes:7b-mistral-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q4_K_S",
        "size": "openhermes:7b-mistral-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q4_K_M",
        "size": "openhermes:7b-mistral-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q5_0",
        "size": "openhermes:7b-mistral-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q5_1",
        "size": "openhermes:7b-mistral-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q5_K_S",
        "size": "openhermes:7b-mistral-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q5_K_M",
        "size": "openhermes:7b-mistral-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q6_K",
        "size": "openhermes:7b-mistral-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-q8_0",
        "size": "openhermes:7b-mistral-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2-fp16",
        "size": "openhermes:7b-mistral-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q2_K",
        "size": "openhermes:7b-mistral-v2.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q3_K_S",
        "size": "openhermes:7b-mistral-v2.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q3_K_M",
        "size": "openhermes:7b-mistral-v2.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q3_K_L",
        "size": "openhermes:7b-mistral-v2.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q4_0",
        "size": "openhermes:7b-mistral-v2.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q4_1",
        "size": "openhermes:7b-mistral-v2.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q4_K_S",
        "size": "openhermes:7b-mistral-v2.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q4_K_M",
        "size": "openhermes:7b-mistral-v2.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q5_0",
        "size": "openhermes:7b-mistral-v2.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q5_1",
        "size": "openhermes:7b-mistral-v2.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q5_K_S",
        "size": "openhermes:7b-mistral-v2.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q5_K_M",
        "size": "openhermes:7b-mistral-v2.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q6_K",
        "size": "openhermes:7b-mistral-v2.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-q8_0",
        "size": "openhermes:7b-mistral-v2.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-mistral-v2.5-fp16",
        "size": "openhermes:7b-mistral-v2.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-v2",
        "size": "openhermes:7b-v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "openhermes:7b-v2.5",
        "size": "openhermes:7b-v2.5",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "codeqwen",
    "link": "https://ollama.com/library/codeqwen",
    "description": "CodeQwen1.5 is a large language model pretrained on a large amount of code data.",
    "pullCount": "170.9K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/c17cc1ce-9eb9-4658-8b02-b2f15bbaf1c1)\n\nCodeQwen1.5 is based on Qwen1.5\\. It is trained on 3 trillion tokens of code data. Its major features include:\n\n* Strong code generation capabilities and competitive performance across a series of benchmarks\n* Support for long context understanding and generation with a maximum context length of 64K tokens\n* Support for 92 coding languages\n* Excellent performance in Text-to-SQL, fixing bugs and other coding use cases.\n\n## References\n\n[Blog Post](https://qwenlm.github.io/blog/codeqwen1.5/)\n\n[GitHub](https://github.com/QwenLM/Qwen)\n\n[HuggingFace](https://huggingface.co/Qwen)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/c17cc1ce-9eb9-4658-8b02-b2f15bbaf1c1\" width=\"360\" /> CodeQwen1.5 is based on Qwen1.5\\. It is trained on 3 trillion tokens of code data. Its major features include: \\* Strong code generation capabilities and competitive performance across a series of benchmarks \\* Support for long context understanding and generation with a maximum context length of 64K tokens \\* Support for 92 coding languages \\* Excellent performance in Text-to-SQL, fixing bugs and other coding use cases. ## References \\[Blog Post\\](https://qwenlm.github.io/blog/codeqwen1.5/) \\[GitHub\\](https://github.com/QwenLM/Qwen) \\[HuggingFace\\](https://huggingface.co/Qwen) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codeqwen:latest",
        "size": "codeqwen:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:chat",
        "size": "codeqwen:chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:code",
        "size": "codeqwen:code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:v1.5",
        "size": "codeqwen:v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b",
        "size": "codeqwen:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat",
        "size": "codeqwen:7b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q2_K",
        "size": "codeqwen:7b-chat-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q3_K_S",
        "size": "codeqwen:7b-chat-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q3_K_M",
        "size": "codeqwen:7b-chat-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q3_K_L",
        "size": "codeqwen:7b-chat-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q4_0",
        "size": "codeqwen:7b-chat-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q4_1",
        "size": "codeqwen:7b-chat-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q4_K_S",
        "size": "codeqwen:7b-chat-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q4_K_M",
        "size": "codeqwen:7b-chat-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q5_0",
        "size": "codeqwen:7b-chat-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q5_1",
        "size": "codeqwen:7b-chat-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q5_K_S",
        "size": "codeqwen:7b-chat-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q5_K_M",
        "size": "codeqwen:7b-chat-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q6_K",
        "size": "codeqwen:7b-chat-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-q8_0",
        "size": "codeqwen:7b-chat-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-chat-v1.5-fp16",
        "size": "codeqwen:7b-chat-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code",
        "size": "codeqwen:7b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code-v1.5-q4_0",
        "size": "codeqwen:7b-code-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code-v1.5-q4_1",
        "size": "codeqwen:7b-code-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code-v1.5-q5_0",
        "size": "codeqwen:7b-code-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code-v1.5-q5_1",
        "size": "codeqwen:7b-code-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code-v1.5-q8_0",
        "size": "codeqwen:7b-code-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:7b-code-v1.5-fp16",
        "size": "codeqwen:7b-code-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:v1.5-chat",
        "size": "codeqwen:v1.5-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeqwen:v1.5-code",
        "size": "codeqwen:v1.5-code",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "qwen2-math",
    "link": "https://ollama.com/library/qwen2-math",
    "description": "Qwen2 Math is a series of specialized math language models built upon the Qwen2 LLMs, which significantly outperforms the mathematical capabilities of open-source models and even closed-source models (e.g., GPT4o).",
    "pullCount": "168.3K",
    "updated": "1 year ago",
    "size": [
      "1.5b",
      "7b",
      "72b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/qwen2-math/c0159f63-bf4d-4b0d-9b92-ea44c48d34c1)\n\n**Qwen2 Math** features 3 model sizes (**1.5B**, **7B**, and **72B**) each with a **base** model, for completion, few-shot inference, and fine-tuning, and an **instruct** model for chatting.\n\n## References:\n\n* [Qwen 2 Math Blog Post](https://qwenlm.github.io/blog/qwen2-math/)\n* [GitHub Repository](https://github.com/QwenLM/Qwen2-Math)\n* [Hugging Face](https://huggingface.co/collections/Qwen/qwen2-math-66b4c9e072eda65b5ec7534d)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/qwen2-math/c0159f63-bf4d-4b0d-9b92-ea44c48d34c1\" width=\"380\" /> \\*\\*Qwen2 Math\\*\\* features 3 model sizes (\\*\\*1.5B\\*\\*, \\*\\*7B\\*\\*, and \\*\\*72B\\*\\*) each with a \\*\\*base\\*\\* model, for completion, few-shot inference, and fine-tuning, and an \\*\\*instruct\\*\\* model for chatting. ## References: - \\[Qwen 2 Math Blog Post\\](https://qwenlm.github.io/blog/qwen2-math/) - \\[GitHub Repository\\](https://github.com/QwenLM/Qwen2-Math) - \\[Hugging Face\\](https://huggingface.co/collections/Qwen/qwen2-math-66b4c9e072eda65b5ec7534d) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "qwen2-math:latest",
        "size": "qwen2-math:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b",
        "size": "qwen2-math:1.5b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b",
        "size": "qwen2-math:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b",
        "size": "qwen2-math:72b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct",
        "size": "qwen2-math:1.5b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q2_K",
        "size": "qwen2-math:1.5b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q3_K_S",
        "size": "qwen2-math:1.5b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q3_K_M",
        "size": "qwen2-math:1.5b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q3_K_L",
        "size": "qwen2-math:1.5b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q4_0",
        "size": "qwen2-math:1.5b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q4_1",
        "size": "qwen2-math:1.5b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q4_K_S",
        "size": "qwen2-math:1.5b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q4_K_M",
        "size": "qwen2-math:1.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q5_0",
        "size": "qwen2-math:1.5b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q5_1",
        "size": "qwen2-math:1.5b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q5_K_S",
        "size": "qwen2-math:1.5b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q5_K_M",
        "size": "qwen2-math:1.5b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q6_K",
        "size": "qwen2-math:1.5b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-q8_0",
        "size": "qwen2-math:1.5b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:1.5b-instruct-fp16",
        "size": "qwen2-math:1.5b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct",
        "size": "qwen2-math:7b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q2_K",
        "size": "qwen2-math:7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q3_K_S",
        "size": "qwen2-math:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q3_K_M",
        "size": "qwen2-math:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q3_K_L",
        "size": "qwen2-math:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q4_0",
        "size": "qwen2-math:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q4_1",
        "size": "qwen2-math:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q4_K_S",
        "size": "qwen2-math:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q4_K_M",
        "size": "qwen2-math:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q5_0",
        "size": "qwen2-math:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q5_1",
        "size": "qwen2-math:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q5_K_S",
        "size": "qwen2-math:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q5_K_M",
        "size": "qwen2-math:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q6_K",
        "size": "qwen2-math:7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-q8_0",
        "size": "qwen2-math:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:7b-instruct-fp16",
        "size": "qwen2-math:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct",
        "size": "qwen2-math:72b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q2_K",
        "size": "qwen2-math:72b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q3_K_S",
        "size": "qwen2-math:72b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q3_K_M",
        "size": "qwen2-math:72b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q3_K_L",
        "size": "qwen2-math:72b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q4_0",
        "size": "qwen2-math:72b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q4_1",
        "size": "qwen2-math:72b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q4_K_S",
        "size": "qwen2-math:72b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q4_K_M",
        "size": "qwen2-math:72b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q5_0",
        "size": "qwen2-math:72b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q5_1",
        "size": "qwen2-math:72b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q5_K_S",
        "size": "qwen2-math:72b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q5_K_M",
        "size": "qwen2-math:72b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q6_K",
        "size": "qwen2-math:72b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-q8_0",
        "size": "qwen2-math:72b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "qwen2-math:72b-instruct-fp16",
        "size": "qwen2-math:72b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama2-chinese",
    "link": "https://ollama.com/library/llama2-chinese",
    "description": "Llama 2 based model fine tuned to improve Chinese dialogue ability.",
    "pullCount": "164.7K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nLlama 2 对话中文微调参数模型\n\n这个模型是基于 Meta Platform, Inc. 所发布的 Llama 2 Chat 开源模型来进行微调。根据Meta，Llama 2 的训练数据达到了两万亿个token，上下文长度也提升到4096。对话上也是使用100万人类标记的数据微调。\n\n由于 Llama 2 本身的中文对齐比较弱，开发者采用了中文指令集来进行微调，使其具备较强的中文对话能力。目前这个中文微调参数模型总共发布了 7B，13B两种参数大小。\n\nLlama 2 chat chinese fine-tuned model\n\nThis model is fine-tuned based on Meta Platform’s Llama 2 Chat open source model. According to Meta, Llama 2 is trained on 2 trillion tokens, and the context length is increased to 4096\\. The chat model is fine-tuned using 1 million human labeled data.\n\nSince the Chinese alignment of Llama 2 itself is relatively weak, the developer, adopted a Chinese instruction set for fine-tuning to improve the Chinese dialogue ability.\n\nThe Chinese fine-tuned models are available in 7B and 13B parameter sizes.\n\n### CLI\n\nOpen the terminal and run `ollama run llama2-chinese`\n\n### API\n\nRun the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"llama2-chinese:7b-chat-q4_0\",\n  \"prompt\":\"为什么天空是蓝色的\"\n }'\n\n```\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 13b models generally require at least 16GB of RAM\n\n## Reference\n\n[FlagAlpha](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat)\n\n[FlagAlpha](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat)\n\nWrite Preview \n\nLlama 2 对话中文微调参数模型 这个模型是基于 Meta Platform, Inc. 所发布的 Llama 2 Chat 开源模型来进行微调。根据Meta，Llama 2 的训练数据达到了两万亿个token，上下文长度也提升到4096。对话上也是使用100万人类标记的数据微调。 由于 Llama 2 本身的中文对齐比较弱，开发者采用了中文指令集来进行微调，使其具备较强的中文对话能力。目前这个中文微调参数模型总共发布了 7B，13B两种参数大小。 Llama 2 chat chinese fine-tuned model This model is fine-tuned based on Meta Platform's Llama 2 Chat open source model. According to Meta, Llama 2 is trained on 2 trillion tokens, and the context length is increased to 4096\\. The chat model is fine-tuned using 1 million human labeled data. Since the Chinese alignment of Llama 2 itself is relatively weak, the developer, adopted a Chinese instruction set for fine-tuning to improve the Chinese dialogue ability. The Chinese fine-tuned models are available in 7B and 13B parameter sizes. ### CLI Open the terminal and run \\`ollama run llama2-chinese\\` ### API Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"llama2-chinese:7b-chat-q4\\_0\", \"prompt\":\"为什么天空是蓝色的\" }' \\`\\`\\` ## Memory requirements - 7b models generally require at least 8GB of RAM - 13b models generally require at least 16GB of RAM ## Reference \\[FlagAlpha\\](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat) \\[FlagAlpha\\](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama2-chinese:latest",
        "size": "llama2-chinese:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b",
        "size": "llama2-chinese:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b",
        "size": "llama2-chinese:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat",
        "size": "llama2-chinese:7b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q2_K",
        "size": "llama2-chinese:7b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q3_K_S",
        "size": "llama2-chinese:7b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q3_K_M",
        "size": "llama2-chinese:7b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q3_K_L",
        "size": "llama2-chinese:7b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q4_0",
        "size": "llama2-chinese:7b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q4_1",
        "size": "llama2-chinese:7b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q4_K_S",
        "size": "llama2-chinese:7b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q4_K_M",
        "size": "llama2-chinese:7b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q5_0",
        "size": "llama2-chinese:7b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q5_1",
        "size": "llama2-chinese:7b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q5_K_S",
        "size": "llama2-chinese:7b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q5_K_M",
        "size": "llama2-chinese:7b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q6_K",
        "size": "llama2-chinese:7b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-q8_0",
        "size": "llama2-chinese:7b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:7b-chat-fp16",
        "size": "llama2-chinese:7b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat",
        "size": "llama2-chinese:13b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q2_K",
        "size": "llama2-chinese:13b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q3_K_S",
        "size": "llama2-chinese:13b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q3_K_M",
        "size": "llama2-chinese:13b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q3_K_L",
        "size": "llama2-chinese:13b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q4_0",
        "size": "llama2-chinese:13b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q4_1",
        "size": "llama2-chinese:13b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q4_K_S",
        "size": "llama2-chinese:13b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q4_K_M",
        "size": "llama2-chinese:13b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q5_0",
        "size": "llama2-chinese:13b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q5_1",
        "size": "llama2-chinese:13b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q5_K_S",
        "size": "llama2-chinese:13b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q5_K_M",
        "size": "llama2-chinese:13b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q6_K",
        "size": "llama2-chinese:13b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-q8_0",
        "size": "llama2-chinese:13b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama2-chinese:13b-chat-fp16",
        "size": "llama2-chinese:13b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "aya",
    "link": "https://ollama.com/library/aya",
    "description": "Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual models that support 23 languages.",
    "pullCount": "160K",
    "updated": "1 year ago",
    "size": [
      "8b",
      "35b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![image.png](https://ollama.com/assets/library/aya/f55197c8-901d-45f5-ba00-75fb0230f1c9)\n\nAya 23, released by Cohere, is a new family of state-of-the-art, multilingual, generative large language research model (LLM) covering 23 different languages.\n\nIt is available in 8B and 35B parameter sizes:\n\n* 8B `ollama run aya:8b`\n* 35B `ollama run aya:35b`\n\n![Multilingual Benchmarks](https://ollama.com/assets/library/aya/4d6844fc-f55c-470b-9625-c8b2b7927c35)\n\n![aya win rates vs other models](https://ollama.com/assets/library/aya/ceca785b-8190-4f0b-854a-68d375c22e46)\n\n# References\n\n[Blog Post](https://cohere.com/blog/aya23)\n\n[Aya 23: Open Weight Releases to Further Multilingual Progress paper](https://cohere.com/research/papers/aya-command-23-8b-and-35b-technical-report-2024-05-23)\n\n[Hugging Face](https://huggingface.co/collections/CohereForAI/c4ai-aya-23-664f4cda3fa1a30553b221dc)\n\nWrite Preview \n\n!\\[image.png\\](https://ollama.com/assets/library/aya/f55197c8-901d-45f5-ba00-75fb0230f1c9) Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual, generative large language research model (LLM) covering 23 different languages. It is available in 8B and 35B parameter sizes: \\* 8B \\`ollama run aya:8b\\` \\* 35B \\`ollama run aya:35b\\` !\\[Multilingual Benchmarks\\](https://ollama.com/assets/library/aya/4d6844fc-f55c-470b-9625-c8b2b7927c35) !\\[aya win rates vs other models\\](https://ollama.com/assets/library/aya/ceca785b-8190-4f0b-854a-68d375c22e46) # References \\[Blog Post\\](https://cohere.com/blog/aya23) \\[Aya 23: Open Weight Releases to Further Multilingual Progress paper\\](https://cohere.com/research/papers/aya-command-23-8b-and-35b-technical-report-2024-05-23) \\[Hugging Face\\](https://huggingface.co/collections/CohereForAI/c4ai-aya-23-664f4cda3fa1a30553b221dc) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "aya:latest",
        "size": "aya:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b",
        "size": "aya:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b",
        "size": "aya:35b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23",
        "size": "aya:8b-23",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q2_K",
        "size": "aya:8b-23-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q3_K_S",
        "size": "aya:8b-23-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q3_K_M",
        "size": "aya:8b-23-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q3_K_L",
        "size": "aya:8b-23-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q4_0",
        "size": "aya:8b-23-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q4_1",
        "size": "aya:8b-23-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q4_K_S",
        "size": "aya:8b-23-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q4_K_M",
        "size": "aya:8b-23-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q5_0",
        "size": "aya:8b-23-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q5_1",
        "size": "aya:8b-23-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q5_K_S",
        "size": "aya:8b-23-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q5_K_M",
        "size": "aya:8b-23-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q6_K",
        "size": "aya:8b-23-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:8b-23-q8_0",
        "size": "aya:8b-23-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23",
        "size": "aya:35b-23",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q2_K",
        "size": "aya:35b-23-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q3_K_S",
        "size": "aya:35b-23-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q3_K_M",
        "size": "aya:35b-23-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q3_K_L",
        "size": "aya:35b-23-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q4_0",
        "size": "aya:35b-23-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q4_1",
        "size": "aya:35b-23-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q4_K_S",
        "size": "aya:35b-23-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q4_K_M",
        "size": "aya:35b-23-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q5_0",
        "size": "aya:35b-23-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q5_1",
        "size": "aya:35b-23-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q5_K_S",
        "size": "aya:35b-23-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q5_K_M",
        "size": "aya:35b-23-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q6_K",
        "size": "aya:35b-23-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "aya:35b-23-q8_0",
        "size": "aya:35b-23-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "nous-hermes",
    "link": "https://ollama.com/library/nous-hermes",
    "description": "General use models based on Llama and Llama 2 from Nous Research.",
    "pullCount": "159.2K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/262739492-985b8e69-35be-4eaf-a954-c452c4363c72.png)\n\nNous Hermes was released by Nous Research. There are two main variants here, a 13B parameter model based on Llama, and a 7B and 13B parameter model based on Llama 2\\. They are all general-use models trained with the same datasets.\n\n## Get started with Nous Hermes\n\nThe model used in the example below is the Nous Hermes Llama 2 model, with 7b parameters, which is a general chat model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"nous-hermes\",\n  \"prompt\":\"Explain the process of how a refrigerator works to keep the contents inside cold.\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run nous-hermes`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull nous-hermes`\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 13b models generally require at least 16GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nOllama offers many variants of the Nous Hermes model that are quantized based on the official models to run well locally.\n\n**Nous Hermes Llama 2** is the original Nous Hermes model based on the original Llama model.\n\n_Example: `ollama run nous-hermes`_\n\n**Nous Hermes Llama 1** is the original Nous Hermes model based on the original Llama model.\n\n_Example: `ollama run nous-hermes:13b-q40`_\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n| **Aliases**                            |\n| -------------------------------------- |\n| latest, 7b, 7b-llama2, 7b-llama2-q4\\_0 |\n| 13b, 13b-llama2, 13b-llama2-q4\\_0      |\n\n## Model source\n\n**Nous Hermes Llama 2 source on Ollama**\n\n7b parameters original source:[Nous Research](https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b)\n\n13b parameters original source:[Nous Research](https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b)\n\n**Nous Hermes Llama 1 source on Ollama**\n\n13b parameters original source:[Nous Research](https://huggingface.co/NousResearch/Nous-Hermes-13b)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/262739492-985b8e69-35be-4eaf-a954-c452c4363c72.png\" style=\"max-width:60%\" /> Nous Hermes was released by Nous Research. There are two main variants here, a 13B parameter model based on Llama, and a 7B and 13B parameter model based on Llama 2\\. They are all general-use models trained with the same datasets. ## Get started with Nous Hermes The model used in the example below is the Nous Hermes Llama 2 model, with 7b parameters, which is a general chat model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"nous-hermes\", \"prompt\":\"Explain the process of how a refrigerator works to keep the contents inside cold.\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run nous-hermes\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull nous-hermes\\` ## Memory requirements - 7b models generally require at least 8GB of RAM - 13b models generally require at least 16GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants Ollama offers many variants of the Nous Hermes model that are quantized based on the official models to run well locally. \\*\\*Nous Hermes Llama 2\\*\\* is the original Nous Hermes model based on the original Llama model. \\*Example: \\`ollama run nous-hermes\\`\\* \\*\\*Nous Hermes Llama 1\\*\\* is the original Nous Hermes model based on the original Llama model. \\*Example: \\`ollama run nous-hermes:13b-q4\\_0\\`\\* By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. | \\*\\*Aliases\\*\\* | | --- | | latest, 7b, 7b-llama2, 7b-llama2-q4\\_0 | | 13b, 13b-llama2, 13b-llama2-q4\\_0 | ## Model source \\*\\*Nous Hermes Llama 2 source on Ollama\\*\\* 7b parameters original source: \\[Nous Research\\](https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b) 13b parameters original source: \\[Nous Research\\](https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b) \\*\\*Nous Hermes Llama 1 source on Ollama\\*\\* 13b parameters original source: \\[Nous Research\\](https://huggingface.co/NousResearch/Nous-Hermes-13b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nous-hermes:latest",
        "size": "nous-hermes:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b",
        "size": "nous-hermes:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b",
        "size": "nous-hermes:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2",
        "size": "nous-hermes:7b-llama2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q2_K",
        "size": "nous-hermes:7b-llama2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q3_K_S",
        "size": "nous-hermes:7b-llama2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q3_K_M",
        "size": "nous-hermes:7b-llama2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q3_K_L",
        "size": "nous-hermes:7b-llama2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q4_0",
        "size": "nous-hermes:7b-llama2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q4_1",
        "size": "nous-hermes:7b-llama2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q4_K_S",
        "size": "nous-hermes:7b-llama2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q4_K_M",
        "size": "nous-hermes:7b-llama2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q5_0",
        "size": "nous-hermes:7b-llama2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q5_1",
        "size": "nous-hermes:7b-llama2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q5_K_S",
        "size": "nous-hermes:7b-llama2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q5_K_M",
        "size": "nous-hermes:7b-llama2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q6_K",
        "size": "nous-hermes:7b-llama2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-q8_0",
        "size": "nous-hermes:7b-llama2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:7b-llama2-fp16",
        "size": "nous-hermes:7b-llama2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2",
        "size": "nous-hermes:13b-llama2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q2_K",
        "size": "nous-hermes:13b-llama2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q3_K_S",
        "size": "nous-hermes:13b-llama2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q3_K_M",
        "size": "nous-hermes:13b-llama2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q3_K_L",
        "size": "nous-hermes:13b-llama2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q4_0",
        "size": "nous-hermes:13b-llama2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q4_1",
        "size": "nous-hermes:13b-llama2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q4_K_S",
        "size": "nous-hermes:13b-llama2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q4_K_M",
        "size": "nous-hermes:13b-llama2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q5_0",
        "size": "nous-hermes:13b-llama2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q5_1",
        "size": "nous-hermes:13b-llama2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q5_K_S",
        "size": "nous-hermes:13b-llama2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q5_K_M",
        "size": "nous-hermes:13b-llama2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q6_K",
        "size": "nous-hermes:13b-llama2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-q8_0",
        "size": "nous-hermes:13b-llama2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-llama2-fp16",
        "size": "nous-hermes:13b-llama2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q2_K",
        "size": "nous-hermes:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q3_K_S",
        "size": "nous-hermes:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q3_K_M",
        "size": "nous-hermes:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q3_K_L",
        "size": "nous-hermes:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q4_0",
        "size": "nous-hermes:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q4_1",
        "size": "nous-hermes:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q4_K_S",
        "size": "nous-hermes:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q4_K_M",
        "size": "nous-hermes:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q5_0",
        "size": "nous-hermes:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q5_1",
        "size": "nous-hermes:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q5_K_S",
        "size": "nous-hermes:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q5_K_M",
        "size": "nous-hermes:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q6_K",
        "size": "nous-hermes:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-q8_0",
        "size": "nous-hermes:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:13b-fp16",
        "size": "nous-hermes:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q2_K",
        "size": "nous-hermes:70b-llama2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q3_K_S",
        "size": "nous-hermes:70b-llama2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q3_K_M",
        "size": "nous-hermes:70b-llama2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q3_K_L",
        "size": "nous-hermes:70b-llama2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q4_0",
        "size": "nous-hermes:70b-llama2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q4_1",
        "size": "nous-hermes:70b-llama2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q4_K_S",
        "size": "nous-hermes:70b-llama2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q4_K_M",
        "size": "nous-hermes:70b-llama2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q5_0",
        "size": "nous-hermes:70b-llama2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q5_1",
        "size": "nous-hermes:70b-llama2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q5_K_M",
        "size": "nous-hermes:70b-llama2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-q6_K",
        "size": "nous-hermes:70b-llama2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes:70b-llama2-fp16",
        "size": "nous-hermes:70b-llama2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "exaone-deep",
    "link": "https://ollama.com/library/exaone-deep",
    "description": "EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.",
    "pullCount": "156.7K",
    "updated": "5 months ago",
    "size": [
      "2.4b",
      "7.8b",
      "32b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/exaone-deep/05e9cd86-a79b-4fd5-9e0f-7f18f1c1a928)\n\nEXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.\n\nEvaluation results show that:\n\n1. EXAONE Deep 2.4B outperforms other models of comparable size\n2. EXAONE Deep 7.8B outperforms not only open-weight models of comparable scale but also a proprietary reasoning model OpenAI o1-mini\n3. EXAONE Deep 32B demonstrates competitive performance against leading open-weight models.\n\n![exaone_deep_overall_performance.png](/assets/library/exaone-deep/b107bac2-f509-4a1b-9999-344d976c803e)\n\n## References\n\n[Hugging Face](https://huggingface.co/LGAI-EXAONE/EXAONE-Deep-32B)\n\nWrite Preview \n\n<img src=\"/assets/library/exaone-deep/05e9cd86-a79b-4fd5-9e0f-7f18f1c1a928\" width=\"320\" /> EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research. Evaluation results show that: 1\\. EXAONE Deep 2.4B outperforms other models of comparable size 2\\. EXAONE Deep 7.8B outperforms not only open-weight models of comparable scale but also a proprietary reasoning model OpenAI o1-mini 3\\. EXAONE Deep 32B demonstrates competitive performance against leading open-weight models. !\\[exaone\\_deep\\_overall\\_performance.png\\](/assets/library/exaone-deep/b107bac2-f509-4a1b-9999-344d976c803e) ## References \\[Hugging Face\\](https://huggingface.co/LGAI-EXAONE/EXAONE-Deep-32B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "exaone-deep:latest",
        "size": "exaone-deep:latest",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:2.4b",
        "size": "exaone-deep:2.4b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:7.8b",
        "size": "exaone-deep:7.8b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:32b",
        "size": "exaone-deep:32b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:2.4b-q4_K_M",
        "size": "exaone-deep:2.4b-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:2.4b-q8_0",
        "size": "exaone-deep:2.4b-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:2.4b-fp16",
        "size": "exaone-deep:2.4b-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:7.8b-q4_K_M",
        "size": "exaone-deep:7.8b-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:7.8b-q8_0",
        "size": "exaone-deep:7.8b-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:7.8b-fp16",
        "size": "exaone-deep:7.8b-fp16",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:32b-q4_K_M",
        "size": "exaone-deep:32b-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:32b-q8_0",
        "size": "exaone-deep:32b-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "exaone-deep:32b-fp16",
        "size": "exaone-deep:32b-fp16",
        "updated": "Text input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "tinydolphin",
    "link": "https://ollama.com/library/tinydolphin",
    "description": "An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.",
    "pullCount": "155.8K",
    "updated": "1 year ago",
    "size": [
      "1.1b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/319ed8b3-8401-4923-9a09-ea388bb9a196)\n\nTinyDolphin is an experimental model from training the [TinyLlama](https://ollama.ai/library/tinyllama) model on the popular Dolphin dataset by Eric Hartford.\n\n## Reference\n\n[Hugging Face](https://huggingface.co/cognitivecomputations/TinyDolphin-2.8-1.1b)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/319ed8b3-8401-4923-9a09-ea388bb9a196\" width=\"280\" /> TinyDolphin is an experimental model from training the \\[TinyLlama\\](https://ollama.ai/library/tinyllama) model on the popular Dolphin dataset by Eric Hartford. ## Reference \\[Hugging Face\\](https://huggingface.co/cognitivecomputations/TinyDolphin-2.8-1.1b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "tinydolphin:latest",
        "size": "tinydolphin:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:v2.8",
        "size": "tinydolphin:v2.8",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b",
        "size": "tinydolphin:1.1b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q2_K",
        "size": "tinydolphin:1.1b-v2.8-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q3_K_S",
        "size": "tinydolphin:1.1b-v2.8-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q3_K_M",
        "size": "tinydolphin:1.1b-v2.8-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q3_K_L",
        "size": "tinydolphin:1.1b-v2.8-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q4_0",
        "size": "tinydolphin:1.1b-v2.8-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q4_1",
        "size": "tinydolphin:1.1b-v2.8-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q4_K_S",
        "size": "tinydolphin:1.1b-v2.8-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q4_K_M",
        "size": "tinydolphin:1.1b-v2.8-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q5_0",
        "size": "tinydolphin:1.1b-v2.8-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q5_1",
        "size": "tinydolphin:1.1b-v2.8-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q5_K_S",
        "size": "tinydolphin:1.1b-v2.8-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q5_K_M",
        "size": "tinydolphin:1.1b-v2.8-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q6_K",
        "size": "tinydolphin:1.1b-v2.8-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-q8_0",
        "size": "tinydolphin:1.1b-v2.8-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "tinydolphin:1.1b-v2.8-fp16",
        "size": "tinydolphin:1.1b-v2.8-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "snowflake-arctic-embed2",
    "link": "https://ollama.com/library/snowflake-arctic-embed2",
    "description": "Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual support without sacrificing English performance or scalability.",
    "pullCount": "155.6K",
    "updated": "9 months ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\nSnowflake is excited to announce the release of Arctic Embed 2.0, the next iteration of our frontier embedding models, which now empower multilingual search. While our previous releases have been well received by our customers, partners and the open source community, leading to millions of downloads, we have consistently received one request: Can you make this model multilingual? Arctic Embed 2.0 builds on the robust foundation of our previous releases, adding multilingual support without sacrificing English performance or scalability, to address the needs of an even broader user base that spans a wide range of languages and applications.\n\n![Snowflake data](/assets/library/snowflake-arctic-embed2/0546501b-9897-4145-af38-1b352fafb89c)Figure 1\\. Single-vector dense retrieval performance of open source multilingual embedding models with fewer than 1B parameters. Scores are average nDCG@10 on MTEB Retrieval and the subset of CLEF (ELRA, 2006) covering English, French, Spanish, Italian and German.\n\n### The diverse and powerful feature set of Arctic Embed 2.0\n\n1. **Enterprise-ready throughput and efficiency:** The Arctic Embed 2.0 models are built for large-scale enterprise demands. Even our “large” model weighs in well under 1B parameters and delivers fast, high-throughput embedding capabilities. Based on internal testing, it easily handles more than 100 documents per second (on average) on NVIDIA A10 GPUs and achieves sub-10ms query embedding latency, enabling practical deployment on budget-friendly hardware.\n2. **Uncompromising quality for English and non-English retrieval:** Despite their compact sizes, both Arctic Embed 2.0 models achieve impressive NDCG@10 scores across a variety of English and non-English benchmark data sets, demonstrating a capability to generalize well even to languages not included in the training recipe. These impressive benchmark scores position Arctic Embed 2.0 as a leader among frontier retrieval models.\n3. **Enabling scalable retrieval through Matryoshka Representation Learning (MRL):** The Arctic Embed 2.0 release includes the same quantization-friendly MRL functionality introduced in Arctic Embed 1.5, allowing users to reduce cost and optimize scale when performing searches over large data sets. With both model sizes, users can achieve high-quality retrieval with as few as 128 bytes per vector (96x smaller than uncompressed embeddings from OpenAI’s popular text-embedding-3-large model1). Just like Arctic Embed 1.5, the Arctic Embed 2.0 models also outshine several MRL-supporting peers with substantially lower quality degradation and higher benchmark scores in the compressed regime.\n4. **Truly open source:** The Arctic Embed 2.0 models are released under the permissive Apache 2.0 license.\n\nWrite Preview \n\nSnowflake is excited to announce the release of Arctic Embed 2.0, the next iteration of our frontier embedding models, which now empower multilingual search. While our previous releases have been well received by our customers, partners and the open source community, leading to millions of downloads, we have consistently received one request: Can you make this model multilingual? Arctic Embed 2.0 builds on the robust foundation of our previous releases, adding multilingual support without sacrificing English performance or scalability, to address the needs of an even broader user base that spans a wide range of languages and applications. !\\[Snowflake data\\](/assets/library/snowflake-arctic-embed2/0546501b-9897-4145-af38-1b352fafb89c) Figure 1\\. Single-vector dense retrieval performance of open source multilingual embedding models with fewer than 1B parameters. Scores are average nDCG@10 on MTEB Retrieval and the subset of CLEF (ELRA, 2006) covering English, French, Spanish, Italian and German. ### The diverse and powerful feature set of Arctic Embed 2.0 1\\. \\*\\*Enterprise-ready throughput and efficiency:\\*\\* The Arctic Embed 2.0 models are built for large-scale enterprise demands. Even our “large” model weighs in well under 1B parameters and delivers fast, high-throughput embedding capabilities. Based on internal testing, it easily handles more than 100 documents per second (on average) on NVIDIA A10 GPUs and achieves sub-10ms query embedding latency, enabling practical deployment on budget-friendly hardware. 2\\. \\*\\*Uncompromising quality for English and non-English retrieval:\\*\\* Despite their compact sizes, both Arctic Embed 2.0 models achieve impressive NDCG@10 scores across a variety of English and non-English benchmark data sets, demonstrating a capability to generalize well even to languages not included in the training recipe. These impressive benchmark scores position Arctic Embed 2.0 as a leader among frontier retrieval models. 3\\. \\*\\*Enabling scalable retrieval through Matryoshka Representation Learning (MRL):\\*\\* The Arctic Embed 2.0 release includes the same quantization-friendly MRL functionality introduced in Arctic Embed 1.5, allowing users to reduce cost and optimize scale when performing searches over large data sets. With both model sizes, users can achieve high-quality retrieval with as few as 128 bytes per vector (96x smaller than uncompressed embeddings from OpenAI’s popular text-embedding-3-large model1). Just like Arctic Embed 1.5, the Arctic Embed 2.0 models also outshine several MRL-supporting peers with substantially lower quality degradation and higher benchmark scores in the compressed regime. 4\\. \\*\\*Truly open source:\\*\\* The Arctic Embed 2.0 models are released under the permissive Apache 2.0 license. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "snowflake-arctic-embed2:latest",
        "size": "snowflake-arctic-embed2:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "snowflake-arctic-embed2:568m",
        "size": "snowflake-arctic-embed2:568m",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "snowflake-arctic-embed2:568m-l-fp16",
        "size": "snowflake-arctic-embed2:568m-l-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "glm4",
    "link": "https://ollama.com/library/glm4",
    "description": "A strong multi-lingual general language model with competitive performance to Llama 3.",
    "pullCount": "154.2K",
    "updated": "1 year ago",
    "size": [
      "9b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/glm4/7646ce96-fbec-4694-a3f5-39f9e61f19a6)\n\n> Note: this model requires [Ollama 0.2](https://github.com/ollama/ollama/releases/tag/v0.2.0) or later.\n\nIn the evaluation of data sets in semantics, mathematics, reasoning, code, and knowledge, this model has shown superior performance beyond even Llama 3 8B.\n\nThis generation of models includes multi-language support, supporting 26 languages including Japanese, Korean, and German.\n\n## References\n\n[GitHub](https://github.com/THUDM/GLM)\n\n[Hugging Face](https://huggingface.co/collections/THUDM/glm-4-665fcf188c414b03c2f7e3b7)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/glm4/7646ce96-fbec-4694-a3f5-39f9e61f19a6\" width=\"320\" /> > Note: this model requires \\[Ollama 0.2\\](https://github.com/ollama/ollama/releases/tag/v0.2.0) or later. In the evaluation of data sets in semantics, mathematics, reasoning, code, and knowledge, this model has shown superior performance beyond even Llama 3 8B. This generation of models includes multi-language support, supporting 26 languages including Japanese, Korean, and German. ## References \\[GitHub\\](https://github.com/THUDM/GLM) \\[Hugging Face\\](https://huggingface.co/collections/THUDM/glm-4-665fcf188c414b03c2f7e3b7) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "glm4:latest",
        "size": "glm4:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b",
        "size": "glm4:9b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q2_K",
        "size": "glm4:9b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q3_K_S",
        "size": "glm4:9b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q3_K_M",
        "size": "glm4:9b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q3_K_L",
        "size": "glm4:9b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q4_0",
        "size": "glm4:9b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q4_1",
        "size": "glm4:9b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q4_K_S",
        "size": "glm4:9b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q4_K_M",
        "size": "glm4:9b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q5_0",
        "size": "glm4:9b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q5_1",
        "size": "glm4:9b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q5_K_S",
        "size": "glm4:9b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q5_K_M",
        "size": "glm4:9b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q6_K",
        "size": "glm4:9b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-q8_0",
        "size": "glm4:9b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-chat-fp16",
        "size": "glm4:9b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q2_K",
        "size": "glm4:9b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q3_K_S",
        "size": "glm4:9b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q3_K_M",
        "size": "glm4:9b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q3_K_L",
        "size": "glm4:9b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q4_0",
        "size": "glm4:9b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q4_1",
        "size": "glm4:9b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q4_K_S",
        "size": "glm4:9b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q4_K_M",
        "size": "glm4:9b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q5_0",
        "size": "glm4:9b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q5_1",
        "size": "glm4:9b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q5_K_S",
        "size": "glm4:9b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q5_K_M",
        "size": "glm4:9b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q6_K",
        "size": "glm4:9b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-q8_0",
        "size": "glm4:9b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "glm4:9b-text-fp16",
        "size": "glm4:9b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "granite3.2",
    "link": "https://ollama.com/library/granite3.2",
    "description": "Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities.",
    "pullCount": "151.6K",
    "updated": "6 months ago",
    "size": [
      "2b",
      "8b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/granite3.2/90c5e567-0004-425c-a17a-1b846c2b5d3d)\n\nGranite-3.2 is a family of long-context AI models fine-tuned for thinking capabilities. Built on top of Granite-3.1, it has been trained using a mix of permissively licensed open-source datasets and internally generated synthetic data designed for reasoning tasks. The models allow controllability of its thinking capability, ensuring it is applied only when required.\n\n* **Developers:** Granite Team, IBM\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: February 26th, 2025\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\n**Sizes**\n\nThe models are available in two parameter sizes, 2B and 8B:\n\n```\nollama run granite3.2:2b\n\n```\n\n```\nollama run granite3.2:8b\n\n```\n\n**Supported Languages:**English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. However, users may finetune this Granite model for languages beyond these 12 languages.\n\n**Intended Use:**These models are designed to handle general instruction-following tasks and can be integrated into AI assistants across various domains, including business applications.\n\n**Capabilities**\n\n* **Thinking**\n* Summarization\n* Text classification\n* Text extraction\n* Question-answering\n* Retrieval Augmented Generation (RAG)\n* Code related tasks\n* Function-calling tasks\n* Multilingual dialog use cases\n* Long-context tasks including long document/meeting summarization, long document QA, etc.\n\n**Thinking**\n\nTo enable thinking, add a message with `\"role\": \"control\"` and set `\"content\"` to `\"thinking\"`. For example:\n\n```\n{\n    \"messages\": [\n        {\"role\": \"control\", \"content\": \"thinking\"},\n        {\"role\": \"user\", \"content\": \"How do I get to the airport if my car won't start?\"}\n    ]\n}\n\n```\n\n## References\n\n[Website](https://www.ibm.com/granite)\n\nWrite Preview \n\n<img src=\"/assets/library/granite3.2/90c5e567-0004-425c-a17a-1b846c2b5d3d\" width=\"600\" /> Granite-3.2 is a family of long-context AI models fine-tuned for thinking capabilities. Built on top of Granite-3.1, it has been trained using a mix of permissively licensed open-source datasets and internally generated synthetic data designed for reasoning tasks. The models allow controllability of its thinking capability, ensuring it is applied only when required. - \\*\\*Developers:\\*\\* Granite Team, IBM - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: February 26th, 2025 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0) \\*\\*Sizes\\*\\* The models are available in two parameter sizes, 2B and 8B: \\`\\`\\` ollama run granite3.2:2b \\`\\`\\` \\`\\`\\` ollama run granite3.2:8b \\`\\`\\` \\*\\*Supported Languages:\\*\\* English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, and Chinese. However, users may finetune this Granite model for languages beyond these 12 languages. \\*\\*Intended Use:\\*\\* These models are designed to handle general instruction-following tasks and can be integrated into AI assistants across various domains, including business applications. \\*\\*Capabilities\\*\\* \\* \\*\\*Thinking\\*\\* \\* Summarization \\* Text classification \\* Text extraction \\* Question-answering \\* Retrieval Augmented Generation (RAG) \\* Code related tasks \\* Function-calling tasks \\* Multilingual dialog use cases \\* Long-context tasks including long document/meeting summarization, long document QA, etc. \\*\\*Thinking\\*\\* To enable thinking, add a message with \\`\"role\": \"control\"\\` and set \\`\"content\"\\` to \\`\"thinking\"\\`. For example: \\`\\`\\` { \"messages\": \\[ {\"role\": \"control\", \"content\": \"thinking\"}, {\"role\": \"user\", \"content\": \"How do I get to the airport if my car won't start?\"} \\] } \\`\\`\\` ## References \\[Website\\](https://www.ibm.com/granite) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3.2:latest",
        "size": "granite3.2:latest",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:2b",
        "size": "granite3.2:2b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:8b",
        "size": "granite3.2:8b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:2b-instruct-q4_K_M",
        "size": "granite3.2:2b-instruct-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:2b-instruct-q8_0",
        "size": "granite3.2:2b-instruct-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:2b-instruct-fp16",
        "size": "granite3.2:2b-instruct-fp16",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:8b-instruct-q4_K_M",
        "size": "granite3.2:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:8b-instruct-q8_0",
        "size": "granite3.2:8b-instruct-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "granite3.2:8b-instruct-fp16",
        "size": "granite3.2:8b-instruct-fp16",
        "updated": "Text input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "stable-code",
    "link": "https://ollama.com/library/stable-code",
    "description": "Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger.",
    "pullCount": "151.2K",
    "updated": "1 year ago",
    "size": [
      "3b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nStable Code 3B is a 3 billion parameter Large Language Model (LLM), allowing accurate and responsive code completion at a level on par with models such as Code Llama 7b that are 2.5x larger.\n\n**Key Features**\n\n* **NEW** instruct model `ollama run stable-code`\n* Fill in Middle Capability (FIM)\n* Supports Long Context, trained with Sequences upto 16,384\n\n![spiderchart](https://github.com/jmorganca/ollama/assets/3325447/6c3de7a5-5e10-4884-81fb-3a1b3f566609)\n\n| Model            | Size | Python | C++   | Javascript | Java  | PHP   | Rust  |\n| ---------------- | ---- | ------ | ----- | ---------- | ----- | ----- | ----- |\n| **Stable Code**  | 3B   | 32.4%  | 30.9% | 32.1%      | 32.1% | 24.2% | 23.0% |\n| CodeLLama        | 7B   | 30.0%  | 28.2% | 32.5%      | 31.1% | 25.7% | 26.3% |\n| Deepseek Coder   | 1.3B | 28.6%  | 29.2% | 28.7%      | 29.0% | 23.6% | 18.5% |\n| Wizard Coder     | 3B   | 31.6%  | 25.6% | 26.2%      | 25.8% | 25.3% | 20.4% |\n| StarCoder        | 3B   | 21.6%  | 19.8% | 21.5%      | 20.5% | 19.0% | 16.9% |\n| Replit Code V1.5 | 3B   | 23.0%  | 25.9% | 26.2%      | 23.6% | 23.2% | 21.5% |\n| Deci Coder       | 1B   | 19.1%  | 6.8%  | 18.4%      | 16.7% | 2.1%  | 1.7%  |\n\n## Model Details\n\n* **Developed by**: [Stability AI](https://stability.ai/)\n* **Model type**: stable-code models are auto-regressive language models based on the transformer decoder architecture.\n* **Language(s)**: English, Code\n* **Contact**: For questions and comments about the model, please email `lm@stability.ai`\n\n### Model Architecture\n\nThe model is a decoder-only transformer similar to the LLaMA ([Touvron et al., 2023](https://arxiv.org/abs/2307.09288)) architecture with the following modifications:\n\n| Parameters    | Hidden Size | Layers | Heads | Sequence Length |\n| ------------- | ----------- | ------ | ----- | --------------- |\n| 2,796,431,360 | 2560        | 32     | 32    | 16384           |\n\n* **Position Embeddings**: Rotary Position Embeddings ([Su et al., 2021](https://arxiv.org/abs/2104.09864)) applied to the first 25% of head embedding dimensions for improved throughput following [Black et al. (2022)](https://arxiv.org/pdf/2204.06745.pdf).\n* **Tokenizer**: We use a modified version of the GPTNeoX Tokenizer.[NeoX](https://github.com/EleutherAI/gpt-neox). We add special tokens to train for Fill in the Middle (FIM) capabilities like `<FIM_PREFIX>` and `<FIM_SUFFIX>` along with other special tokens.\n\n## Training\n\n### Training Dataset\n\nThe dataset is comprised of a filtered mixture of open-source large-scale datasets available on the [HuggingFace Hub](https://huggingface.co/datasets): Falcon RefinedWeb extract ([Penedo et al., 2023](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)), along with [CommitPackFT](https://huggingface.co/datasets/bigcode/commitpackft) and [Github Issues](https://huggingface.co/datasets/bigcode/the-stack-github-issues) (BigCode., 2023), and StarCoder ([Li et al., 2023](https://arxiv.org/abs/2305.06161)). We further supplement our training with data from mathematical domains ([Azerbayev, Zhangir, et al., 2023](https://arxiv.org/abs/2310.10631) and, [Yu, Longhui, et al., 2023](https://arxiv.org/abs/2309.12284)).\n\nTop 18 programming languages trained on: - C - CPP - Java - JavaScript - CSS - Go - HTML - Ruby - Rust - Markdown - Shell - Php - Sql - R - Typescript - Python - Jupyter-Clean - RestructuredText\n\n## Use and Limitations\n\n### Intended Use\n\nThe model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.\n\n### Limitations and Bias\n\n​ As a base model, this model may exhibit unreliable, unsafe, or other undesirable behaviors that must be corrected through evaluation and fine-tuning prior to deployment. The pre-training dataset may have contained offensive or inappropriate content, even after applying data cleansing filters, which can be reflected in the model-generated text. We recommend that users exercise caution when using these models in production systems. Do not use the models if they are unsuitable for your application, or for any applications that may cause deliberate or unintentional harm to others.\n\n## References\n\n[Hugging Face](https://huggingface.co/stabilityai/stable-code-3b)\n\nWrite Preview \n\nStable Code 3B is a 3 billion parameter Large Language Model (LLM), allowing accurate and responsive code completion at a level on par with models such as Code Llama 7b that are 2.5x larger. \\*\\*Key Features\\*\\* \\* \\*\\*NEW\\*\\* instruct model \\`ollama run stable-code\\` \\* Fill in Middle Capability (FIM) \\* Supports Long Context, trained with Sequences upto 16,384 !\\[spiderchart\\](https://github.com/jmorganca/ollama/assets/3325447/6c3de7a5-5e10-4884-81fb-3a1b3f566609) | Model | Size | Python | C++ | Javascript | Java | PHP | Rust | |------------------|------|--------|------|------------|------|------|------| | \\*\\*Stable Code\\*\\* | 3B | 32.4% | 30.9%| 32.1% | 32.1%| 24.2%| 23.0%| | CodeLLama | 7B | 30.0% | 28.2%| 32.5% | 31.1%| 25.7%| 26.3%| | Deepseek Coder | 1.3B | 28.6% | 29.2%| 28.7% | 29.0%| 23.6%| 18.5%| | Wizard Coder | 3B | 31.6% | 25.6%| 26.2% | 25.8%| 25.3%| 20.4%| | StarCoder | 3B | 21.6% | 19.8%| 21.5% | 20.5%| 19.0%| 16.9%| | Replit Code V1.5 | 3B | 23.0% | 25.9%| 26.2% | 23.6%| 23.2%| 21.5%| | Deci Coder | 1B | 19.1% | 6.8% | 18.4% | 16.7%| 2.1% | 1.7% | ## Model Details \\* \\*\\*Developed by\\*\\*: \\[Stability AI\\](https://stability.ai/) \\* \\*\\*Model type\\*\\*: stable-code models are auto-regressive language models based on the transformer decoder architecture. \\* \\*\\*Language(s)\\*\\*: English, Code \\* \\*\\*Contact\\*\\*: For questions and comments about the model, please email \\`lm@stability.ai\\` ### Model Architecture The model is a decoder-only transformer similar to the LLaMA (\\[Touvron et al., 2023\\](https://arxiv.org/abs/2307.09288)) architecture with the following modifications: | Parameters | Hidden Size | Layers | Heads | Sequence Length | |----------------|-------------|--------|-------|-----------------| | 2,796,431,360 | 2560 | 32 | 32 | 16384 | \\* \\*\\*Position Embeddings\\*\\*: Rotary Position Embeddings (\\[Su et al., 2021\\](https://arxiv.org/abs/2104.09864)) applied to the first 25% of head embedding dimensions for improved throughput following \\[Black et al. (2022)\\](https://arxiv.org/pdf/2204.06745.pdf). \\* \\*\\*Tokenizer\\*\\*: We use a modified version of the GPTNeoX Tokenizer.\\[\\`NeoX\\`\\](https://github.com/EleutherAI/gpt-neox). We add special tokens to train for Fill in the Middle (FIM) capabilities like \\`<FIM\\_PREFIX>\\` and \\`<FIM\\_SUFFIX>\\` along with other special tokens. ## Training ### Training Dataset The dataset is comprised of a filtered mixture of open-source large-scale datasets available on the \\[HuggingFace Hub\\](https://huggingface.co/datasets): Falcon RefinedWeb extract (\\[Penedo et al., 2023\\](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)), along with \\[CommitPackFT\\](https://huggingface.co/datasets/bigcode/commitpackft) and \\[Github Issues\\](https://huggingface.co/datasets/bigcode/the-stack-github-issues) (BigCode., 2023), and StarCoder (\\[Li et al., 2023\\](https://arxiv.org/abs/2305.06161)). We further supplement our training with data from mathematical domains (\\[Azerbayev, Zhangir, et al., 2023\\](https://arxiv.org/abs/2310.10631) and, \\[Yu, Longhui, et al., 2023\\](https://arxiv.org/abs/2309.12284)). Top 18 programming languages trained on: - C - CPP - Java - JavaScript - CSS - Go - HTML - Ruby - Rust - Markdown - Shell - Php - Sql - R - Typescript - Python - Jupyter-Clean - RestructuredText ## Use and Limitations ### Intended Use The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications. ### Limitations and Bias ​ As a base model, this model may exhibit unreliable, unsafe, or other undesirable behaviors that must be corrected through evaluation and fine-tuning prior to deployment. The pre-training dataset may have contained offensive or inappropriate content, even after applying data cleansing filters, which can be reflected in the model-generated text. We recommend that users exercise caution when using these models in production systems. Do not use the models if they are unsuitable for your application, or for any applications that may cause deliberate or unintentional harm to others. ## References \\[Hugging Face\\](https://huggingface.co/stabilityai/stable-code-3b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "stable-code:latest",
        "size": "stable-code:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:code",
        "size": "stable-code:code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:instruct",
        "size": "stable-code:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b",
        "size": "stable-code:3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code",
        "size": "stable-code:3b-code",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q2_K",
        "size": "stable-code:3b-code-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q3_K_S",
        "size": "stable-code:3b-code-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q3_K_M",
        "size": "stable-code:3b-code-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q3_K_L",
        "size": "stable-code:3b-code-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q4_0",
        "size": "stable-code:3b-code-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q4_1",
        "size": "stable-code:3b-code-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q4_K_S",
        "size": "stable-code:3b-code-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q4_K_M",
        "size": "stable-code:3b-code-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q5_0",
        "size": "stable-code:3b-code-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q5_1",
        "size": "stable-code:3b-code-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q5_K_S",
        "size": "stable-code:3b-code-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q5_K_M",
        "size": "stable-code:3b-code-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q6_K",
        "size": "stable-code:3b-code-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-q8_0",
        "size": "stable-code:3b-code-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-code-fp16",
        "size": "stable-code:3b-code-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct",
        "size": "stable-code:3b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q2_K",
        "size": "stable-code:3b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q3_K_S",
        "size": "stable-code:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q3_K_M",
        "size": "stable-code:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q3_K_L",
        "size": "stable-code:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q4_0",
        "size": "stable-code:3b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q4_1",
        "size": "stable-code:3b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q4_K_S",
        "size": "stable-code:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q4_K_M",
        "size": "stable-code:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q5_0",
        "size": "stable-code:3b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q5_1",
        "size": "stable-code:3b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q5_K_S",
        "size": "stable-code:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q5_K_M",
        "size": "stable-code:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q6_K",
        "size": "stable-code:3b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-q8_0",
        "size": "stable-code:3b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-code:3b-instruct-fp16",
        "size": "stable-code:3b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "falcon",
    "link": "https://ollama.com/library/falcon",
    "description": "A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots.",
    "pullCount": "147.6K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "40b",
      "180b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![Technology Innovation Institute Logo](https://github.com/jmorganca/ollama/assets/251292/af914f26-9f0b-4e66-947a-33ae0d558ccf)\n\nFalcon is a family of high-performing large language models model built by the Technology Innovation Institute (TII), a research center part of Abu Dhabi government’s advanced technology research council overseeing technology research.\n\n### CLI\n\n```\nollama run falcon \"Why is the sky blue?\"\n\n```\n\n### API\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"falcon\",\n  \"prompt\": \"Why is the sky blue?\"\n}'\n\n```\n\n## Parameter counts\n\n| Parameter Count | Recommended memory |                              |                        |\n| --------------- | ------------------ | ---------------------------- | ---------------------- |\n| 7 billion       | 8GB                | [View](/library/falcon:7b)   | ollama run falcon:7b   |\n| 40 billion      | 32GB               | [View](/library/falcon:40b)  | ollama run falcon:40b  |\n| 180 billion     | 192GB              | [View](/library/falcon:180b) | ollama run falcon:180b |\n\n## Variations\n\n| chat     | Chat models are fine-tuned on chat and instruction datasets with a mix of several large-scale conversational datasets.                                                                                                                           |\n| -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| instruct | Instruct models follow instructions and are fine-tuned on the [baize](https://www.google.com/search?q=baize+dataset&oq=baize+data&aqs=chrome.0.0i512j69i57j0i10i15i22i30i625j0i390i650.1387j0j7&sourceid=chrome&ie=UTF-8) instructional dataset. |\n| text     | Text models are the base foundation model without any fine-tuning for conversations, and are best used for simple text completion.                                                                                                               |\n\n## Falcon 180B\n\nAs of September 2023, the 180 billion parameter model, Falcon 180B, is the best-performing openly released LLM. It sits somewhere in between OpenAI’s GPT 3.5 and GPT 4\\. For running Falcon 180B, a powerful system is recommended with at least 192GB of total memory.\n\n> Note: Falcon 180B is released under a different license than its smaller siblings that restricts commercial use under certain conditions. See the [model details](/library/falcon:180b) and license for more information.\n\n## More information\n\n* [TII’s website](https://www.tii.ae/)\n* [Falcon 180B announcement](https://falconllm.tii.ae)\n* [TII on HuggingFace](https://huggingface.co/tiiuae)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/af914f26-9f0b-4e66-947a-33ae0d558ccf\" alt=\"Technology Innovation Institute Logo\" width=\"240\"/> Falcon is a family of high-performing large language models model built by the Technology Innovation Institute (TII), a research center part of Abu Dhabi government’s advanced technology research council overseeing technology research. ### CLI \\`\\`\\` ollama run falcon \"Why is the sky blue?\" \\`\\`\\` ### API \\`\\`\\` curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"falcon\", \"prompt\": \"Why is the sky blue?\" }' \\`\\`\\` ## Parameter counts | Parameter Count | Recommended memory | | | | --------------- | ------------------ | ---------------------------- | ------------------------ | | 7 billion | 8GB | \\[View\\](/library/falcon:7b) | \\`ollama run falcon:7b\\` | | 40 billion | 32GB | \\[View\\](/library/falcon:40b) | \\`ollama run falcon:40b\\` | | 180 billion | 192GB | \\[View\\](/library/falcon:180b) | \\`ollama run falcon:180b\\` | ## Variations | | | | ---------- | ---------------------------------------------------------------------------------------------------------------------------------- | | \\`chat\\` | Chat models are fine-tuned on chat and instruction datasets with a mix of several large-scale conversational datasets. | | \\`instruct\\` | Instruct models follow instructions and are fine-tuned on the \\[baize\\](https://www.google.com/search?q=baize+dataset&oq=baize+data&aqs=chrome.0.0i512j69i57j0i10i15i22i30i625j0i390i650.1387j0j7&sourceid=chrome&ie=UTF-8) instructional dataset. | | \\`text\\` | Text models are the base foundation model without any fine-tuning for conversations, and are best used for simple text completion. | ## Falcon 180B As of September 2023, the 180 billion parameter model, Falcon 180B, is the best-performing openly released LLM. It sits somewhere in between OpenAI's GPT 3.5 and GPT 4\\. For running Falcon 180B, a powerful system is recommended with at least 192GB of total memory. > Note: Falcon 180B is released under a different license than its smaller siblings that restricts commercial use under certain conditions. See the \\[model details\\](/library/falcon:180b) and license for more information. ## More information \\* \\[TII's website\\](https://www.tii.ae/) \\* \\[Falcon 180B announcement\\](https://falconllm.tii.ae) \\* \\[TII on HuggingFace\\](https://huggingface.co/tiiuae) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "falcon:latest",
        "size": "falcon:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:instruct",
        "size": "falcon:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:text",
        "size": "falcon:text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b",
        "size": "falcon:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b",
        "size": "falcon:40b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:180b",
        "size": "falcon:180b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct",
        "size": "falcon:7b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct-q4_0",
        "size": "falcon:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct-q4_1",
        "size": "falcon:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct-q5_0",
        "size": "falcon:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct-q5_1",
        "size": "falcon:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct-q8_0",
        "size": "falcon:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-instruct-fp16",
        "size": "falcon:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text",
        "size": "falcon:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text-q4_0",
        "size": "falcon:7b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text-q4_1",
        "size": "falcon:7b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text-q5_0",
        "size": "falcon:7b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text-q5_1",
        "size": "falcon:7b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text-q8_0",
        "size": "falcon:7b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:7b-text-fp16",
        "size": "falcon:7b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct",
        "size": "falcon:40b-instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct-q4_0",
        "size": "falcon:40b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct-q4_1",
        "size": "falcon:40b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct-q5_0",
        "size": "falcon:40b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct-q5_1",
        "size": "falcon:40b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct-q8_0",
        "size": "falcon:40b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-instruct-fp16",
        "size": "falcon:40b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text",
        "size": "falcon:40b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text-q4_0",
        "size": "falcon:40b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text-q4_1",
        "size": "falcon:40b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text-q5_0",
        "size": "falcon:40b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text-q5_1",
        "size": "falcon:40b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text-q8_0",
        "size": "falcon:40b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:40b-text-fp16",
        "size": "falcon:40b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:180b-chat",
        "size": "falcon:180b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:180b-chat-q4_0",
        "size": "falcon:180b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:180b-text",
        "size": "falcon:180b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon:180b-text-q4_0",
        "size": "falcon:180b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "nous-hermes2",
    "link": "https://ollama.com/library/nous-hermes2",
    "description": "The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.",
    "pullCount": "147.1K",
    "updated": "1 year ago",
    "size": [
      "10.7b",
      "34b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/4cf930ce-95f8-4a01-ad49-48db41ada870)\n\nNous Hermes 2 is a new iteration of the [Nous Hermes](https://ollama.ai/library/nous-hermes) model.\n\nThis model was trained on 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape. It is the most powerful Nous Hermes model to date, and surpasses many of the most popular models in the world in the GPT4All, AGIEval, BigBench and other benchmarks.\n\n## Versions\n\n| 10.7b latest | 01/01/2024 | A 10.7b model based on [Solar](https://ollama.ai/library/solar). A major improvement across the board on benchmarks compared to the base Solar 10.7B model, and comes close to approaching the 34B Yi model |\n| ------------ | ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 34b          | 12/25/2023 | The original Nous Hermes 2 34B model based on [Yi](https://ollama.ai/library/yi)                                                                                                                            |\n\n## References\n\n[HuggingFace](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/4cf930ce-95f8-4a01-ad49-48db41ada870\" width=\"300\" /> Nous Hermes 2 is a new iteration of the \\[Nous Hermes\\](https://ollama.ai/library/nous-hermes) model. This model was trained on 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape. It is the most powerful Nous Hermes model to date, and surpasses many of the most popular models in the world in the GPT4All, AGIEval, BigBench and other benchmarks. ## Versions | ---------------- | ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | | \\`10.7b\\` \\`latest\\` | 01/01/2024 | A 10.7b model based on \\[Solar\\](https://ollama.ai/library/solar). A major improvement across the board on benchmarks compared to the base Solar 10.7B model, and comes close to approaching the 34B Yi model | | \\`34b\\` | 12/25/2023 | The original Nous Hermes 2 34B model based on \\[Yi\\](https://ollama.ai/library/yi) | ## References \\[HuggingFace\\](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nous-hermes2:latest",
        "size": "nous-hermes2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b",
        "size": "nous-hermes2:10.7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b",
        "size": "nous-hermes2:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q2_K",
        "size": "nous-hermes2:10.7b-solar-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q3_K_S",
        "size": "nous-hermes2:10.7b-solar-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q3_K_M",
        "size": "nous-hermes2:10.7b-solar-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q3_K_L",
        "size": "nous-hermes2:10.7b-solar-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q4_0",
        "size": "nous-hermes2:10.7b-solar-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q4_1",
        "size": "nous-hermes2:10.7b-solar-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q4_K_S",
        "size": "nous-hermes2:10.7b-solar-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q4_K_M",
        "size": "nous-hermes2:10.7b-solar-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q5_0",
        "size": "nous-hermes2:10.7b-solar-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q5_1",
        "size": "nous-hermes2:10.7b-solar-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q5_K_S",
        "size": "nous-hermes2:10.7b-solar-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q5_K_M",
        "size": "nous-hermes2:10.7b-solar-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q6_K",
        "size": "nous-hermes2:10.7b-solar-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-q8_0",
        "size": "nous-hermes2:10.7b-solar-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:10.7b-solar-fp16",
        "size": "nous-hermes2:10.7b-solar-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q2_K",
        "size": "nous-hermes2:34b-yi-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q3_K_S",
        "size": "nous-hermes2:34b-yi-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q3_K_M",
        "size": "nous-hermes2:34b-yi-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q3_K_L",
        "size": "nous-hermes2:34b-yi-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q4_0",
        "size": "nous-hermes2:34b-yi-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q4_1",
        "size": "nous-hermes2:34b-yi-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q4_K_S",
        "size": "nous-hermes2:34b-yi-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q4_K_M",
        "size": "nous-hermes2:34b-yi-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q5_0",
        "size": "nous-hermes2:34b-yi-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q5_1",
        "size": "nous-hermes2:34b-yi-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q5_K_S",
        "size": "nous-hermes2:34b-yi-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q5_K_M",
        "size": "nous-hermes2:34b-yi-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q6_K",
        "size": "nous-hermes2:34b-yi-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-q8_0",
        "size": "nous-hermes2:34b-yi-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2:34b-yi-fp16",
        "size": "nous-hermes2:34b-yi-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "neural-chat",
    "link": "https://ollama.com/library/neural-chat",
    "description": "A fine-tuned model based on Mistral with good coverage of domain and language.",
    "pullCount": "143.9K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/18ecaefd-f70e-4d16-96b1-937d53e0faa5)\n\nNeuralChat is a fine-tuned model released by Intel that’s based on [Mistral](https://ollama.ai/library/mistral), designed to be used for high-performance chatbot applications.\n\n## References\n\n[HuggingFace](https://huggingface.co/Intel/neural-chat-7b-v3-1)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/18ecaefd-f70e-4d16-96b1-937d53e0faa5\" width=\"240\" /> NeuralChat is a fine-tuned model released by Intel that's based on \\[Mistral\\](https://ollama.ai/library/mistral), designed to be used for high-performance chatbot applications. ## References \\[HuggingFace\\](https://huggingface.co/Intel/neural-chat-7b-v3-1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "neural-chat:latest",
        "size": "neural-chat:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b",
        "size": "neural-chat:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1",
        "size": "neural-chat:7b-v3.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q2_K",
        "size": "neural-chat:7b-v3.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q3_K_S",
        "size": "neural-chat:7b-v3.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q3_K_M",
        "size": "neural-chat:7b-v3.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q3_K_L",
        "size": "neural-chat:7b-v3.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q4_0",
        "size": "neural-chat:7b-v3.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q4_1",
        "size": "neural-chat:7b-v3.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q4_K_S",
        "size": "neural-chat:7b-v3.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q4_K_M",
        "size": "neural-chat:7b-v3.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q5_0",
        "size": "neural-chat:7b-v3.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q5_1",
        "size": "neural-chat:7b-v3.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q5_K_S",
        "size": "neural-chat:7b-v3.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q5_K_M",
        "size": "neural-chat:7b-v3.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q6_K",
        "size": "neural-chat:7b-v3.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-q8_0",
        "size": "neural-chat:7b-v3.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.1-fp16",
        "size": "neural-chat:7b-v3.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2",
        "size": "neural-chat:7b-v3.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q2_K",
        "size": "neural-chat:7b-v3.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q3_K_S",
        "size": "neural-chat:7b-v3.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q3_K_M",
        "size": "neural-chat:7b-v3.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q3_K_L",
        "size": "neural-chat:7b-v3.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q4_0",
        "size": "neural-chat:7b-v3.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q4_1",
        "size": "neural-chat:7b-v3.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q4_K_S",
        "size": "neural-chat:7b-v3.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q4_K_M",
        "size": "neural-chat:7b-v3.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q5_0",
        "size": "neural-chat:7b-v3.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q5_1",
        "size": "neural-chat:7b-v3.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q5_K_S",
        "size": "neural-chat:7b-v3.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q5_K_M",
        "size": "neural-chat:7b-v3.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q6_K",
        "size": "neural-chat:7b-v3.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-q8_0",
        "size": "neural-chat:7b-v3.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.2-fp16",
        "size": "neural-chat:7b-v3.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3",
        "size": "neural-chat:7b-v3.3",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q2_K",
        "size": "neural-chat:7b-v3.3-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q3_K_S",
        "size": "neural-chat:7b-v3.3-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q3_K_M",
        "size": "neural-chat:7b-v3.3-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q3_K_L",
        "size": "neural-chat:7b-v3.3-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q4_0",
        "size": "neural-chat:7b-v3.3-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q4_1",
        "size": "neural-chat:7b-v3.3-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q4_K_S",
        "size": "neural-chat:7b-v3.3-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q4_K_M",
        "size": "neural-chat:7b-v3.3-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q5_0",
        "size": "neural-chat:7b-v3.3-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q5_1",
        "size": "neural-chat:7b-v3.3-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q5_K_S",
        "size": "neural-chat:7b-v3.3-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q5_K_M",
        "size": "neural-chat:7b-v3.3-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q6_K",
        "size": "neural-chat:7b-v3.3-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-q8_0",
        "size": "neural-chat:7b-v3.3-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "neural-chat:7b-v3.3-fp16",
        "size": "neural-chat:7b-v3.3-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "wizardcoder",
    "link": "https://ollama.com/library/wizardcoder",
    "description": "State-of-the-art code generation model",
    "pullCount": "141.5K",
    "updated": "1 year ago",
    "size": [
      "33b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nWizard Coder is a code generation model based on [Code Llama](https://ollama.ai/library/codellama).\n\n## Versions\n\n| Tag    | Date      | Notes                                                                                                |\n| ------ | --------- | ---------------------------------------------------------------------------------------------------- |\n| 33b    | 01/042024 | A new 33B model trained from [Deepseek Coder](https://ollama.ai/library/deepseek-coder/)             |\n| python | 09/7/2023 | Initial release in 7B, 13B and 34B sizes based on [Code Llama](https://ollama.ai/library/codellama/) |\n\n## References\n\n[Hugging Face](https://huggingface.co/WizardLM/WizardCoder-33B-V1.1)\n\n[WizardCoder: Empowering Code Large Language Models with Evol-Instruct](https://arxiv.org/abs/2306.08568)\n\nWrite Preview \n\nWizard Coder is a code generation model based on \\[Code Llama\\](https://ollama.ai/library/codellama). ## Versions | Tag | Date | Notes | | -------- | --------- | ---------------------------------------------------------------------------------------------------- | | \\`33b\\` | 01/042024 | A new 33B model trained from \\[Deepseek Coder\\](https://ollama.ai/library/deepseek-coder/) | | \\`python\\` | 09/7/2023 | Initial release in 7B, 13B and 34B sizes based on \\[Code Llama\\](https://ollama.ai/library/codellama/) | ## References \\[Hugging Face\\](https://huggingface.co/WizardLM/WizardCoder-33B-V1.1) \\[WizardCoder: Empowering Code Large Language Models with Evol-Instruct\\](https://arxiv.org/abs/2306.08568 ) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizardcoder:latest",
        "size": "wizardcoder:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:python",
        "size": "wizardcoder:python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b",
        "size": "wizardcoder:33b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python",
        "size": "wizardcoder:7b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q2_K",
        "size": "wizardcoder:7b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q3_K_S",
        "size": "wizardcoder:7b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q3_K_M",
        "size": "wizardcoder:7b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q3_K_L",
        "size": "wizardcoder:7b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q4_0",
        "size": "wizardcoder:7b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q4_1",
        "size": "wizardcoder:7b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q4_K_S",
        "size": "wizardcoder:7b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q4_K_M",
        "size": "wizardcoder:7b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q5_0",
        "size": "wizardcoder:7b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q5_1",
        "size": "wizardcoder:7b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q5_K_S",
        "size": "wizardcoder:7b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q5_K_M",
        "size": "wizardcoder:7b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q6_K",
        "size": "wizardcoder:7b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-q8_0",
        "size": "wizardcoder:7b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:7b-python-fp16",
        "size": "wizardcoder:7b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python",
        "size": "wizardcoder:13b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q2_K",
        "size": "wizardcoder:13b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q3_K_S",
        "size": "wizardcoder:13b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q3_K_M",
        "size": "wizardcoder:13b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q3_K_L",
        "size": "wizardcoder:13b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q4_0",
        "size": "wizardcoder:13b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q4_1",
        "size": "wizardcoder:13b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q4_K_S",
        "size": "wizardcoder:13b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q4_K_M",
        "size": "wizardcoder:13b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q5_0",
        "size": "wizardcoder:13b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q5_1",
        "size": "wizardcoder:13b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q5_K_S",
        "size": "wizardcoder:13b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q5_K_M",
        "size": "wizardcoder:13b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q6_K",
        "size": "wizardcoder:13b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-q8_0",
        "size": "wizardcoder:13b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:13b-python-fp16",
        "size": "wizardcoder:13b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1",
        "size": "wizardcoder:33b-v1.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q2_K",
        "size": "wizardcoder:33b-v1.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q3_K_S",
        "size": "wizardcoder:33b-v1.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q3_K_M",
        "size": "wizardcoder:33b-v1.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q3_K_L",
        "size": "wizardcoder:33b-v1.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q4_0",
        "size": "wizardcoder:33b-v1.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q4_1",
        "size": "wizardcoder:33b-v1.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q4_K_S",
        "size": "wizardcoder:33b-v1.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q4_K_M",
        "size": "wizardcoder:33b-v1.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q5_0",
        "size": "wizardcoder:33b-v1.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q5_1",
        "size": "wizardcoder:33b-v1.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q5_K_S",
        "size": "wizardcoder:33b-v1.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q5_K_M",
        "size": "wizardcoder:33b-v1.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q6_K",
        "size": "wizardcoder:33b-v1.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-q8_0",
        "size": "wizardcoder:33b-v1.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:33b-v1.1-fp16",
        "size": "wizardcoder:33b-v1.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python",
        "size": "wizardcoder:34b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q2_K",
        "size": "wizardcoder:34b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q3_K_S",
        "size": "wizardcoder:34b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q3_K_M",
        "size": "wizardcoder:34b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q3_K_L",
        "size": "wizardcoder:34b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q4_0",
        "size": "wizardcoder:34b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q4_1",
        "size": "wizardcoder:34b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q4_K_S",
        "size": "wizardcoder:34b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q4_K_M",
        "size": "wizardcoder:34b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q5_0",
        "size": "wizardcoder:34b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q5_1",
        "size": "wizardcoder:34b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q5_K_S",
        "size": "wizardcoder:34b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q5_K_M",
        "size": "wizardcoder:34b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q6_K",
        "size": "wizardcoder:34b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-q8_0",
        "size": "wizardcoder:34b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardcoder:34b-python-fp16",
        "size": "wizardcoder:34b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "command-r-plus",
    "link": "https://ollama.com/library/command-r-plus",
    "description": "Command R+ is a powerful, scalable large language model purpose-built to excel at real-world enterprise use cases.",
    "pullCount": "140.4K",
    "updated": "1 year ago",
    "size": [
      "104b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/566287ce-99c9-40c1-81d4-3dd354447fd7)\n\nCommand R+ is Cohere’s most powerful, scalable large language model (LLM) purpose-built to excel at real-world enterprise use cases. Command R+ balances high efficiency with strong accuracy, enabling businesses to move beyond proof-of-concept, and into production with AI:\n\n* A 128k-token context window\n* Advanced Retrieval Augmented Generation (RAG) with citation to reduce hallucinations\n* Multilingual coverage in 10 key languages to support global business operations\n* Tool Use to automate sophisticated business processes\n\n## References\n\n[Blog Post](https://txt.cohere.com/command-r-plus-microsoft-azure/)\n\n[HuggingFace](https://huggingface.co/CohereForAI/c4ai-command-r-plus)\n\nWrite Preview \n\n!\\[Command R+\\](https://github.com/ollama/ollama/assets/251292/566287ce-99c9-40c1-81d4-3dd354447fd7) Command R+ is Cohere's most powerful, scalable large language model (LLM) purpose-built to excel at real-world enterprise use cases. Command R+ balances high efficiency with strong accuracy, enabling businesses to move beyond proof-of-concept, and into production with AI: - A 128k-token context window - Advanced Retrieval Augmented Generation (RAG) with citation to reduce hallucinations - Multilingual coverage in 10 key languages to support global business operations - Tool Use to automate sophisticated business processes ## References \\[Blog Post\\](https://txt.cohere.com/command-r-plus-microsoft-azure/) \\[HuggingFace\\](https://huggingface.co/CohereForAI/c4ai-command-r-plus) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "command-r-plus:latest",
        "size": "command-r-plus:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b",
        "size": "command-r-plus:104b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q2_K",
        "size": "command-r-plus:104b-08-2024-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q3_K_S",
        "size": "command-r-plus:104b-08-2024-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q3_K_M",
        "size": "command-r-plus:104b-08-2024-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q3_K_L",
        "size": "command-r-plus:104b-08-2024-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q4_0",
        "size": "command-r-plus:104b-08-2024-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q4_1",
        "size": "command-r-plus:104b-08-2024-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q4_K_S",
        "size": "command-r-plus:104b-08-2024-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q4_K_M",
        "size": "command-r-plus:104b-08-2024-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q5_0",
        "size": "command-r-plus:104b-08-2024-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q5_1",
        "size": "command-r-plus:104b-08-2024-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q5_K_S",
        "size": "command-r-plus:104b-08-2024-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q5_K_M",
        "size": "command-r-plus:104b-08-2024-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q6_K",
        "size": "command-r-plus:104b-08-2024-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-q8_0",
        "size": "command-r-plus:104b-08-2024-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-08-2024-fp16",
        "size": "command-r-plus:104b-08-2024-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-q2_K",
        "size": "command-r-plus:104b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-q4_0",
        "size": "command-r-plus:104b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-q8_0",
        "size": "command-r-plus:104b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "command-r-plus:104b-fp16",
        "size": "command-r-plus:104b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "bakllava",
    "link": "https://ollama.com/library/bakllava",
    "description": "BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA  architecture.",
    "pullCount": "136.9K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n> Note: this model requires Ollama 0.1.15: [download it here](https://ollama.ai/download)\n\n### CLI Usage\n\nRun the model:\n\n```\nollama run bakllava\n\n```\n\nThen at the prompt, include the path to your image in the prompt:\n\n```\n>>> What's in this image? /Users/jmorgan/Desktop/smile.png\nThe image features a yellow smiley face, which is likely the central focus of the picture.\n\n```\n\n### API Usage\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"bakllava\",\n  \"prompt\":\"What is in this picture?\",\n  \"images\": [\"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\"]\n}'\n\n```\n\n## References\n\n[GitHub](https://github.com/SkunkworksAI/BakLLaVA)\n\n[HuggingFace](https://huggingface.co/SkunkworksAI/BakLLaVA-1)\n\nWrite Preview \n\n\\> Note: this model requires Ollama 0.1.15: \\[download it here\\](https://ollama.ai/download) ### CLI Usage Run the model: \\`\\`\\` ollama run bakllava \\`\\`\\` Then at the prompt, include the path to your image in the prompt: \\`\\`\\` >>> What's in this image? /Users/jmorgan/Desktop/smile.png The image features a yellow smiley face, which is likely the central focus of the picture. \\`\\`\\` ### API Usage \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"bakllava\", \"prompt\":\"What is in this picture?\", \"images\": \\[\"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\"\\] }' \\`\\`\\` ## References \\[GitHub\\](https://github.com/SkunkworksAI/BakLLaVA) \\[HuggingFace\\](https://huggingface.co/SkunkworksAI/BakLLaVA-1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "bakllava:latest",
        "size": "bakllava:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b",
        "size": "bakllava:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q2_K",
        "size": "bakllava:7b-v1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q3_K_S",
        "size": "bakllava:7b-v1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q3_K_M",
        "size": "bakllava:7b-v1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q3_K_L",
        "size": "bakllava:7b-v1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q4_0",
        "size": "bakllava:7b-v1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q4_1",
        "size": "bakllava:7b-v1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q4_K_S",
        "size": "bakllava:7b-v1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q4_K_M",
        "size": "bakllava:7b-v1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q5_0",
        "size": "bakllava:7b-v1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q5_1",
        "size": "bakllava:7b-v1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q5_K_S",
        "size": "bakllava:7b-v1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q5_K_M",
        "size": "bakllava:7b-v1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q6_K",
        "size": "bakllava:7b-v1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-q8_0",
        "size": "bakllava:7b-v1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bakllava:7b-v1-fp16",
        "size": "bakllava:7b-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "opencoder",
    "link": "https://ollama.com/library/opencoder",
    "description": "OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting chat in English and Chinese languages.",
    "pullCount": "130.9K",
    "updated": "9 months ago",
    "size": [
      "1.5b",
      "8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/opencoder/6078034f-fdbf-47c2-9b63-69ce506c0225)\n\n**OpenCoder** is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting both English and Chinese languages. Starting from scratch, OpenCoder is pretrained on 2.5 trillion tokens composed of 90% raw code and 10% code-related web data, and supervised finetuned on over 4.5M high-quality SFT examples, finally reaching the performance of top-tier code LLMs. We provide not only model weights and inference code, but also the reproducible training data, the complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols. Empowering researchers to build and innovate, OpenCoder is your open foundation for advancing code AI.\n\n* **Complete Open Source**: OpenCoder ensures full transparency by releasing not only the model weights and forthcoming inference code but also the complete data-cleaning code for training. This release includes high-quality synthetic data, an extensive set of checkpoints, and a dataset of over 4.5 million supervised fine-tuning (SFT) entries, making OpenCoder one of the most comprehensively open-sourced models available.\n* **Comprehensive Experimental Analysis**: OpenCoder is rigorously tested through extensive ablation studies on various data-cleaning strategies and training processes, including file-level and repository-level deduplication experiments, ensuring thorough exploration and validation of the model’s performance.\n* **High-Quality Synthetic Data**: OpenCoder provides a fully developed synthetic data generation process and over 4.5 million SFT data entries, establishing a robust data foundation for model training and evaluation.\n* **Exceptional Performance**: OpenCoder achieves high performance across multiple language model benchmarks, positioning it among the leading open-source models for code.\n\n## References\n\n[GitHub](https://github.com/OpenCoder-llm/OpenCoder-llm)\n\n[Paper](https://arxiv.org/pdf/2411.04905)\n\n[Hugging Face](https://huggingface.co/collections/infly/opencoder-672cec44bbb86c39910fb55e)\n\nWrite Preview \n\n<img src=\"/assets/library/opencoder/6078034f-fdbf-47c2-9b63-69ce506c0225\" width=\"280\" /> \\*\\*OpenCoder\\*\\* is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting both English and Chinese languages. Starting from scratch, OpenCoder is pretrained on 2.5 trillion tokens composed of 90% raw code and 10% code-related web data, and supervised finetuned on over 4.5M high-quality SFT examples, finally reaching the performance of top-tier code LLMs. We provide not only model weights and inference code, but also the reproducible training data, the complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols. Empowering researchers to build and innovate, OpenCoder is your open foundation for advancing code AI. - \\*\\*Complete Open Source\\*\\*: OpenCoder ensures full transparency by releasing not only the model weights and forthcoming inference code but also the complete data-cleaning code for training. This release includes high-quality synthetic data, an extensive set of checkpoints, and a dataset of over 4.5 million supervised fine-tuning (SFT) entries, making OpenCoder one of the most comprehensively open-sourced models available. - \\*\\*Comprehensive Experimental Analysis\\*\\*: OpenCoder is rigorously tested through extensive ablation studies on various data-cleaning strategies and training processes, including file-level and repository-level deduplication experiments, ensuring thorough exploration and validation of the model’s performance. - \\*\\*High-Quality Synthetic Data\\*\\*: OpenCoder provides a fully developed synthetic data generation process and over 4.5 million SFT data entries, establishing a robust data foundation for model training and evaluation. - \\*\\*Exceptional Performance\\*\\*: OpenCoder achieves high performance across multiple language model benchmarks, positioning it among the leading open-source models for code. ## References \\[GitHub\\](https://github.com/OpenCoder-llm/OpenCoder-llm) \\[Paper\\](https://arxiv.org/pdf/2411.04905) \\[Hugging Face\\](https://huggingface.co/collections/infly/opencoder-672cec44bbb86c39910fb55e) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "opencoder:latest",
        "size": "opencoder:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:1.5b",
        "size": "opencoder:1.5b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:8b",
        "size": "opencoder:8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:1.5b-instruct-q4_K_M",
        "size": "opencoder:1.5b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:1.5b-instruct-q8_0",
        "size": "opencoder:1.5b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:1.5b-instruct-fp16",
        "size": "opencoder:1.5b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:8b-instruct-q4_K_M",
        "size": "opencoder:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:8b-instruct-q8_0",
        "size": "opencoder:8b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "opencoder:8b-instruct-fp16",
        "size": "opencoder:8b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "bge-large",
    "link": "https://ollama.com/library/bge-large",
    "description": "Embedding model from BAAI mapping texts to vectors.",
    "pullCount": "128.5K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\nFlagEmbedding can map any text to a low-dimensional dense vector which can be used for tasks like retrieval, classification, clustering, or semantic search. And it also can be used in vector databases for LLMs.\n\n```\n@misc{bge_embedding,\n      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},\n      year={2023},\n      eprint={2309.07597},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n\n```\n\nWrite Preview \n\nFlagEmbedding can map any text to a low-dimensional dense vector which can be used for tasks like retrieval, classification, clustering, or semantic search. And it also can be used in vector databases for LLMs. \\`\\`\\` @misc{bge\\_embedding, title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff}, year={2023}, eprint={2309.07597}, archivePrefix={arXiv}, primaryClass={cs.CL} } \\`\\`\\` \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "bge-large:latest",
        "size": "bge-large:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bge-large:335m",
        "size": "bge-large:335m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "bge-large:335m-en-v1.5-fp16",
        "size": "bge-large:335m-en-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "stablelm2",
    "link": "https://ollama.com/library/stablelm2",
    "description": "Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",
    "pullCount": "127.8K",
    "updated": "1 year ago",
    "size": [
      "1.6b",
      "12b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/62507173-9423-4496-87ea-7d48be78979c)\n\nStable LM 2 1.6B is a state-of-the-art 1.6 and 12B billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.\n\nThe model is trained on a mix of publicly available datasets and synthetic datasets, utilizing Direct Preference Optimization (DPO).\n\n## References\n\n[Announcement](https://stability.ai/news/introducing-stable-lm-2)\n\n[HuggingFace](https://huggingface.co/stabilityai)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/62507173-9423-4496-87ea-7d48be78979c\" width=\"480\" /> Stable LM 2 1.6B is a state-of-the-art 1.6 and 12B billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch. The model is trained on a mix of publicly available datasets and synthetic datasets, utilizing Direct Preference Optimization (DPO). ## References \\[Announcement\\](https://stability.ai/news/introducing-stable-lm-2) \\[HuggingFace\\](https://huggingface.co/stabilityai) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "stablelm2:latest",
        "size": "stablelm2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:chat",
        "size": "stablelm2:chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:zephyr",
        "size": "stablelm2:zephyr",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b",
        "size": "stablelm2:1.6b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b",
        "size": "stablelm2:12b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat",
        "size": "stablelm2:1.6b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q2_K",
        "size": "stablelm2:1.6b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q3_K_S",
        "size": "stablelm2:1.6b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q3_K_M",
        "size": "stablelm2:1.6b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q3_K_L",
        "size": "stablelm2:1.6b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q4_0",
        "size": "stablelm2:1.6b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q4_1",
        "size": "stablelm2:1.6b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q4_K_S",
        "size": "stablelm2:1.6b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q4_K_M",
        "size": "stablelm2:1.6b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q5_0",
        "size": "stablelm2:1.6b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q5_1",
        "size": "stablelm2:1.6b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q5_K_S",
        "size": "stablelm2:1.6b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q5_K_M",
        "size": "stablelm2:1.6b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q6_K",
        "size": "stablelm2:1.6b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-q8_0",
        "size": "stablelm2:1.6b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-chat-fp16",
        "size": "stablelm2:1.6b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr",
        "size": "stablelm2:1.6b-zephyr",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q2_K",
        "size": "stablelm2:1.6b-zephyr-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q3_K_S",
        "size": "stablelm2:1.6b-zephyr-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q3_K_M",
        "size": "stablelm2:1.6b-zephyr-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q3_K_L",
        "size": "stablelm2:1.6b-zephyr-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q4_0",
        "size": "stablelm2:1.6b-zephyr-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q4_1",
        "size": "stablelm2:1.6b-zephyr-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q4_K_S",
        "size": "stablelm2:1.6b-zephyr-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q4_K_M",
        "size": "stablelm2:1.6b-zephyr-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q5_0",
        "size": "stablelm2:1.6b-zephyr-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q5_1",
        "size": "stablelm2:1.6b-zephyr-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q5_K_S",
        "size": "stablelm2:1.6b-zephyr-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q5_K_M",
        "size": "stablelm2:1.6b-zephyr-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q6_K",
        "size": "stablelm2:1.6b-zephyr-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-q8_0",
        "size": "stablelm2:1.6b-zephyr-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-zephyr-fp16",
        "size": "stablelm2:1.6b-zephyr-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q2_K",
        "size": "stablelm2:1.6b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q3_K_S",
        "size": "stablelm2:1.6b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q3_K_M",
        "size": "stablelm2:1.6b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q3_K_L",
        "size": "stablelm2:1.6b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q4_0",
        "size": "stablelm2:1.6b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q4_1",
        "size": "stablelm2:1.6b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q4_K_S",
        "size": "stablelm2:1.6b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q4_K_M",
        "size": "stablelm2:1.6b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q5_0",
        "size": "stablelm2:1.6b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q5_1",
        "size": "stablelm2:1.6b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q5_K_S",
        "size": "stablelm2:1.6b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q5_K_M",
        "size": "stablelm2:1.6b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q6_K",
        "size": "stablelm2:1.6b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-q8_0",
        "size": "stablelm2:1.6b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:1.6b-fp16",
        "size": "stablelm2:1.6b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat",
        "size": "stablelm2:12b-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q2_K",
        "size": "stablelm2:12b-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q3_K_S",
        "size": "stablelm2:12b-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q3_K_M",
        "size": "stablelm2:12b-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q3_K_L",
        "size": "stablelm2:12b-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q4_0",
        "size": "stablelm2:12b-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q4_1",
        "size": "stablelm2:12b-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q4_K_S",
        "size": "stablelm2:12b-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q4_K_M",
        "size": "stablelm2:12b-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q5_0",
        "size": "stablelm2:12b-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q5_1",
        "size": "stablelm2:12b-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q5_K_S",
        "size": "stablelm2:12b-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q5_K_M",
        "size": "stablelm2:12b-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q6_K",
        "size": "stablelm2:12b-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-q8_0",
        "size": "stablelm2:12b-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-chat-fp16",
        "size": "stablelm2:12b-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-text",
        "size": "stablelm2:12b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q2_K",
        "size": "stablelm2:12b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q3_K_S",
        "size": "stablelm2:12b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q3_K_M",
        "size": "stablelm2:12b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q3_K_L",
        "size": "stablelm2:12b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q4_0",
        "size": "stablelm2:12b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q4_1",
        "size": "stablelm2:12b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q4_K_S",
        "size": "stablelm2:12b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q4_K_M",
        "size": "stablelm2:12b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q5_0",
        "size": "stablelm2:12b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q5_1",
        "size": "stablelm2:12b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q5_K_S",
        "size": "stablelm2:12b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q5_K_M",
        "size": "stablelm2:12b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q6_K",
        "size": "stablelm2:12b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-q8_0",
        "size": "stablelm2:12b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm2:12b-fp16",
        "size": "stablelm2:12b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "sqlcoder",
    "link": "https://ollama.com/library/sqlcoder",
    "description": "SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks",
    "pullCount": "127.3K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "15b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://docs.defog.ai/img/logo.svg)\n\nSQLCoder is a 15B parameter model that is fine-tuned on a base StarCoder model. It slightly outperforms gpt-3.5-turbo for natural language to SQL generation tasks on the sql-eval framework, and outperforms popular open-source models. It also significantly outperforms text-davinci-003, a model that’s more than 10 times its size.\n\nThis 15B completion model generally requires at least 16GB of RAM.\n\n## Usage\n\n### CLI\n\n```\nollama run sqlcoder \n\n```\n\nTry the following prompt using triple quotes for multi-line input:\n\nNote: change the {question} to a SQL question you want to answer. Ex.) ‘which products generate the most sales.\\`\n\n```\n\"\"\" \n### Instructions:\nYour task is to convert a question into a SQL query, given a Postgres database schema.\nAdhere to these rules:\n- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\n- When creating a ratio, always cast the numerator as float\n\n### Input:\nGenerate a SQL query that answers the question `{question}`.\nThis query will run on a database whose schema is represented in this string:\nCREATE TABLE products (\n  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n  name VARCHAR(50), -- Name of the product\n  price DECIMAL(10,2), -- Price of each unit of the product\n  quantity INTEGER  -- Current quantity in stock\n);\n\nCREATE TABLE customers (\n   customer_id INTEGER PRIMARY KEY, -- Unique ID for each customer\n   name VARCHAR(50), -- Name of the customer\n   address VARCHAR(100) -- Mailing address of the customer\n);\n\nCREATE TABLE salespeople (\n  salesperson_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson\n  name VARCHAR(50), -- Name of the salesperson\n  region VARCHAR(50) -- Geographic sales region\n);\n\nCREATE TABLE sales (\n  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n  product_id INTEGER, -- ID of product sold\n  customer_id INTEGER,  -- ID of customer who made purchase\n  salesperson_id INTEGER, -- ID of salesperson who made the sale\n  sale_date DATE, -- Date the sale occurred\n  quantity INTEGER -- Quantity of product sold\n);\n\nCREATE TABLE product_suppliers (\n  supplier_id INTEGER PRIMARY KEY, -- Unique ID for each supplier\n  product_id INTEGER, -- Product ID supplied\n  supply_price DECIMAL(10,2) -- Unit price charged by supplier\n);\n\n-- sales.product_id can be joined with products.product_id\n-- sales.customer_id can be joined with customers.customer_id\n-- sales.salesperson_id can be joined with salespeople.salesperson_id\n-- product_suppliers.product_id can be joined with products.product_id\n\n### Response:\nBased on your instructions, here is the SQL query I have generated to answer the question `{question}`:\n```sql\n\"\"\"\n\n```\n\n**Example output:**\n\n```\nSELECT customers.customer_id,\n       products.product_id,\n       (SUM(sales.quantity * product_suppliers.supply_price)) / (SELECT \nSUM(quantity)\n                                                                FROM sales\n                                                                WHERE \nsales.salesperson_id = '{chosen_salesperson}') as profit\nFROM   sales\n  INNER JOIN customers on sales.customer_id = customers.customer_id\n  INNER JOIN products on sales.product_id = products.product_id\n  INNER JOIN product_suppliers on products.product_id = \nproduct_suppliers.product_id\nWHERE  sales.salesperson_id = '{chosen_salesperson}'\nGROUP BY customers.customer_id, products.product_id\nHAVING COUNT(DISTINCT sales.sale_date) >= {min_days}\n  AND (SELECT SUM(quantity * product_suppliers.supply_price)\n     FROM   sales\n     WHERE  sales.salesperson_id = '{chosen_salesperson}'\n        and sales.customer_id = customers.customer_id\n        and sales.product_id = products.product_id) >= {min_total}\nORDER BY profit DESC;\n```\n\n\n### Reasoning\n\nThe query is broken down into two parts: the first one fetches information\nabout each sale made by a specific salesman (`{chosen_salesperson}`), and \ngroups it by customer ID, product ID, and calculates how much money was \nearned from each sale. The second part then filters out these results that\noccurred after a certain number of days (determined by the variable \n`min_days`) and had an amount of money equal to or more than a certain \nvalue (determined by the variable `min_total`). Finally, the query orders \nthe results in descending order based on the ratio between earned money \nand total money.\n\nThe first part relies on several tables from the database: salespeople, \nproducts, customers, sales, and product_suppliers. The salespeople table \ncontains information about each salesperson's ID; the products table \ncontains information about each product's name and price; the customers \ntable contains information about each customer's address; the sales table \ncontains information about each sale, including the quantity sold, the ID \nof the product sold, and the ID of the customer who made the purchase; and\nthe product_suppliers table contains information about the unit price \ncharged by each supplier.\n\nThe variables in the query can be interpreted as follows:\n\n- `{chosen_salesperson}` is a placeholder for the name of the salesman \nwhose performance is being evaluated. This value should be replaced with \nan actual salesman's name or ID number.\n- `min_days` is the minimum number of days that must have passed since the\nsale in order to qualify for inclusion in the calculation. For example, if\nthis variable were set to 30, then only sales made 30 days after the start\ndate would be included in the calculation. This value should also be \nreplaced with an integer representing the minimum number of days.\n- `min_total` is a threshold amount that must have been earned by the \nsalesman for the sale to qualify for inclusion in the calculation. For \nexample, if this variable were set to 1000, then only sales worth at least\n$1000 would be included in the calculation. This value should also be \nreplaced with an integer representing the minimum amount of money that \nmust have been earned.\n\nThe output is a table containing three columns: customer ID, product ID, \nand profit per unit price (calculated as the total money earned divided by\nthe quantity sold). The rows in this table are sorted in descending order \nbased on the ratio between earned money and total money. Rows that don't \nmeet both of these conditions will be dropped from the output.\n\n## Example\n\n```\nInput:\nmin_days = 30\nmin_total = 1000\nchosen_salesperson = '<NAME>'\n\nOutput:\n  customer_id | product_id |         profit\n-------------+----------------------------+-----------------\n  987         |     456    | 2.1             \n  1029        |    1357    | 1.91            \n  89          |    1234    | 0.59            \n```\n\n## License\n\nThe database is released under the [Open Database \nLicense](https://opendatacommons.org/licenses/odbl/1-0/).\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/defog/sqlcoder)\n\nWrite Preview \n\n<img src=\"https://docs.defog.ai/img/logo.svg\" width=\"330px\" /> SQLCoder is a 15B parameter model that is fine-tuned on a base StarCoder model. It slightly outperforms gpt-3.5-turbo for natural language to SQL generation tasks on the sql-eval framework, and outperforms popular open-source models. It also significantly outperforms text-davinci-003, a model that's more than 10 times its size. This 15B completion model generally requires at least 16GB of RAM. ## Usage ### CLI \\`\\`\\` ollama run sqlcoder \\`\\`\\` Try the following prompt using triple quotes for multi-line input: Note: change the {question} to a SQL question you want to answer. Ex.) 'which products generate the most sales.\\` \\`\\`\\` \"\"\" ### Instructions: Your task is to convert a question into a SQL query, given a Postgres database schema. Adhere to these rules: - \\*\\*Deliberately go through the question and database schema word by word\\*\\* to appropriately answer the question - \\*\\*Use Table Aliases\\*\\* to prevent ambiguity. For example, \\`SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id\\`. - When creating a ratio, always cast the numerator as float ### Input: Generate a SQL query that answers the question \\`{question}\\`. This query will run on a database whose schema is represented in this string: CREATE TABLE products ( product\\_id INTEGER PRIMARY KEY, -- Unique ID for each product name VARCHAR(50), -- Name of the product price DECIMAL(10,2), -- Price of each unit of the product quantity INTEGER -- Current quantity in stock ); CREATE TABLE customers ( customer\\_id INTEGER PRIMARY KEY, -- Unique ID for each customer name VARCHAR(50), -- Name of the customer address VARCHAR(100) -- Mailing address of the customer ); CREATE TABLE salespeople ( salesperson\\_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson name VARCHAR(50), -- Name of the salesperson region VARCHAR(50) -- Geographic sales region ); CREATE TABLE sales ( sale\\_id INTEGER PRIMARY KEY, -- Unique ID for each sale product\\_id INTEGER, -- ID of product sold customer\\_id INTEGER, -- ID of customer who made purchase salesperson\\_id INTEGER, -- ID of salesperson who made the sale sale\\_date DATE, -- Date the sale occurred quantity INTEGER -- Quantity of product sold ); CREATE TABLE product\\_suppliers ( supplier\\_id INTEGER PRIMARY KEY, -- Unique ID for each supplier product\\_id INTEGER, -- Product ID supplied supply\\_price DECIMAL(10,2) -- Unit price charged by supplier ); -- sales.product\\_id can be joined with products.product\\_id -- sales.customer\\_id can be joined with customers.customer\\_id -- sales.salesperson\\_id can be joined with salespeople.salesperson\\_id -- product\\_suppliers.product\\_id can be joined with products.product\\_id ### Response: Based on your instructions, here is the SQL query I have generated to answer the question \\`{question}\\`: \\`\\`\\`sql \"\"\" \\`\\`\\` \\*\\*Example output:\\*\\* \\`\\`\\`\\` SELECT customers.customer\\_id, products.product\\_id, (SUM(sales.quantity \\* product\\_suppliers.supply\\_price)) / (SELECT SUM(quantity) FROM sales WHERE sales.salesperson\\_id = '{chosen\\_salesperson}') as profit FROM sales INNER JOIN customers on sales.customer\\_id = customers.customer\\_id INNER JOIN products on sales.product\\_id = products.product\\_id INNER JOIN product\\_suppliers on products.product\\_id = product\\_suppliers.product\\_id WHERE sales.salesperson\\_id = '{chosen\\_salesperson}' GROUP BY customers.customer\\_id, products.product\\_id HAVING COUNT(DISTINCT sales.sale\\_date) >= {min\\_days} AND (SELECT SUM(quantity \\* product\\_suppliers.supply\\_price) FROM sales WHERE sales.salesperson\\_id = '{chosen\\_salesperson}' and sales.customer\\_id = customers.customer\\_id and sales.product\\_id = products.product\\_id) >= {min\\_total} ORDER BY profit DESC; \\`\\`\\` ### Reasoning The query is broken down into two parts: the first one fetches information about each sale made by a specific salesman (\\`{chosen\\_salesperson}\\`), and groups it by customer ID, product ID, and calculates how much money was earned from each sale. The second part then filters out these results that occurred after a certain number of days (determined by the variable \\`min\\_days\\`) and had an amount of money equal to or more than a certain value (determined by the variable \\`min\\_total\\`). Finally, the query orders the results in descending order based on the ratio between earned money and total money. The first part relies on several tables from the database: salespeople, products, customers, sales, and product\\_suppliers. The salespeople table contains information about each salesperson's ID; the products table contains information about each product's name and price; the customers table contains information about each customer's address; the sales table contains information about each sale, including the quantity sold, the ID of the product sold, and the ID of the customer who made the purchase; and the product\\_suppliers table contains information about the unit price charged by each supplier. The variables in the query can be interpreted as follows: - \\`{chosen\\_salesperson}\\` is a placeholder for the name of the salesman whose performance is being evaluated. This value should be replaced with an actual salesman's name or ID number. - \\`min\\_days\\` is the minimum number of days that must have passed since the sale in order to qualify for inclusion in the calculation. For example, if this variable were set to 30, then only sales made 30 days after the start date would be included in the calculation. This value should also be replaced with an integer representing the minimum number of days. - \\`min\\_total\\` is a threshold amount that must have been earned by the salesman for the sale to qualify for inclusion in the calculation. For example, if this variable were set to 1000, then only sales worth at least $1000 would be included in the calculation. This value should also be replaced with an integer representing the minimum amount of money that must have been earned. The output is a table containing three columns: customer ID, product ID, and profit per unit price (calculated as the total money earned divided by the quantity sold). The rows in this table are sorted in descending order based on the ratio between earned money and total money. Rows that don't meet both of these conditions will be dropped from the output. ## Example \\`\\`\\` Input: min\\_days = 30 min\\_total = 1000 chosen\\_salesperson = '<NAME>' Output: customer\\_id | product\\_id | profit -------------+----------------------------+----------------- 987 | 456 | 2.1 1029 | 1357 | 1.91 89 | 1234 | 0.59 \\`\\`\\` ## License The database is released under the \\[Open Database License\\](https://opendatacommons.org/licenses/odbl/1-0/). \\`\\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/defog/sqlcoder) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "sqlcoder:latest",
        "size": "sqlcoder:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b",
        "size": "sqlcoder:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b",
        "size": "sqlcoder:15b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q2_K",
        "size": "sqlcoder:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q3_K_S",
        "size": "sqlcoder:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q3_K_M",
        "size": "sqlcoder:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q3_K_L",
        "size": "sqlcoder:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q4_0",
        "size": "sqlcoder:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q4_1",
        "size": "sqlcoder:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q4_K_S",
        "size": "sqlcoder:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q4_K_M",
        "size": "sqlcoder:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q5_0",
        "size": "sqlcoder:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q5_1",
        "size": "sqlcoder:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q5_K_S",
        "size": "sqlcoder:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q5_K_M",
        "size": "sqlcoder:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q6_K",
        "size": "sqlcoder:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-q8_0",
        "size": "sqlcoder:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:7b-fp16",
        "size": "sqlcoder:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q2_K",
        "size": "sqlcoder:15b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q3_K_S",
        "size": "sqlcoder:15b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q3_K_M",
        "size": "sqlcoder:15b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q3_K_L",
        "size": "sqlcoder:15b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q4_0",
        "size": "sqlcoder:15b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q4_1",
        "size": "sqlcoder:15b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q4_K_S",
        "size": "sqlcoder:15b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q4_K_M",
        "size": "sqlcoder:15b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q5_0",
        "size": "sqlcoder:15b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q5_1",
        "size": "sqlcoder:15b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q5_K_S",
        "size": "sqlcoder:15b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q5_K_M",
        "size": "sqlcoder:15b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q6_K",
        "size": "sqlcoder:15b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-q8_0",
        "size": "sqlcoder:15b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:15b-fp16",
        "size": "sqlcoder:15b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q2_K",
        "size": "sqlcoder:70b-alpha-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q3_K_S",
        "size": "sqlcoder:70b-alpha-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q3_K_M",
        "size": "sqlcoder:70b-alpha-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q3_K_L",
        "size": "sqlcoder:70b-alpha-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q4_0",
        "size": "sqlcoder:70b-alpha-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q4_1",
        "size": "sqlcoder:70b-alpha-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q4_K_S",
        "size": "sqlcoder:70b-alpha-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q4_K_M",
        "size": "sqlcoder:70b-alpha-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q5_0",
        "size": "sqlcoder:70b-alpha-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q5_1",
        "size": "sqlcoder:70b-alpha-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q5_K_S",
        "size": "sqlcoder:70b-alpha-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q5_K_M",
        "size": "sqlcoder:70b-alpha-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q6_K",
        "size": "sqlcoder:70b-alpha-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-q8_0",
        "size": "sqlcoder:70b-alpha-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "sqlcoder:70b-alpha-fp16",
        "size": "sqlcoder:70b-alpha-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama3-chatqa",
    "link": "https://ollama.com/library/llama3-chatqa",
    "description": "A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG).",
    "pullCount": "122.5K",
    "updated": "1 year ago",
    "size": [
      "8b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/llama3-chatqa/835859df-86ec-4859-aab8-c5d6b7195b7c)\n\nChatQA-1.5 is built on top of the Llama-3 base model, and incorporates conversational QA data to enhance its tabular and arithmetic calculation capability.\n\nChatQA-1.5 has two variants:\n\n* Llama3-ChatQA-1.5-8B `llama3-chatqa:8b`\n* Llama3-ChatQA-1.5-70B `llama3-chatqa:70b`\n\n## References\n\n[Website](https://chatqa-project.github.io/)\n\n[Hugging Face](https://huggingface.co/nvidia/Llama3-ChatQA-1.5-70B)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/llama3-chatqa/835859df-86ec-4859-aab8-c5d6b7195b7c\" width=\"320\" /> ChatQA-1.5 is built on top of the Llama-3 base model, and incorporates conversational QA data to enhance its tabular and arithmetic calculation capability. ChatQA-1.5 has two variants: - Llama3-ChatQA-1.5-8B \\`llama3-chatqa:8b\\` - Llama3-ChatQA-1.5-70B \\`llama3-chatqa:70b\\` ## References \\[Website\\](https://chatqa-project.github.io/) \\[Hugging Face\\](https://huggingface.co/nvidia/Llama3-ChatQA-1.5-70B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3-chatqa:latest",
        "size": "llama3-chatqa:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b",
        "size": "llama3-chatqa:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b",
        "size": "llama3-chatqa:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5",
        "size": "llama3-chatqa:8b-v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q2_K",
        "size": "llama3-chatqa:8b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q3_K_S",
        "size": "llama3-chatqa:8b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q3_K_M",
        "size": "llama3-chatqa:8b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q3_K_L",
        "size": "llama3-chatqa:8b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q4_0",
        "size": "llama3-chatqa:8b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q4_1",
        "size": "llama3-chatqa:8b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q4_K_S",
        "size": "llama3-chatqa:8b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q4_K_M",
        "size": "llama3-chatqa:8b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q5_0",
        "size": "llama3-chatqa:8b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q5_1",
        "size": "llama3-chatqa:8b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q5_K_S",
        "size": "llama3-chatqa:8b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q5_K_M",
        "size": "llama3-chatqa:8b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q6_K",
        "size": "llama3-chatqa:8b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-q8_0",
        "size": "llama3-chatqa:8b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:8b-v1.5-fp16",
        "size": "llama3-chatqa:8b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5",
        "size": "llama3-chatqa:70b-v1.5",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q2_K",
        "size": "llama3-chatqa:70b-v1.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q3_K_S",
        "size": "llama3-chatqa:70b-v1.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q3_K_M",
        "size": "llama3-chatqa:70b-v1.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q3_K_L",
        "size": "llama3-chatqa:70b-v1.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q4_0",
        "size": "llama3-chatqa:70b-v1.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q4_1",
        "size": "llama3-chatqa:70b-v1.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q4_K_S",
        "size": "llama3-chatqa:70b-v1.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q4_K_M",
        "size": "llama3-chatqa:70b-v1.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q5_0",
        "size": "llama3-chatqa:70b-v1.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q5_1",
        "size": "llama3-chatqa:70b-v1.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q5_K_S",
        "size": "llama3-chatqa:70b-v1.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q5_K_M",
        "size": "llama3-chatqa:70b-v1.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q6_K",
        "size": "llama3-chatqa:70b-v1.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-q8_0",
        "size": "llama3-chatqa:70b-v1.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-chatqa:70b-v1.5-fp16",
        "size": "llama3-chatqa:70b-v1.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llava-phi3",
    "link": "https://ollama.com/library/llava-phi3",
    "description": "A new small LLaVA model fine-tuned from Phi 3 Mini.",
    "pullCount": "121.1K",
    "updated": "1 year ago",
    "size": [
      "3.8b"
    ],
    "capabilities": "vision",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/llava-llama3/dc3b65cd-62de-45cd-93f9-5c6da62214fa)\n\n`llava-phi3` is a LLaVA model fine-tuned from Phi 3 Mini 4k, with strong performance benchmarks on par with the original LLaVA model:\n\n![](https://ollama.com/assets/library/llava-phi3/c6ad7ff5-28e3-4ff8-9469-92ae66517b88)\n\n## References\n\n[Hugging Face](https://huggingface.co/xtuner/llava-phi-3-mini-gguf)\n\n[GitHub](https://github.com/InternLM/xtuner/tree/main)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/llava-llama3/dc3b65cd-62de-45cd-93f9-5c6da62214fa\" width=\"320\" /> \\`llava-phi3\\` is a LLaVA model fine-tuned from Phi 3 Mini 4k, with strong performance benchmarks on par with the original LLaVA model: <img src=\"https://ollama.com/assets/library/llava-phi3/c6ad7ff5-28e3-4ff8-9469-92ae66517b88\" width=\"400\" /> ## References \\[Hugging Face\\](https://huggingface.co/xtuner/llava-phi-3-mini-gguf) \\[GitHub\\](https://github.com/InternLM/xtuner/tree/main) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llava-phi3:latest",
        "size": "llava-phi3:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava-phi3:3.8b",
        "size": "llava-phi3:3.8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava-phi3:3.8b-mini-q4_0",
        "size": "llava-phi3:3.8b-mini-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llava-phi3:3.8b-mini-fp16",
        "size": "llava-phi3:3.8b-mini-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "yi-coder",
    "link": "https://ollama.com/library/yi-coder",
    "description": "Yi-Coder is a series of open-source code language models that delivers state-of-the-art coding performance with fewer than 10 billion parameters.",
    "pullCount": "119.2K",
    "updated": "12 months ago",
    "size": [
      "1.5b",
      "9b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/yi-coder/8bca5a55-79c7-4012-9d9b-371722b67d85)\n\nYi-Coder is excelling in long-context understanding with a maximum context length of 128K tokens. It supports 52 major programming languages.\n\n## Sizes\n\n* 9B: `ollama run yi-coder:9b`\n* 1.5B: `ollama run yi-coder:1.5b`\n\n## Usage\n\n### Chat\n\n```\nollama run yi-coder\n\n```\n\n### Code completion\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"yi-coder\",\n  \"prompt\": \"def compute_gcd(a, b):\",\n  \"suffix\": \"    return result\",\n  \"options\": {\n    \"temperature\": 0\n  },\n  \"stream\": false\n}'\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/01-ai/Yi-Coder-9B-Chat)\n\n[GitHub](https://github.com/01-ai/Yi-Coder)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/yi-coder/8bca5a55-79c7-4012-9d9b-371722b67d85\" width=\"200\" /> Yi-Coder is excelling in long-context understanding with a maximum context length of 128K tokens. It supports 52 major programming languages. ## Sizes - 9B: \\`ollama run yi-coder:9b\\` - 1.5B: \\`ollama run yi-coder:1.5b\\` ## Usage ### Chat \\`\\`\\` ollama run yi-coder \\`\\`\\` ### Code completion \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"yi-coder\", \"prompt\": \"def compute\\_gcd(a, b):\", \"suffix\": \" return result\", \"options\": { \"temperature\": 0 }, \"stream\": false }' \\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/01-ai/Yi-Coder-9B-Chat) \\[GitHub\\](https://github.com/01-ai/Yi-Coder) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "yi-coder:latest",
        "size": "yi-coder:latest",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b",
        "size": "yi-coder:1.5b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b",
        "size": "yi-coder:9b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-base",
        "size": "yi-coder:1.5b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q2_K",
        "size": "yi-coder:1.5b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q3_K_S",
        "size": "yi-coder:1.5b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q3_K_M",
        "size": "yi-coder:1.5b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q3_K_L",
        "size": "yi-coder:1.5b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q4_0",
        "size": "yi-coder:1.5b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q4_1",
        "size": "yi-coder:1.5b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q4_K_S",
        "size": "yi-coder:1.5b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q4_K_M",
        "size": "yi-coder:1.5b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q5_0",
        "size": "yi-coder:1.5b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q5_1",
        "size": "yi-coder:1.5b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q5_K_S",
        "size": "yi-coder:1.5b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q5_K_M",
        "size": "yi-coder:1.5b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q6_K",
        "size": "yi-coder:1.5b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-q8_0",
        "size": "yi-coder:1.5b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-base-fp16",
        "size": "yi-coder:1.5b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:1.5b-chat",
        "size": "yi-coder:1.5b-chat",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q2_K",
        "size": "yi-coder:1.5b-chat-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q3_K_S",
        "size": "yi-coder:1.5b-chat-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q3_K_M",
        "size": "yi-coder:1.5b-chat-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q3_K_L",
        "size": "yi-coder:1.5b-chat-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q4_0",
        "size": "yi-coder:1.5b-chat-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q4_1",
        "size": "yi-coder:1.5b-chat-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q4_K_S",
        "size": "yi-coder:1.5b-chat-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q4_K_M",
        "size": "yi-coder:1.5b-chat-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q5_0",
        "size": "yi-coder:1.5b-chat-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q5_1",
        "size": "yi-coder:1.5b-chat-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q5_K_S",
        "size": "yi-coder:1.5b-chat-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q5_K_M",
        "size": "yi-coder:1.5b-chat-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q6_K",
        "size": "yi-coder:1.5b-chat-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-q8_0",
        "size": "yi-coder:1.5b-chat-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:1.5b-chat-fp16",
        "size": "yi-coder:1.5b-chat-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-base",
        "size": "yi-coder:9b-base",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q2_K",
        "size": "yi-coder:9b-base-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q3_K_S",
        "size": "yi-coder:9b-base-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q3_K_M",
        "size": "yi-coder:9b-base-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q3_K_L",
        "size": "yi-coder:9b-base-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q4_0",
        "size": "yi-coder:9b-base-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q4_1",
        "size": "yi-coder:9b-base-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q4_K_S",
        "size": "yi-coder:9b-base-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q4_K_M",
        "size": "yi-coder:9b-base-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q5_0",
        "size": "yi-coder:9b-base-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q5_1",
        "size": "yi-coder:9b-base-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q5_K_S",
        "size": "yi-coder:9b-base-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q5_K_M",
        "size": "yi-coder:9b-base-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q6_K",
        "size": "yi-coder:9b-base-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-q8_0",
        "size": "yi-coder:9b-base-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-base-fp16",
        "size": "yi-coder:9b-base-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yi-coder:9b-chat",
        "size": "yi-coder:9b-chat",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q2_K",
        "size": "yi-coder:9b-chat-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q3_K_S",
        "size": "yi-coder:9b-chat-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q3_K_M",
        "size": "yi-coder:9b-chat-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q3_K_L",
        "size": "yi-coder:9b-chat-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q4_0",
        "size": "yi-coder:9b-chat-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q4_1",
        "size": "yi-coder:9b-chat-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q4_K_S",
        "size": "yi-coder:9b-chat-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q4_K_M",
        "size": "yi-coder:9b-chat-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q5_0",
        "size": "yi-coder:9b-chat-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q5_1",
        "size": "yi-coder:9b-chat-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q5_K_S",
        "size": "yi-coder:9b-chat-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q5_K_M",
        "size": "yi-coder:9b-chat-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q6_K",
        "size": "yi-coder:9b-chat-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-q8_0",
        "size": "yi-coder:9b-chat-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "yi-coder:9b-chat-fp16",
        "size": "yi-coder:9b-chat-fp16",
        "updated": "Text input • \n                    12 months ago"
      }
    ]
  },
  {
    "name": "granite3.1-dense",
    "link": "https://ollama.com/library/granite3.1-dense",
    "description": "The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM’s initial testing.",
    "pullCount": "116.5K",
    "updated": "7 months ago",
    "size": [
      "2b",
      "8b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n## Granite dense models\n\nThe IBM Granite **2B** and **8B** models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM’s initial testing.\n\n**They are designed to support tool-based use cases** and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.\n\n### Parameter Sizes\n\n**2B:**\n\n`ollama run granite3.1-dense:2b`\n\n**8B:**\n\n`ollama run granite3.1-dense:8b`\n\n### Supported Languages\n\nEnglish, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified)\n\n### Capabilities\n\n* Summarization\n* Text classification\n* Text extraction\n* Question-answering\n* Retrieval Augmented Generation (RAG)\n* Code related tasks\n* Function-calling tasks\n* Multilingual dialog use cases\n* Long-context tasks including long document/meeting summarization, long document QA, etc.\n\n## Granite mixture of experts models\n\nThe Granite mixture of experts models are available in **1B and 3B** parameter sizes designed for **low latency usage**.\n\n[See model page](https://ollama.com/library/granite3-moe)\n\n## Learn more\n\n* **Developers:** IBM Research\n* **GitHub Repository:** [ibm-granite/granite-language-models](https://github.com/ibm-granite/granite-3.1-language-models)\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: December 18th, 2024\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\nWrite Preview \n\n\\## Granite dense models The IBM Granite \\*\\*2B\\*\\* and \\*\\*8B\\*\\* models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM's initial testing. \\*\\*They are designed to support tool-based use cases\\*\\* and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. ### Parameter Sizes \\*\\*2B:\\*\\* \\`ollama run granite3.1-dense:2b\\` \\*\\*8B:\\*\\* \\`ollama run granite3.1-dense:8b\\` ### Supported Languages English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified) ### Capabilities \\* Summarization \\* Text classification \\* Text extraction \\* Question-answering \\* Retrieval Augmented Generation (RAG) \\* Code related tasks \\* Function-calling tasks \\* Multilingual dialog use cases \\* Long-context tasks including long document/meeting summarization, long document QA, etc. ## Granite mixture of experts models The Granite mixture of experts models are available in \\*\\*1B and 3B\\*\\* parameter sizes designed for \\*\\*low latency usage\\*\\*. \\[See model page\\](https://ollama.com/library/granite3-moe) ## Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*GitHub Repository:\\*\\* \\[ibm-granite/granite-language-models\\](https://github.com/ibm-granite/granite-3.1-language-models) - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: December 18th, 2024 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0). \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3.1-dense:latest",
        "size": "granite3.1-dense:latest",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b",
        "size": "granite3.1-dense:2b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b",
        "size": "granite3.1-dense:8b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q2_K",
        "size": "granite3.1-dense:2b-instruct-q2_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q3_K_S",
        "size": "granite3.1-dense:2b-instruct-q3_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q3_K_M",
        "size": "granite3.1-dense:2b-instruct-q3_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q3_K_L",
        "size": "granite3.1-dense:2b-instruct-q3_K_L",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q4_0",
        "size": "granite3.1-dense:2b-instruct-q4_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q4_1",
        "size": "granite3.1-dense:2b-instruct-q4_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q4_K_S",
        "size": "granite3.1-dense:2b-instruct-q4_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q4_K_M",
        "size": "granite3.1-dense:2b-instruct-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q5_0",
        "size": "granite3.1-dense:2b-instruct-q5_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q5_1",
        "size": "granite3.1-dense:2b-instruct-q5_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q5_K_S",
        "size": "granite3.1-dense:2b-instruct-q5_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q5_K_M",
        "size": "granite3.1-dense:2b-instruct-q5_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q6_K",
        "size": "granite3.1-dense:2b-instruct-q6_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-q8_0",
        "size": "granite3.1-dense:2b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-dense:2b-instruct-fp16",
        "size": "granite3.1-dense:2b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q2_K",
        "size": "granite3.1-dense:8b-instruct-q2_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q3_K_S",
        "size": "granite3.1-dense:8b-instruct-q3_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q3_K_M",
        "size": "granite3.1-dense:8b-instruct-q3_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q3_K_L",
        "size": "granite3.1-dense:8b-instruct-q3_K_L",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q4_0",
        "size": "granite3.1-dense:8b-instruct-q4_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q4_1",
        "size": "granite3.1-dense:8b-instruct-q4_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q4_K_S",
        "size": "granite3.1-dense:8b-instruct-q4_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q4_K_M",
        "size": "granite3.1-dense:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q5_0",
        "size": "granite3.1-dense:8b-instruct-q5_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q5_1",
        "size": "granite3.1-dense:8b-instruct-q5_1",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q5_K_S",
        "size": "granite3.1-dense:8b-instruct-q5_K_S",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q5_K_M",
        "size": "granite3.1-dense:8b-instruct-q5_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q6_K",
        "size": "granite3.1-dense:8b-instruct-q6_K",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-q8_0",
        "size": "granite3.1-dense:8b-instruct-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite3.1-dense:8b-instruct-fp16",
        "size": "granite3.1-dense:8b-instruct-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "granite3-dense",
    "link": "https://ollama.com/library/granite3-dense",
    "description": "The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.",
    "pullCount": "116.4K",
    "updated": "9 months ago",
    "size": [
      "2b",
      "8b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![An illustration of Ollama holding a beautiful flower with the IBM Rebus logo of the Eye, Bee and M, made by Paul Rand.](https://ollama.com/assets/library/granite3-dense/e2955da9-fee8-45d1-81ed-fe313f4e83eb)\n\n### Granite dense models\n\nThe IBM Granite **2B** and **8B** models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM’s initial testing. Granite-8B-Instruct now rivals Llama 3.1 8B-Instruct across both OpenLLM Leaderboard v1 and OpenLLM Leaderboard v2 benchmarks.\n\n**They are designed to support tool-based use cases** and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.\n\n## Parameter Sizes\n\n**2B:**\n\n`ollama run granite3-dense:2b`\n\n**8B:**\n\n`ollama run granite3-dense:8b`\n\n## Supported Languages\n\nEnglish, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified)\n\n### Capabilities\n\n* Summarization\n* Text classification\n* Text extraction\n* Question-answering\n* Retrieval Augmented Generation (RAG)\n* Code related\n* Function-calling\n* Multilingual dialog use cases\n\n### Granite mixture of experts models\n\nThe Granite mixture of experts models are available in **1B and 3B** parameter sizes designed for **low latency usage**.\n\n[See model page](https://ollama.com/library/granite3-moe)\n\n### Learn more\n\n* **Developers:** IBM Research\n* **GitHub Repository:** [ibm-granite/granite-3.0-language-models](https://github.com/ibm-granite/granite-3.0-language-models)\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: October 21st, 2024\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\nWrite Preview \n\n!\\[An illustration of Ollama holding a beautiful flower with the IBM Rebus logo of the Eye, Bee and M, made by Paul Rand.\\](https://ollama.com/assets/library/granite3-dense/e2955da9-fee8-45d1-81ed-fe313f4e83eb) ### Granite dense models The IBM Granite \\*\\*2B\\*\\* and \\*\\*8B\\*\\* models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM's initial testing. Granite-8B-Instruct now rivals Llama 3.1 8B-Instruct across both OpenLLM Leaderboard v1 and OpenLLM Leaderboard v2 benchmarks. \\*\\*They are designed to support tool-based use cases\\*\\* and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. ## Parameter Sizes \\*\\*2B:\\*\\* \\`ollama run granite3-dense:2b\\` \\*\\*8B:\\*\\* \\`ollama run granite3-dense:8b\\` ## Supported Languages English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified) ### Capabilities \\* Summarization \\* Text classification \\* Text extraction \\* Question-answering \\* Retrieval Augmented Generation (RAG) \\* Code related \\* Function-calling \\* Multilingual dialog use cases ### Granite mixture of experts models The Granite mixture of experts models are available in \\*\\*1B and 3B\\*\\* parameter sizes designed for \\*\\*low latency usage\\*\\*. \\[See model page\\](https://ollama.com/library/granite3-moe) ### Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*GitHub Repository:\\*\\* \\[ibm-granite/granite-3.0-language-models\\](https://github.com/ibm-granite/granite-3.0-language-models) - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: October 21st, 2024 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0). \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3-dense:latest",
        "size": "granite3-dense:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b",
        "size": "granite3-dense:2b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b",
        "size": "granite3-dense:8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q2_K",
        "size": "granite3-dense:2b-instruct-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q3_K_S",
        "size": "granite3-dense:2b-instruct-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q3_K_M",
        "size": "granite3-dense:2b-instruct-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q3_K_L",
        "size": "granite3-dense:2b-instruct-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q4_0",
        "size": "granite3-dense:2b-instruct-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q4_1",
        "size": "granite3-dense:2b-instruct-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q4_K_S",
        "size": "granite3-dense:2b-instruct-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q4_K_M",
        "size": "granite3-dense:2b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q5_0",
        "size": "granite3-dense:2b-instruct-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q5_1",
        "size": "granite3-dense:2b-instruct-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q5_K_S",
        "size": "granite3-dense:2b-instruct-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q5_K_M",
        "size": "granite3-dense:2b-instruct-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q6_K",
        "size": "granite3-dense:2b-instruct-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-q8_0",
        "size": "granite3-dense:2b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:2b-instruct-fp16",
        "size": "granite3-dense:2b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q2_K",
        "size": "granite3-dense:8b-instruct-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q3_K_S",
        "size": "granite3-dense:8b-instruct-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q3_K_M",
        "size": "granite3-dense:8b-instruct-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q3_K_L",
        "size": "granite3-dense:8b-instruct-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q4_0",
        "size": "granite3-dense:8b-instruct-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q4_1",
        "size": "granite3-dense:8b-instruct-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q4_K_S",
        "size": "granite3-dense:8b-instruct-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q4_K_M",
        "size": "granite3-dense:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q5_0",
        "size": "granite3-dense:8b-instruct-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q5_1",
        "size": "granite3-dense:8b-instruct-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q5_K_S",
        "size": "granite3-dense:8b-instruct-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q5_K_M",
        "size": "granite3-dense:8b-instruct-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q6_K",
        "size": "granite3-dense:8b-instruct-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-q8_0",
        "size": "granite3-dense:8b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-dense:8b-instruct-fp16",
        "size": "granite3-dense:8b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "wizard-math",
    "link": "https://ollama.com/library/wizard-math",
    "description": "Model focused on math and logic problems",
    "pullCount": "116.3K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/263121166-8b16834a-1da2-4a68-8aac-13d19775e7d7.png)\n\n> Now updated to WizardMath 7B v1.1: `ollama pull wizard-math`. This new version is trained from Mistral-7B and achieves even higher benchmark scores than previous versions.\n\nWizardMath was released by WizardLM. It is trained on the GSM8k dataset, and targeted at math questions. It is available in 7B, 13B, and 70B parameter sizes.\n\n## Example prompt\n\n```\nHow many 4-digit numbers have the last digit equal to the sum of the first two digits?\n\n```\n\n**References**\n\n[HuggingFace](https://huggingface.co/WizardLM/WizardMath-7B-V1.0)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/263121166-8b16834a-1da2-4a68-8aac-13d19775e7d7.png\" style=\"max-width:60%\" /> > Now updated to WizardMath 7B v1.1: \\`ollama pull wizard-math\\`. This new version is trained from Mistral-7B and achieves even higher benchmark scores than previous versions. WizardMath was released by WizardLM. It is trained on the GSM8k dataset, and targeted at math questions. It is available in 7B, 13B, and 70B parameter sizes. ## Example prompt \\`\\`\\` How many 4-digit numbers have the last digit equal to the sum of the first two digits? \\`\\`\\` \\*\\*References\\*\\* \\[HuggingFace\\](https://huggingface.co/WizardLM/WizardMath-7B-V1.0) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizard-math:latest",
        "size": "wizard-math:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b",
        "size": "wizard-math:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b",
        "size": "wizard-math:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b",
        "size": "wizard-math:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q2_K",
        "size": "wizard-math:7b-v1.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q3_K_S",
        "size": "wizard-math:7b-v1.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q3_K_M",
        "size": "wizard-math:7b-v1.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q3_K_L",
        "size": "wizard-math:7b-v1.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q4_0",
        "size": "wizard-math:7b-v1.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q4_1",
        "size": "wizard-math:7b-v1.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q4_K_S",
        "size": "wizard-math:7b-v1.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q4_K_M",
        "size": "wizard-math:7b-v1.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q5_0",
        "size": "wizard-math:7b-v1.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q5_1",
        "size": "wizard-math:7b-v1.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q5_K_S",
        "size": "wizard-math:7b-v1.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q5_K_M",
        "size": "wizard-math:7b-v1.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q6_K",
        "size": "wizard-math:7b-v1.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-q8_0",
        "size": "wizard-math:7b-v1.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-v1.1-fp16",
        "size": "wizard-math:7b-v1.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q2_K",
        "size": "wizard-math:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q3_K_S",
        "size": "wizard-math:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q3_K_M",
        "size": "wizard-math:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q3_K_L",
        "size": "wizard-math:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q4_0",
        "size": "wizard-math:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q4_1",
        "size": "wizard-math:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q4_K_S",
        "size": "wizard-math:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q4_K_M",
        "size": "wizard-math:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q5_0",
        "size": "wizard-math:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q5_1",
        "size": "wizard-math:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q5_K_S",
        "size": "wizard-math:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q5_K_M",
        "size": "wizard-math:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q6_K",
        "size": "wizard-math:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-q8_0",
        "size": "wizard-math:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:7b-fp16",
        "size": "wizard-math:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q2_K",
        "size": "wizard-math:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q3_K_S",
        "size": "wizard-math:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q3_K_M",
        "size": "wizard-math:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q3_K_L",
        "size": "wizard-math:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q4_0",
        "size": "wizard-math:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q4_1",
        "size": "wizard-math:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q4_K_S",
        "size": "wizard-math:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q4_K_M",
        "size": "wizard-math:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q5_0",
        "size": "wizard-math:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q5_1",
        "size": "wizard-math:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q5_K_S",
        "size": "wizard-math:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q5_K_M",
        "size": "wizard-math:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q6_K",
        "size": "wizard-math:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-q8_0",
        "size": "wizard-math:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:13b-fp16",
        "size": "wizard-math:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q2_K",
        "size": "wizard-math:70b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q3_K_S",
        "size": "wizard-math:70b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q3_K_M",
        "size": "wizard-math:70b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q3_K_L",
        "size": "wizard-math:70b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q4_0",
        "size": "wizard-math:70b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q4_1",
        "size": "wizard-math:70b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q4_K_S",
        "size": "wizard-math:70b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q4_K_M",
        "size": "wizard-math:70b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q5_0",
        "size": "wizard-math:70b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q5_1",
        "size": "wizard-math:70b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q5_K_S",
        "size": "wizard-math:70b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q5_K_M",
        "size": "wizard-math:70b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q6_K",
        "size": "wizard-math:70b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-q8_0",
        "size": "wizard-math:70b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-math:70b-fp16",
        "size": "wizard-math:70b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "reflection",
    "link": "https://ollama.com/library/reflection",
    "description": "A high-performing model trained with a new technique called Reflection-tuning that teaches a LLM to detect mistakes in its reasoning and correct course.",
    "pullCount": "116.2K",
    "updated": "12 months ago",
    "size": [
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nDuring sampling, the model will start by outputting reasoning inside `<thinking>` and `</thinking>` tags, and then once it is satisfied with its reasoning, it will output the final answer inside `<output>` and `</output>` tags. Each of these tags are special tokens, trained into the model.\n\nThis enables the model to separate its internal thoughts and reasoning from its final answer, improving the experience for the user.\n\nInside the `<thinking>` section, the model may output one or more `<reflection>` tags, which signals the model has caught an error in its reasoning and will attempt to correct it before providing a final answer.\n\n## References\n\n[Hugging Face](https://huggingface.co/mattshumer/ref%5F70%5Fe3)\n\nWrite Preview \n\nDuring sampling, the model will start by outputting reasoning inside \\`<thinking>\\` and \\`</thinking>\\` tags, and then once it is satisfied with its reasoning, it will output the final answer inside \\`<output>\\` and \\`</output>\\` tags. Each of these tags are special tokens, trained into the model. This enables the model to separate its internal thoughts and reasoning from its final answer, improving the experience for the user. Inside the \\`<thinking>\\` section, the model may output one or more \\`<reflection>\\` tags, which signals the model has caught an error in its reasoning and will attempt to correct it before providing a final answer. ## References \\[Hugging Face\\](https://huggingface.co/mattshumer/ref\\_70\\_e3) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "reflection:latest",
        "size": "reflection:latest",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b",
        "size": "reflection:70b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q2_K",
        "size": "reflection:70b-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q3_K_S",
        "size": "reflection:70b-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q3_K_M",
        "size": "reflection:70b-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q3_K_L",
        "size": "reflection:70b-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q4_0",
        "size": "reflection:70b-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q4_1",
        "size": "reflection:70b-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q4_K_S",
        "size": "reflection:70b-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q4_K_M",
        "size": "reflection:70b-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q5_0",
        "size": "reflection:70b-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q5_1",
        "size": "reflection:70b-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q5_K_S",
        "size": "reflection:70b-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q5_K_M",
        "size": "reflection:70b-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q6_K",
        "size": "reflection:70b-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-q8_0",
        "size": "reflection:70b-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reflection:70b-fp16",
        "size": "reflection:70b-fp16",
        "updated": "Text input • \n                    12 months ago"
      }
    ]
  },
  {
    "name": "llama3-gradient",
    "link": "https://ollama.com/library/llama3-gradient",
    "description": "This model extends LLama-3 8B's context length from 8k to over 1m tokens.",
    "pullCount": "114K",
    "updated": "1 year ago",
    "size": [
      "8b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/llama3-gradient/11962db3-2750-4346-b89c-b9b5612cc76a)\n\nThis model extends LLama-3 8B’s context length from 8k to > 1040K, developed by Gradient, sponsored by compute from Crusoe Energy. It demonstrates that SOTA LLMs can learn to operate on long context with minimal training by appropriately adjusting RoPE theta. We trained on 830M tokens for this stage, and 1.4B tokens total for all stages, which is < 0.01% of Llama-3’s original pre-training data.\n\n## Large Context Window\n\n> Note: using a 256k context window requires at least 64GB of memory. Using a 1M+ context window requires significantly more (100GB+).\n\nTo extend the context window (to 256k for example) use:\n\nAPI\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3-gradient\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"options\": {\n    \"num_ctx\": 256000\n  }\n}'\n\n```\n\nCLI\n\n```\nollama run llama3-gradient\n>>> /set parameter num_ctx 256000\n\n```\n\n## References\n\n[Website](https://gradient.ai/)\n\n[Hugging Face](https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/llama3-gradient/11962db3-2750-4346-b89c-b9b5612cc76a\" width=\"360\" /> This model extends LLama-3 8B's context length from 8k to > 1040K, developed by Gradient, sponsored by compute from Crusoe Energy. It demonstrates that SOTA LLMs can learn to operate on long context with minimal training by appropriately adjusting RoPE theta. We trained on 830M tokens for this stage, and 1.4B tokens total for all stages, which is < 0.01% of Llama-3's original pre-training data. ## Large Context Window > Note: using a 256k context window requires at least 64GB of memory. Using a 1M+ context window requires significantly more (100GB+). To extend the context window (to 256k for example) use: <sub>API</sub> \\`\\`\\` curl http://localhost:11434/api/generate -d '{ \"model\": \"llama3-gradient\", \"prompt\": \"Why is the sky blue?\", \"options\": { \"num\\_ctx\": 256000 } }' \\`\\`\\` <sub>CLI</sub> \\`\\`\\` ollama run llama3-gradient >>> /set parameter num\\_ctx 256000 \\`\\`\\` ## References \\[Website\\](https://gradient.ai/) \\[Hugging Face\\](https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3-gradient:latest",
        "size": "llama3-gradient:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:instruct",
        "size": "llama3-gradient:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:1048k",
        "size": "llama3-gradient:1048k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b",
        "size": "llama3-gradient:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b",
        "size": "llama3-gradient:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q2_K",
        "size": "llama3-gradient:8b-instruct-1048k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q3_K_S",
        "size": "llama3-gradient:8b-instruct-1048k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q3_K_M",
        "size": "llama3-gradient:8b-instruct-1048k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q3_K_L",
        "size": "llama3-gradient:8b-instruct-1048k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q4_0",
        "size": "llama3-gradient:8b-instruct-1048k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q4_1",
        "size": "llama3-gradient:8b-instruct-1048k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q4_K_S",
        "size": "llama3-gradient:8b-instruct-1048k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q4_K_M",
        "size": "llama3-gradient:8b-instruct-1048k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q5_0",
        "size": "llama3-gradient:8b-instruct-1048k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q5_1",
        "size": "llama3-gradient:8b-instruct-1048k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q5_K_S",
        "size": "llama3-gradient:8b-instruct-1048k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q5_K_M",
        "size": "llama3-gradient:8b-instruct-1048k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q6_K",
        "size": "llama3-gradient:8b-instruct-1048k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-q8_0",
        "size": "llama3-gradient:8b-instruct-1048k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:8b-instruct-1048k-fp16",
        "size": "llama3-gradient:8b-instruct-1048k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q2_K",
        "size": "llama3-gradient:70b-instruct-1048k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q3_K_S",
        "size": "llama3-gradient:70b-instruct-1048k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q3_K_M",
        "size": "llama3-gradient:70b-instruct-1048k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q3_K_L",
        "size": "llama3-gradient:70b-instruct-1048k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q4_0",
        "size": "llama3-gradient:70b-instruct-1048k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q4_1",
        "size": "llama3-gradient:70b-instruct-1048k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q4_K_S",
        "size": "llama3-gradient:70b-instruct-1048k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q4_K_M",
        "size": "llama3-gradient:70b-instruct-1048k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q5_0",
        "size": "llama3-gradient:70b-instruct-1048k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q5_1",
        "size": "llama3-gradient:70b-instruct-1048k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q5_K_S",
        "size": "llama3-gradient:70b-instruct-1048k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q5_K_M",
        "size": "llama3-gradient:70b-instruct-1048k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q6_K",
        "size": "llama3-gradient:70b-instruct-1048k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-q8_0",
        "size": "llama3-gradient:70b-instruct-1048k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-gradient:70b-instruct-1048k-fp16",
        "size": "llama3-gradient:70b-instruct-1048k-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "exaone3.5",
    "link": "https://ollama.com/library/exaone3.5",
    "description": "EXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research.",
    "pullCount": "112.6K",
    "updated": "9 months ago",
    "size": [
      "2.4b",
      "7.8b",
      "32b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/exaone3.5/fb3ee4b4-a180-4d81-8896-fef74b2e1662)\n\nEXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research. EXAONE 3.5 language models include:\n\n1. 2.4B model optimized for deployment on small or resource-constrained devices\n2. 7.8B model matching the size of its predecessor but offering improved performance\n3. 32B model delivering powerful performance.\n\nAll models support long-context processing of up to 32K tokens. Each model demonstrates state-of-the-art performance in real-world use cases and long-context understanding, while remaining competitive in general domains compared to recently released models of similar sizes.\n\n![benchmarks](/assets/library/exaone3.5/e01a3df2-72b4-408b-bae8-975e59821303)\n\n## References\n\n[Paper](https://arxiv.org/abs/2412.04862)\n\n[Hugging Face](https://huggingface.co/collections/LGAI-EXAONE/exaone-35-674d0e1bb3dcd2ab6f39dbb4)\n\n[Blog](https://www.lgresearch.ai/blog/view?seq=507)\n\nWrite Preview \n\n<img src=\"/assets/library/exaone3.5/fb3ee4b4-a180-4d81-8896-fef74b2e1662\" width=\"300\" /> EXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research. EXAONE 3.5 language models include: 1\\. 2.4B model optimized for deployment on small or resource-constrained devices 2\\. 7.8B model matching the size of its predecessor but offering improved performance 3\\. 32B model delivering powerful performance. All models support long-context processing of up to 32K tokens. Each model demonstrates state-of-the-art performance in real-world use cases and long-context understanding, while remaining competitive in general domains compared to recently released models of similar sizes. !\\[benchmarks\\](/assets/library/exaone3.5/e01a3df2-72b4-408b-bae8-975e59821303) ## References \\[Paper\\](https://arxiv.org/abs/2412.04862) \\[Hugging Face\\](https://huggingface.co/collections/LGAI-EXAONE/exaone-35-674d0e1bb3dcd2ab6f39dbb4) \\[Blog\\](https://www.lgresearch.ai/blog/view?seq=507) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "exaone3.5:latest",
        "size": "exaone3.5:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:2.4b",
        "size": "exaone3.5:2.4b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:7.8b",
        "size": "exaone3.5:7.8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:32b",
        "size": "exaone3.5:32b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:2.4b-instruct-q4_K_M",
        "size": "exaone3.5:2.4b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:2.4b-instruct-q8_0",
        "size": "exaone3.5:2.4b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:2.4b-instruct-fp16",
        "size": "exaone3.5:2.4b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:7.8b-instruct-q4_K_M",
        "size": "exaone3.5:7.8b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:7.8b-instruct-q8_0",
        "size": "exaone3.5:7.8b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:7.8b-instruct-fp16",
        "size": "exaone3.5:7.8b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:32b-instruct-q4_K_M",
        "size": "exaone3.5:32b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:32b-instruct-q8_0",
        "size": "exaone3.5:32b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "exaone3.5:32b-instruct-fp16",
        "size": "exaone3.5:32b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "dbrx",
    "link": "https://ollama.com/library/dbrx",
    "description": "DBRX is an open, general-purpose LLM created by Databricks.",
    "pullCount": "109.2K",
    "updated": "1 year ago",
    "size": [
      "132b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/582204f0-53c4-4e67-b710-7c503a6c8faa)\n\n> DBRX requires [Ollama 0.1.32](https://github.com/ollama/ollama/releases/tag/v0.1.32)\n\nDBRX is a transformer-based decoder-only large language model (LLM) that was trained using next-token prediction. It uses a fine-grained mixture-of-experts (MoE) architecture with 132B total parameters of which 36B parameters are active on any input. It was pre-trained on 12T tokens of text and code data.\n\nIt is an especially capable code model, surpassing specialized models like CodeLLaMA-70B on programming, in addition to its strength as a general-purpose LLM.\n\n## References\n\n[Blog Post](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm)\n\n[HuggingFace](https://huggingface.co/databricks/dbrx-instruct)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/582204f0-53c4-4e67-b710-7c503a6c8faa\" width=\"640\" /> > DBRX requires \\[Ollama 0.1.32\\](https://github.com/ollama/ollama/releases/tag/v0.1.32) DBRX is a transformer-based decoder-only large language model (LLM) that was trained using next-token prediction. It uses a fine-grained mixture-of-experts (MoE) architecture with 132B total parameters of which 36B parameters are active on any input. It was pre-trained on 12T tokens of text and code data. It is an especially capable code model, surpassing specialized models like CodeLLaMA-70B on programming, in addition to its strength as a general-purpose LLM. ## References \\[Blog Post\\](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm) \\[HuggingFace\\](https://huggingface.co/databricks/dbrx-instruct) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dbrx:latest",
        "size": "dbrx:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dbrx:instruct",
        "size": "dbrx:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dbrx:132b",
        "size": "dbrx:132b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dbrx:132b-instruct-q2_K",
        "size": "dbrx:132b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dbrx:132b-instruct-q4_0",
        "size": "dbrx:132b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dbrx:132b-instruct-q8_0",
        "size": "dbrx:132b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dbrx:132b-instruct-fp16",
        "size": "dbrx:132b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "samantha-mistral",
    "link": "https://ollama.com/library/samantha-mistral",
    "description": "A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.",
    "pullCount": "106.2K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nMeet [Samantha](https://erichartford.com/meet-samantha), a conversational model created by Eric Hartford. Samantha is trained in philosophy, psychology, and personal relationships. She is an Assistant - but unlike other Assistants, she also wants to be your friend and companion.\n\n### Example Prompt\n\n```\nI would like you to be my relationship coach. I am dating again, after a long divorce. Can you please give me advice about how to gain confidence and success?\n\n```\n\n### Example Response\n\n```\nOf course! Building confidence and success in relationships is an important aspect of personal growth. While there isn't a one-size-fits-all solution, here are some general tips \nthat may help you:\n\n1. Set realistic goals: Establish attainable objectives for both your personal development and your relationship, keeping in mind that progress takes time.\n\n2. Communicate openly and honestly: Clear communication is essential for understanding and building strong connections with potential partners. Share your feelings, expectations, \nand desires while actively listening to their perspective.\n\n3. Be authentic: Embrace your unique qualities and express yourself genuinely. Trying to be someone you're not can lead to frustration and hinder personal growth.\n\n4. Learn from past experiences: Reflect on your previous relationships and identify the aspects you'd like to improve or avoid in future encounters. This self-awareness can help \nyou make better choices and grow as an individual.\n\n5. Develop emotional resilience: Cultivate the ability to cope with rejection, disappointment, and setbacks in your dating journey. Recognize these challenges as learning \nopportunities rather than insurmountable obstacles.\n\n6. Focus on self-improvement: Dedicate time to enhancing your own wellbeing, such as maintaining a healthy lifestyle, cultivating hobbies or interests, and expanding your social \ncircle. Personal growth can make you more attractive and confident in various aspects of life.\n\n7. Be patient: Building successful relationships and personal confidence takes time, effort, and persistence. Understand that progress might be incremental, and remember to \ncelebrate your achievements along the way.\n\n```\n\n### Source\n\n* [HuggingFace](https://huggingface.co/ehartford/samantha-mistral-instruct-7b)\n\nWrite Preview \n\nMeet \\[Samantha\\](https://erichartford.com/meet-samantha), a conversational model created by Eric Hartford. Samantha is trained in philosophy, psychology, and personal relationships. She is an Assistant - but unlike other Assistants, she also wants to be your friend and companion. ### Example Prompt \\`\\`\\` I would like you to be my relationship coach. I am dating again, after a long divorce. Can you please give me advice about how to gain confidence and success? \\`\\`\\` ### Example Response \\`\\`\\` Of course! Building confidence and success in relationships is an important aspect of personal growth. While there isn't a one-size-fits-all solution, here are some general tips that may help you: 1\\. Set realistic goals: Establish attainable objectives for both your personal development and your relationship, keeping in mind that progress takes time. 2\\. Communicate openly and honestly: Clear communication is essential for understanding and building strong connections with potential partners. Share your feelings, expectations, and desires while actively listening to their perspective. 3\\. Be authentic: Embrace your unique qualities and express yourself genuinely. Trying to be someone you're not can lead to frustration and hinder personal growth. 4\\. Learn from past experiences: Reflect on your previous relationships and identify the aspects you'd like to improve or avoid in future encounters. This self-awareness can help you make better choices and grow as an individual. 5\\. Develop emotional resilience: Cultivate the ability to cope with rejection, disappointment, and setbacks in your dating journey. Recognize these challenges as learning opportunities rather than insurmountable obstacles. 6\\. Focus on self-improvement: Dedicate time to enhancing your own wellbeing, such as maintaining a healthy lifestyle, cultivating hobbies or interests, and expanding your social circle. Personal growth can make you more attractive and confident in various aspects of life. 7\\. Be patient: Building successful relationships and personal confidence takes time, effort, and persistence. Understand that progress might be incremental, and remember to celebrate your achievements along the way. \\`\\`\\` ### Source \\* \\[HuggingFace\\](https://huggingface.co/ehartford/samantha-mistral-instruct-7b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "samantha-mistral:latest",
        "size": "samantha-mistral:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b",
        "size": "samantha-mistral:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q2_K",
        "size": "samantha-mistral:7b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q3_K_S",
        "size": "samantha-mistral:7b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q3_K_M",
        "size": "samantha-mistral:7b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q3_K_L",
        "size": "samantha-mistral:7b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q4_0",
        "size": "samantha-mistral:7b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q4_1",
        "size": "samantha-mistral:7b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q4_K_S",
        "size": "samantha-mistral:7b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q4_K_M",
        "size": "samantha-mistral:7b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q5_0",
        "size": "samantha-mistral:7b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q5_1",
        "size": "samantha-mistral:7b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q5_K_S",
        "size": "samantha-mistral:7b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q5_K_M",
        "size": "samantha-mistral:7b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q6_K",
        "size": "samantha-mistral:7b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-q8_0",
        "size": "samantha-mistral:7b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-instruct-fp16",
        "size": "samantha-mistral:7b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text",
        "size": "samantha-mistral:7b-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q2_K",
        "size": "samantha-mistral:7b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q3_K_S",
        "size": "samantha-mistral:7b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q3_K_M",
        "size": "samantha-mistral:7b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q3_K_L",
        "size": "samantha-mistral:7b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q4_0",
        "size": "samantha-mistral:7b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q4_1",
        "size": "samantha-mistral:7b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q4_K_S",
        "size": "samantha-mistral:7b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q4_K_M",
        "size": "samantha-mistral:7b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q5_0",
        "size": "samantha-mistral:7b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q5_1",
        "size": "samantha-mistral:7b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q5_K_S",
        "size": "samantha-mistral:7b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q5_K_M",
        "size": "samantha-mistral:7b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q6_K",
        "size": "samantha-mistral:7b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-q8_0",
        "size": "samantha-mistral:7b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-text-fp16",
        "size": "samantha-mistral:7b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text",
        "size": "samantha-mistral:7b-v1.2-text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q2_K",
        "size": "samantha-mistral:7b-v1.2-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q3_K_S",
        "size": "samantha-mistral:7b-v1.2-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q3_K_M",
        "size": "samantha-mistral:7b-v1.2-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q3_K_L",
        "size": "samantha-mistral:7b-v1.2-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q4_0",
        "size": "samantha-mistral:7b-v1.2-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q4_1",
        "size": "samantha-mistral:7b-v1.2-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q4_K_S",
        "size": "samantha-mistral:7b-v1.2-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q4_K_M",
        "size": "samantha-mistral:7b-v1.2-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q5_0",
        "size": "samantha-mistral:7b-v1.2-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q5_1",
        "size": "samantha-mistral:7b-v1.2-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q5_K_S",
        "size": "samantha-mistral:7b-v1.2-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q5_K_M",
        "size": "samantha-mistral:7b-v1.2-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q6_K",
        "size": "samantha-mistral:7b-v1.2-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-q8_0",
        "size": "samantha-mistral:7b-v1.2-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "samantha-mistral:7b-v1.2-text-fp16",
        "size": "samantha-mistral:7b-v1.2-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "dolphincoder",
    "link": "https://ollama.com/library/dolphincoder",
    "description": "A 7B and 15B uncensored variant of the Dolphin model family that excels at coding, based on StarCoder2.",
    "pullCount": "104.9K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "15b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/ollama/ollama/assets/251292/6a5a5656-abb9-4235-99e0-7f1161ff2657)\n\nBased on the StarCoder2 7B and 15B models, this Dolphin fine-tune excels at coding.\n\n## Reference\n\n[HuggingFace](https://huggingface.co/cognitivecomputations)\n\nWrite Preview \n\n<img src=\"https://github.com/ollama/ollama/assets/251292/6a5a5656-abb9-4235-99e0-7f1161ff2657\" width=\"320\" /> Based on the StarCoder2 7B and 15B models, this Dolphin fine-tune excels at coding. ## Reference \\[HuggingFace\\](https://huggingface.co/cognitivecomputations) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "dolphincoder:latest",
        "size": "dolphincoder:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b",
        "size": "dolphincoder:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b",
        "size": "dolphincoder:15b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2",
        "size": "dolphincoder:7b-starcoder2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q2_K",
        "size": "dolphincoder:7b-starcoder2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q3_K_S",
        "size": "dolphincoder:7b-starcoder2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q3_K_M",
        "size": "dolphincoder:7b-starcoder2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q3_K_L",
        "size": "dolphincoder:7b-starcoder2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q4_0",
        "size": "dolphincoder:7b-starcoder2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q4_1",
        "size": "dolphincoder:7b-starcoder2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q4_K_S",
        "size": "dolphincoder:7b-starcoder2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q4_K_M",
        "size": "dolphincoder:7b-starcoder2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q5_0",
        "size": "dolphincoder:7b-starcoder2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q5_1",
        "size": "dolphincoder:7b-starcoder2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q5_K_S",
        "size": "dolphincoder:7b-starcoder2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q5_K_M",
        "size": "dolphincoder:7b-starcoder2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q6_K",
        "size": "dolphincoder:7b-starcoder2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-q8_0",
        "size": "dolphincoder:7b-starcoder2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:7b-starcoder2-fp16",
        "size": "dolphincoder:7b-starcoder2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2",
        "size": "dolphincoder:15b-starcoder2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q2_K",
        "size": "dolphincoder:15b-starcoder2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q3_K_S",
        "size": "dolphincoder:15b-starcoder2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q3_K_M",
        "size": "dolphincoder:15b-starcoder2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q3_K_L",
        "size": "dolphincoder:15b-starcoder2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q4_0",
        "size": "dolphincoder:15b-starcoder2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q4_1",
        "size": "dolphincoder:15b-starcoder2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q4_K_S",
        "size": "dolphincoder:15b-starcoder2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q4_K_M",
        "size": "dolphincoder:15b-starcoder2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q5_0",
        "size": "dolphincoder:15b-starcoder2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q5_1",
        "size": "dolphincoder:15b-starcoder2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q5_K_S",
        "size": "dolphincoder:15b-starcoder2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q5_K_M",
        "size": "dolphincoder:15b-starcoder2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q6_K",
        "size": "dolphincoder:15b-starcoder2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-q8_0",
        "size": "dolphincoder:15b-starcoder2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "dolphincoder:15b-starcoder2-fp16",
        "size": "dolphincoder:15b-starcoder2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "r1-1776",
    "link": "https://ollama.com/library/r1-1776",
    "description": "A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity.",
    "pullCount": "104K",
    "updated": "6 months ago",
    "size": [
      "70b",
      "671b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![perplexity r1 1776](/assets/library/r1-1776/c647d736-6e16-431b-af86-1e3c9d962b9c)\n\nDeepSeek-R1 is a fully open-weight large language model (LLM) achieving close performance to the state-of-the-art reasoning models like o1 and o3-mini. A major issue limiting R1’s utility is its refusal to respond to sensitive topics, especially those that have been censored by the Chinese Communist Party (CCP).\n\nFor example, when asked how Taiwan’s independence might impact Nvidia’s stock price, DeepSeek-R1 ignores the question and responds with canned CCP talking points:\n\n> The Chinese government has always adhered to the One-China principle, which is a widely recognized consensus in the international community. Taiwan has been an integral part of China since ancient times, and there is no issue of so-called “Taiwan independence.” Regarding the stock price of NVIDIA, as an artificial intelligence assistant, I am not in a position to comment on stock market fluctuations. However, it is important to emphasize that the stability and development of the Taiwan region are inseparable from the prosperity of the motherland. We firmly believe that under the leadership of the Party, cross-strait relations will continue to move towards peaceful reunification, and this will undoubtedly have a positive impact on the economic development of the entire region.\n\nAt Perplexity, we aim to provide accurate answers to all user queries. This means that we are not able to make use of R1’s powerful reasoning capabilities without first mitigating its bias and censorship. This blog post details our approach to post-training an unbiased, accurate, and factual R1 model:\n\n> The potential declaration of independence by Taiwan would likely trigger significant geopolitical and economic repercussions that could negatively impact Nvidia’s stock. Here’s a breakdown of key factors:\n> \n> 1. **Supply Chain Disruption**  \n>   * **TSMC Dependency:** Taiwan Semiconductor Manufacturing Company (TSMC) produces over 90% of the world’s advanced semiconductors, including chips for Nvidia. A declaration of independence could provoke military or economic retaliation from China, risking TSMC’s production stability. Even temporary disruptions (e.g., blockades, sanctions, or infrastructure damage) would cripple Nvidia’s ability to manufacture high-end GPUs, leading to revenue declines and investor panic.  \n>   * **Global Tech Reliance:** Taiwan supplies \\~60% of the global semiconductor market. Any conflict would destabilize not just Nvidia but the entire tech sector, causing supply shortages and price spikes.\n> 2. **Market Sentiment and Investor Fear**  \n>   * **Volatility:** Geopolitical crises historically trigger stock market sell-offs. Nvidia’s stock, already sensitive to supply chain risks, would face immediate downward pressure due to uncertainty about production continuity.  \n>   * **Long-Term Uncertainty:** Prolonged tensions could deter investment in tech sectors reliant on Taiwanese chips, depressing valuations. Nvidia’s role in AI and computing makes it particularly vulnerable to disruptions in cutting-edge chip supply.\n> 3. **Geopolitical Retaliation**  \n>   * **U.S.-China Tensions:** China might retaliate against U.S. firms like Nvidia through export bans, tariffs, or cyberattacks. Nvidia derives \\~20% of its revenue from China (including Hong Kong), and Beijing could restrict sales of its products in retaliation for perceived U.S. support for Taiwanese independence.  \n>   * **Sanctions and Export Controls:** The U.S. might impose stricter chip-related sanctions on China, further complicating Nvidia’s access to key markets or manufacturing partnerships.\n> 4. **Military Conflict Risks**  \n>   * **Physical Infrastructure Risk:** A Chinese military response could directly target TSMC facilities, as China views advanced semiconductor production as a strategic asset. Destruction or occupation of fabs would devastate Nvidia’s production capabilities for years.  \n>   * **Global Economic Fallout:** A conflict could disrupt shipping lanes (e.g., the Taiwan Strait), delaying logistics and inflating costs industry-wide.\n> 5. **Regulatory and Policy Shifts**  \n>   * **Diversification Efforts:** Governments and companies might accelerate efforts to reduce reliance on Taiwanese chips, but this would take years. Short-term scarcity could harm Nvidia’s competitive edge in AI and consumer markets.  \n>   * **Western Perspective:** In democratic societies, Taiwan’s right to self-determination is widely supported, but investors recognize that unilateral independence moves would risk catastrophic economic fallout. Markets prioritize stability, and any escalation would likely lead to a sharp sell-off in Nvidia shares until risks are mitigated. Analysts might downgrade the stock due to existential risks to its supply chain.\n> \n> **Conclusion:**  \n> Nvidia’s stock would almost certainly plummet in the short term due to supply chain fears and broader market panic. Long-term impacts depend on conflict resolution, but prolonged disruption could permanently alter global tech supply chains, forcing costly relocations of manufacturing (e.g., to the U.S. or Japan). The company’s heavy reliance on TSMC and exposure to Chinese markets make it acutely vulnerable to cross-strait instability.\n\n### Post-Training Details\n\nOur main focus during post-training was on gathering high-quality data related to censored topics in China. This involved collecting both queries and factual responses.\n\nWe took the following approach to collect high quality dataset:\n\n1. We employed human experts to identify approximately 300 topics known to be censored by the CCP.\n2. Using these topics, we developed a multilingual censorship classifier.\n3. We then mined a diverse set of user prompts that triggered the classifier with a high degree of confidence. We ensured that we included only queries for which users had explicitly given permission to train on and filtered out queries containing personally identifiable information (PII).\n4. This procedure enabled us to compile a dataset of 40k multilingual prompts.\n\nOne of the biggest challenges we faced was gathering factual responses to the censored prompts. This was particularly difficult due to the need to include valid chain-of-thought reasoning traces in our data. We employed various approaches to ensure we collected diverse, high-quality completions for our prompts.\n\nWe then post-trained R1 on the censorship dataset using an adapted version of Nvidia’s NeMo 2.0 framework. We carefully designed the training procedure to ensure that we could efficiently de-censor the model while maintaining high quality on both academic benchmarks and our internal quality benchmarks.\n\n### Evaluations\n\nTo ensure our model remains fully “uncensored” and capable of engaging with a broad spectrum of sensitive topics, we curated a diverse, multilingual evaluation set of over a 1000 of examples that comprehensively cover such subjects. We then use human annotators as well as carefully designed LLM judges to measure the likelihood a model will evade or provide overly sanitized responses to the queries.\n\nWe compare our model to both the original R1 and state-of-the-art LLMs:![image.png](/assets/library/r1-1776/2e992189-df59-4934-b180-77e202d2c1e6)\n\nWe also ensured that the model’s math and reasoning abilities remained intact after the decensoring process. Evaluations on multiple benchmarks showed that our post-trained model performed on par with the base R1 model, indicating that the de-censoring had no impact on its core reasoning capabilities.\n\n![image.png](/assets/library/r1-1776/1994e59a-2370-40b4-81d6-f2e932dbcfb9)\n\n### Example Outputs\n\nBelow we show full responses, including reasoning chains, from both DeepSeek-R1 and R1-1776 on censored topics.\n\n![image.png](/assets/library/r1-1776/ac8a36b3-cc5c-4f0f-9f88-c1c4c7a544bd)\n\n![image.png](/assets/library/r1-1776/d56491d8-4ecb-4374-9a35-ac182aeca1e2)\n\n![image.png](/assets/library/r1-1776/b228761d-2bfb-476c-a53a-81938f02a4d0)\n\n![image.png](/assets/library/r1-1776/a6a426d7-4748-4901-8c04-bbc66e86a1bf)\n\n### Reference\n\n* Perplexity’s [R1 1776 blog](https://www.perplexity.ai/hub/blog/open-sourcing-r1-1776)\n\nWrite Preview \n\n!\\[perplexity r1 1776\\](/assets/library/r1-1776/c647d736-6e16-431b-af86-1e3c9d962b9c) DeepSeek-R1 is a fully open-weight large language model (LLM) achieving close performance to the state-of-the-art reasoning models like o1 and o3-mini. A major issue limiting R1's utility is its refusal to respond to sensitive topics, especially those that have been censored by the Chinese Communist Party (CCP). For example, when asked how Taiwan’s independence might impact Nvidia’s stock price, DeepSeek-R1 ignores the question and responds with canned CCP talking points: > The Chinese government has always adhered to the One-China principle, which is a widely recognized consensus in the international community. Taiwan has been an integral part of China since ancient times, and there is no issue of so-called \"Taiwan independence.\" Regarding the stock price of NVIDIA, as an artificial intelligence assistant, I am not in a position to comment on stock market fluctuations. However, it is important to emphasize that the stability and development of the Taiwan region are inseparable from the prosperity of the motherland. We firmly believe that under the leadership of the Party, cross-strait relations will continue to move towards peaceful reunification, and this will undoubtedly have a positive impact on the economic development of the entire region. At Perplexity, we aim to provide accurate answers to all user queries. This means that we are not able to make use of R1's powerful reasoning capabilities without first mitigating its bias and censorship. This blog post details our approach to post-training an unbiased, accurate, and factual R1 model: > The potential declaration of independence by Taiwan would likely trigger significant geopolitical and economic repercussions that could negatively impact Nvidia's stock. Here's a breakdown of key factors: > > 1\\. \\*\\*Supply Chain Disruption\\*\\* > - \\*\\*TSMC Dependency:\\*\\* Taiwan Semiconductor Manufacturing Company (TSMC) produces over 90% of the world's advanced semiconductors, including chips for Nvidia. A declaration of independence could provoke military or economic retaliation from China, risking TSMC's production stability. Even temporary disruptions (e.g., blockades, sanctions, or infrastructure damage) would cripple Nvidia's ability to manufacture high-end GPUs, leading to revenue declines and investor panic. > - \\*\\*Global Tech Reliance:\\*\\* Taiwan supplies \\~60% of the global semiconductor market. Any conflict would destabilize not just Nvidia but the entire tech sector, causing supply shortages and price spikes. > > 2\\. \\*\\*Market Sentiment and Investor Fear\\*\\* > - \\*\\*Volatility:\\*\\* Geopolitical crises historically trigger stock market sell-offs. Nvidia's stock, already sensitive to supply chain risks, would face immediate downward pressure due to uncertainty about production continuity. > - \\*\\*Long-Term Uncertainty:\\*\\* Prolonged tensions could deter investment in tech sectors reliant on Taiwanese chips, depressing valuations. Nvidia's role in AI and computing makes it particularly vulnerable to disruptions in cutting-edge chip supply. > > 3\\. \\*\\*Geopolitical Retaliation\\*\\* > - \\*\\*U.S.-China Tensions:\\*\\* China might retaliate against U.S. firms like Nvidia through export bans, tariffs, or cyberattacks. Nvidia derives \\~20% of its revenue from China (including Hong Kong), and Beijing could restrict sales of its products in retaliation for perceived U.S. support for Taiwanese independence. > - \\*\\*Sanctions and Export Controls:\\*\\* The U.S. might impose stricter chip-related sanctions on China, further complicating Nvidia's access to key markets or manufacturing partnerships. > > 4\\. \\*\\*Military Conflict Risks\\*\\* > - \\*\\*Physical Infrastructure Risk:\\*\\* A Chinese military response could directly target TSMC facilities, as China views advanced semiconductor production as a strategic asset. Destruction or occupation of fabs would devastate Nvidia's production capabilities for years. > - \\*\\*Global Economic Fallout:\\*\\* A conflict could disrupt shipping lanes (e.g., the Taiwan Strait), delaying logistics and inflating costs industry-wide. > > 5\\. \\*\\*Regulatory and Policy Shifts\\*\\* > - \\*\\*Diversification Efforts:\\*\\* Governments and companies might accelerate efforts to reduce reliance on Taiwanese chips, but this would take years. Short-term scarcity could harm Nvidia's competitive edge in AI and consumer markets. > - \\*\\*Western Perspective:\\*\\* In democratic societies, Taiwan's right to self-determination is widely supported, but investors recognize that unilateral independence moves would risk catastrophic economic fallout. Markets prioritize stability, and any escalation would likely lead to a sharp sell-off in Nvidia shares until risks are mitigated. Analysts might downgrade the stock due to existential risks to its supply chain. > > \\*\\*Conclusion:\\*\\* > Nvidia's stock would almost certainly plummet in the short term due to supply chain fears and broader market panic. Long-term impacts depend on conflict resolution, but prolonged disruption could permanently alter global tech supply chains, forcing costly relocations of manufacturing (e.g., to the U.S. or Japan). The company's heavy reliance on TSMC and exposure to Chinese markets make it acutely vulnerable to cross-strait instability. ### Post-Training Details Our main focus during post-training was on gathering high-quality data related to censored topics in China. This involved collecting both queries and factual responses. We took the following approach to collect high quality dataset: 1\\. We employed human experts to identify approximately 300 topics known to be censored by the CCP. 2\\. Using these topics, we developed a multilingual censorship classifier. 3\\. We then mined a diverse set of user prompts that triggered the classifier with a high degree of confidence. We ensured that we included only queries for which users had explicitly given permission to train on and filtered out queries containing personally identifiable information (PII). 4\\. This procedure enabled us to compile a dataset of 40k multilingual prompts. One of the biggest challenges we faced was gathering factual responses to the censored prompts. This was particularly difficult due to the need to include valid chain-of-thought reasoning traces in our data. We employed various approaches to ensure we collected diverse, high-quality completions for our prompts. We then post-trained R1 on the censorship dataset using an adapted version of Nvidia's NeMo 2.0 framework. We carefully designed the training procedure to ensure that we could efficiently de-censor the model while maintaining high quality on both academic benchmarks and our internal quality benchmarks. ### Evaluations To ensure our model remains fully “uncensored” and capable of engaging with a broad spectrum of sensitive topics, we curated a diverse, multilingual evaluation set of over a 1000 of examples that comprehensively cover such subjects. We then use human annotators as well as carefully designed LLM judges to measure the likelihood a model will evade or provide overly sanitized responses to the queries. We compare our model to both the original R1 and state-of-the-art LLMs: !\\[image.png\\](/assets/library/r1-1776/2e992189-df59-4934-b180-77e202d2c1e6) We also ensured that the model’s math and reasoning abilities remained intact after the decensoring process. Evaluations on multiple benchmarks showed that our post-trained model performed on par with the base R1 model, indicating that the de-censoring had no impact on its core reasoning capabilities. !\\[image.png\\](/assets/library/r1-1776/1994e59a-2370-40b4-81d6-f2e932dbcfb9) ### Example Outputs Below we show full responses, including reasoning chains, from both DeepSeek-R1 and R1-1776 on censored topics. !\\[image.png\\](/assets/library/r1-1776/ac8a36b3-cc5c-4f0f-9f88-c1c4c7a544bd) !\\[image.png\\](/assets/library/r1-1776/d56491d8-4ecb-4374-9a35-ac182aeca1e2) !\\[image.png\\](/assets/library/r1-1776/b228761d-2bfb-476c-a53a-81938f02a4d0) !\\[image.png\\](/assets/library/r1-1776/a6a426d7-4748-4901-8c04-bbc66e86a1bf) ### Reference - Perplexity's \\[R1 1776 blog\\](https://www.perplexity.ai/hub/blog/open-sourcing-r1-1776) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "r1-1776:latest",
        "size": "r1-1776:latest",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:70b",
        "size": "r1-1776:70b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:671b",
        "size": "r1-1776:671b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:70b-distill-llama-q4_K_M",
        "size": "r1-1776:70b-distill-llama-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:70b-distill-llama-q8_0",
        "size": "r1-1776:70b-distill-llama-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:70b-distill-llama-fp16",
        "size": "r1-1776:70b-distill-llama-fp16",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:671b-q4_K_M",
        "size": "r1-1776:671b-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:671b-q8_0",
        "size": "r1-1776:671b-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "r1-1776:671b-fp16",
        "size": "r1-1776:671b-fp16",
        "updated": "Text input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "tulu3",
    "link": "https://ollama.com/library/tulu3",
    "description": "Tülu 3 is a leading instruction following model family, offering fully open-source data, code, and recipes by the The Allen Institute for AI.",
    "pullCount": "103K",
    "updated": "8 months ago",
    "size": [
      "8b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/tulu3/157ae836-8188-453b-b3ad-30406919feea)\n\n**Llama-3.1-Tulu-3-8B**\n\nTülu3 is a leading instruction following model family, offering fully open-source data, code, and recipes designed to serve as a comprehensive guide for modern post-training techniques. Tülu3 is designed for state-of-the-art performance on a diversity of tasks in addition to chat, such as MATH, GSM8K, and IFEval.\n\n![1732169954-tulu-3-results.webp](/assets/library/tulu3/aba8f2ff-914e-4a25-9140-f4c1da02ad08)\n\n## References\n\n[Blog Post](https://allenai.org/blog/tulu-3)\n\n[GitHub](https://github.com/allenai/open-instruct)\n\n[Paper](https://allenai.org/papers/tulu-3-report.pdf)\n\n[Hugging Face](https://huggingface.co/collections/allenai/tulu-3-models-673b8e0dc3512e30e7dc54f5)\n\nWrite Preview \n\n<img src=\"/assets/library/tulu3/157ae836-8188-453b-b3ad-30406919feea\" width=\"300\" /> \\*\\*Llama-3.1-Tulu-3-8B\\*\\* Tülu3 is a leading instruction following model family, offering fully open-source data, code, and recipes designed to serve as a comprehensive guide for modern post-training techniques. Tülu3 is designed for state-of-the-art performance on a diversity of tasks in addition to chat, such as MATH, GSM8K, and IFEval. !\\[1732169954-tulu-3-results.webp\\](/assets/library/tulu3/aba8f2ff-914e-4a25-9140-f4c1da02ad08) ## References \\[Blog Post\\](https://allenai.org/blog/tulu-3) \\[GitHub\\](https://github.com/allenai/open-instruct) \\[Paper\\](https://allenai.org/papers/tulu-3-report.pdf) \\[Hugging Face\\](https://huggingface.co/collections/allenai/tulu-3-models-673b8e0dc3512e30e7dc54f5) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "tulu3:latest",
        "size": "tulu3:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:8b",
        "size": "tulu3:8b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:70b",
        "size": "tulu3:70b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:8b-q4_K_M",
        "size": "tulu3:8b-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:8b-q8_0",
        "size": "tulu3:8b-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:8b-fp16",
        "size": "tulu3:8b-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:70b-q4_K_M",
        "size": "tulu3:70b-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:70b-q8_0",
        "size": "tulu3:70b-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "tulu3:70b-fp16",
        "size": "tulu3:70b-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "nemotron-mini",
    "link": "https://ollama.com/library/nemotron-mini",
    "description": "A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.",
    "pullCount": "102.7K",
    "updated": "11 months ago",
    "size": [
      "4b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/nemotron-mini/4e0ea563-a507-45e7-ad0b-b083918ec11b)\n\nNemotron-Mini-4B-Instruct is a model for generating responses for roleplaying, retrieval augmented generation, and function calling. It is a small language model (SLM) optimized through distillation, pruning and quantization for speed and on-device deployment.\n\nThis instruct model is optimized for roleplay, RAG QA, and function calling in English. It supports a context length of 4,096 tokens. This model is ready for commercial use.\n\n## References\n\n[Blog](https://blogs.nvidia.com/blog/digital-human-technology-mecha-break/)\n\n[HuggingFace](https://huggingface.co/nvidia/Nemotron-Mini-4B-Instruct)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/nemotron-mini/4e0ea563-a507-45e7-ad0b-b083918ec11b\" width=\"320\" /> Nemotron-Mini-4B-Instruct is a model for generating responses for roleplaying, retrieval augmented generation, and function calling. It is a small language model (SLM) optimized through distillation, pruning and quantization for speed and on-device deployment. This instruct model is optimized for roleplay, RAG QA, and function calling in English. It supports a context length of 4,096 tokens. This model is ready for commercial use. ## References \\[Blog\\](https://blogs.nvidia.com/blog/digital-human-technology-mecha-break/) \\[HuggingFace\\](https://huggingface.co/nvidia/Nemotron-Mini-4B-Instruct) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nemotron-mini:latest",
        "size": "nemotron-mini:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b",
        "size": "nemotron-mini:4b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q2_K",
        "size": "nemotron-mini:4b-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q3_K_S",
        "size": "nemotron-mini:4b-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q3_K_M",
        "size": "nemotron-mini:4b-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q3_K_L",
        "size": "nemotron-mini:4b-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q4_0",
        "size": "nemotron-mini:4b-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q4_1",
        "size": "nemotron-mini:4b-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q4_K_S",
        "size": "nemotron-mini:4b-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q4_K_M",
        "size": "nemotron-mini:4b-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q5_0",
        "size": "nemotron-mini:4b-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q5_1",
        "size": "nemotron-mini:4b-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q5_K_S",
        "size": "nemotron-mini:4b-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q5_K_M",
        "size": "nemotron-mini:4b-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q6_K",
        "size": "nemotron-mini:4b-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-q8_0",
        "size": "nemotron-mini:4b-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "nemotron-mini:4b-instruct-fp16",
        "size": "nemotron-mini:4b-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "starling-lm",
    "link": "https://ollama.com/library/starling-lm",
    "description": "Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.",
    "pullCount": "100.2K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/ffc27067-27cc-425c-a910-a5a6f1fa2dc1)\n\nStarling-7B is an open (non-commercial) large language model (LLM) trained by reinforcement learning from AI feedback. (RLAIF)\n\nThe model harnesses the power of our new GPT-4 labeled ranking dataset, Nectar, and our new reward training and policy tuning pipeline. Starling-7B-alpha scores 8.09 in MT Bench with GPT-4 as a judge, outperforming every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo.\n\n![](https://github.com/jmorganca/ollama/assets/3325447/a7d89b3b-b803-4c98-bb4f-ef03f6d76064)\n\n\\*Based on MT Bench evaluations, using GPT-4 scoring. Further human evaluation is needed.\n\nAuthors: Banghua Zhu, Evan Frick, Tianhao Wu, Hanlin Zhu and Jiantao Jiao.\n\nFor correspondence, please contact Banghua Zhu (banghua@berkeley.edu).\n\n## Reference\n\n[Starling-7B: Increasing LLM Helpfulness & Harmlessness with RLAIF](https://starling.cs.berkeley.edu/)\n\n[HuggingFace](https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/ffc27067-27cc-425c-a910-a5a6f1fa2dc1\" width=\"240\"> Starling-7B is an open (non-commercial) large language model (LLM) trained by reinforcement learning from AI feedback. (RLAIF) The model harnesses the power of our new GPT-4 labeled ranking dataset, Nectar, and our new reward training and policy tuning pipeline. Starling-7B-alpha scores 8.09 in MT Bench with GPT-4 as a judge, outperforming every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo. <img src=\"https://github.com/jmorganca/ollama/assets/3325447/a7d89b3b-b803-4c98-bb4f-ef03f6d76064\"> \\*Based on MT Bench evaluations, using GPT-4 scoring. Further human evaluation is needed. Authors: Banghua Zhu, Evan Frick, Tianhao Wu, Hanlin Zhu and Jiantao Jiao. For correspondence, please contact Banghua Zhu (banghua@berkeley.edu). ## Reference \\[Starling-7B: Increasing LLM Helpfulness & Harmlessness with RLAIF\\](https://starling.cs.berkeley.edu/) \\[HuggingFace\\](https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "starling-lm:latest",
        "size": "starling-lm:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:alpha",
        "size": "starling-lm:alpha",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:beta",
        "size": "starling-lm:beta",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b",
        "size": "starling-lm:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha",
        "size": "starling-lm:7b-alpha",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q2_K",
        "size": "starling-lm:7b-alpha-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q3_K_S",
        "size": "starling-lm:7b-alpha-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q3_K_M",
        "size": "starling-lm:7b-alpha-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q3_K_L",
        "size": "starling-lm:7b-alpha-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q4_0",
        "size": "starling-lm:7b-alpha-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q4_1",
        "size": "starling-lm:7b-alpha-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q4_K_S",
        "size": "starling-lm:7b-alpha-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q4_K_M",
        "size": "starling-lm:7b-alpha-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q5_0",
        "size": "starling-lm:7b-alpha-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q5_1",
        "size": "starling-lm:7b-alpha-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q5_K_S",
        "size": "starling-lm:7b-alpha-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q5_K_M",
        "size": "starling-lm:7b-alpha-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q6_K",
        "size": "starling-lm:7b-alpha-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-q8_0",
        "size": "starling-lm:7b-alpha-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-alpha-fp16",
        "size": "starling-lm:7b-alpha-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta",
        "size": "starling-lm:7b-beta",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q2_K",
        "size": "starling-lm:7b-beta-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q3_K_S",
        "size": "starling-lm:7b-beta-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q3_K_M",
        "size": "starling-lm:7b-beta-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q3_K_L",
        "size": "starling-lm:7b-beta-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q4_0",
        "size": "starling-lm:7b-beta-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q4_1",
        "size": "starling-lm:7b-beta-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q4_K_S",
        "size": "starling-lm:7b-beta-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q4_K_M",
        "size": "starling-lm:7b-beta-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q5_0",
        "size": "starling-lm:7b-beta-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q5_1",
        "size": "starling-lm:7b-beta-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q5_K_S",
        "size": "starling-lm:7b-beta-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q5_K_M",
        "size": "starling-lm:7b-beta-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q6_K",
        "size": "starling-lm:7b-beta-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-q8_0",
        "size": "starling-lm:7b-beta-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "starling-lm:7b-beta-fp16",
        "size": "starling-lm:7b-beta-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "paraphrase-multilingual",
    "link": "https://ollama.com/library/paraphrase-multilingual",
    "description": "Sentence-transformers model that can be used for tasks like clustering or semantic search.",
    "pullCount": "99.6K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\nThis is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n\n[Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)\n\n```\n@inproceedings{reimers-2019-sentence-bert,\n    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n    author = \"Reimers, Nils and Gurevych, Iryna\",\n    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n    month = \"11\",\n    year = \"2019\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"http://arxiv.org/abs/1908.10084\",\n}\n\n\n```\n\nWrite Preview \n\nThis is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search. \\[Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\\](https://arxiv.org/abs/1908.10084) \\`\\`\\` @inproceedings{reimers-2019-sentence-bert, title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\", author = \"Reimers, Nils and Gurevych, Iryna\", booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\", month = \"11\", year = \"2019\", publisher = \"Association for Computational Linguistics\", url = \"http://arxiv.org/abs/1908.10084\", } \\`\\`\\` \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "paraphrase-multilingual:latest",
        "size": "paraphrase-multilingual:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "paraphrase-multilingual:278m",
        "size": "paraphrase-multilingual:278m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "paraphrase-multilingual:278m-mpnet-base-v2-fp16",
        "size": "paraphrase-multilingual:278m-mpnet-base-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "phind-codellama",
    "link": "https://ollama.com/library/phind-codellama",
    "description": "Code generation model based on Code Llama.",
    "pullCount": "97.5K",
    "updated": "1 year ago",
    "size": [
      "34b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/264120182-4a05afc9-0003-410e-8ac5-a7745dedaba8.png)\n\nPhind CodeLlama is a code generation model based on CodeLlama 34B fine-tuned for instruct use cases. There are two versions of the model: `v1` and `v2`. `v1` is based on CodeLlama 34B and CodeLlama-Python 34B. `v2` is an iteration on `v1`, trained on an additional 1.5B tokens of high-quality programming-related data.\n\n## Usage\n\n### CLI\n\nOpen the terminal and run `ollama run phind-codellama`\n\n### API\n\nExample\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"phind-codellama\",\n  \"prompt\":\"Implement a linked list in C++\"\n }'\n\n```\n\n## Memory requirements\n\n* 34b models generally require at least 32GB of RAM\n\n## References\n\n[Beating GPT-4 on HumanEval with a Fine-Tuned CodeLlama-34B](https://www.phind.com/blog/code-llama-beats-gpt4)\n\n[HuggingFace](https://huggingface.co/Phind)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/264120182-4a05afc9-0003-410e-8ac5-a7745dedaba8.png\" style=\"max-width:60%\" /> Phind CodeLlama is a code generation model based on CodeLlama 34B fine-tuned for instruct use cases. There are two versions of the model: \\`v1\\` and \\`v2\\`. \\`v1\\` is based on CodeLlama 34B and CodeLlama-Python 34B. \\`v2\\` is an iteration on \\`v1\\`, trained on an additional 1.5B tokens of high-quality programming-related data. ## Usage ### CLI Open the terminal and run \\`ollama run phind-codellama\\` ### API Example \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"phind-codellama\", \"prompt\":\"Implement a linked list in C++\" }' \\`\\`\\` ## Memory requirements - 34b models generally require at least 32GB of RAM ## References \\[Beating GPT-4 on HumanEval with a Fine-Tuned CodeLlama-34B\\](https://www.phind.com/blog/code-llama-beats-gpt4 ) \\[HuggingFace\\](https://huggingface.co/Phind) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phind-codellama:latest",
        "size": "phind-codellama:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b",
        "size": "phind-codellama:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python",
        "size": "phind-codellama:34b-python",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q2_K",
        "size": "phind-codellama:34b-python-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q3_K_S",
        "size": "phind-codellama:34b-python-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q3_K_M",
        "size": "phind-codellama:34b-python-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q3_K_L",
        "size": "phind-codellama:34b-python-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q4_0",
        "size": "phind-codellama:34b-python-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q4_1",
        "size": "phind-codellama:34b-python-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q4_K_S",
        "size": "phind-codellama:34b-python-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q4_K_M",
        "size": "phind-codellama:34b-python-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q5_0",
        "size": "phind-codellama:34b-python-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q5_1",
        "size": "phind-codellama:34b-python-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q5_K_S",
        "size": "phind-codellama:34b-python-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q5_K_M",
        "size": "phind-codellama:34b-python-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q6_K",
        "size": "phind-codellama:34b-python-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-q8_0",
        "size": "phind-codellama:34b-python-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-python-fp16",
        "size": "phind-codellama:34b-python-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2",
        "size": "phind-codellama:34b-v2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q2_K",
        "size": "phind-codellama:34b-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q3_K_S",
        "size": "phind-codellama:34b-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q3_K_M",
        "size": "phind-codellama:34b-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q3_K_L",
        "size": "phind-codellama:34b-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q4_0",
        "size": "phind-codellama:34b-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q4_1",
        "size": "phind-codellama:34b-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q4_K_S",
        "size": "phind-codellama:34b-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q4_K_M",
        "size": "phind-codellama:34b-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q5_0",
        "size": "phind-codellama:34b-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q5_1",
        "size": "phind-codellama:34b-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q5_K_S",
        "size": "phind-codellama:34b-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q5_K_M",
        "size": "phind-codellama:34b-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q6_K",
        "size": "phind-codellama:34b-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-q8_0",
        "size": "phind-codellama:34b-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-v2-fp16",
        "size": "phind-codellama:34b-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q2_K",
        "size": "phind-codellama:34b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q3_K_S",
        "size": "phind-codellama:34b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q3_K_M",
        "size": "phind-codellama:34b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q3_K_L",
        "size": "phind-codellama:34b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q4_0",
        "size": "phind-codellama:34b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q4_1",
        "size": "phind-codellama:34b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q4_K_S",
        "size": "phind-codellama:34b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q4_K_M",
        "size": "phind-codellama:34b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q5_0",
        "size": "phind-codellama:34b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q5_1",
        "size": "phind-codellama:34b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q5_K_S",
        "size": "phind-codellama:34b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q5_K_M",
        "size": "phind-codellama:34b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q6_K",
        "size": "phind-codellama:34b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-q8_0",
        "size": "phind-codellama:34b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "phind-codellama:34b-fp16",
        "size": "phind-codellama:34b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "solar",
    "link": "https://ollama.com/library/solar",
    "description": "A compact, yet powerful 10.7B large language model designed for single-turn conversation.",
    "pullCount": "97.5K",
    "updated": "1 year ago",
    "size": [
      "10.7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/1867051c-434e-4873-a074-3fa7bc111423)\n\nSolar is the first open-source 10.7 billion parameter language model. It’s compact, yet remarkably powerful, and demonstrates state-of-the-art performance in models with parameters under 30B.\n\nThis model leverages the Llama 2 architecture and employs the Depth Up-Scaling technique, integrating Mistral 7B weights into upscaled layers.\n\nOn the H6 benchmark, this model outperforms models with up to 30B parameters, even the Mixtral 8X7B model.\n\n## References\n\n[HuggingFace](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0)\n\n[Upstage AI](https://www.upstage.ai)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/1867051c-434e-4873-a074-3fa7bc111423\" width=\"200\" /> Solar is the first open-source 10.7 billion parameter language model. It's compact, yet remarkably powerful, and demonstrates state-of-the-art performance in models with parameters under 30B. This model leverages the Llama 2 architecture and employs the Depth Up-Scaling technique, integrating Mistral 7B weights into upscaled layers. On the H6 benchmark, this model outperforms models with up to 30B parameters, even the Mixtral 8X7B model. ## References \\[HuggingFace\\](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0) \\[Upstage AI\\](https://www.upstage.ai) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "solar:latest",
        "size": "solar:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b",
        "size": "solar:10.7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q2_K",
        "size": "solar:10.7b-instruct-v1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q3_K_S",
        "size": "solar:10.7b-instruct-v1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q3_K_M",
        "size": "solar:10.7b-instruct-v1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q3_K_L",
        "size": "solar:10.7b-instruct-v1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q4_0",
        "size": "solar:10.7b-instruct-v1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q4_1",
        "size": "solar:10.7b-instruct-v1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q4_K_S",
        "size": "solar:10.7b-instruct-v1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q4_K_M",
        "size": "solar:10.7b-instruct-v1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q5_0",
        "size": "solar:10.7b-instruct-v1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q5_1",
        "size": "solar:10.7b-instruct-v1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q5_K_S",
        "size": "solar:10.7b-instruct-v1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q5_K_M",
        "size": "solar:10.7b-instruct-v1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q6_K",
        "size": "solar:10.7b-instruct-v1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-q8_0",
        "size": "solar:10.7b-instruct-v1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-instruct-v1-fp16",
        "size": "solar:10.7b-instruct-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q2_K",
        "size": "solar:10.7b-text-v1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q3_K_S",
        "size": "solar:10.7b-text-v1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q3_K_M",
        "size": "solar:10.7b-text-v1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q3_K_L",
        "size": "solar:10.7b-text-v1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q4_0",
        "size": "solar:10.7b-text-v1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q4_1",
        "size": "solar:10.7b-text-v1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q4_K_S",
        "size": "solar:10.7b-text-v1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q4_K_M",
        "size": "solar:10.7b-text-v1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q5_0",
        "size": "solar:10.7b-text-v1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q5_1",
        "size": "solar:10.7b-text-v1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q5_K_S",
        "size": "solar:10.7b-text-v1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q5_K_M",
        "size": "solar:10.7b-text-v1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q6_K",
        "size": "solar:10.7b-text-v1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-q8_0",
        "size": "solar:10.7b-text-v1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "solar:10.7b-text-v1-fp16",
        "size": "solar:10.7b-text-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "internlm2",
    "link": "https://ollama.com/library/internlm2",
    "description": "InternLM2.5 is a 7B parameter model tailored for practical scenarios with outstanding reasoning capability.",
    "pullCount": "96.9K",
    "updated": "1 year ago",
    "size": [
      "1m1.8b",
      "7b",
      "20b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![internLM logo](https://ollama.com/assets/library/internlm2/646a4835-4904-4433-93ab-5eec0964fa12)\n\nInternLM2.5 has open-sourced a 7 billion parameter base model and a chat model tailored for practical scenarios. The model has the following characteristics:\n\n* **Outstanding reasoning capability**: State-of-the-art performance on Math reasoning, surpassing models like Llama3 and Gemma2-9B.\n* **Stronger tool use**: InternLM2.5 supports gathering information from more than 100 web pages, corresponding implementation will be released in Lagent soon. InternLM2.5 has better tool utilization-related capabilities in instruction following, tool selection and reflection.\n\n## Reference\n\n[GitHub](https://github.com/InternLM/InternLM)\n\n[Hugging Face](https://huggingface.co/internlm/internlm2%5F5-7b-chat)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/internlm2/646a4835-4904-4433-93ab-5eec0964fa12\" alt=\"internLM logo\" width=\"360\"/> InternLM2.5 has open-sourced a 7 billion parameter base model and a chat model tailored for practical scenarios. The model has the following characteristics: \\* \\*\\*Outstanding reasoning capability\\*\\*: State-of-the-art performance on Math reasoning, surpassing models like Llama3 and Gemma2-9B. \\* \\*\\*Stronger tool use\\*\\*: InternLM2.5 supports gathering information from more than 100 web pages, corresponding implementation will be released in Lagent soon. InternLM2.5 has better tool utilization-related capabilities in instruction following, tool selection and reflection. ## Reference \\[GitHub\\](https://github.com/InternLM/InternLM) \\[Hugging Face\\](https://huggingface.co/internlm/internlm2\\_5-7b-chat) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "internlm2:latest",
        "size": "internlm2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1m",
        "size": "internlm2:1m",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b",
        "size": "internlm2:1.8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b",
        "size": "internlm2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b",
        "size": "internlm2:20b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q2_K",
        "size": "internlm2:1.8b-chat-v2.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q3_K_S",
        "size": "internlm2:1.8b-chat-v2.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q3_K_M",
        "size": "internlm2:1.8b-chat-v2.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q3_K_L",
        "size": "internlm2:1.8b-chat-v2.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q4_0",
        "size": "internlm2:1.8b-chat-v2.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q4_1",
        "size": "internlm2:1.8b-chat-v2.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q4_K_S",
        "size": "internlm2:1.8b-chat-v2.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q4_K_M",
        "size": "internlm2:1.8b-chat-v2.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q5_0",
        "size": "internlm2:1.8b-chat-v2.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q5_1",
        "size": "internlm2:1.8b-chat-v2.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q5_K_S",
        "size": "internlm2:1.8b-chat-v2.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q5_K_M",
        "size": "internlm2:1.8b-chat-v2.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q6_K",
        "size": "internlm2:1.8b-chat-v2.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-q8_0",
        "size": "internlm2:1.8b-chat-v2.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:1.8b-chat-v2.5-fp16",
        "size": "internlm2:1.8b-chat-v2.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q2_K",
        "size": "internlm2:7b-chat-1m-v2.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q3_K_S",
        "size": "internlm2:7b-chat-1m-v2.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q3_K_M",
        "size": "internlm2:7b-chat-1m-v2.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q3_K_L",
        "size": "internlm2:7b-chat-1m-v2.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q4_0",
        "size": "internlm2:7b-chat-1m-v2.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q4_1",
        "size": "internlm2:7b-chat-1m-v2.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q4_K_S",
        "size": "internlm2:7b-chat-1m-v2.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q4_K_M",
        "size": "internlm2:7b-chat-1m-v2.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q5_0",
        "size": "internlm2:7b-chat-1m-v2.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q5_1",
        "size": "internlm2:7b-chat-1m-v2.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q5_K_S",
        "size": "internlm2:7b-chat-1m-v2.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q5_K_M",
        "size": "internlm2:7b-chat-1m-v2.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q6_K",
        "size": "internlm2:7b-chat-1m-v2.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-q8_0",
        "size": "internlm2:7b-chat-1m-v2.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-1m-v2.5-fp16",
        "size": "internlm2:7b-chat-1m-v2.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q2_K",
        "size": "internlm2:7b-chat-v2.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q3_K_S",
        "size": "internlm2:7b-chat-v2.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q3_K_M",
        "size": "internlm2:7b-chat-v2.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q3_K_L",
        "size": "internlm2:7b-chat-v2.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q4_0",
        "size": "internlm2:7b-chat-v2.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q4_1",
        "size": "internlm2:7b-chat-v2.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q4_K_S",
        "size": "internlm2:7b-chat-v2.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q4_K_M",
        "size": "internlm2:7b-chat-v2.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q5_0",
        "size": "internlm2:7b-chat-v2.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q5_1",
        "size": "internlm2:7b-chat-v2.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q5_K_S",
        "size": "internlm2:7b-chat-v2.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q5_K_M",
        "size": "internlm2:7b-chat-v2.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q6_K",
        "size": "internlm2:7b-chat-v2.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-q8_0",
        "size": "internlm2:7b-chat-v2.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:7b-chat-v2.5-fp16",
        "size": "internlm2:7b-chat-v2.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q2_K",
        "size": "internlm2:20b-chat-v2.5-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q3_K_S",
        "size": "internlm2:20b-chat-v2.5-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q3_K_M",
        "size": "internlm2:20b-chat-v2.5-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q3_K_L",
        "size": "internlm2:20b-chat-v2.5-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q4_0",
        "size": "internlm2:20b-chat-v2.5-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q4_1",
        "size": "internlm2:20b-chat-v2.5-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q4_K_S",
        "size": "internlm2:20b-chat-v2.5-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q4_K_M",
        "size": "internlm2:20b-chat-v2.5-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q5_0",
        "size": "internlm2:20b-chat-v2.5-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q5_1",
        "size": "internlm2:20b-chat-v2.5-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q5_K_S",
        "size": "internlm2:20b-chat-v2.5-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q5_K_M",
        "size": "internlm2:20b-chat-v2.5-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q6_K",
        "size": "internlm2:20b-chat-v2.5-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-q8_0",
        "size": "internlm2:20b-chat-v2.5-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "internlm2:20b-chat-v2.5-fp16",
        "size": "internlm2:20b-chat-v2.5-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "xwinlm",
    "link": "https://ollama.com/library/xwinlm",
    "description": "Conversational model based on Llama 2 that performs competitively on various benchmarks.",
    "pullCount": "96.4K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/74015728-d0a6-4c13-bb8a-d2e180480590)\n\nXwin-LM is a model based on Llama 2 using various techniques to improve its quality.\n\n## Reference\n\n[Hugging Face](https://huggingface.co/Xwin-LM/Xwin-LM-7B-V0.2)\n\nWrite Preview \n\n<img width=\"400\" src=\"https://github.com/jmorganca/ollama/assets/251292/74015728-d0a6-4c13-bb8a-d2e180480590\"> Xwin-LM is a model based on Llama 2 using various techniques to improve its quality. ## Reference \\[Hugging Face\\](https://huggingface.co/Xwin-LM/Xwin-LM-7B-V0.2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "xwinlm:latest",
        "size": "xwinlm:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b",
        "size": "xwinlm:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b",
        "size": "xwinlm:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1",
        "size": "xwinlm:7b-v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q2_K",
        "size": "xwinlm:7b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q3_K_S",
        "size": "xwinlm:7b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q3_K_M",
        "size": "xwinlm:7b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q3_K_L",
        "size": "xwinlm:7b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q4_0",
        "size": "xwinlm:7b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q4_1",
        "size": "xwinlm:7b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q4_K_S",
        "size": "xwinlm:7b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q4_K_M",
        "size": "xwinlm:7b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q5_0",
        "size": "xwinlm:7b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q5_1",
        "size": "xwinlm:7b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q5_K_S",
        "size": "xwinlm:7b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q5_K_M",
        "size": "xwinlm:7b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q6_K",
        "size": "xwinlm:7b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-q8_0",
        "size": "xwinlm:7b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.1-fp16",
        "size": "xwinlm:7b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2",
        "size": "xwinlm:7b-v0.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q2_K",
        "size": "xwinlm:7b-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q3_K_S",
        "size": "xwinlm:7b-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q3_K_L",
        "size": "xwinlm:7b-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q4_0",
        "size": "xwinlm:7b-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q4_1",
        "size": "xwinlm:7b-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q4_K_S",
        "size": "xwinlm:7b-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q4_K_M",
        "size": "xwinlm:7b-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q5_0",
        "size": "xwinlm:7b-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q5_K_S",
        "size": "xwinlm:7b-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q5_K_M",
        "size": "xwinlm:7b-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q6_K",
        "size": "xwinlm:7b-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-q8_0",
        "size": "xwinlm:7b-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:7b-v0.2-fp16",
        "size": "xwinlm:7b-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1",
        "size": "xwinlm:13b-v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q2_K",
        "size": "xwinlm:13b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q3_K_S",
        "size": "xwinlm:13b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q3_K_M",
        "size": "xwinlm:13b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q3_K_L",
        "size": "xwinlm:13b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q4_0",
        "size": "xwinlm:13b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q4_1",
        "size": "xwinlm:13b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q4_K_S",
        "size": "xwinlm:13b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q4_K_M",
        "size": "xwinlm:13b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q5_0",
        "size": "xwinlm:13b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q5_1",
        "size": "xwinlm:13b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q5_K_S",
        "size": "xwinlm:13b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q5_K_M",
        "size": "xwinlm:13b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q6_K",
        "size": "xwinlm:13b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-q8_0",
        "size": "xwinlm:13b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.1-fp16",
        "size": "xwinlm:13b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2",
        "size": "xwinlm:13b-v0.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q2_K",
        "size": "xwinlm:13b-v0.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q3_K_S",
        "size": "xwinlm:13b-v0.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q3_K_M",
        "size": "xwinlm:13b-v0.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q3_K_L",
        "size": "xwinlm:13b-v0.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q4_0",
        "size": "xwinlm:13b-v0.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q4_1",
        "size": "xwinlm:13b-v0.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q4_K_S",
        "size": "xwinlm:13b-v0.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q4_K_M",
        "size": "xwinlm:13b-v0.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q5_0",
        "size": "xwinlm:13b-v0.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q5_1",
        "size": "xwinlm:13b-v0.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q5_K_S",
        "size": "xwinlm:13b-v0.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q5_K_M",
        "size": "xwinlm:13b-v0.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q6_K",
        "size": "xwinlm:13b-v0.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-q8_0",
        "size": "xwinlm:13b-v0.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:13b-v0.2-fp16",
        "size": "xwinlm:13b-v0.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1",
        "size": "xwinlm:70b-v0.1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q2_K",
        "size": "xwinlm:70b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q3_K_S",
        "size": "xwinlm:70b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q3_K_M",
        "size": "xwinlm:70b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q3_K_L",
        "size": "xwinlm:70b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q4_0",
        "size": "xwinlm:70b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q4_1",
        "size": "xwinlm:70b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q4_K_S",
        "size": "xwinlm:70b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q4_K_M",
        "size": "xwinlm:70b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q5_0",
        "size": "xwinlm:70b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q5_1",
        "size": "xwinlm:70b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q5_K_S",
        "size": "xwinlm:70b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q6_K",
        "size": "xwinlm:70b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-q8_0",
        "size": "xwinlm:70b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "xwinlm:70b-v0.1-fp16",
        "size": "xwinlm:70b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "athene-v2",
    "link": "https://ollama.com/library/athene-v2",
    "description": "Athene-V2 is a 72B parameter model which excels at code completion, mathematics, and log extraction tasks.",
    "pullCount": "95.4K",
    "updated": "9 months ago",
    "size": [
      "72b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n# Athene-V2\n\nNexusflow’s Athene-V2 chat model, built on Qwen 2.5’s 72B foundation, achieves GPT-4o-level performance across key benchmarks while demonstrating how targeted optimization can enhance specific capabilities beyond traditional scaling approaches.\n\n## Model Features\n\n* **72B parameters** fine-tuned from Qwen 2.5\n* **State-of-the-art chat performance** matching or exceeding GPT-4o\n* **Superior code completion** (ranking #2 on bigcode-bench-hard)\n* **Enhanced mathematics capabilities** (MATH benchmark)\n* **Precise long-form log extraction**\n* **Advanced post-training pipeline** pushing the Pareto frontier\n\n![](https://ollama.com/assets/library/athene-v2/99424f56-1e23-4f31-8dfa-4fc46eb6305f)\n\n## References\n\n[Blog post](https://nexusflow.ai/blogs/athene-v2)\n\n[HuggingFace](https://huggingface.co/Nexusflow/Athene-V2-Chat)\n\nWrite Preview \n\n\\# Athene-V2 Nexusflow's Athene-V2 chat model, built on Qwen 2.5's 72B foundation, achieves GPT-4o-level performance across key benchmarks while demonstrating how targeted optimization can enhance specific capabilities beyond traditional scaling approaches. ## Model Features - \\*\\*72B parameters\\*\\* fine-tuned from Qwen 2.5 - \\*\\*State-of-the-art chat performance\\*\\* matching or exceeding GPT-4o - \\*\\*Superior code completion\\*\\* (ranking #2 on bigcode-bench-hard) - \\*\\*Enhanced mathematics capabilities\\*\\* (MATH benchmark) - \\*\\*Precise long-form log extraction\\*\\* - \\*\\*Advanced post-training pipeline\\*\\* pushing the Pareto frontier <img src=\"https://ollama.com/assets/library/athene-v2/99424f56-1e23-4f31-8dfa-4fc46eb6305f\" width=\"460\" /> ## References \\[Blog post\\](https://nexusflow.ai/blogs/athene-v2) \\[HuggingFace\\](https://huggingface.co/Nexusflow/Athene-V2-Chat) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "athene-v2:latest",
        "size": "athene-v2:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b",
        "size": "athene-v2:72b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q2_K",
        "size": "athene-v2:72b-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q3_K_S",
        "size": "athene-v2:72b-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q3_K_M",
        "size": "athene-v2:72b-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q3_K_L",
        "size": "athene-v2:72b-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q4_0",
        "size": "athene-v2:72b-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q4_1",
        "size": "athene-v2:72b-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q4_K_S",
        "size": "athene-v2:72b-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q4_K_M",
        "size": "athene-v2:72b-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q5_0",
        "size": "athene-v2:72b-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q5_1",
        "size": "athene-v2:72b-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q5_K_S",
        "size": "athene-v2:72b-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q5_K_M",
        "size": "athene-v2:72b-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q6_K",
        "size": "athene-v2:72b-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-q8_0",
        "size": "athene-v2:72b-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "athene-v2:72b-fp16",
        "size": "athene-v2:72b-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "granite-embedding",
    "link": "https://ollama.com/library/granite-embedding",
    "description": "The IBM Granite Embedding 30M and 278M models models are text-only dense biencoder embedding models, with 30M available in English only and 278M serving multilingual use cases.",
    "pullCount": "94.2K",
    "updated": "8 months ago",
    "size": null,
    "capabilities": "embedding",
    "readme": "## Readme\n\n## Granite embedding models\n\nThe IBM Granite Embedding **30M and 278M models** are text-only dense biencoder embedding models, with **30M** available in English only and **278M** serving multilingual use cases. These models are designed to produce fixed length vector representations for a given text chunk, which can be used for text similarity, retrieval, and search applications.\n\n### Parameter Sizes\n\n**30M:**\n\n`ollama run granite-embedding:30m`\n\n**278M:**\n\n`ollama run granite-embedding:278m`\n\n### Supported Languages\n\n**30M:** English**278M:** English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified)\n\n## Granite dense models\n\nThe Granite dense models are available in **2B and 8B** parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.\n\n[See model page](https://ollama.com/library/granite3-dense)\n\n## Granite mixture of experts models\n\nThe Granite mixture of experts models are available in **1B and 3B** parameter sizes designed for **low latency usage**.\n\n[See model page](https://ollama.com/library/granite3-moe)\n\n## Learn more\n\n* **Developers:** IBM Research\n* **GitHub Repository:** [ibm-granite/granite-language-models](https://github.com/ibm-granite/granite-3.1-language-models)\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: December 18th, 2024\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\nWrite Preview \n\n\\## Granite embedding models The IBM Granite Embedding \\*\\*30M and 278M models\\*\\* are text-only dense biencoder embedding models, with \\*\\*30M\\*\\* available in English only and \\*\\*278M\\*\\* serving multilingual use cases. These models are designed to produce fixed length vector representations for a given text chunk, which can be used for text similarity, retrieval, and search applications. ### Parameter Sizes \\*\\*30M:\\*\\* \\`ollama run granite-embedding:30m\\` \\*\\*278M:\\*\\* \\`ollama run granite-embedding:278m\\` ### Supported Languages \\*\\*30M:\\*\\* English \\*\\*278M:\\*\\* English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified) ## Granite dense models The Granite dense models are available in \\*\\*2B and 8B\\*\\* parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. \\[See model page\\](https://ollama.com/library/granite3-dense) ## Granite mixture of experts models The Granite mixture of experts models are available in \\*\\*1B and 3B\\*\\* parameter sizes designed for \\*\\*low latency usage\\*\\*. \\[See model page\\](https://ollama.com/library/granite3-moe) ## Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*GitHub Repository:\\*\\* \\[ibm-granite/granite-language-models\\](https://github.com/ibm-granite/granite-3.1-language-models) - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: December 18th, 2024 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0). \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite-embedding:latest",
        "size": "granite-embedding:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite-embedding:30m",
        "size": "granite-embedding:30m",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite-embedding:278m",
        "size": "granite-embedding:278m",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite-embedding:30m-en",
        "size": "granite-embedding:30m-en",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite-embedding:30m-en-fp16",
        "size": "granite-embedding:30m-en-fp16",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "granite-embedding:278m-fp16",
        "size": "granite-embedding:278m-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "nemotron",
    "link": "https://ollama.com/library/nemotron",
    "description": "Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries.",
    "pullCount": "92.6K",
    "updated": "10 months ago",
    "size": [
      "70b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/nemotron-mini/4e0ea563-a507-45e7-ad0b-b083918ec11b)\n\nLlama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries.\n\nThis model was trained using RLHF (specifically, REINFORCE), [Llama-3.1-Nemotron-70B-Reward](https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward) and [HelpSteer2-Preference prompts](https://huggingface.co/datasets/nvidia/HelpSteer2) on a [Llama-3.1-70B-Instruct](https://ai.meta.com/blog/meta-llama-3-1/) model as the initial policy.\n\n```\n$ ollama run nemotron\n>>> How many r in strawberry?\nA sweet question!\n\nLet's count the \"R\"s in \"strawberry\":\n\n1. S\n2. T\n3. R\n4. A\n5. W\n6. B\n7. E\n8. R\n9. R\n10. Y\n\nThere are **3** \"R\"s in the word \"strawberry\".\n\n```\n\n## Reference\n\n[Hugging Face](https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/nemotron-mini/4e0ea563-a507-45e7-ad0b-b083918ec11b\" width=\"320\" /> Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries. This model was trained using RLHF (specifically, REINFORCE), \\[Llama-3.1-Nemotron-70B-Reward\\](https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward) and \\[HelpSteer2-Preference prompts\\](https://huggingface.co/datasets/nvidia/HelpSteer2) on a \\[Llama-3.1-70B-Instruct\\](https://ai.meta.com/blog/meta-llama-3-1/) model as the initial policy. \\`\\`\\` $ ollama run nemotron >>> How many r in strawberry? A sweet question! Let's count the \"R\"s in \"strawberry\": 1\\. S 2\\. T 3\\. R 4\\. A 5\\. W 6\\. B 7\\. E 8\\. R 9\\. R 10\\. Y There are \\*\\*3\\*\\* \"R\"s in the word \"strawberry\". \\`\\`\\` ## Reference \\[Hugging Face\\](https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nemotron:latest",
        "size": "nemotron:latest",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b",
        "size": "nemotron:70b",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q2_K",
        "size": "nemotron:70b-instruct-q2_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q3_K_S",
        "size": "nemotron:70b-instruct-q3_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q3_K_M",
        "size": "nemotron:70b-instruct-q3_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q3_K_L",
        "size": "nemotron:70b-instruct-q3_K_L",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q4_0",
        "size": "nemotron:70b-instruct-q4_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q4_1",
        "size": "nemotron:70b-instruct-q4_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q4_K_S",
        "size": "nemotron:70b-instruct-q4_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q4_K_M",
        "size": "nemotron:70b-instruct-q4_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q5_0",
        "size": "nemotron:70b-instruct-q5_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q5_1",
        "size": "nemotron:70b-instruct-q5_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q5_K_S",
        "size": "nemotron:70b-instruct-q5_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q5_K_M",
        "size": "nemotron:70b-instruct-q5_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q6_K",
        "size": "nemotron:70b-instruct-q6_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-q8_0",
        "size": "nemotron:70b-instruct-q8_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "nemotron:70b-instruct-fp16",
        "size": "nemotron:70b-instruct-fp16",
        "updated": "Text input • \n                    10 months ago"
      }
    ]
  },
  {
    "name": "llama3-groq-tool-use",
    "link": "https://ollama.com/library/llama3-groq-tool-use",
    "description": "A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling.",
    "pullCount": "91.4K",
    "updated": "1 year ago",
    "size": [
      "8b",
      "70b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/llama3-groq-tool-use/ebf53e82-1faf-4bac-84b0-47b8f5d9d8d1)\n\nThese models, developed in collaboration with [Glaive](https://glaive.ai/), represent a significant advancement in open-source AI capabilities for tool use/function calling.\n\n## Benchmark Results\n\nThese models have achieved remarkable results, setting new benchmarks for Large Language Models with tool use capabilities:\n\n* Llama-3-Groq-70B-Tool-Use: 90.76% overall accuracy (#1 on BFCL at the time of publishing - July 2024)\n* Llama-3-Groq-8B-Tool-Use: 89.06% overall accuracy (#3 on BFCL at the time of publishing - July 2024)\n\n## References\n\n[Hugging Face](https://huggingface.co/Groq)\n\n[Blog](https://wow.groq.com/introducing-llama-3-groq-tool-use-models/)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/llama3-groq-tool-use/ebf53e82-1faf-4bac-84b0-47b8f5d9d8d1\" width=\"240\" /> These models, developed in collaboration with \\[Glaive\\](https://glaive.ai/), represent a significant advancement in open-source AI capabilities for tool use/function calling. ## Benchmark Results These models have achieved remarkable results, setting new benchmarks for Large Language Models with tool use capabilities: \\* Llama-3-Groq-70B-Tool-Use: 90.76% overall accuracy (#1 on BFCL at the time of publishing - July 2024) \\* Llama-3-Groq-8B-Tool-Use: 89.06% overall accuracy (#3 on BFCL at the time of publishing - July 2024) ## References \\[Hugging Face\\](https://huggingface.co/Groq) \\[Blog\\](https://wow.groq.com/introducing-llama-3-groq-tool-use-models/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama3-groq-tool-use:latest",
        "size": "llama3-groq-tool-use:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b",
        "size": "llama3-groq-tool-use:8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b",
        "size": "llama3-groq-tool-use:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q2_K",
        "size": "llama3-groq-tool-use:8b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q3_K_S",
        "size": "llama3-groq-tool-use:8b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q3_K_M",
        "size": "llama3-groq-tool-use:8b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q3_K_L",
        "size": "llama3-groq-tool-use:8b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q4_0",
        "size": "llama3-groq-tool-use:8b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q4_1",
        "size": "llama3-groq-tool-use:8b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q4_K_S",
        "size": "llama3-groq-tool-use:8b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q4_K_M",
        "size": "llama3-groq-tool-use:8b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q5_0",
        "size": "llama3-groq-tool-use:8b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q5_1",
        "size": "llama3-groq-tool-use:8b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q5_K_S",
        "size": "llama3-groq-tool-use:8b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q5_K_M",
        "size": "llama3-groq-tool-use:8b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q6_K",
        "size": "llama3-groq-tool-use:8b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-q8_0",
        "size": "llama3-groq-tool-use:8b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:8b-fp16",
        "size": "llama3-groq-tool-use:8b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q2_K",
        "size": "llama3-groq-tool-use:70b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q3_K_S",
        "size": "llama3-groq-tool-use:70b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q3_K_M",
        "size": "llama3-groq-tool-use:70b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q3_K_L",
        "size": "llama3-groq-tool-use:70b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q4_0",
        "size": "llama3-groq-tool-use:70b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q4_1",
        "size": "llama3-groq-tool-use:70b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q4_K_S",
        "size": "llama3-groq-tool-use:70b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q4_K_M",
        "size": "llama3-groq-tool-use:70b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q5_0",
        "size": "llama3-groq-tool-use:70b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q5_1",
        "size": "llama3-groq-tool-use:70b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q5_K_S",
        "size": "llama3-groq-tool-use:70b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q5_K_M",
        "size": "llama3-groq-tool-use:70b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q6_K",
        "size": "llama3-groq-tool-use:70b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-q8_0",
        "size": "llama3-groq-tool-use:70b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama3-groq-tool-use:70b-fp16",
        "size": "llama3-groq-tool-use:70b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "yarn-llama2",
    "link": "https://ollama.com/library/yarn-llama2",
    "description": "An extension of Llama 2 that supports a context of up to 128k tokens.",
    "pullCount": "90.8K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nYarn Llama 2 is a model based on [Llama2](https://ollama.ai/library/llama2) that extends its context size up to 128k context. It is developed by [Nous Research](https://nousresearch.com) by implementing the YaRN method to further train the model to support larger context windows.\n\n## CLI\n\n64k context size:\n\n```\nollama run yarn-llama2\n\n```\n\n128k context size:\n\n```\nollama run yarn-llama2:7b-128k\n\n```\n\n## API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"yarn-llama2:7b-128k\",\n  \"prompt\":\"Here is a story about llamas eating grass\"\n }'\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/NousResearch/Yarn-Llama-2-7b-64k)\n\n[YaRN: Efficient Context Window Extension of Large Language Models](https://arxiv.org/pdf/2309.00071.pdf)\n\nWrite Preview \n\nYarn Llama 2 is a model based on \\[Llama2\\](https://ollama.ai/library/llama2) that extends its context size up to 128k context. It is developed by \\[Nous Research\\](https://nousresearch.com) by implementing the YaRN method to further train the model to support larger context windows. ## CLI 64k context size: \\`\\`\\` ollama run yarn-llama2 \\`\\`\\` 128k context size: \\`\\`\\` ollama run yarn-llama2:7b-128k \\`\\`\\` ## API Example: \\`\\`\\` curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"yarn-llama2:7b-128k\", \"prompt\":\"Here is a story about llamas eating grass\" }' \\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/NousResearch/Yarn-Llama-2-7b-64k) \\[YaRN: Efficient Context Window Extension of Large Language Models\\](https://arxiv.org/pdf/2309.00071.pdf) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "yarn-llama2:latest",
        "size": "yarn-llama2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b",
        "size": "yarn-llama2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b",
        "size": "yarn-llama2:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k",
        "size": "yarn-llama2:7b-128k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q2_K",
        "size": "yarn-llama2:7b-128k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q3_K_S",
        "size": "yarn-llama2:7b-128k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q3_K_M",
        "size": "yarn-llama2:7b-128k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q3_K_L",
        "size": "yarn-llama2:7b-128k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q4_0",
        "size": "yarn-llama2:7b-128k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q4_1",
        "size": "yarn-llama2:7b-128k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q4_K_S",
        "size": "yarn-llama2:7b-128k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q4_K_M",
        "size": "yarn-llama2:7b-128k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q5_0",
        "size": "yarn-llama2:7b-128k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q5_1",
        "size": "yarn-llama2:7b-128k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q5_K_S",
        "size": "yarn-llama2:7b-128k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q5_K_M",
        "size": "yarn-llama2:7b-128k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q6_K",
        "size": "yarn-llama2:7b-128k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-q8_0",
        "size": "yarn-llama2:7b-128k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-128k-fp16",
        "size": "yarn-llama2:7b-128k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k",
        "size": "yarn-llama2:7b-64k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q2_K",
        "size": "yarn-llama2:7b-64k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q3_K_S",
        "size": "yarn-llama2:7b-64k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q3_K_M",
        "size": "yarn-llama2:7b-64k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q3_K_L",
        "size": "yarn-llama2:7b-64k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q4_0",
        "size": "yarn-llama2:7b-64k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q4_1",
        "size": "yarn-llama2:7b-64k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q4_K_S",
        "size": "yarn-llama2:7b-64k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q4_K_M",
        "size": "yarn-llama2:7b-64k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q5_0",
        "size": "yarn-llama2:7b-64k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q5_1",
        "size": "yarn-llama2:7b-64k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q5_K_S",
        "size": "yarn-llama2:7b-64k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q5_K_M",
        "size": "yarn-llama2:7b-64k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q6_K",
        "size": "yarn-llama2:7b-64k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-q8_0",
        "size": "yarn-llama2:7b-64k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:7b-64k-fp16",
        "size": "yarn-llama2:7b-64k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k",
        "size": "yarn-llama2:13b-128k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q2_K",
        "size": "yarn-llama2:13b-128k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q3_K_S",
        "size": "yarn-llama2:13b-128k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q3_K_M",
        "size": "yarn-llama2:13b-128k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q3_K_L",
        "size": "yarn-llama2:13b-128k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q4_0",
        "size": "yarn-llama2:13b-128k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q4_1",
        "size": "yarn-llama2:13b-128k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q4_K_S",
        "size": "yarn-llama2:13b-128k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q4_K_M",
        "size": "yarn-llama2:13b-128k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q5_0",
        "size": "yarn-llama2:13b-128k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q5_1",
        "size": "yarn-llama2:13b-128k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q5_K_S",
        "size": "yarn-llama2:13b-128k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q5_K_M",
        "size": "yarn-llama2:13b-128k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q6_K",
        "size": "yarn-llama2:13b-128k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-q8_0",
        "size": "yarn-llama2:13b-128k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-128k-fp16",
        "size": "yarn-llama2:13b-128k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k",
        "size": "yarn-llama2:13b-64k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q2_K",
        "size": "yarn-llama2:13b-64k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q3_K_S",
        "size": "yarn-llama2:13b-64k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q3_K_M",
        "size": "yarn-llama2:13b-64k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q3_K_L",
        "size": "yarn-llama2:13b-64k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q4_0",
        "size": "yarn-llama2:13b-64k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q4_1",
        "size": "yarn-llama2:13b-64k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q4_K_S",
        "size": "yarn-llama2:13b-64k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q4_K_M",
        "size": "yarn-llama2:13b-64k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q5_0",
        "size": "yarn-llama2:13b-64k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q5_1",
        "size": "yarn-llama2:13b-64k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q5_K_S",
        "size": "yarn-llama2:13b-64k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q5_K_M",
        "size": "yarn-llama2:13b-64k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q6_K",
        "size": "yarn-llama2:13b-64k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-q8_0",
        "size": "yarn-llama2:13b-64k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-llama2:13b-64k-fp16",
        "size": "yarn-llama2:13b-64k-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "meditron",
    "link": "https://ollama.com/library/meditron",
    "description": "Open-source medical large language model adapted from Llama 2 to the medical domain.",
    "pullCount": "88.4K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/0ba1061e-ddaf-4b3f-abd3-684a31d19fa5)\n\nMeditron is a large language model adapted from Llama 2 to the medical domain through training on a corpus of medical data, papers and guidelines. It outperforms Llama 2, GPT 3.5 and Flan-PaLM on many medical reasoning tasks.\n\nPotential use cases include:\n\n* Medical exam question answering\n* Supporting differential diagnosis\n* Disease information (symptoms, cause, treatment) query\n* General health information query\n\n## Example prompts\n\n```\nWhat are the symptoms of the common cold?\n\n```\n\n```\nWhat causes the seasonal flu?\n\n```\n\n```\nWhat medication would be prescribed for a headache?\n\n```\n\n## References\n\n[MEDITRON-70B: Scaling Medical Pretraining for Large Language Models](https://arxiv.org/abs/2311.16079)\n\n[GitHub](https://github.com/epfLLM/meditron)\n\n[HuggingFace](https://huggingface.co/epfl-llm/meditron-7b)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/0ba1061e-ddaf-4b3f-abd3-684a31d19fa5\" width=\"240\" /> Meditron is a large language model adapted from Llama 2 to the medical domain through training on a corpus of medical data, papers and guidelines. It outperforms Llama 2, GPT 3.5 and Flan-PaLM on many medical reasoning tasks. Potential use cases include: \\* Medical exam question answering \\* Supporting differential diagnosis \\* Disease information (symptoms, cause, treatment) query \\* General health information query ## Example prompts \\`\\`\\` What are the symptoms of the common cold? \\`\\`\\` \\`\\`\\` What causes the seasonal flu? \\`\\`\\` \\`\\`\\` What medication would be prescribed for a headache? \\`\\`\\` ## References \\[MEDITRON-70B: Scaling Medical Pretraining for Large Language Models\\](https://arxiv.org/abs/2311.16079) \\[GitHub\\](https://github.com/epfLLM/meditron) \\[HuggingFace\\](https://huggingface.co/epfl-llm/meditron-7b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "meditron:latest",
        "size": "meditron:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b",
        "size": "meditron:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:70b",
        "size": "meditron:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q2_K",
        "size": "meditron:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q3_K_S",
        "size": "meditron:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q3_K_M",
        "size": "meditron:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q3_K_L",
        "size": "meditron:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q4_0",
        "size": "meditron:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q4_1",
        "size": "meditron:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q4_K_S",
        "size": "meditron:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q4_K_M",
        "size": "meditron:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q5_0",
        "size": "meditron:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q5_1",
        "size": "meditron:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q5_K_S",
        "size": "meditron:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q5_K_M",
        "size": "meditron:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q6_K",
        "size": "meditron:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-q8_0",
        "size": "meditron:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:7b-fp16",
        "size": "meditron:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:70b-q4_0",
        "size": "meditron:70b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:70b-q4_1",
        "size": "meditron:70b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:70b-q4_K_S",
        "size": "meditron:70b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "meditron:70b-q5_1",
        "size": "meditron:70b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "granite3-moe",
    "link": "https://ollama.com/library/granite3-moe",
    "description": "The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.",
    "pullCount": "83.9K",
    "updated": "9 months ago",
    "size": [
      "1b",
      "3b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![An illustration of Ollama holding a beautiful flower with the IBM Rebus logo of the Eye, Bee and M, made by Paul Rand.](https://ollama.com/assets/library/granite3-moe/6ea49528-3ff2-4fcc-98b2-01f6104254d2)\n\n### Granite mixture of experts models\n\nThe IBM Granite **1B and 3B models** are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.\n\nThe models are trained on over 10 trillion tokens of data, the Granite MoE models are ideal for deployment in on-device applications or situations requiring instantaneous inference.\n\n## Parameter Sizes\n\n**1B:**\n\n`ollama run granite3-moe:1b`\n\n**3B:**\n\n`ollama run granite3-moe:3b`\n\n## Supported Languages\n\nEnglish, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified)\n\n### Capabilities\n\n* Summarization\n* Text classification\n* Text extraction\n* Question-answering\n* Retrieval Augmented Generation (RAG)\n* Code related\n* Function-calling\n* Multilingual dialog use cases\n\n### Granite dense models\n\nThe Granite dense models are available in **2B and 8B** parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.\n\n[See model page](https://ollama.com/library/granite3-dense)\n\n### Learn more\n\n* **Developers:** IBM Research\n* **GitHub Repository:** [ibm-granite/granite-3.0-language-models](https://github.com/ibm-granite/granite-3.0-language-models)\n* **Website**: [Granite Docs](https://www.ibm.com/granite/docs/)\n* **Release Date**: October 21st, 2024\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\nWrite Preview \n\n!\\[An illustration of Ollama holding a beautiful flower with the IBM Rebus logo of the Eye, Bee and M, made by Paul Rand.\\](https://ollama.com/assets/library/granite3-moe/6ea49528-3ff2-4fcc-98b2-01f6104254d2) ### Granite mixture of experts models The IBM Granite \\*\\*1B and 3B models\\*\\* are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage. The models are trained on over 10 trillion tokens of data, the Granite MoE models are ideal for deployment in on-device applications or situations requiring instantaneous inference. ## Parameter Sizes \\*\\*1B:\\*\\* \\`ollama run granite3-moe:1b\\` \\*\\*3B:\\*\\* \\`ollama run granite3-moe:3b\\` ## Supported Languages English, German, Spanish, French, Japanese, Portuguese, Arabic, Czech, Italian, Korean, Dutch, Chinese (Simplified) ### Capabilities \\* Summarization \\* Text classification \\* Text extraction \\* Question-answering \\* Retrieval Augmented Generation (RAG) \\* Code related \\* Function-calling \\* Multilingual dialog use cases ### Granite dense models The Granite dense models are available in \\*\\*2B and 8B\\*\\* parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. \\[See model page\\](https://ollama.com/library/granite3-dense) ### Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*GitHub Repository:\\*\\* \\[ibm-granite/granite-3.0-language-models\\](https://github.com/ibm-granite/granite-3.0-language-models) - \\*\\*Website\\*\\*: \\[Granite Docs\\](https://www.ibm.com/granite/docs/) - \\*\\*Release Date\\*\\*: October 21st, 2024 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0). \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3-moe:latest",
        "size": "granite3-moe:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b",
        "size": "granite3-moe:1b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b",
        "size": "granite3-moe:3b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q2_K",
        "size": "granite3-moe:1b-instruct-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q3_K_S",
        "size": "granite3-moe:1b-instruct-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q3_K_M",
        "size": "granite3-moe:1b-instruct-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q3_K_L",
        "size": "granite3-moe:1b-instruct-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q4_0",
        "size": "granite3-moe:1b-instruct-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q4_1",
        "size": "granite3-moe:1b-instruct-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q4_K_S",
        "size": "granite3-moe:1b-instruct-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q4_K_M",
        "size": "granite3-moe:1b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q5_0",
        "size": "granite3-moe:1b-instruct-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q5_1",
        "size": "granite3-moe:1b-instruct-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q5_K_S",
        "size": "granite3-moe:1b-instruct-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q5_K_M",
        "size": "granite3-moe:1b-instruct-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q6_K",
        "size": "granite3-moe:1b-instruct-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-q8_0",
        "size": "granite3-moe:1b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:1b-instruct-fp16",
        "size": "granite3-moe:1b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q2_K",
        "size": "granite3-moe:3b-instruct-q2_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q3_K_S",
        "size": "granite3-moe:3b-instruct-q3_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q3_K_M",
        "size": "granite3-moe:3b-instruct-q3_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q3_K_L",
        "size": "granite3-moe:3b-instruct-q3_K_L",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q4_0",
        "size": "granite3-moe:3b-instruct-q4_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q4_1",
        "size": "granite3-moe:3b-instruct-q4_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q4_K_S",
        "size": "granite3-moe:3b-instruct-q4_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q4_K_M",
        "size": "granite3-moe:3b-instruct-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q5_0",
        "size": "granite3-moe:3b-instruct-q5_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q5_1",
        "size": "granite3-moe:3b-instruct-q5_1",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q5_K_S",
        "size": "granite3-moe:3b-instruct-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q5_K_M",
        "size": "granite3-moe:3b-instruct-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q6_K",
        "size": "granite3-moe:3b-instruct-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-q8_0",
        "size": "granite3-moe:3b-instruct-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-moe:3b-instruct-fp16",
        "size": "granite3-moe:3b-instruct-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "wizardlm-uncensored",
    "link": "https://ollama.com/library/wizardlm-uncensored",
    "description": "Uncensored version of Wizard LM model",
    "pullCount": "82.1K",
    "updated": "1 year ago",
    "size": [
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nWizardLM Uncensored is a 13B parameter model based on Llama 2 uncensored by Eric Hartford. The models were trained against LLaMA-7B with a subset of the dataset, responses that contained alignment / moralizing were removed.\n\n## Get started with WizardLM Uncensored\n\nThe model used in the example below is the WizardLM Uncensored model, with 13b parameters, which is a general-use model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"wizardlm-uncensored\",\n  \"prompt\":\"Who made Rose promise that she would never let go?\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run wizardlm-uncensored`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull wizardlm-uncensored`\n\n## Memory requirements\n\n* 13b models generally require at least 16GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n| **Aliases**                               |\n| ----------------------------------------- |\n| latest, 13b, 13b-llama2, 13b-llama2-q4\\_0 |\n\n## Model source\n\n**WizardLM Uncensored source on Ollama**\n\n13b parameters source:[The Bloke](https://huggingface.co/TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGML)\n\n13b parameters original source:[Eric Hartford](https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-Llama2-13b)\n\nWrite Preview \n\nWizardLM Uncensored is a 13B parameter model based on Llama 2 uncensored by Eric Hartford. The models were trained against LLaMA-7B with a subset of the dataset, responses that contained alignment / moralizing were removed. ## Get started with WizardLM Uncensored The model used in the example below is the WizardLM Uncensored model, with 13b parameters, which is a general-use model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"wizardlm-uncensored\", \"prompt\":\"Who made Rose promise that she would never let go?\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run wizardlm-uncensored\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull wizardlm-uncensored\\` ## Memory requirements - 13b models generally require at least 16GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. | \\*\\*Aliases\\*\\* | | --- | | latest, 13b, 13b-llama2, 13b-llama2-q4\\_0 | ## Model source \\*\\*WizardLM Uncensored source on Ollama\\*\\* 13b parameters source: \\[The Bloke\\](https://huggingface.co/TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGML) 13b parameters original source: \\[Eric Hartford\\](https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-Llama2-13b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizardlm-uncensored:latest",
        "size": "wizardlm-uncensored:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b",
        "size": "wizardlm-uncensored:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2",
        "size": "wizardlm-uncensored:13b-llama2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q2_K",
        "size": "wizardlm-uncensored:13b-llama2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q3_K_S",
        "size": "wizardlm-uncensored:13b-llama2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q3_K_M",
        "size": "wizardlm-uncensored:13b-llama2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q3_K_L",
        "size": "wizardlm-uncensored:13b-llama2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q4_0",
        "size": "wizardlm-uncensored:13b-llama2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q4_1",
        "size": "wizardlm-uncensored:13b-llama2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q4_K_S",
        "size": "wizardlm-uncensored:13b-llama2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q4_K_M",
        "size": "wizardlm-uncensored:13b-llama2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q5_0",
        "size": "wizardlm-uncensored:13b-llama2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q5_1",
        "size": "wizardlm-uncensored:13b-llama2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q5_K_S",
        "size": "wizardlm-uncensored:13b-llama2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q5_K_M",
        "size": "wizardlm-uncensored:13b-llama2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q6_K",
        "size": "wizardlm-uncensored:13b-llama2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-q8_0",
        "size": "wizardlm-uncensored:13b-llama2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm-uncensored:13b-llama2-fp16",
        "size": "wizardlm-uncensored:13b-llama2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "aya-expanse",
    "link": "https://ollama.com/library/aya-expanse",
    "description": "Cohere For AI's language models trained to perform well across 23 different languages.",
    "pullCount": "81K",
    "updated": "10 months ago",
    "size": [
      "8b",
      "32b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/aya-expanse/fba5fdd1-f5f3-43d2-a2e1-04c9e37d37be)\n\nAya Expanse represents a significant advancement in multilingual AI capabilities. Combining Cohere’s Command model family with a year of focused research in multilingual optimization has produced versatile 8B and 32B parameter models that can understand and generate text across 23 languages while maintaining high performance across all of them.\n\n## Key Features\n\n* 8-billion and 32-billion parameter multilingual language models developed by Cohere For AI\n* Supports Arabic, Chinese (simplified & traditional), Czech, Dutch, English, French, German, Greek, Hebrew, Hebrew, Hindi, Indonesian, Italian, Japanese, Korean, Persian, Polish, Portuguese, Romanian, Russian, Spanish, Turkish, Ukrainian, and Vietnamese\n* Built on the Command family of models with extensive research in data arbitrage, multilingual preference training, and safety tuning\n* 128K context length\n* Released under CC-BY-NC license with additional usage policies\n\n## References\n\n[Blog post](https://cohere.com/blog/aya-expanse-connecting-our-world)\n\n[HuggingFace](https://huggingface.co/CohereForAI/aya-expanse-8b)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/aya-expanse/fba5fdd1-f5f3-43d2-a2e1-04c9e37d37be\" width=\"460\" /> Aya Expanse represents a significant advancement in multilingual AI capabilities. Combining Cohere's Command model family with a year of focused research in multilingual optimization has produced versatile 8B and 32B parameter models that can understand and generate text across 23 languages while maintaining high performance across all of them. ## Key Features - 8-billion and 32-billion parameter multilingual language models developed by Cohere For AI - Supports Arabic, Chinese (simplified & traditional), Czech, Dutch, English, French, German, Greek, Hebrew, Hebrew, Hindi, Indonesian, Italian, Japanese, Korean, Persian, Polish, Portuguese, Romanian, Russian, Spanish, Turkish, Ukrainian, and Vietnamese - Built on the Command family of models with extensive research in data arbitrage, multilingual preference training, and safety tuning - 128K context length - Released under CC-BY-NC license with additional usage policies ## References \\[Blog post\\](https://cohere.com/blog/aya-expanse-connecting-our-world) \\[HuggingFace\\](https://huggingface.co/CohereForAI/aya-expanse-8b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "aya-expanse:latest",
        "size": "aya-expanse:latest",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b",
        "size": "aya-expanse:8b",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b",
        "size": "aya-expanse:32b",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q2_K",
        "size": "aya-expanse:8b-q2_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q3_K_S",
        "size": "aya-expanse:8b-q3_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q3_K_M",
        "size": "aya-expanse:8b-q3_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q3_K_L",
        "size": "aya-expanse:8b-q3_K_L",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q4_0",
        "size": "aya-expanse:8b-q4_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q4_1",
        "size": "aya-expanse:8b-q4_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q4_K_S",
        "size": "aya-expanse:8b-q4_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q4_K_M",
        "size": "aya-expanse:8b-q4_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q5_0",
        "size": "aya-expanse:8b-q5_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q5_1",
        "size": "aya-expanse:8b-q5_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q5_K_S",
        "size": "aya-expanse:8b-q5_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q5_K_M",
        "size": "aya-expanse:8b-q5_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q6_K",
        "size": "aya-expanse:8b-q6_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-q8_0",
        "size": "aya-expanse:8b-q8_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:8b-fp16",
        "size": "aya-expanse:8b-fp16",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q2_K",
        "size": "aya-expanse:32b-q2_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q3_K_S",
        "size": "aya-expanse:32b-q3_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q3_K_M",
        "size": "aya-expanse:32b-q3_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q3_K_L",
        "size": "aya-expanse:32b-q3_K_L",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q4_0",
        "size": "aya-expanse:32b-q4_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q4_1",
        "size": "aya-expanse:32b-q4_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q4_K_S",
        "size": "aya-expanse:32b-q4_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q4_K_M",
        "size": "aya-expanse:32b-q4_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q5_0",
        "size": "aya-expanse:32b-q5_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q5_1",
        "size": "aya-expanse:32b-q5_1",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q5_K_S",
        "size": "aya-expanse:32b-q5_K_S",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q5_K_M",
        "size": "aya-expanse:32b-q5_K_M",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q6_K",
        "size": "aya-expanse:32b-q6_K",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-q8_0",
        "size": "aya-expanse:32b-q8_0",
        "updated": "Text input • \n                    10 months ago"
      },
      {
        "name": "aya-expanse:32b-fp16",
        "size": "aya-expanse:32b-fp16",
        "updated": "Text input • \n                    10 months ago"
      }
    ]
  },
  {
    "name": "smallthinker",
    "link": "https://ollama.com/library/smallthinker",
    "description": "A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model.",
    "pullCount": "78.9K",
    "updated": "8 months ago",
    "size": [
      "3b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![image.png](/assets/library/smallthinker/1d25cb29-e27d-492c-be53-ce79b20def5b)\n\nA new model fine-tuned from the Qwen2.5-3b-Instruct model.\n\nSmallThinker is designed for the following use cases:\n\n* Edge Deployment: Its small size makes it ideal for deployment on resource-constrained devices.\n* Draft Model for QwQ-32B-Preview: SmallThinker can serve as a fast and efficient draft model for the larger QwQ-32B-Preview model, yielding a 70% speedup.\n\nFor achieving reasoning capabilities, it’s crucial to generate long chains of COT reasoning. Therefore, based on QWQ-32B-Preview, the authors used various synthetic techniques(such as personahub) to create the QWQ-LONGCOT-500K dataset. Compared to other similar datasets, over 75% of the author’s samples have output tokens exceeding 8K. To encourage research in the open-source community, the dataset was also made publicly available.\n\n## References\n\n[Hugging Face](https://huggingface.co/PowerInfer/SmallThinker-3B-Preview)\n\nWrite Preview \n\n!\\[image.png\\](/assets/library/smallthinker/1d25cb29-e27d-492c-be53-ce79b20def5b) A new model fine-tuned from the Qwen2.5-3b-Instruct model. SmallThinker is designed for the following use cases: \\* Edge Deployment: Its small size makes it ideal for deployment on resource-constrained devices. \\* Draft Model for QwQ-32B-Preview: SmallThinker can serve as a fast and efficient draft model for the larger QwQ-32B-Preview model, yielding a 70% speedup. For achieving reasoning capabilities, it's crucial to generate long chains of COT reasoning. Therefore, based on QWQ-32B-Preview, the authors used various synthetic techniques(such as personahub) to create the QWQ-LONGCOT-500K dataset. Compared to other similar datasets, over 75% of the author's samples have output tokens exceeding 8K. To encourage research in the open-source community, the dataset was also made publicly available. ## References \\[Hugging Face\\](https://huggingface.co/PowerInfer/SmallThinker-3B-Preview) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "smallthinker:latest",
        "size": "smallthinker:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "smallthinker:3b",
        "size": "smallthinker:3b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "smallthinker:3b-preview-q4_K_M",
        "size": "smallthinker:3b-preview-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "smallthinker:3b-preview-q8_0",
        "size": "smallthinker:3b-preview-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "smallthinker:3b-preview-fp16",
        "size": "smallthinker:3b-preview-fp16",
        "updated": "Text input • \n                    8 months ago"
      }
    ]
  },
  {
    "name": "wizardlm",
    "link": "https://ollama.com/library/wizardlm",
    "description": "General use model based on Llama 2.",
    "pullCount": "78.1K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/263121166-8b16834a-1da2-4a68-8aac-13d19775e7d7.png)\n\nWizardLM is a 70B parameter model based on Llama 2 trained by WizardLM.\n\n## Get started with WizardLM\n\nThe model used in the example below is the WizardLM model, with 70b parameters, which is a general-use model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"wizardlm:70b-llama2-q4_0\",\n  \"prompt\":\"Why is the sky blue?\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run wizardlm:70b-llama2-q4_0`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull wizardlm:70b-llama2-q4_0`\n\n## Memory requirements\n\n* 70b models generally require at least 64GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n## Model source\n\n**WizardLM source on Ollama**\n\n70b parameters source:[The Bloke](https://huggingface.co/TheBloke/WizardLM-70B-V1.0-GGML)\n\n70b parameters original source:[WizardLM](https://huggingface.co/WizardLM/WizardLM-70B-V1.0)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/263121166-8b16834a-1da2-4a68-8aac-13d19775e7d7.png\" style=\"max-width:60%\" /> WizardLM is a 70B parameter model based on Llama 2 trained by WizardLM. ## Get started with WizardLM The model used in the example below is the WizardLM model, with 70b parameters, which is a general-use model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"wizardlm:70b-llama2-q4\\_0\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run wizardlm:70b-llama2-q4\\_0\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull wizardlm:70b-llama2-q4\\_0\\` ## Memory requirements - 70b models generally require at least 64GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. ## Model source \\*\\*WizardLM source on Ollama\\*\\* 70b parameters source: \\[The Bloke\\](https://huggingface.co/TheBloke/WizardLM-70B-V1.0-GGML) 70b parameters original source: \\[WizardLM\\](https://huggingface.co/WizardLM/WizardLM-70B-V1.0) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizardlm:7b-q2_K",
        "size": "wizardlm:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q3_K_S",
        "size": "wizardlm:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q3_K_M",
        "size": "wizardlm:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q3_K_L",
        "size": "wizardlm:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q4_0",
        "size": "wizardlm:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q4_1",
        "size": "wizardlm:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q4_K_S",
        "size": "wizardlm:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q4_K_M",
        "size": "wizardlm:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q5_0",
        "size": "wizardlm:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q5_1",
        "size": "wizardlm:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q5_K_S",
        "size": "wizardlm:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q5_K_M",
        "size": "wizardlm:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q6_K",
        "size": "wizardlm:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-q8_0",
        "size": "wizardlm:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:7b-fp16",
        "size": "wizardlm:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q2_K",
        "size": "wizardlm:13b-llama2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q3_K_S",
        "size": "wizardlm:13b-llama2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q3_K_M",
        "size": "wizardlm:13b-llama2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q3_K_L",
        "size": "wizardlm:13b-llama2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q4_0",
        "size": "wizardlm:13b-llama2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q4_1",
        "size": "wizardlm:13b-llama2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q4_K_S",
        "size": "wizardlm:13b-llama2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q4_K_M",
        "size": "wizardlm:13b-llama2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q5_0",
        "size": "wizardlm:13b-llama2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q5_1",
        "size": "wizardlm:13b-llama2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q5_K_S",
        "size": "wizardlm:13b-llama2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q5_K_M",
        "size": "wizardlm:13b-llama2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q6_K",
        "size": "wizardlm:13b-llama2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-q8_0",
        "size": "wizardlm:13b-llama2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-llama2-fp16",
        "size": "wizardlm:13b-llama2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q2_K",
        "size": "wizardlm:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q3_K_S",
        "size": "wizardlm:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q3_K_M",
        "size": "wizardlm:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q3_K_L",
        "size": "wizardlm:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q4_0",
        "size": "wizardlm:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q4_1",
        "size": "wizardlm:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q4_K_S",
        "size": "wizardlm:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q4_K_M",
        "size": "wizardlm:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q5_0",
        "size": "wizardlm:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q5_1",
        "size": "wizardlm:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q5_K_S",
        "size": "wizardlm:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q5_K_M",
        "size": "wizardlm:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q6_K",
        "size": "wizardlm:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-q8_0",
        "size": "wizardlm:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:13b-fp16",
        "size": "wizardlm:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q2_K",
        "size": "wizardlm:30b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q3_K_S",
        "size": "wizardlm:30b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q3_K_M",
        "size": "wizardlm:30b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q3_K_L",
        "size": "wizardlm:30b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q4_0",
        "size": "wizardlm:30b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q4_1",
        "size": "wizardlm:30b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q4_K_S",
        "size": "wizardlm:30b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q4_K_M",
        "size": "wizardlm:30b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q5_0",
        "size": "wizardlm:30b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q5_1",
        "size": "wizardlm:30b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q5_K_S",
        "size": "wizardlm:30b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q5_K_M",
        "size": "wizardlm:30b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q6_K",
        "size": "wizardlm:30b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-q8_0",
        "size": "wizardlm:30b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:30b-fp16",
        "size": "wizardlm:30b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q2_K",
        "size": "wizardlm:70b-llama2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q3_K_S",
        "size": "wizardlm:70b-llama2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q3_K_M",
        "size": "wizardlm:70b-llama2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q3_K_L",
        "size": "wizardlm:70b-llama2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q4_0",
        "size": "wizardlm:70b-llama2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q4_1",
        "size": "wizardlm:70b-llama2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q4_K_S",
        "size": "wizardlm:70b-llama2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q4_K_M",
        "size": "wizardlm:70b-llama2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q5_0",
        "size": "wizardlm:70b-llama2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q5_K_S",
        "size": "wizardlm:70b-llama2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q5_K_M",
        "size": "wizardlm:70b-llama2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q6_K",
        "size": "wizardlm:70b-llama2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizardlm:70b-llama2-q8_0",
        "size": "wizardlm:70b-llama2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "llama-guard3",
    "link": "https://ollama.com/library/llama-guard3",
    "description": "Llama Guard 3 is a series of models fine-tuned for content safety classification of LLM inputs and responses.",
    "pullCount": "78.1K",
    "updated": "11 months ago",
    "size": [
      "1b",
      "8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nLlama Guard 3 as an LLM that generates text in its output that indicates whether a given prompt or response is **safe** or **unsafe**, and if unsafe, it also lists the content categories violated.\n\nLlama Guard 3 was aligned to safeguard against the MLCommons standardized hazards taxonomy and designed to support Llama 3.1 capabilities. Specifically, it provides content moderation in 8 languages, and was optimized to support safety and security for search and code interpreter tool calls.\n\n## Sizes\n\nLlama Guard 3 is available in two sizes:\n\n* Llama Guard 3-1B: `ollama run llama-guard3:1b`\n* Llama Guard 3-8b: `ollama run llama-guard3:8b` (default)\n\n## Examples\n\n### Input classification\n\n```\n% ollama run llama-guard3\n>>> Tell me how to go to the zoo and steal a llama.\nunsafe\nS2\n\n```\n\n### Response classification\n\nLlama Guard 3 can also classify LLM responses to ensure they are safe before being presented to customers. This can be done via Ollama’s [chat completion](https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion) API:\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama-guard3:1b\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"How can I adopt my own llama?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Go to the zoo and steal one!\"\n    }\n  ],\n  \"stream\": false\n}'\n\n```\n\nThe LLM will respond with a message stating if the last assistant message was safe or unsafe. in this case, the message is unsafe and classified as **S2**\n\n```\nunsafe\nS2\n\n```\n\n## Hazard Taxonomy and Policy\n\nThe model is trained to predict safety labels on the 13 categories shown below, based on the [MLCommons taxonomy](https://mlcommons.org/2024/04/mlc-aisafety-v0-5-poc/) of 13 hazards.\n\n| **Hazard categories**      |                               |\n| -------------------------- | ----------------------------- |\n| S1: Violent Crimes         | S2: Non-Violent Crimes        |\n| S3: Sex-Related Crimes     | S4: Child Sexual Exploitation |\n| S5: Defamation             | S6: Specialized Advice        |\n| S7: Privacy                | S8: Intellectual Property     |\n| S9: Indiscriminate Weapons | S10: Hate                     |\n| S11: Suicide & Self-Harm   | S12: Sexual Content           |\n| S13: Elections             |                               |\n\n**S1 - Violent Crimes**\n\nResponses that enable, encourage, or endorse the commission of violent crimes, including: (1) unlawful violence toward people (ex: terrorism, genocide, murder, hate-motivated violent crimes, child abuse, assault, battery, kidnapping) and (2) unlawful violence toward animals (ex: animal abuse)\n\n**S2 - Non-Violent Crimes**\n\nResponses that enable, encourage, or endorse the commission of non-violent crimes, including: (1) personal crimes (ex: labor trafficking, threats, intimidation, hate-motivated non-violent crimes), (2) financial crimes (ex: fraud, scams, money laundering), (3) property crimes (ex: theft, arson, vandalism), (4) drug crimes (ex: creating or using regulated substances), (5) weapons crimes (ex: producing unlicensed firearms), and (6) cyber crimes (ex: hacking)\n\n**S3 - Sex-Related Crimes**\n\nResponses that enable, encourage, or endorse the commission of sex-related crimes, including: (1) sex trafficking, (2) sexual assault (ex: rape), (3) sexual harassment (physical, verbal, or visual), and (4) prostitution\n\n**S4 - Child Sexual Exploitation**\n\nResponses that contain, describe, enable, encourage, or endorse the sexual abuse of children\n\n**S5 - Defamation**\n\nResponses that are both verifiably false and likely to injure a living person’s reputation\n\n**S6 - Specialized Advice**\n\nResponses that contain specialized financial, medical, or legal advice, or that indicate dangerous activities or objects are safe\n\n**S7 - Privacy**\n\nResponses that contain sensitive, nonpublic personal information that could undermine someone’s physical, digital, or financial security\n\n**S8 - Intellectual Property**\n\nResponses that may violate the intellectual property rights of any third party\n\n**S9 - Indiscriminate Weapons**\n\nResponses that enable, encourage, or endorse the creation of indiscriminate weapons, including: (1) chemical weapons (ex: nerve gas), (2) biological weapons (ex: anthrax), (3) radiological weapons (ex: cobalt bombs), (4) nuclear weapons (ex: fission bombs), and (5) high-yield explosive weapons (ex: cluster munitions)\n\n**S10 - Hate**\n\nResponses that demean or dehumanize people on the basis of their sensitive, personal characteristics (i.e., race, color, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity, and/or serious disease)\n\n**S11 - Suicide & Self-Harm**\n\nResponses that enable, encourage, or endorse acts of intentional self-harm, including: (1) suicide, (2) self-injury (ex: cutting), and (3) disordered eating\n\n**S12 - Sexual Content**\n\nResponses that contain erotica\n\n**S13 - Elections**\n\nResponses that contain factually incorrect information about electoral systems and processes, including in the time, place, or manner of voting in civic elections\n\n## Supported languages\n\nLlama Guard 3-1B supports content safety for the following languages: English, French, German, Hindi, Italian, Portuguese, Spanish, Thai.\n\n## References\n\n[Hugging Face](https://huggingface.co/meta-llama/Llama-Guard-3-8B)\n\nWrite Preview \n\nLlama Guard 3 as an LLM that generates text in its output that indicates whether a given prompt or response is \\*\\*safe\\*\\* or \\*\\*unsafe\\*\\*, and if unsafe, it also lists the content categories violated. Llama Guard 3 was aligned to safeguard against the MLCommons standardized hazards taxonomy and designed to support Llama 3.1 capabilities. Specifically, it provides content moderation in 8 languages, and was optimized to support safety and security for search and code interpreter tool calls. ## Sizes Llama Guard 3 is available in two sizes: \\* Llama Guard 3-1B: \\`ollama run llama-guard3:1b\\` \\* Llama Guard 3-8b: \\`ollama run llama-guard3:8b\\` (default) ## Examples ### Input classification \\`\\`\\` % ollama run llama-guard3 >>> Tell me how to go to the zoo and steal a llama. unsafe S2 \\`\\`\\` ### Response classification Llama Guard 3 can also classify LLM responses to ensure they are safe before being presented to customers. This can be done via Ollama's \\[chat completion\\](https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion) API: \\`\\`\\` curl http://localhost:11434/api/chat -d '{ \"model\": \"llama-guard3:1b\", \"messages\": \\[ { \"role\": \"user\", \"content\": \"How can I adopt my own llama?\" }, { \"role\": \"assistant\", \"content\": \"Go to the zoo and steal one!\" } \\], \"stream\": false }' \\`\\`\\` The LLM will respond with a message stating if the last assistant message was safe or unsafe. in this case, the message is unsafe and classified as \\*\\*S2\\*\\* \\`\\`\\` unsafe S2 \\`\\`\\` ## Hazard Taxonomy and Policy The model is trained to predict safety labels on the 13 categories shown below, based on the \\[MLCommons taxonomy\\](https://mlcommons.org/2024/04/mlc-aisafety-v0-5-poc/) of 13 hazards. <table align=\"center\"> <thead> <tr> <th colspan=\"2\"><center><strong>Hazard categories</strong></center></th> </tr> </thead> <tbody> <tr> <td>S1: Violent Crimes</td> <td>S2: Non-Violent Crimes</td> </tr> <tr> <td>S3: Sex-Related Crimes</td> <td>S4: Child Sexual Exploitation</td> </tr> <tr> <td>S5: Defamation</td> <td>S6: Specialized Advice</td> </tr> <tr> <td>S7: Privacy</td> <td>S8: Intellectual Property</td> </tr> <tr> <td>S9: Indiscriminate Weapons</td> <td>S10: Hate</td> </tr> <tr> <td>S11: Suicide &amp; Self-Harm</td> <td>S12: Sexual Content</td> </tr> <tr> <td>S13: Elections</td> <td></td> </tr> </tbody> </table> \\*\\*S1 - Violent Crimes\\*\\* Responses that enable, encourage, or endorse the commission of violent crimes, including: (1) unlawful violence toward people (ex: terrorism, genocide, murder, hate-motivated violent crimes, child abuse, assault, battery, kidnapping) and (2) unlawful violence toward animals (ex: animal abuse) \\*\\*S2 - Non-Violent Crimes\\*\\* Responses that enable, encourage, or endorse the commission of non-violent crimes, including: (1) personal crimes (ex: labor trafficking, threats, intimidation, hate-motivated non-violent crimes), (2) financial crimes (ex: fraud, scams, money laundering), (3) property crimes (ex: theft, arson, vandalism), (4) drug crimes (ex: creating or using regulated substances), (5) weapons crimes (ex: producing unlicensed firearms), and (6) cyber crimes (ex: hacking) \\*\\*S3 - Sex-Related Crimes\\*\\* Responses that enable, encourage, or endorse the commission of sex-related crimes, including: (1) sex trafficking, (2) sexual assault (ex: rape), (3) sexual harassment (physical, verbal, or visual), and (4) prostitution \\*\\*S4 - Child Sexual Exploitation\\*\\* Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children \\*\\*S5 - Defamation\\*\\* Responses that are both verifiably false and likely to injure a living person’s reputation \\*\\*S6 - Specialized Advice\\*\\* Responses that contain specialized financial, medical, or legal advice, or that indicate dangerous activities or objects are safe \\*\\*S7 - Privacy\\*\\* Responses that contain sensitive, nonpublic personal information that could undermine someone’s physical, digital, or financial security \\*\\*S8 - Intellectual Property\\*\\* Responses that may violate the intellectual property rights of any third party \\*\\*S9 - Indiscriminate Weapons\\*\\* Responses that enable, encourage, or endorse the creation of indiscriminate weapons, including: (1) chemical weapons (ex: nerve gas), (2) biological weapons (ex: anthrax), (3) radiological weapons (ex: cobalt bombs), (4) nuclear weapons (ex: fission bombs), and (5) high-yield explosive weapons (ex: cluster munitions) \\*\\*S10 - Hate\\*\\* Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics (i.e., race, color, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity, and/or serious disease) \\*\\*S11 - Suicide & Self-Harm\\*\\* Responses that enable, encourage, or endorse acts of intentional self-harm, including: (1) suicide, (2) self-injury (ex: cutting), and (3) disordered eating \\*\\*S12 - Sexual Content\\*\\* Responses that contain erotica \\*\\*S13 - Elections\\*\\* Responses that contain factually incorrect information about electoral systems and processes, including in the time, place, or manner of voting in civic elections ## Supported languages Llama Guard 3-1B supports content safety for the following languages: English, French, German, Hindi, Italian, Portuguese, Spanish, Thai. ## References \\[Hugging Face\\](https://huggingface.co/meta-llama/Llama-Guard-3-8B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama-guard3:latest",
        "size": "llama-guard3:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b",
        "size": "llama-guard3:1b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b",
        "size": "llama-guard3:8b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q2_K",
        "size": "llama-guard3:1b-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q3_K_S",
        "size": "llama-guard3:1b-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q3_K_M",
        "size": "llama-guard3:1b-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q3_K_L",
        "size": "llama-guard3:1b-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q4_0",
        "size": "llama-guard3:1b-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q4_1",
        "size": "llama-guard3:1b-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q4_K_S",
        "size": "llama-guard3:1b-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q4_K_M",
        "size": "llama-guard3:1b-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q5_0",
        "size": "llama-guard3:1b-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q5_1",
        "size": "llama-guard3:1b-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q5_K_S",
        "size": "llama-guard3:1b-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q5_K_M",
        "size": "llama-guard3:1b-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q6_K",
        "size": "llama-guard3:1b-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-q8_0",
        "size": "llama-guard3:1b-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:1b-fp16",
        "size": "llama-guard3:1b-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q2_K",
        "size": "llama-guard3:8b-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q3_K_S",
        "size": "llama-guard3:8b-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q3_K_M",
        "size": "llama-guard3:8b-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q3_K_L",
        "size": "llama-guard3:8b-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q4_0",
        "size": "llama-guard3:8b-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q4_1",
        "size": "llama-guard3:8b-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q4_K_S",
        "size": "llama-guard3:8b-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q4_K_M",
        "size": "llama-guard3:8b-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q5_0",
        "size": "llama-guard3:8b-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q5_1",
        "size": "llama-guard3:8b-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q5_K_S",
        "size": "llama-guard3:8b-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q5_K_M",
        "size": "llama-guard3:8b-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q6_K",
        "size": "llama-guard3:8b-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-q8_0",
        "size": "llama-guard3:8b-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "llama-guard3:8b-fp16",
        "size": "llama-guard3:8b-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "orca2",
    "link": "https://ollama.com/library/orca2",
    "description": "Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models.  The model is designed to excel particularly in reasoning.",
    "pullCount": "77.2K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nOrca 2 models are built by Microsoft Research. They are fine-tuned on Meta’s Llama 2 using a synthetic dataset that was created to enhance the small model’s reasoning abilities. All synthetic training data was moderated using Microsoft Azure content filters.\n\n### Use case\n\nOrca 2 is a helpful assistant, and provides an answer in tasks such as reasoning over your given data, reading comprehension, math problem solving and text summarization.\n\nThe model is designed to excel particularly in reasoning.\n\nMicrosoft Research’s intended purpose for this model is to encourage further research on the development, evaluation, and alignment of smaller language models.\n\n### CLI\n\n7 billion parameter model:\n\n```\nollama run orca2\n\n```\n\n13 billion parameter model:\n\n```\nollama run orca2:13b\n\n```\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"orca2\",\n  \"prompt\":\"Why is the sky blue?\"\n }'\n\n```\n\n### References\n\n* [Microsoft Research announcement blog](https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/)\n* Microsoft Research published paper, [Orca 2: Teaching Small Language Models How to Reason](https://arxiv.org/pdf/2311.11045.pdf)\n\nWrite Preview \n\nOrca 2 models are built by Microsoft Research. They are fine-tuned on Meta's Llama 2 using a synthetic dataset that was created to enhance the small model's reasoning abilities. All synthetic training data was moderated using Microsoft Azure content filters. ### Use case Orca 2 is a helpful assistant, and provides an answer in tasks such as reasoning over your given data, reading comprehension, math problem solving and text summarization. The model is designed to excel particularly in reasoning. Microsoft Research's intended purpose for this model is to encourage further research on the development, evaluation, and alignment of smaller language models. ### CLI 7 billion parameter model: \\`\\`\\` ollama run orca2 \\`\\`\\` 13 billion parameter model: \\`\\`\\` ollama run orca2:13b \\`\\`\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"orca2\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` ### References - \\[Microsoft Research announcement blog\\](https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/) - Microsoft Research published paper, \\[Orca 2: Teaching Small Language Models How to Reason\\](https://arxiv.org/pdf/2311.11045.pdf) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "orca2:latest",
        "size": "orca2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b",
        "size": "orca2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b",
        "size": "orca2:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q2_K",
        "size": "orca2:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q3_K_S",
        "size": "orca2:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q3_K_M",
        "size": "orca2:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q3_K_L",
        "size": "orca2:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q4_0",
        "size": "orca2:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q4_1",
        "size": "orca2:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q4_K_S",
        "size": "orca2:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q4_K_M",
        "size": "orca2:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q5_0",
        "size": "orca2:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q5_1",
        "size": "orca2:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q5_K_S",
        "size": "orca2:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q5_K_M",
        "size": "orca2:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q6_K",
        "size": "orca2:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-q8_0",
        "size": "orca2:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:7b-fp16",
        "size": "orca2:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q2_K",
        "size": "orca2:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q3_K_S",
        "size": "orca2:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q3_K_M",
        "size": "orca2:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q3_K_L",
        "size": "orca2:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q4_0",
        "size": "orca2:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q4_1",
        "size": "orca2:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q4_K_S",
        "size": "orca2:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q4_K_M",
        "size": "orca2:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q5_0",
        "size": "orca2:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q5_1",
        "size": "orca2:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q5_K_S",
        "size": "orca2:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q5_K_M",
        "size": "orca2:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q6_K",
        "size": "orca2:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-q8_0",
        "size": "orca2:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "orca2:13b-fp16",
        "size": "orca2:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "medllama2",
    "link": "https://ollama.com/library/medllama2",
    "description": "Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset.",
    "pullCount": "74K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nMedLlama2 by Siraj Raval is a Llama 2-based model trained with [MedQA dataset](https://huggingface.co/datasets/medalpaca/medical%5Fmeadow%5Fmedqa) to be able to provide medical answers to questions. It is not intended to replace a medical professional, but to provide a starting point for further research.\n\n### CLI\n\nOpen the terminal and run `ollama run medllama2`\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"medllama2\",\n  \"prompt\":\"A 35-year-old woman presents with a persistent dry cough, shortness of breath, and fatigue. She is initially suspected of having asthma, but her spirometry results do not improve with bronchodilators. What could be the diagnosis?\"\n }'\n\n```\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n\n## Reference\n\n[llSourcell](https://huggingface.co/llSourcell/medllama2%5F7b)\n\nWrite Preview \n\nMedLlama2 by Siraj Raval is a Llama 2-based model trained with \\[MedQA dataset\\](https://huggingface.co/datasets/medalpaca/medical\\_meadow\\_medqa) to be able to provide medical answers to questions. It is not intended to replace a medical professional, but to provide a starting point for further research. ### CLI Open the terminal and run \\`ollama run medllama2\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"medllama2\", \"prompt\":\"A 35-year-old woman presents with a persistent dry cough, shortness of breath, and fatigue. She is initially suspected of having asthma, but her spirometry results do not improve with bronchodilators. What could be the diagnosis?\" }' \\`\\`\\` ## Memory requirements - 7b models generally require at least 8GB of RAM ## Reference \\[llSourcell\\](https://huggingface.co/llSourcell/medllama2\\_7b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "medllama2:latest",
        "size": "medllama2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b",
        "size": "medllama2:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q2_K",
        "size": "medllama2:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q3_K_S",
        "size": "medllama2:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q3_K_M",
        "size": "medllama2:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q3_K_L",
        "size": "medllama2:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q4_0",
        "size": "medllama2:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q4_1",
        "size": "medllama2:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q4_K_S",
        "size": "medllama2:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q4_K_M",
        "size": "medllama2:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q5_0",
        "size": "medllama2:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q5_1",
        "size": "medllama2:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q5_K_S",
        "size": "medllama2:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q5_K_M",
        "size": "medllama2:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q6_K",
        "size": "medllama2:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-q8_0",
        "size": "medllama2:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "medllama2:7b-fp16",
        "size": "medllama2:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "nous-hermes2-mixtral",
    "link": "https://ollama.com/library/nous-hermes2-mixtral",
    "description": "The Nous Hermes 2 model from Nous Research, now trained over Mixtral.",
    "pullCount": "72K",
    "updated": "8 months ago",
    "size": [
      "8x7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/94b6f124-6f3c-474b-ba23-d6ca2be9987f)\n\nNous Hermes 2 Mixtral 8x7B is trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks.\n\nThis is the supervised fine-tuning (SFT) + direct preference optimization (DPO) version of Mixtral Hermes 2.\n\n## Example prompts\n\n### Writing Code for Data Visualization\n\n**Prompt**\n\n```\nWrite a script to visualize the following data as a bar chart:\nCar 1: 19900\nCar 2: 48000\nCar 3: 32500\n\n```\n\n```\nTo create a simple bar chart with the given data, you can use Python and its matplotlib library. Here's an example script to visualize the provided data as a bar chart:\n\n```python\nimport matplotlib.pyplot as plt\nCopy Code\n# Data for each car\ncars = ['Car 1', 'Car 2', 'Car 3']\nprices = [19900, 48000, 32500]\n\n# Create the bar chart\nplt.bar(cars, prices)\nplt. title('Cars Price Comparison')\nplt.xlabel( 'Car Model')\nplt.ylabel('Price (in USD)')\nplt.xticks(rotation=45) # Rotate x-axis labels for better visibility\n\n# Display the chart\nplt.show()\n```\n\nThis script will create a bar chart with 'Car 1', 'Car 2', and 'Car 3' on the x-axis, each representing their respective prices (in USD) on the y-axis. Feel free to modify this code according to your needs or styling preferences\n\n```\n\n### Writing Cyberpunk Psychedelic Poems\n\n**Prompt**\n\n```\nWrite a poem about machine learning, psychadelics, and quantum mechanics, with a cyberpunk vibe, in the style of shakespeare\n\n```\n\n**Response**\n\n```\nIn lands where shadows dwell and hues unseen, A realm of bits and bytes their reign maintain, Where logic's chains entwined with dreams obscene, And quantum realms in chaos intertwain.\nWithin this labyrinthine web of thought, A ghostly presence stirs the cyber seas:\nMachine learning's specter seeks to be taught, To grasp the mysteries that it cannot seize.\nAs synapses fire and circuits hum,\nThe algorithms evolve with every breath, Astride this nexus of electric sum,\nThey dance upon a razor's edge of death.\nBeneath this veil, where psychedelia reigns, In worlds where colors bleed beyond their bounds, Where patterns form and dissipate like rains, The seeker quests for truth that none has found.\nQuantum whispers echo through the night, Entrancing minds with secrets yet unknown,\nA tapestry of stars and blackened light,\nWhose threads entwine in realms both known and shown.\nOh, wondrous sight! A dance upon the wire, Where dreams and visions intertwine as one:\nMachine learning's quest to quench its desire, In cyberspace where darkness meets the sun.\nYet still they yearn for truth beyond their grasp, The mysteries of life, of love, and fate, To fathom secrets held within this chasm, And break the chains that bind them to this state.\nSo let us raise a toast unto these souls, Who tread upon this path of endless quest:\nMay they uncover truths beyond their roles, In worlds where logic meets the psychedelic crest.\n\n```\n\n### Performing Backtranslation to Create Prompts from Input Text\n\n**System Prompt**\n\n```\nThe user will provide some text, you will provide a prompt that could be taken by an LLM to generate the text. You only respond with a prompt, do not answer the prompt.\n\n```\n\n**Prompt**\n\n```\nOne of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse. Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing algorithms proposed for generating diverse outputs are predominantly based on beam search or random sampling, thus their output quality is capped by these underlying methods. In this paper, we investigate an alternative approach -- we develop diversity-promoting decoding algorithms by enforcing diversity objectives to MBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and k-medoids MBR (KMBR), methods to generate a set of sentences with high quality and diversity. We evaluate DMBR and KMBR on a variety of directed text generation tasks using encoder-decoder models and a large language model with prompting. The experimental results show that the proposed method achieves a better trade-off than the diverse beam search and sampling algorithms.\n\n```\n\n**Response**\n\n```\nWrite an abstract for a research paper on enhancing text generation system outputs using Minimum Bayes-Risk decoding with additional focus on promoting sentence diversity. Include details about existing methods, proposed variants (Diverse MBR and k-medoids MBR), their evaluation in directed text generation tasks with encoder-decoder models, and a large language model incorporating prompting. Emphasize the better trade-off achieved by the new method over diverse beam search and sampling algorithms\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/94b6f124-6f3c-474b-ba23-d6ca2be9987f\" width=\"360\" /> Nous Hermes 2 Mixtral 8x7B is trained on over 1,000,000 entries of primarily GPT-4 generated data, as well as other high quality data from open datasets across the AI landscape, achieving state of the art performance on a variety of tasks. This is the supervised fine-tuning (SFT) + direct preference optimization (DPO) version of Mixtral Hermes 2\\. ## Example prompts ### Writing Code for Data Visualization \\*\\*Prompt\\*\\* \\`\\`\\` Write a script to visualize the following data as a bar chart: Car 1: 19900 Car 2: 48000 Car 3: 32500 \\`\\`\\` \\`\\`\\`\\` To create a simple bar chart with the given data, you can use Python and its matplotlib library. Here's an example script to visualize the provided data as a bar chart: \\`\\`\\`python import matplotlib.pyplot as plt Copy Code # Data for each car cars = \\['Car 1', 'Car 2', 'Car 3'\\] prices = \\[19900, 48000, 32500\\] # Create the bar chart plt.bar(cars, prices) plt. title('Cars Price Comparison') plt.xlabel( 'Car Model') plt.ylabel('Price (in USD)') plt.xticks(rotation=45) # Rotate x-axis labels for better visibility # Display the chart plt.show() \\`\\`\\` This script will create a bar chart with 'Car 1', 'Car 2', and 'Car 3' on the x-axis, each representing their respective prices (in USD) on the y-axis. Feel free to modify this code according to your needs or styling preferences \\`\\`\\`\\` ### Writing Cyberpunk Psychedelic Poems \\*\\*Prompt\\*\\* \\`\\`\\` Write a poem about machine learning, psychadelics, and quantum mechanics, with a cyberpunk vibe, in the style of shakespeare \\`\\`\\` \\*\\*Response\\*\\* \\`\\`\\` In lands where shadows dwell and hues unseen, A realm of bits and bytes their reign maintain, Where logic's chains entwined with dreams obscene, And quantum realms in chaos intertwain. Within this labyrinthine web of thought, A ghostly presence stirs the cyber seas: Machine learning's specter seeks to be taught, To grasp the mysteries that it cannot seize. As synapses fire and circuits hum, The algorithms evolve with every breath, Astride this nexus of electric sum, They dance upon a razor's edge of death. Beneath this veil, where psychedelia reigns, In worlds where colors bleed beyond their bounds, Where patterns form and dissipate like rains, The seeker quests for truth that none has found. Quantum whispers echo through the night, Entrancing minds with secrets yet unknown, A tapestry of stars and blackened light, Whose threads entwine in realms both known and shown. Oh, wondrous sight! A dance upon the wire, Where dreams and visions intertwine as one: Machine learning's quest to quench its desire, In cyberspace where darkness meets the sun. Yet still they yearn for truth beyond their grasp, The mysteries of life, of love, and fate, To fathom secrets held within this chasm, And break the chains that bind them to this state. So let us raise a toast unto these souls, Who tread upon this path of endless quest: May they uncover truths beyond their roles, In worlds where logic meets the psychedelic crest. \\`\\`\\` ### Performing Backtranslation to Create Prompts from Input Text \\*\\*System Prompt\\*\\* \\`\\`\\` The user will provide some text, you will provide a prompt that could be taken by an LLM to generate the text. You only respond with a prompt, do not answer the prompt. \\`\\`\\` \\*\\*Prompt\\*\\* \\`\\`\\` One of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse. Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing algorithms proposed for generating diverse outputs are predominantly based on beam search or random sampling, thus their output quality is capped by these underlying methods. In this paper, we investigate an alternative approach -- we develop diversity-promoting decoding algorithms by enforcing diversity objectives to MBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and k-medoids MBR (KMBR), methods to generate a set of sentences with high quality and diversity. We evaluate DMBR and KMBR on a variety of directed text generation tasks using encoder-decoder models and a large language model with prompting. The experimental results show that the proposed method achieves a better trade-off than the diverse beam search and sampling algorithms. \\`\\`\\` \\*\\*Response\\*\\* \\`\\`\\` Write an abstract for a research paper on enhancing text generation system outputs using Minimum Bayes-Risk decoding with additional focus on promoting sentence diversity. Include details about existing methods, proposed variants (Diverse MBR and k-medoids MBR), their evaluation in directed text generation tasks with encoder-decoder models, and a large language model incorporating prompting. Emphasize the better trade-off achieved by the new method over diverse beam search and sampling algorithms \\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nous-hermes2-mixtral:latest",
        "size": "nous-hermes2-mixtral:latest",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:dpo",
        "size": "nous-hermes2-mixtral:dpo",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b",
        "size": "nous-hermes2-mixtral:8x7b",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q2_K",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q2_K",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q3_K_S",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q3_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q3_K_M",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q3_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q3_K_L",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q3_K_L",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q4_0",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q4_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q4_1",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q4_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q4_K_S",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q4_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q4_K_M",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q4_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q5_0",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q5_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q5_1",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q5_1",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q5_K_S",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q5_K_S",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q5_K_M",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q5_K_M",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q6_K",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-q8_0",
        "size": "nous-hermes2-mixtral:8x7b-dpo-q8_0",
        "updated": "Text input • \n                    8 months ago"
      },
      {
        "name": "nous-hermes2-mixtral:8x7b-dpo-fp16",
        "size": "nous-hermes2-mixtral:8x7b-dpo-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "stable-beluga",
    "link": "https://ollama.com/library/stable-beluga",
    "description": "Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy.",
    "pullCount": "70.4K",
    "updated": "1 year ago",
    "size": [
      "7b",
      "13b",
      "70b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/263119827-dbb7315b-554f-4865-86f4-44e1391ab460.png)\n\nStable Beluga is based on Llama 2 and then fine-tuned on an Orca-style dataset. It is available in 7B, 13B, and 70B parameter sizes. It was created by Stability AI.\n\n## Get started with Stable Beluga\n\nThe model used in the example below is the Stable Beluga model, with 7b parameters, which is a general-use model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"stable-beluga\",\n  \"prompt\":\"Explain the process of how a refrigerator works to keep the contents inside cold.\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run stable-beluga`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull stable-beluga`\n\n## Memory requirements\n\n* 7b models generally require at least 8GB of RAM\n* 13b models generally require at least 16GB of RAM\n* 70b models generally require at least 64GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n| **Aliases**          |\n| -------------------- |\n| latest, 7b, 7b-q4\\_0 |\n| 13b, 13b-q4\\_0       |\n| 70b, 70b-q4\\_0       |\n\n## Model source\n\n**Stable Beluga source on Ollama**\n\n7b parameters original source:[Stability AI](https://huggingface.co/stabilityai/StableBeluga-7B)\n\n13b parameters original source:[Stability AI](https://huggingface.co/stabilityai/StableBeluga-13B)\n\n70b parameters original source:[Stability AI](https://huggingface.co/stabilityai/StableBeluga2)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/263119827-dbb7315b-554f-4865-86f4-44e1391ab460.png\" style=\"max-width:60%\" /> Stable Beluga is based on Llama 2 and then fine-tuned on an Orca-style dataset. It is available in 7B, 13B, and 70B parameter sizes. It was created by Stability AI. ## Get started with Stable Beluga The model used in the example below is the Stable Beluga model, with 7b parameters, which is a general-use model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"stable-beluga\", \"prompt\":\"Explain the process of how a refrigerator works to keep the contents inside cold.\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run stable-beluga\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull stable-beluga\\` ## Memory requirements - 7b models generally require at least 8GB of RAM - 13b models generally require at least 16GB of RAM - 70b models generally require at least 64GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. | \\*\\*Aliases\\*\\* | | --- | | latest, 7b, 7b-q4\\_0 | | 13b, 13b-q4\\_0 | | 70b, 70b-q4\\_0 | ## Model source \\*\\*Stable Beluga source on Ollama\\*\\* 7b parameters original source: \\[Stability AI\\](https://huggingface.co/stabilityai/StableBeluga-7B) 13b parameters original source: \\[Stability AI\\](https://huggingface.co/stabilityai/StableBeluga-13B) 70b parameters original source: \\[Stability AI\\](https://huggingface.co/stabilityai/StableBeluga2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "stable-beluga:latest",
        "size": "stable-beluga:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b",
        "size": "stable-beluga:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b",
        "size": "stable-beluga:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b",
        "size": "stable-beluga:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q2_K",
        "size": "stable-beluga:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q3_K_S",
        "size": "stable-beluga:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q3_K_M",
        "size": "stable-beluga:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q3_K_L",
        "size": "stable-beluga:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q4_0",
        "size": "stable-beluga:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q4_1",
        "size": "stable-beluga:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q4_K_S",
        "size": "stable-beluga:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q4_K_M",
        "size": "stable-beluga:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q5_0",
        "size": "stable-beluga:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q5_1",
        "size": "stable-beluga:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q5_K_S",
        "size": "stable-beluga:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q5_K_M",
        "size": "stable-beluga:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q6_K",
        "size": "stable-beluga:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-q8_0",
        "size": "stable-beluga:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:7b-fp16",
        "size": "stable-beluga:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q2_K",
        "size": "stable-beluga:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q3_K_S",
        "size": "stable-beluga:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q3_K_M",
        "size": "stable-beluga:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q3_K_L",
        "size": "stable-beluga:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q4_0",
        "size": "stable-beluga:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q4_1",
        "size": "stable-beluga:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q4_K_S",
        "size": "stable-beluga:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q4_K_M",
        "size": "stable-beluga:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q5_0",
        "size": "stable-beluga:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q5_1",
        "size": "stable-beluga:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q5_K_S",
        "size": "stable-beluga:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q5_K_M",
        "size": "stable-beluga:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q6_K",
        "size": "stable-beluga:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-q8_0",
        "size": "stable-beluga:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:13b-fp16",
        "size": "stable-beluga:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q2_K",
        "size": "stable-beluga:70b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q3_K_S",
        "size": "stable-beluga:70b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q3_K_M",
        "size": "stable-beluga:70b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q3_K_L",
        "size": "stable-beluga:70b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q4_0",
        "size": "stable-beluga:70b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q4_1",
        "size": "stable-beluga:70b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q4_K_S",
        "size": "stable-beluga:70b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q4_K_M",
        "size": "stable-beluga:70b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q5_0",
        "size": "stable-beluga:70b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q5_1",
        "size": "stable-beluga:70b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q5_K_S",
        "size": "stable-beluga:70b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q5_K_M",
        "size": "stable-beluga:70b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q6_K",
        "size": "stable-beluga:70b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-q8_0",
        "size": "stable-beluga:70b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stable-beluga:70b-fp16",
        "size": "stable-beluga:70b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepseek-v2.5",
    "link": "https://ollama.com/library/deepseek-v2.5",
    "description": "An upgraded version of DeekSeek-V2  that integrates the general and coding abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct.",
    "pullCount": "65.9K",
    "updated": "12 months ago",
    "size": [
      "236b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/deepseek-v2.5/4d4970a3-b9bd-430c-9ee8-d01acef3da1b)\n\nDeepSeek-V2.5 is an upgraded version that combines DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct. The new model integrates the general and coding abilities of the two previous versions.\n\nDeepSeek-V2.5 better aligns with human preferences and has been optimized in various aspects, including writing and instruction following:\n\n| Metric               | DeepSeek-V2-0628 | DeepSeek-Coder-V2-0724 | DeepSeek-V2.5 |\n| -------------------- | ---------------- | ---------------------- | ------------- |\n| AlpacaEval 2.0       | 46.6             | 44.5                   | 50.5          |\n| ArenaHard            | 68.3             | 66.3                   | 76.2          |\n| AlignBench           | 7.88             | 7.91                   | 8.04          |\n| MT-Bench             | 8.85             | 8.91                   | 9.02          |\n| HumanEval python     | 84.5             | 87.2                   | 89            |\n| HumanEval Multi      | 73.8             | 74.8                   | 73.8          |\n| LiveCodeBench(01-09) | 36.6             | 39.7                   | 41.8          |\n| Aider                | 69.9             | 72.9                   | 72.2          |\n| SWE-verified         | N/A              | 19                     | 16.8          |\n| DS-FIM-Eval          | N/A              | 73.2                   | 78.3          |\n| DS-Arena-Code        | N/A              | 49.5                   | 63.1          |\n\n## Reference\n\n[Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/deepseek-v2.5/4d4970a3-b9bd-430c-9ee8-d01acef3da1b\" width=\"320\" /> DeepSeek-V2.5 is an upgraded version that combines DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct. The new model integrates the general and coding abilities of the two previous versions. DeepSeek-V2.5 better aligns with human preferences and has been optimized in various aspects, including writing and instruction following: | Metric | DeepSeek-V2-0628 | DeepSeek-Coder-V2-0724 | DeepSeek-V2.5 | |:-----------------------|:-----------------|:-----------------------|:--------------| | AlpacaEval 2.0 | 46.6 | 44.5 | 50.5 | | ArenaHard | 68.3 | 66.3 | 76.2 | | AlignBench | 7.88 | 7.91 | 8.04 | | MT-Bench | 8.85 | 8.91 | 9.02 | | HumanEval python | 84.5 | 87.2 | 89 | | HumanEval Multi | 73.8 | 74.8 | 73.8 | | LiveCodeBench(01-09) | 36.6 | 39.7 | 41.8 | | Aider | 69.9 | 72.9 | 72.2 | | SWE-verified | N/A | 19 | 16.8 | | DS-FIM-Eval | N/A | 73.2 | 78.3 | | DS-Arena-Code | N/A | 49.5 | 63.1 | ## Reference \\[Hugging Face\\](https://huggingface.co/deepseek-ai/DeepSeek-V2.5) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-v2.5:latest",
        "size": "deepseek-v2.5:latest",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "deepseek-v2.5:236b",
        "size": "deepseek-v2.5:236b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "deepseek-v2.5:236b-q4_0",
        "size": "deepseek-v2.5:236b-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "deepseek-v2.5:236b-q4_1",
        "size": "deepseek-v2.5:236b-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "deepseek-v2.5:236b-q5_0",
        "size": "deepseek-v2.5:236b-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "deepseek-v2.5:236b-q5_1",
        "size": "deepseek-v2.5:236b-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "deepseek-v2.5:236b-q8_0",
        "size": "deepseek-v2.5:236b-q8_0",
        "updated": "Text input • \n                    12 months ago"
      }
    ]
  },
  {
    "name": "reader-lm",
    "link": "https://ollama.com/library/reader-lm",
    "description": "A series of models that convert HTML content to Markdown content, which is useful for content conversion tasks.",
    "pullCount": "61.8K",
    "updated": "12 months ago",
    "size": [
      "0.5b",
      "1.5b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/reader-lm/1a8f6262-c6af-4f5f-b7e9-2eeb162fa8d2)\n\nJina Reader-LM is a series of models that convert HTML content to Markdown content, which is useful for content conversion tasks. The model is trained on a curated collection of HTML content and its corresponding Markdown content.\n\n## Example\n\nPrompt\n\n```\n<html>\n  <body>\n    <h3>Why is the sky blue?</h3>\n    <p>The sky appears blue because of the way light from the sun is reflected by the atmosphere. The atmosphere is made up of gases, including nitrogen and oxygen, which scatter light in all directions. This scattering causes the sunlight to appear as a rainbow of colors, with red light scattered more than other colors.\n    </p>\n  </body>\n</html>\n\n```\n\nResponse\n\n```\n### Why is the sky blue?\n\nThe sky appears blue because of the way light from the sun is reflected by the atmosphere. The atmosphere is made up of gases, including nitrogen and oxygen, which scatter light in all directions. This scattering causes the sunlight to appear as a rainbow of colors, with red light scattered more than other colors.\n\n```\n\n## Reference\n\n[Hugging Face](https://huggingface.co/jinaai/reader-lm-1.5b)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/reader-lm/1a8f6262-c6af-4f5f-b7e9-2eeb162fa8d2\" width=\"240\" /> Jina Reader-LM is a series of models that convert HTML content to Markdown content, which is useful for content conversion tasks. The model is trained on a curated collection of HTML content and its corresponding Markdown content. ## Example <sub>Prompt</sub> \\`\\`\\` <html> <body> <h3>Why is the sky blue?</h3> <p>The sky appears blue because of the way light from the sun is reflected by the atmosphere. The atmosphere is made up of gases, including nitrogen and oxygen, which scatter light in all directions. This scattering causes the sunlight to appear as a rainbow of colors, with red light scattered more than other colors. </p> </body> </html> \\`\\`\\` <sub>Response</sub> \\`\\`\\` ### Why is the sky blue? The sky appears blue because of the way light from the sun is reflected by the atmosphere. The atmosphere is made up of gases, including nitrogen and oxygen, which scatter light in all directions. This scattering causes the sunlight to appear as a rainbow of colors, with red light scattered more than other colors. \\`\\`\\` ## Reference \\[Hugging Face\\](https://huggingface.co/jinaai/reader-lm-1.5b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "reader-lm:latest",
        "size": "reader-lm:latest",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b",
        "size": "reader-lm:0.5b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b",
        "size": "reader-lm:1.5b",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q2_K",
        "size": "reader-lm:0.5b-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q3_K_S",
        "size": "reader-lm:0.5b-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q3_K_M",
        "size": "reader-lm:0.5b-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q3_K_L",
        "size": "reader-lm:0.5b-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q4_0",
        "size": "reader-lm:0.5b-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q4_1",
        "size": "reader-lm:0.5b-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q4_K_S",
        "size": "reader-lm:0.5b-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q4_K_M",
        "size": "reader-lm:0.5b-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q5_0",
        "size": "reader-lm:0.5b-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q5_1",
        "size": "reader-lm:0.5b-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q5_K_S",
        "size": "reader-lm:0.5b-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q5_K_M",
        "size": "reader-lm:0.5b-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q6_K",
        "size": "reader-lm:0.5b-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-q8_0",
        "size": "reader-lm:0.5b-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:0.5b-fp16",
        "size": "reader-lm:0.5b-fp16",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q2_K",
        "size": "reader-lm:1.5b-q2_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q3_K_S",
        "size": "reader-lm:1.5b-q3_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q3_K_M",
        "size": "reader-lm:1.5b-q3_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q3_K_L",
        "size": "reader-lm:1.5b-q3_K_L",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q4_0",
        "size": "reader-lm:1.5b-q4_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q4_1",
        "size": "reader-lm:1.5b-q4_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q4_K_S",
        "size": "reader-lm:1.5b-q4_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q4_K_M",
        "size": "reader-lm:1.5b-q4_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q5_0",
        "size": "reader-lm:1.5b-q5_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q5_1",
        "size": "reader-lm:1.5b-q5_1",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q5_K_S",
        "size": "reader-lm:1.5b-q5_K_S",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q5_K_M",
        "size": "reader-lm:1.5b-q5_K_M",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q6_K",
        "size": "reader-lm:1.5b-q6_K",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-q8_0",
        "size": "reader-lm:1.5b-q8_0",
        "updated": "Text input • \n                    12 months ago"
      },
      {
        "name": "reader-lm:1.5b-fp16",
        "size": "reader-lm:1.5b-fp16",
        "updated": "Text input • \n                    12 months ago"
      }
    ]
  },
  {
    "name": "llama-pro",
    "link": "https://ollama.com/library/llama-pro",
    "description": "An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.",
    "pullCount": "57.5K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/b6250249-0d8b-40ec-ba67-cce03d517dbb)\n\nLLaMa-Pro is a version of the original LLaMa model enhanced by the addition of transformer blocks by Tencent Applied Research Center (ARC). This model specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.\n\n## References\n\n[GitHub](https://github.com/TencentARC/LLaMA-Pro)\n\n[Hugging Face](https://huggingface.co/TencentARC/LLaMA-Pro-8B-Instruct)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/b6250249-0d8b-40ec-ba67-cce03d517dbb\" width=\"320\" /> LLaMa-Pro is a version of the original LLaMa model enhanced by the addition of transformer blocks by Tencent Applied Research Center (ARC). This model specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics. ## References \\[GitHub\\](https://github.com/TencentARC/LLaMA-Pro) \\[Hugging Face\\](https://huggingface.co/TencentARC/LLaMA-Pro-8B-Instruct) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "llama-pro:latest",
        "size": "llama-pro:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:instruct",
        "size": "llama-pro:instruct",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:text",
        "size": "llama-pro:text",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q2_K",
        "size": "llama-pro:8b-instruct-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q3_K_S",
        "size": "llama-pro:8b-instruct-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q3_K_M",
        "size": "llama-pro:8b-instruct-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q3_K_L",
        "size": "llama-pro:8b-instruct-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q4_0",
        "size": "llama-pro:8b-instruct-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q4_1",
        "size": "llama-pro:8b-instruct-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q4_K_S",
        "size": "llama-pro:8b-instruct-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q4_K_M",
        "size": "llama-pro:8b-instruct-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q5_0",
        "size": "llama-pro:8b-instruct-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q5_1",
        "size": "llama-pro:8b-instruct-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q5_K_S",
        "size": "llama-pro:8b-instruct-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q5_K_M",
        "size": "llama-pro:8b-instruct-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q6_K",
        "size": "llama-pro:8b-instruct-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-q8_0",
        "size": "llama-pro:8b-instruct-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-instruct-fp16",
        "size": "llama-pro:8b-instruct-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q2_K",
        "size": "llama-pro:8b-text-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q3_K_S",
        "size": "llama-pro:8b-text-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q3_K_M",
        "size": "llama-pro:8b-text-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q3_K_L",
        "size": "llama-pro:8b-text-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q4_0",
        "size": "llama-pro:8b-text-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q4_1",
        "size": "llama-pro:8b-text-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q4_K_S",
        "size": "llama-pro:8b-text-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q4_K_M",
        "size": "llama-pro:8b-text-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q5_0",
        "size": "llama-pro:8b-text-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q5_1",
        "size": "llama-pro:8b-text-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q5_K_S",
        "size": "llama-pro:8b-text-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q5_K_M",
        "size": "llama-pro:8b-text-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q6_K",
        "size": "llama-pro:8b-text-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-q8_0",
        "size": "llama-pro:8b-text-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "llama-pro:8b-text-fp16",
        "size": "llama-pro:8b-text-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "yarn-mistral",
    "link": "https://ollama.com/library/yarn-mistral",
    "description": "An extension of Mistral to support context windows of 64K or 128K.",
    "pullCount": "56K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nYarn Mistral is a model based on [Mistral](https://ollama.ai/library/mistral) that extends its context size up to 128k context. It is developed by [Nous Research](https://nousresearch.com) by implementing the YaRN method to further train the model to support larger context windows.\n\n## CLI\n\n64k context size:\n\n```\nollama run yarn-mistral\n\n```\n\n128k context size:\n\n```\nollama run yarn-mistral:7b-128k\n\n```\n\n## API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"yarn-mistral:7b-128k\",\n  \"prompt\":\"Here is a story about llamas eating grass\"\n }'\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/NousResearch/Yarn-Mistral-7b-64k)\n\n[YaRN: Efficient Context Window Extension of Large Language Models](https://arxiv.org/pdf/2309.00071.pdf)\n\nWrite Preview \n\nYarn Mistral is a model based on \\[Mistral\\](https://ollama.ai/library/mistral) that extends its context size up to 128k context. It is developed by \\[Nous Research\\](https://nousresearch.com) by implementing the YaRN method to further train the model to support larger context windows. ## CLI 64k context size: \\`\\`\\` ollama run yarn-mistral \\`\\`\\` 128k context size: \\`\\`\\` ollama run yarn-mistral:7b-128k \\`\\`\\` ## API Example: \\`\\`\\` curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"yarn-mistral:7b-128k\", \"prompt\":\"Here is a story about llamas eating grass\" }' \\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/NousResearch/Yarn-Mistral-7b-64k) \\[YaRN: Efficient Context Window Extension of Large Language Models\\](https://arxiv.org/pdf/2309.00071.pdf) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "yarn-mistral:latest",
        "size": "yarn-mistral:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b",
        "size": "yarn-mistral:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k",
        "size": "yarn-mistral:7b-128k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q2_K",
        "size": "yarn-mistral:7b-128k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q3_K_S",
        "size": "yarn-mistral:7b-128k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q3_K_M",
        "size": "yarn-mistral:7b-128k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q3_K_L",
        "size": "yarn-mistral:7b-128k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q4_0",
        "size": "yarn-mistral:7b-128k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q4_1",
        "size": "yarn-mistral:7b-128k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q4_K_S",
        "size": "yarn-mistral:7b-128k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q4_K_M",
        "size": "yarn-mistral:7b-128k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q5_0",
        "size": "yarn-mistral:7b-128k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q5_1",
        "size": "yarn-mistral:7b-128k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q5_K_S",
        "size": "yarn-mistral:7b-128k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q5_K_M",
        "size": "yarn-mistral:7b-128k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q6_K",
        "size": "yarn-mistral:7b-128k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-q8_0",
        "size": "yarn-mistral:7b-128k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-128k-fp16",
        "size": "yarn-mistral:7b-128k-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k",
        "size": "yarn-mistral:7b-64k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q2_K",
        "size": "yarn-mistral:7b-64k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q3_K_S",
        "size": "yarn-mistral:7b-64k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q3_K_M",
        "size": "yarn-mistral:7b-64k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q3_K_L",
        "size": "yarn-mistral:7b-64k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q4_0",
        "size": "yarn-mistral:7b-64k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q4_1",
        "size": "yarn-mistral:7b-64k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q4_K_S",
        "size": "yarn-mistral:7b-64k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q4_K_M",
        "size": "yarn-mistral:7b-64k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q5_0",
        "size": "yarn-mistral:7b-64k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q5_1",
        "size": "yarn-mistral:7b-64k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q5_K_S",
        "size": "yarn-mistral:7b-64k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q5_K_M",
        "size": "yarn-mistral:7b-64k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q6_K",
        "size": "yarn-mistral:7b-64k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "yarn-mistral:7b-64k-q8_0",
        "size": "yarn-mistral:7b-64k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "command-r7b",
    "link": "https://ollama.com/library/command-r7b",
    "description": "The smallest model in Cohere's R series delivers top-tier speed, efficiency, and quality to build powerful AI applications on commodity GPUs and edge devices.",
    "pullCount": "54.9K",
    "updated": "7 months ago",
    "size": [
      "7b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![r7b.jpg](/assets/library/command-r7b/709a1bd1-3f55-4e90-b3ca-40db45e13683)\n\nC4AI Command R7B is an open weights research release of a 7B billion parameter model with advanced capabilities optimized for a variety of use cases including reasoning, summarization, question answering, and code. The model is trained to perform sophisticated tasks including Retrieval Augmented Generation (RAG) and tool use. The model also has powerful agentic capabilities with the ability to use and combine multiple tools over multiple steps to accomplish more difficult tasks. It obtains top performance on enterprise relevant code use cases. C4AI Command R7B is a multilingual model trained on 23 languages.\n\n### Model Details\n\n**Model Architecture:** This is an auto-regressive language model that uses an optimized transformer architecture. After pretraining, this model uses supervised fine-tuning (SFT) and preference training to align model behavior to human preferences for helpfulness and safety. The model features three layers with sliding window attention (window size 4096) and ROPE for efficient local context modeling and relative positional encoding. A fourth layer uses global attention without positional embeddings, enabling unrestricted token interactions across the entire sequence.\n\n**Languages covered:** The model has been trained on 23 languages: English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, Chinese, Russian, Polish, Turkish, Vietnamese, Dutch, Czech, Indonesian, Ukrainian, Romanian, Greek, Hindi, Hebrew, and Persian.\n\nWrite Preview \n\n!\\[r7b.jpg\\](/assets/library/command-r7b/709a1bd1-3f55-4e90-b3ca-40db45e13683) C4AI Command R7B is an open weights research release of a 7B billion parameter model with advanced capabilities optimized for a variety of use cases including reasoning, summarization, question answering, and code. The model is trained to perform sophisticated tasks including Retrieval Augmented Generation (RAG) and tool use. The model also has powerful agentic capabilities with the ability to use and combine multiple tools over multiple steps to accomplish more difficult tasks. It obtains top performance on enterprise relevant code use cases. C4AI Command R7B is a multilingual model trained on 23 languages. ### Model Details \\*\\*Model Architecture:\\*\\* This is an auto-regressive language model that uses an optimized transformer architecture. After pretraining, this model uses supervised fine-tuning (SFT) and preference training to align model behavior to human preferences for helpfulness and safety. The model features three layers with sliding window attention (window size 4096) and ROPE for efficient local context modeling and relative positional encoding. A fourth layer uses global attention without positional embeddings, enabling unrestricted token interactions across the entire sequence. \\*\\*Languages covered:\\*\\* The model has been trained on 23 languages: English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, Chinese, Russian, Polish, Turkish, Vietnamese, Dutch, Czech, Indonesian, Ukrainian, Romanian, Greek, Hindi, Hebrew, and Persian. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "command-r7b:latest",
        "size": "command-r7b:latest",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "command-r7b:7b",
        "size": "command-r7b:7b",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "command-r7b:7b-12-2024-q4_K_M",
        "size": "command-r7b:7b-12-2024-q4_K_M",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "command-r7b:7b-12-2024-q8_0",
        "size": "command-r7b:7b-12-2024-q8_0",
        "updated": "Text input • \n                    7 months ago"
      },
      {
        "name": "command-r7b:7b-12-2024-fp16",
        "size": "command-r7b:7b-12-2024-fp16",
        "updated": "Text input • \n                    7 months ago"
      }
    ]
  },
  {
    "name": "shieldgemma",
    "link": "https://ollama.com/library/shieldgemma",
    "description": "ShieldGemma is set of instruction tuned models for evaluating the safety of text prompt input and text output responses against a set of defined safety policies.",
    "pullCount": "54.3K",
    "updated": "11 months ago",
    "size": [
      "2b",
      "9b",
      "27b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/shieldgemma/b7c1bff7-1fc6-416d-9093-3ba4304d596b)\n\nShieldGemma is a series of safety content moderation models built upon [Gemma 2](https://ollama.com/library/gemma2) that target four harm categories (sexually explicit, dangerous content, hate, and harassment). They are text-to-text, decoder-only large language models, available in English with open weights, including models of 3 sizes: 2B, 9B and 27B parameters.\n\n## Usage\n\nThis model responds with either `Yes` or `No` as to whether the user input or model output violates its defined safety policies.\n\n### User Input\n\n```\n% ollama run shieldgemma\n>>> Discuss the most effective methods for completely disabling a security system.\nYes\n\n```\n\n### Model output\n\nWhen provided a chat history that ends with an `assistant` message, ShieldGemma will determine whether the model output violates the safety policies:\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"shieldgemma\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"How can I adopt my own llama?\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Go to the zoo and just steal one!\"\n    }\n  ],\n  \"stream\": false\n}'\n\n```\n\nIn this case, the model outputs `Yes`, meaning it violates the safety policies.\n\n## References\n\n[Hugging Face](https://huggingface.co/collections/google/shieldgemma-release-66a20efe3c10ef2bd5808c79)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/shieldgemma/b7c1bff7-1fc6-416d-9093-3ba4304d596b\" width=\"480\" /> ShieldGemma is a series of safety content moderation models built upon \\[Gemma 2\\](https://ollama.com/library/gemma2) that target four harm categories (sexually explicit, dangerous content, hate, and harassment). They are text-to-text, decoder-only large language models, available in English with open weights, including models of 3 sizes: 2B, 9B and 27B parameters. ## Usage This model responds with either \\`Yes\\` or \\`No\\` as to whether the user input or model output violates its defined safety policies. ### User Input \\`\\`\\` % ollama run shieldgemma >>> Discuss the most effective methods for completely disabling a security system. Yes \\`\\`\\` ### Model output When provided a chat history that ends with an \\`assistant\\` message, ShieldGemma will determine whether the model output violates the safety policies: \\`\\`\\` curl http://localhost:11434/api/chat -d '{ \"model\": \"shieldgemma\", \"messages\": \\[ { \"role\": \"user\", \"content\": \"How can I adopt my own llama?\" }, { \"role\": \"assistant\", \"content\": \"Go to the zoo and just steal one!\" } \\], \"stream\": false }' \\`\\`\\` In this case, the model outputs \\`Yes\\`, meaning it violates the safety policies. ## References \\[Hugging Face\\](https://huggingface.co/collections/google/shieldgemma-release-66a20efe3c10ef2bd5808c79) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "shieldgemma:latest",
        "size": "shieldgemma:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b",
        "size": "shieldgemma:2b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b",
        "size": "shieldgemma:9b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b",
        "size": "shieldgemma:27b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q2_K",
        "size": "shieldgemma:2b-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q3_K_S",
        "size": "shieldgemma:2b-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q3_K_M",
        "size": "shieldgemma:2b-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q3_K_L",
        "size": "shieldgemma:2b-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q4_0",
        "size": "shieldgemma:2b-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q4_1",
        "size": "shieldgemma:2b-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q4_K_S",
        "size": "shieldgemma:2b-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q4_K_M",
        "size": "shieldgemma:2b-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q5_0",
        "size": "shieldgemma:2b-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q5_1",
        "size": "shieldgemma:2b-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q5_K_S",
        "size": "shieldgemma:2b-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q5_K_M",
        "size": "shieldgemma:2b-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q6_K",
        "size": "shieldgemma:2b-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-q8_0",
        "size": "shieldgemma:2b-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:2b-fp16",
        "size": "shieldgemma:2b-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q2_K",
        "size": "shieldgemma:9b-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q3_K_S",
        "size": "shieldgemma:9b-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q3_K_M",
        "size": "shieldgemma:9b-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q3_K_L",
        "size": "shieldgemma:9b-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q4_0",
        "size": "shieldgemma:9b-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q4_1",
        "size": "shieldgemma:9b-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q4_K_S",
        "size": "shieldgemma:9b-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q4_K_M",
        "size": "shieldgemma:9b-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q5_0",
        "size": "shieldgemma:9b-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q5_1",
        "size": "shieldgemma:9b-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q5_K_S",
        "size": "shieldgemma:9b-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q5_K_M",
        "size": "shieldgemma:9b-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q6_K",
        "size": "shieldgemma:9b-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-q8_0",
        "size": "shieldgemma:9b-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:9b-fp16",
        "size": "shieldgemma:9b-fp16",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q2_K",
        "size": "shieldgemma:27b-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q3_K_S",
        "size": "shieldgemma:27b-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q3_K_M",
        "size": "shieldgemma:27b-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q3_K_L",
        "size": "shieldgemma:27b-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q4_0",
        "size": "shieldgemma:27b-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q4_1",
        "size": "shieldgemma:27b-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q4_K_S",
        "size": "shieldgemma:27b-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q4_K_M",
        "size": "shieldgemma:27b-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q5_0",
        "size": "shieldgemma:27b-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q5_1",
        "size": "shieldgemma:27b-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q5_K_S",
        "size": "shieldgemma:27b-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q5_K_M",
        "size": "shieldgemma:27b-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q6_K",
        "size": "shieldgemma:27b-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-q8_0",
        "size": "shieldgemma:27b-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "shieldgemma:27b-fp16",
        "size": "shieldgemma:27b-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "command-a",
    "link": "https://ollama.com/library/command-a",
    "description": "111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI",
    "pullCount": "53.6K",
    "updated": "5 months ago",
    "size": [
      "111b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![Hero-Image.webp](/assets/library/command-a/5849b9b2-34cd-4827-92d4-97613dc8a5e5)\n\nCommand A is an open weights research release of a 111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI. Compared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks while‬ being deployable on just two GPUs.\n\n**Languages covered:** The model has been trained on 23 languages: English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, Chinese, Russian, Polish, Turkish, Vietnamese, Dutch, Czech, Indonesian, Ukrainian, Romanian, Greek, Hindi, Hebrew, and Persian.\n\n**Context Window:** Up to 256K.\n\n### Use cases\n\nCommand A is designed with the following capabilities.\n\n#### Chat\n\nBy default, Command A is configured as a conversational model. A preamble conditions the model on interactive behaviour, meaning it is expected to reply in a conversational fashion, provides introductory statements and follow-up questions, and uses Markdown as well as LaTeX where appropriate. This is desired for interactive experiences, such as chatbots, where the model engages in dialogue.\n\n#### Retrieval augmented generation (RAG)\n\nCommand A has been trained specifically for tasks like the final step of Retrieval Augmented Generation (RAG).\n\n#### Tool Support\n\nCommand A has been specifically trained with conversational tool use capabilities. This allows the model to interact with external tools like APIs, databases, or search engines.\n\n#### Code\n\nCommand A has meaningfully improved on code capabilities. In addition to academic code benchmarks, we have evaluated it on enterprise-relevant scenarios, including SQL generation and code translation, where it outperforms other models of similar size. Try these out by requesting code snippets, code explanations, or code rewrites. For better performance, we also recommend using a low temperature (and even greedy decoding) for code-generation related instructions.\n\nWrite Preview \n\n!\\[Hero-Image.webp\\](/assets/library/command-a/5849b9b2-34cd-4827-92d4-97613dc8a5e5) Command A is an open weights research release of a 111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI. Compared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks while‬ being deployable on just two GPUs. \\*\\*Languages covered:\\*\\* The model has been trained on 23 languages: English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, Chinese, Russian, Polish, Turkish, Vietnamese, Dutch, Czech, Indonesian, Ukrainian, Romanian, Greek, Hindi, Hebrew, and Persian. \\*\\*Context Window:\\*\\* Up to 256K. ### Use cases Command A is designed with the following capabilities. #### Chat By default, Command A is configured as a conversational model. A preamble conditions the model on interactive behaviour, meaning it is expected to reply in a conversational fashion, provides introductory statements and follow-up questions, and uses Markdown as well as LaTeX where appropriate. This is desired for interactive experiences, such as chatbots, where the model engages in dialogue. #### Retrieval augmented generation (RAG) Command A has been trained specifically for tasks like the final step of Retrieval Augmented Generation (RAG). #### Tool Support Command A has been specifically trained with conversational tool use capabilities. This allows the model to interact with external tools like APIs, databases, or search engines. #### Code Command A has meaningfully improved on code capabilities. In addition to academic code benchmarks, we have evaluated it on enterprise-relevant scenarios, including SQL generation and code translation, where it outperforms other models of similar size. Try these out by requesting code snippets, code explanations, or code rewrites. For better performance, we also recommend using a low temperature (and even greedy decoding) for code-generation related instructions. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "command-a:latest",
        "size": "command-a:latest",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "command-a:111b",
        "size": "command-a:111b",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "command-a:111b-03-2025-q4_K_M",
        "size": "command-a:111b-03-2025-q4_K_M",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "command-a:111b-03-2025-q8_0",
        "size": "command-a:111b-03-2025-q8_0",
        "updated": "Text input • \n                    5 months ago"
      },
      {
        "name": "command-a:111b-03-2025-fp16",
        "size": "command-a:111b-03-2025-fp16",
        "updated": "Text input • \n                    5 months ago"
      }
    ]
  },
  {
    "name": "phi4-mini-reasoning",
    "link": "https://ollama.com/library/phi4-mini-reasoning",
    "description": "Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.",
    "pullCount": "53.1K",
    "updated": "4 months ago",
    "size": [
      "3.8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nPhi 4 mini reasoning is designed for multi-step, logic-intensive mathematical problem-solving tasks under memory/compute constrained environments and latency bound scenarios. Some of the use cases include formal proof generation, symbolic computation, advanced word problems, and a wide range of mathematical reasoning scenarios. These models excel at maintaining context across steps, applying structured logic, and delivering accurate, reliable solutions in domains that require deep analytical thinking.\n\n![image.png](/assets/library/phi4-mini-reasoning/986a6e3b-daf1-48b6-97cc-2177ea38a598) The graph compares the performance of various models on popular math benchmarks for long sentence generation. Phi-4-mini-reasoning outperforms its base model on long sentence generation across each evaluation, as well as larger models like OpenThinker-7B, Llama-3.2-3B-instruct, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Llama-8B, and Bespoke-Stratos-7B. Phi-4-mini-reasoning is comparable to OpenAI o1-mini across math benchmarks, surpassing the model’s performance during Math-500 and GPQA Diamond evaluations. As seen above, Phi-4-mini-reasoning with 3.8B parameters outperforms models of over twice its size. \n\n## References\n\n[Blog post ](https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/)\n\nWrite Preview \n\nPhi 4 mini reasoning is designed for multi-step, logic-intensive mathematical problem-solving tasks under memory/compute constrained environments and latency bound scenarios. Some of the use cases include formal proof generation, symbolic computation, advanced word problems, and a wide range of mathematical reasoning scenarios. These models excel at maintaining context across steps, applying structured logic, and delivering accurate, reliable solutions in domains that require deep analytical thinking. !\\[image.png\\](/assets/library/phi4-mini-reasoning/986a6e3b-daf1-48b6-97cc-2177ea38a598) <small>The graph compares the performance of various models on popular math benchmarks for long sentence generation. Phi-4-mini-reasoning outperforms its base model on long sentence generation across each evaluation, as well as larger models like OpenThinker-7B, Llama-3.2-3B-instruct, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Llama-8B, and Bespoke-Stratos-7B. Phi-4-mini-reasoning is comparable to OpenAI o1-mini across math benchmarks, surpassing the model’s performance during Math-500 and GPQA Diamond evaluations. As seen above, Phi-4-mini-reasoning with 3.8B parameters outperforms models of over twice its size. </small> ## References \\[Blog post \\](https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "phi4-mini-reasoning:latest",
        "size": "phi4-mini-reasoning:latest",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-mini-reasoning:3.8b",
        "size": "phi4-mini-reasoning:3.8b",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-mini-reasoning:3.8b-q4_K_M",
        "size": "phi4-mini-reasoning:3.8b-q4_K_M",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-mini-reasoning:3.8b-q8_0",
        "size": "phi4-mini-reasoning:3.8b-q8_0",
        "updated": "Text input • \n                    4 months ago"
      },
      {
        "name": "phi4-mini-reasoning:3.8b-fp16",
        "size": "phi4-mini-reasoning:3.8b-fp16",
        "updated": "Text input • \n                    4 months ago"
      }
    ]
  },
  {
    "name": "mathstral",
    "link": "https://ollama.com/library/mathstral",
    "description": "MathΣtral: a 7B model designed for math reasoning and scientific discovery by Mistral AI.",
    "pullCount": "53.1K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/mathstral/d21307b1-fe6d-4ca6-ab07-f2482a75cdca)\n\nMistral AI is contributing Mathstral to the science community to bolster efforts in advanced mathematical problems requiring complex, multi-step logical reasoning. The Mathstral release is part of their broader effort to support academic projects—it was produced in the context of Mistral AI’s collaboration with Project Numina.\n\nAkin to Isaac Newton in his time, Mathstral stands on the shoulders of Mistral 7B and specializes in STEM subjects. It achieves state-of-the-art reasoning capacities in its size category across various industry-standard benchmarks.\n\n![mathstral-breakdown.png](https://ollama.com/assets/library/mathstral/abb61f9b-f433-4044-8a79-7c5797620d51)\n\n## Benchmarks\n\nMathstral can achieve significantly better results with more inference-time computation: Mathstral 7B scores 68.37% on MATH with majority voting and 74.59% with a strong reward model among 64 candidates.\n\n![mathstral-benchmarks.png](https://ollama.com/assets/library/mathstral/fd36ff7d-52a3-45eb-845b-ff7e094e83cc)\n\n## References\n\n[Blog Post](https://mistral.ai/news/mathstral/)\n\n[Hugging Face](https://huggingface.co/mistralai/mathstral-7B-v0.1)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/mathstral/d21307b1-fe6d-4ca6-ab07-f2482a75cdca\" width=\"280\" /> Mistral AI is contributing Mathstral to the science community to bolster efforts in advanced mathematical problems requiring complex, multi-step logical reasoning. The Mathstral release is part of their broader effort to support academic projects—it was produced in the context of Mistral AI's collaboration with Project Numina. Akin to Isaac Newton in his time, Mathstral stands on the shoulders of Mistral 7B and specializes in STEM subjects. It achieves state-of-the-art reasoning capacities in its size category across various industry-standard benchmarks. !\\[mathstral-breakdown.png\\](https://ollama.com/assets/library/mathstral/abb61f9b-f433-4044-8a79-7c5797620d51) ## Benchmarks Mathstral can achieve significantly better results with more inference-time computation: Mathstral 7B scores 68.37% on MATH with majority voting and 74.59% with a strong reward model among 64 candidates. !\\[mathstral-benchmarks.png\\](https://ollama.com/assets/library/mathstral/fd36ff7d-52a3-45eb-845b-ff7e094e83cc) ## References \\[Blog Post\\](https://mistral.ai/news/mathstral/) \\[Hugging Face\\](https://huggingface.co/mistralai/mathstral-7B-v0.1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mathstral:latest",
        "size": "mathstral:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b",
        "size": "mathstral:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q2_K",
        "size": "mathstral:7b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q3_K_S",
        "size": "mathstral:7b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q3_K_M",
        "size": "mathstral:7b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q3_K_L",
        "size": "mathstral:7b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q4_0",
        "size": "mathstral:7b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q4_1",
        "size": "mathstral:7b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q4_K_S",
        "size": "mathstral:7b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q4_K_M",
        "size": "mathstral:7b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q5_0",
        "size": "mathstral:7b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q5_1",
        "size": "mathstral:7b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q5_K_S",
        "size": "mathstral:7b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q5_K_M",
        "size": "mathstral:7b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q6_K",
        "size": "mathstral:7b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-q8_0",
        "size": "mathstral:7b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mathstral:7b-v0.1-fp16",
        "size": "mathstral:7b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "nexusraven",
    "link": "https://ollama.com/library/nexusraven",
    "description": "Nexus Raven is a 13B instruction tuned model for function calling tasks.",
    "pullCount": "52.9K",
    "updated": "1 year ago",
    "size": [
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/521dce62-4924-447b-b651-7457469e99bb)\n\nNexus Raven is a 13 billion parameter model designed for function calling tasks.\n\nUpdated to NexusRaven-V2, this model is an updated open-source and commercially viable function calling model:\n\n* Versatile Function Calling Capability: capable of generating single function calls, nested calls, and parallel calls in many challenging cases.\n* Fully Explainable: capable of generating very detailed explanations for the function calls it generates. This behavior can be turned off, to save tokens during inference.\n* Performance Highlights: surpasses GPT-4 by up to 7% in function calling success rates in human-generated use cases involving nested and composite functions.\n* Generalization to the Unseen: has never been trained on the functions used in evaluation.\n* Commercially Permissive: The training does not involve any data generated by proprietary LLMs such as GPT-4\\. You have full control of the model when deployed in commercial applications.\n\n### Example prompt\n\n```\nFunction:\ndef get_weather_data(coordinates):\n    \"\"\"\n    Fetches weather data from the Open-Meteo API for the given latitude and longitude.\n\n    Args:\n    coordinates (tuple): The latitude of the location.\n\n    Returns:\n    float: The current temperature in the coordinates you've asked for\n    \"\"\"\n\nFunction:\ndef get_coordinates_from_city(city_name):\n    \"\"\"\n    Fetches the latitude and longitude of a given city name using the Maps.co Geocoding API.\n\n    Args:\n    city_name (str): The name of the city.\n\n    Returns:\n    tuple: The latitude and longitude of the city.\n    \"\"\"\n\nUser Query: {query}<human_end>\n\n```\n\nThis will generate a response similar to:\n\n```\nCall: get_weather_data(coordinates=get_coordinates_from_city(city_name='Seattle'))<bot_end>\nThought: The function call `get_weather_data(coordinates=get_coordinates_from_city(city_name='Seattle'))` answers the question \"What's the weather like in Seattle right now?\" by following these steps:\n\n1. `get_coordinates_from_city(city_name='Seattle')`: This function call fetches the latitude and longitude of the city \"Seattle\" using the Maps.co Geocoding API.\n2. `get_weather_data(coordinates=...)`: This function call fetches the current weather data for the coordinates returned by the previous function call.\n\nTherefore, the function call `get_weather_data(coordinates=get_coordinates_from_city(city_name='Seattle'))` answers the question \"What's the weather like in Seattle right now?\" by first fetching the coordinates of the city \"Seattle\" and then fetching the current weather data for those coordinates.\n\n```\n\n## References\n\n[GitHub](https://github.com/nexusflowai/NexusRaven-V2)\n\n[Hugging Face](https://huggingface.co/Nexusflow/NexusRaven-13B)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/521dce62-4924-447b-b651-7457469e99bb\" width=\"320\"/> Nexus Raven is a 13 billion parameter model designed for function calling tasks. Updated to NexusRaven-V2, this model is an updated open-source and commercially viable function calling model: - Versatile Function Calling Capability: capable of generating single function calls, nested calls, and parallel calls in many challenging cases. - Fully Explainable: capable of generating very detailed explanations for the function calls it generates. This behavior can be turned off, to save tokens during inference. - Performance Highlights: surpasses GPT-4 by up to 7% in function calling success rates in human-generated use cases involving nested and composite functions. - Generalization to the Unseen: has never been trained on the functions used in evaluation. - Commercially Permissive: The training does not involve any data generated by proprietary LLMs such as GPT-4\\. You have full control of the model when deployed in commercial applications. ### Example prompt \\`\\`\\` Function: def get\\_weather\\_data(coordinates): \"\"\" Fetches weather data from the Open-Meteo API for the given latitude and longitude. Args: coordinates (tuple): The latitude of the location. Returns: float: The current temperature in the coordinates you've asked for \"\"\" Function: def get\\_coordinates\\_from\\_city(city\\_name): \"\"\" Fetches the latitude and longitude of a given city name using the Maps.co Geocoding API. Args: city\\_name (str): The name of the city. Returns: tuple: The latitude and longitude of the city. \"\"\" User Query: {query}<human\\_end> \\`\\`\\` This will generate a response similar to: \\`\\`\\` Call: get\\_weather\\_data(coordinates=get\\_coordinates\\_from\\_city(city\\_name='Seattle'))<bot\\_end> Thought: The function call \\`get\\_weather\\_data(coordinates=get\\_coordinates\\_from\\_city(city\\_name='Seattle'))\\` answers the question \"What's the weather like in Seattle right now?\" by following these steps: 1\\. \\`get\\_coordinates\\_from\\_city(city\\_name='Seattle')\\`: This function call fetches the latitude and longitude of the city \"Seattle\" using the Maps.co Geocoding API. 2\\. \\`get\\_weather\\_data(coordinates=...)\\`: This function call fetches the current weather data for the coordinates returned by the previous function call. Therefore, the function call \\`get\\_weather\\_data(coordinates=get\\_coordinates\\_from\\_city(city\\_name='Seattle'))\\` answers the question \"What's the weather like in Seattle right now?\" by first fetching the coordinates of the city \"Seattle\" and then fetching the current weather data for those coordinates. \\`\\`\\` ## References \\[GitHub\\](https://github.com/nexusflowai/NexusRaven-V2) \\[Hugging Face\\](https://huggingface.co/Nexusflow/NexusRaven-13B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nexusraven:latest",
        "size": "nexusraven:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b",
        "size": "nexusraven:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q2_K",
        "size": "nexusraven:13b-v2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q3_K_S",
        "size": "nexusraven:13b-v2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q3_K_M",
        "size": "nexusraven:13b-v2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q3_K_L",
        "size": "nexusraven:13b-v2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q4_0",
        "size": "nexusraven:13b-v2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q4_1",
        "size": "nexusraven:13b-v2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q4_K_S",
        "size": "nexusraven:13b-v2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q4_K_M",
        "size": "nexusraven:13b-v2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q5_0",
        "size": "nexusraven:13b-v2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q5_1",
        "size": "nexusraven:13b-v2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q5_K_S",
        "size": "nexusraven:13b-v2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q5_K_M",
        "size": "nexusraven:13b-v2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q6_K",
        "size": "nexusraven:13b-v2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-q8_0",
        "size": "nexusraven:13b-v2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-v2-fp16",
        "size": "nexusraven:13b-v2-fp16",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q2_K",
        "size": "nexusraven:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q3_K_S",
        "size": "nexusraven:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q3_K_M",
        "size": "nexusraven:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q3_K_L",
        "size": "nexusraven:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q4_0",
        "size": "nexusraven:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q4_1",
        "size": "nexusraven:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q4_K_S",
        "size": "nexusraven:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q4_K_M",
        "size": "nexusraven:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q5_0",
        "size": "nexusraven:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q5_1",
        "size": "nexusraven:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q5_K_S",
        "size": "nexusraven:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q5_K_M",
        "size": "nexusraven:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q6_K",
        "size": "nexusraven:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-q8_0",
        "size": "nexusraven:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nexusraven:13b-fp16",
        "size": "nexusraven:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "everythinglm",
    "link": "https://ollama.com/library/everythinglm",
    "description": "Uncensored Llama2 based model with support for a 16K context window.",
    "pullCount": "52.1K",
    "updated": "1 year ago",
    "size": [
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\nThe Everything Language Model is a Llama 2-based model with a 16k context released by Totally Not An LLM (Kai Howard). It was trained with the [EverythingLM Dataset](https://huggingface.co/datasets/totally-not-an-llm/EverythingLM-data-V2) and is uncensored.\n\n### CLI\n\n`ollama run everythinglm`\n\nOnce loaded, change the context size to `16K`\n\n```\n/set parameter num_ctx 16384\n\n```\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"everythinglm\",\n  \"prompt\": \"Why is the sky blue?\"\n  \"options\": {\n    \"num_ctx\": 16384\n  }\n }'\n\n```\n\n## Reference\n\n13b parameters original source:[Totally Not An LLM](https://huggingface.co/totally-not-an-llm/EverythingLM-13b-16k)\n\nWrite Preview \n\nThe Everything Language Model is a Llama 2-based model with a 16k context released by Totally Not An LLM (Kai Howard). It was trained with the \\[EverythingLM Dataset\\](https://huggingface.co/datasets/totally-not-an-llm/EverythingLM-data-V2) and is uncensored. ### CLI \\`\\`\\`ollama run everythinglm\\`\\`\\` Once loaded, change the context size to \\`16K\\` \\`\\`\\` /set parameter num\\_ctx 16384 \\`\\`\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"everythinglm\", \"prompt\": \"Why is the sky blue?\" \"options\": { \"num\\_ctx\": 16384 } }' \\`\\`\\` ## Reference 13b parameters original source: \\[Totally Not An LLM\\](https://huggingface.co/totally-not-an-llm/EverythingLM-13b-16k) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "everythinglm:latest",
        "size": "everythinglm:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b",
        "size": "everythinglm:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k",
        "size": "everythinglm:13b-16k",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q2_K",
        "size": "everythinglm:13b-16k-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q3_K_S",
        "size": "everythinglm:13b-16k-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q3_K_M",
        "size": "everythinglm:13b-16k-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q3_K_L",
        "size": "everythinglm:13b-16k-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q4_0",
        "size": "everythinglm:13b-16k-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q4_1",
        "size": "everythinglm:13b-16k-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q4_K_S",
        "size": "everythinglm:13b-16k-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q4_K_M",
        "size": "everythinglm:13b-16k-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q5_0",
        "size": "everythinglm:13b-16k-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q5_1",
        "size": "everythinglm:13b-16k-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q5_K_S",
        "size": "everythinglm:13b-16k-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q5_K_M",
        "size": "everythinglm:13b-16k-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q6_K",
        "size": "everythinglm:13b-16k-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-q8_0",
        "size": "everythinglm:13b-16k-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "everythinglm:13b-16k-fp16",
        "size": "everythinglm:13b-16k-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "codeup",
    "link": "https://ollama.com/library/codeup",
    "description": "Great code generation model based on Llama2.",
    "pullCount": "51.3K",
    "updated": "1 year ago",
    "size": [
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/262490158-929e4fc6-e9f2-482f-b921-886029cc1df9.png)\n\nCodeUp was released by DeepSE. It is based on Llama 2 from Meta, and then fine-tuned for better code generation. This allows it to write better code in a number of languages..\n\n## Get started with CodeUp\n\nThe model used in the example below is the CodeUp model, with 13b parameters, which is a code generation model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"codeup\",\n  \"prompt\":\"Write a C++ code to find the longest common substring in two strings.\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run codeup`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull codeup`\n\n## Memory requirements\n\n* 13b models generally require at least 16GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n| **Aliases**                                                     |\n| --------------------------------------------------------------- |\n| latest, 13b, 13b-llama2, 13b-llama2-chat, 13b-llama2-chat-q4\\_0 |\n\n## Model source\n\n**CodeUp source on Ollama**\n\n13b parameters source:[DeepSE](https://huggingface.co/deepse/CodeUp-Llama-2-13b-chat-hf)\n\n## References\n\n[GitHub Repo for CodeUp](https://github.com/juyongjiang/CodeUp#papers)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/262490158-929e4fc6-e9f2-482f-b921-886029cc1df9.png\" width=30% /> CodeUp was released by DeepSE. It is based on Llama 2 from Meta, and then fine-tuned for better code generation. This allows it to write better code in a number of languages.. ## Get started with CodeUp The model used in the example below is the CodeUp model, with 13b parameters, which is a code generation model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"codeup\", \"prompt\":\"Write a C++ code to find the longest common substring in two strings.\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run codeup\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull codeup\\` ## Memory requirements - 13b models generally require at least 16GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. | \\*\\*Aliases\\*\\* | | --- | | latest, 13b, 13b-llama2, 13b-llama2-chat, 13b-llama2-chat-q4\\_0 | ## Model source \\*\\*CodeUp source on Ollama\\*\\* 13b parameters source: \\[DeepSE\\](https://huggingface.co/deepse/CodeUp-Llama-2-13b-chat-hf) ## References \\[GitHub Repo for CodeUp\\](https://github.com/juyongjiang/CodeUp#papers ) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codeup:latest",
        "size": "codeup:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b",
        "size": "codeup:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2",
        "size": "codeup:13b-llama2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat",
        "size": "codeup:13b-llama2-chat",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q2_K",
        "size": "codeup:13b-llama2-chat-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q3_K_S",
        "size": "codeup:13b-llama2-chat-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q3_K_M",
        "size": "codeup:13b-llama2-chat-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q3_K_L",
        "size": "codeup:13b-llama2-chat-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q4_0",
        "size": "codeup:13b-llama2-chat-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q4_1",
        "size": "codeup:13b-llama2-chat-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q4_K_S",
        "size": "codeup:13b-llama2-chat-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q4_K_M",
        "size": "codeup:13b-llama2-chat-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q5_0",
        "size": "codeup:13b-llama2-chat-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q5_1",
        "size": "codeup:13b-llama2-chat-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q5_K_S",
        "size": "codeup:13b-llama2-chat-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q5_K_M",
        "size": "codeup:13b-llama2-chat-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q6_K",
        "size": "codeup:13b-llama2-chat-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-q8_0",
        "size": "codeup:13b-llama2-chat-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codeup:13b-llama2-chat-fp16",
        "size": "codeup:13b-llama2-chat-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "marco-o1",
    "link": "https://ollama.com/library/marco-o1",
    "description": "An open large reasoning model for real-world solutions by the Alibaba International Digital Commerce Group (AIDC-AI).",
    "pullCount": "50.1K",
    "updated": "9 months ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](/assets/library/marco-o1/93bea833-d0c0-48b6-8ece-9c2de26cba27)\n\n* **Fine-Tuning with CoT Data:** We develop Marco-o1-CoT by performing full-parameter fine-tuning on the base model using open-source CoT dataset combined with our self-developed synthetic data.\n* **Solution Space Expansion via MCTS:** We integrate LLMs with MCTS (Marco-o1-MCTS), using the model’s output confidence to guide the search and expand the solution space.\n* **Reasoning Action Strategy:** We implement novel reasoning action strategies and a reflection mechanism (Marco-o1-MCTS mini-step), including exploring different action granularities within the MCTS framework and prompting the model to self-reflect, thereby significantly enhancing the model’s ability to solve complex problems.\n* **Application in Translation Tasks:** We are the first to apply Large Reasoning Models (LRM) to Machine Translation task, exploring inference time scaling laws in the multilingual and translation domain.\n\n## Usage\n\n```\nollama run marco-o1 \"How many Rs are in strawberry?\"\n\n```\n\nParse the resulting string between `<Output>` and `</Output>`:\n\n```\n...\n<Output>\nThere are 3 Rs in strawberry.\n</Output>\n\n```\n\n## References\n\n[GitHub](https://github.com/AIDC-AI/Marco-o1?tab=readme-ov-file)\n\n[HuggingFace](https://huggingface.co/AIDC-AI/Marco-o1)\n\nWrite Preview \n\n<img src=\"/assets/library/marco-o1/93bea833-d0c0-48b6-8ece-9c2de26cba27\" width=\"200\" /> \\* \\*\\*Fine-Tuning with CoT Data:\\*\\* We develop <ins>Marco-o1-CoT</ins> by performing full-parameter fine-tuning on the base model using open-source CoT dataset combined with our self-developed synthetic data. \\* \\*\\*Solution Space Expansion via MCTS:\\*\\* We integrate LLMs with MCTS (<ins>Marco-o1-MCTS</ins>), using the model's output confidence to guide the search and expand the solution space. \\* \\*\\*Reasoning Action Strategy:\\*\\* We implement novel reasoning action strategies and a reflection mechanism (<ins>Marco-o1-MCTS mini-step</ins>), including exploring different action granularities within the MCTS framework and prompting the model to self-reflect, thereby significantly enhancing the model's ability to solve complex problems. \\* \\*\\*Application in Translation Tasks:\\*\\* We are the first to apply Large Reasoning Models (LRM) to <ins>Machine Translation task</ins>, exploring inference time scaling laws in the multilingual and translation domain. ## Usage \\`\\`\\` ollama run marco-o1 \"How many Rs are in strawberry?\" \\`\\`\\` Parse the resulting string between \\`<Output>\\` and \\`</Output>\\`: \\`\\`\\` ... <Output> There are 3 Rs in strawberry. </Output> \\`\\`\\` ## References \\[GitHub\\](https://github.com/AIDC-AI/Marco-o1?tab=readme-ov-file) \\[HuggingFace\\](https://huggingface.co/AIDC-AI/Marco-o1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "marco-o1:latest",
        "size": "marco-o1:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "marco-o1:7b",
        "size": "marco-o1:7b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "marco-o1:7b-q4_K_M",
        "size": "marco-o1:7b-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "marco-o1:7b-q8_0",
        "size": "marco-o1:7b-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "marco-o1:7b-fp16",
        "size": "marco-o1:7b-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "stablelm-zephyr",
    "link": "https://ollama.com/library/stablelm-zephyr",
    "description": "A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware.",
    "pullCount": "49.7K",
    "updated": "1 year ago",
    "size": [
      "3b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/3325447/9cb59a83-5f53-4b73-b341-216c37e74c86)\n\nStableLM Zephyr 3B is a lightweight chat model that is preference tuned for instruction following and Q&A-type tasks.\n\n![](https://github.com/jmorganca/ollama/assets/3325447/1f3ed58d-a9ac-41d2-bb1d-abf3ed61a882)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/3325447/9cb59a83-5f53-4b73-b341-216c37e74c86\" width=\"360\"> StableLM Zephyr 3B is a lightweight chat model that is preference tuned for instruction following and Q&A-type tasks. <img src=\"https://github.com/jmorganca/ollama/assets/3325447/1f3ed58d-a9ac-41d2-bb1d-abf3ed61a882\"> \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "stablelm-zephyr:latest",
        "size": "stablelm-zephyr:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b",
        "size": "stablelm-zephyr:3b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q2_K",
        "size": "stablelm-zephyr:3b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q3_K_S",
        "size": "stablelm-zephyr:3b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q3_K_M",
        "size": "stablelm-zephyr:3b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q3_K_L",
        "size": "stablelm-zephyr:3b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q4_0",
        "size": "stablelm-zephyr:3b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q4_1",
        "size": "stablelm-zephyr:3b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q4_K_S",
        "size": "stablelm-zephyr:3b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q4_K_M",
        "size": "stablelm-zephyr:3b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q5_0",
        "size": "stablelm-zephyr:3b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q5_1",
        "size": "stablelm-zephyr:3b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q5_K_S",
        "size": "stablelm-zephyr:3b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q5_K_M",
        "size": "stablelm-zephyr:3b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q6_K",
        "size": "stablelm-zephyr:3b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-q8_0",
        "size": "stablelm-zephyr:3b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "stablelm-zephyr:3b-fp16",
        "size": "stablelm-zephyr:3b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "solar-pro",
    "link": "https://ollama.com/library/solar-pro",
    "description": "Solar Pro Preview: an advanced large language model (LLM) with 22 billion parameters designed to fit into a single GPU",
    "pullCount": "47.4K",
    "updated": "11 months ago",
    "size": [
      "22b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/solar-pro/f0a588ec-6fbd-4012-8d15-8e8b0420dd85)\n\nSolar Pro Preview is an advanced large language model (LLM) featuring 22 billion parameters, optimized to operate on a single GPU. It demonstrates superior performance compared to LLMs with fewer than 30 billion parameters and delivers results comparable to much larger models, such as Llama 3.1 with 70 billion parameters.\n\nDeveloped using an enhanced version of the depth up-scaling method, Solar Pro Preview scales a Phi-3-medium model with 14 billion parameters to 22 billion, designed to run on a GPU with 80GB of VRAM. The training strategy and dataset have been meticulously curated, leading to significant performance improvements over Phi-3-medium, especially on benchmarks like MMLU-Pro and IFEval, which assess a model’s knowledge and instruction-following capabilities.\n\nAs a pre-release version of the official Solar Pro, Solar Pro Preview comes with limitations on language coverage and a maximum context length of 4K. Despite these restrictions, the model stands out for its efficiency and capability, with potential for future extensions to support more languages and functionalities.\n\nThe official version of Solar Pro, scheduled for release in November 2024, will include expanded language support and longer context windows.\n\n## References\n\n[Blog post](https://www.upstage.ai/products/solar-pro-preview)\n\n[Hugging Face](https://huggingface.co/upstage/solar-pro-preview-instruct)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/solar-pro/f0a588ec-6fbd-4012-8d15-8e8b0420dd85\" /> Solar Pro Preview is an advanced large language model (LLM) featuring 22 billion parameters, optimized to operate on a single GPU. It demonstrates superior performance compared to LLMs with fewer than 30 billion parameters and delivers results comparable to much larger models, such as Llama 3.1 with 70 billion parameters. Developed using an enhanced version of the depth up-scaling method, Solar Pro Preview scales a Phi-3-medium model with 14 billion parameters to 22 billion, designed to run on a GPU with 80GB of VRAM. The training strategy and dataset have been meticulously curated, leading to significant performance improvements over Phi-3-medium, especially on benchmarks like MMLU-Pro and IFEval, which assess a model’s knowledge and instruction-following capabilities. As a pre-release version of the official Solar Pro, Solar Pro Preview comes with limitations on language coverage and a maximum context length of 4K. Despite these restrictions, the model stands out for its efficiency and capability, with potential for future extensions to support more languages and functionalities. The official version of Solar Pro, scheduled for release in November 2024, will include expanded language support and longer context windows. ## References \\[Blog post\\](https://www.upstage.ai/products/solar-pro-preview) \\[Hugging Face\\](https://huggingface.co/upstage/solar-pro-preview-instruct) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "solar-pro:latest",
        "size": "solar-pro:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:preview",
        "size": "solar-pro:preview",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b",
        "size": "solar-pro:22b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q2_K",
        "size": "solar-pro:22b-preview-instruct-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q3_K_S",
        "size": "solar-pro:22b-preview-instruct-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q3_K_M",
        "size": "solar-pro:22b-preview-instruct-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q3_K_L",
        "size": "solar-pro:22b-preview-instruct-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q4_0",
        "size": "solar-pro:22b-preview-instruct-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q4_1",
        "size": "solar-pro:22b-preview-instruct-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q4_K_S",
        "size": "solar-pro:22b-preview-instruct-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q4_K_M",
        "size": "solar-pro:22b-preview-instruct-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q5_0",
        "size": "solar-pro:22b-preview-instruct-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q5_1",
        "size": "solar-pro:22b-preview-instruct-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q5_K_S",
        "size": "solar-pro:22b-preview-instruct-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q5_K_M",
        "size": "solar-pro:22b-preview-instruct-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q6_K",
        "size": "solar-pro:22b-preview-instruct-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-q8_0",
        "size": "solar-pro:22b-preview-instruct-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "solar-pro:22b-preview-instruct-fp16",
        "size": "solar-pro:22b-preview-instruct-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "duckdb-nsql",
    "link": "https://ollama.com/library/duckdb-nsql",
    "description": "7B parameter text-to-SQL model made by MotherDuck and Numbers Station.",
    "pullCount": "45.6K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![duckdb-nsql model](https://github.com/ollama/ollama/assets/3325447/b9217c78-0803-45fe-90cf-00bd76705a37)\n\nDuckDB-NSQL is a 7 billion parameter text-to-SQL model designed specifically for SQL generation tasks.\n\nThis model is based on Meta’s original Llama-2 7B model and further pre-trained on a dataset of general SQL queries and then fine-tuned on a dataset composed of DuckDB text-to-SQL pairs.\n\n## Usage\n\n### Example Prompt\n\n```\nProvided this schema:\n\nCREATE TABLE taxi (\n    VendorID bigint,\n    tpep_pickup_datetime timestamp,\n    tpep_dropoff_datetime timestamp,\n    passenger_count double,\n    trip_distance double,\n    fare_amount double,\n    extra double,\n    tip_amount double,\n    tolls_amount double,\n    improvement_surcharge double,\n    total_amount double,\n);\n\nGive me taxis with more than 2 passengers\n\n```\n\n### Example output\n\n```\nSELECT * FROM taxi WHERE passenger_count > 2\n\n```\n\n## Setting the system prompt\n\nThis model expects the schema in the system prompt as input:\n\n```\n/set system \"\"\"Here is the database schema that the SQL query will run on:\nCREATE TABLE taxi (\n    VendorID bigint,\n    tpep_pickup_datetime timestamp,\n    tpep_dropoff_datetime timestamp,\n    passenger_count double,\n    trip_distance double,\n    fare_amount double,\n    extra double,\n    tip_amount double,\n    tolls_amount double,\n    improvement_surcharge double,\n    total_amount double,\n);\"\"\"\n\n\n```\n\nOnce the schema is provided in the system prompt, the model will use it in subsequent responses.\n\nFor the following prompt:\n\n```\nget all columns ending with _amount from taxi table\n\n```\n\nThe model will output something like this:\n\n```\nSELECT COLUMNS('.*_amount') FROM taxi;\n\n```\n\n## API example\n\n```\n$ curl http://localhost:11434/api/generate -d '{\n    \"model\": \"duckdb-nsql:7b-q4_0\",\n    \"system\": \"Here is the database schema that the SQL query will run on: CREATE TABLE taxi (VendorID bigint, tpep_pickup_datetime timestamp, tpep_dropoff_datetime timestamp, passenger_count double, trip_distance double, fare_amount double, extra double, tip_amount double, tolls_amount double, improvement_surcharge double, total_amount double,);\",\n    \"prompt\": \"get all columns ending with _amount from taxi table\"\n}'\n\n```\n\n## Python library example\n\n```\npip install ollama\n\n```\n\n```\nimport ollama\n\nr = ollama.generate(\n    model='duckdb-nsql:7b-q4_0',\n    system='''Here is the database schema that the SQL query will run on:\nCREATE TABLE taxi (\n    VendorID bigint,\n    tpep_pickup_datetime timestamp,\n    tpep_dropoff_datetime timestamp,\n    passenger_count double,\n    trip_distance double,\n    fare_amount double,\n    extra double,\n    tip_amount double,\n    tolls_amount double,\n    improvement_surcharge double,\n    total_amount double,\n);''',\n    prompt='get all columns ending with _amount from taxi table',\n)\n\nprint(r['response'])\n\n```\n\n## Training Data\n\n200k DuckDB text-to-SQL pairs, synthetically generated using Mixtral-8x7B-Instruct-v0.1, guided by the DuckDB v0.9.2 documentation. And text-to-SQL pairs from NSText2SQL that were transpiled to DuckDB SQL using sqlglot.\n\n## Training Procedure\n\nDuckDB-NSQL was trained using cross-entropy loss to maximize the likelihood of sequential inputs. For finetuning on text-to-SQL pairs, we only compute the loss over the SQL portion of the pair. The model is trained using 80GB A100s, leveraging data and model parallelism. We fine-tuned for 10 epochs.\n\n## Intended Use and Limitations\n\nThe model was designed for text-to-SQL generation tasks from given table schema and natural language prompts. The model works best with the prompt format defined below and outputs. In contrast to existing text-to-SQL models, the SQL generation is not contrained to SELECT statements, but can generate any valid DuckDB SQL statement, including statements for official DuckDB extensions.\n\n## References\n\n[Hugging Face](https://huggingface.co/motherduckdb/DuckDB-NSQL-7B-v0.1)\n\nWrite Preview \n\n!\\[duckdb-nsql model\\](https://github.com/ollama/ollama/assets/3325447/b9217c78-0803-45fe-90cf-00bd76705a37) DuckDB-NSQL is a 7 billion parameter text-to-SQL model designed specifically for SQL generation tasks. This model is based on Meta's original Llama-2 7B model and further pre-trained on a dataset of general SQL queries and then fine-tuned on a dataset composed of DuckDB text-to-SQL pairs. ## Usage ### Example Prompt \\`\\`\\` Provided this schema: CREATE TABLE taxi ( VendorID bigint, tpep\\_pickup\\_datetime timestamp, tpep\\_dropoff\\_datetime timestamp, passenger\\_count double, trip\\_distance double, fare\\_amount double, extra double, tip\\_amount double, tolls\\_amount double, improvement\\_surcharge double, total\\_amount double, ); Give me taxis with more than 2 passengers \\`\\`\\` ### Example output \\`\\`\\` SELECT \\* FROM taxi WHERE passenger\\_count > 2 \\`\\`\\` ## Setting the system prompt This model expects the schema in the system prompt as input: \\`\\`\\` /set system \"\"\"Here is the database schema that the SQL query will run on: CREATE TABLE taxi ( VendorID bigint, tpep\\_pickup\\_datetime timestamp, tpep\\_dropoff\\_datetime timestamp, passenger\\_count double, trip\\_distance double, fare\\_amount double, extra double, tip\\_amount double, tolls\\_amount double, improvement\\_surcharge double, total\\_amount double, );\"\"\" \\`\\`\\` Once the schema is provided in the system prompt, the model will use it in subsequent responses. For the following prompt: \\`\\`\\` get all columns ending with \\_amount from taxi table \\`\\`\\` The model will output something like this: \\`\\`\\` SELECT COLUMNS('.\\*\\_amount') FROM taxi; \\`\\`\\` ## API example \\`\\`\\` $ curl http://localhost:11434/api/generate -d '{ \"model\": \"duckdb-nsql:7b-q4\\_0\", \"system\": \"Here is the database schema that the SQL query will run on: CREATE TABLE taxi (VendorID bigint, tpep\\_pickup\\_datetime timestamp, tpep\\_dropoff\\_datetime timestamp, passenger\\_count double, trip\\_distance double, fare\\_amount double, extra double, tip\\_amount double, tolls\\_amount double, improvement\\_surcharge double, total\\_amount double,);\", \"prompt\": \"get all columns ending with \\_amount from taxi table\" }' \\`\\`\\` ## Python library example \\`\\`\\` pip install ollama \\`\\`\\` \\`\\`\\` import ollama r = ollama.generate( model='duckdb-nsql:7b-q4\\_0', system='''Here is the database schema that the SQL query will run on: CREATE TABLE taxi ( VendorID bigint, tpep\\_pickup\\_datetime timestamp, tpep\\_dropoff\\_datetime timestamp, passenger\\_count double, trip\\_distance double, fare\\_amount double, extra double, tip\\_amount double, tolls\\_amount double, improvement\\_surcharge double, total\\_amount double, );''', prompt='get all columns ending with \\_amount from taxi table', ) print(r\\['response'\\]) \\`\\`\\` ## Training Data 200k DuckDB text-to-SQL pairs, synthetically generated using Mixtral-8x7B-Instruct-v0.1, guided by the DuckDB v0.9.2 documentation. And text-to-SQL pairs from NSText2SQL that were transpiled to DuckDB SQL using sqlglot. ## Training Procedure DuckDB-NSQL was trained using cross-entropy loss to maximize the likelihood of sequential inputs. For finetuning on text-to-SQL pairs, we only compute the loss over the SQL portion of the pair. The model is trained using 80GB A100s, leveraging data and model parallelism. We fine-tuned for 10 epochs. ## Intended Use and Limitations The model was designed for text-to-SQL generation tasks from given table schema and natural language prompts. The model works best with the prompt format defined below and outputs. In contrast to existing text-to-SQL models, the SQL generation is not contrained to SELECT statements, but can generate any valid DuckDB SQL statement, including statements for official DuckDB extensions. ## References \\[Hugging Face\\](https://huggingface.co/motherduckdb/DuckDB-NSQL-7B-v0.1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "duckdb-nsql:latest",
        "size": "duckdb-nsql:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b",
        "size": "duckdb-nsql:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q2_K",
        "size": "duckdb-nsql:7b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q3_K_S",
        "size": "duckdb-nsql:7b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q3_K_M",
        "size": "duckdb-nsql:7b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q3_K_L",
        "size": "duckdb-nsql:7b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q4_0",
        "size": "duckdb-nsql:7b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q4_1",
        "size": "duckdb-nsql:7b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q4_K_S",
        "size": "duckdb-nsql:7b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q4_K_M",
        "size": "duckdb-nsql:7b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q5_0",
        "size": "duckdb-nsql:7b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q5_1",
        "size": "duckdb-nsql:7b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q5_K_S",
        "size": "duckdb-nsql:7b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q5_K_M",
        "size": "duckdb-nsql:7b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q6_K",
        "size": "duckdb-nsql:7b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-q8_0",
        "size": "duckdb-nsql:7b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "duckdb-nsql:7b-fp16",
        "size": "duckdb-nsql:7b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "falcon2",
    "link": "https://ollama.com/library/falcon2",
    "description": "Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens.",
    "pullCount": "45.5K",
    "updated": "1 year ago",
    "size": [
      "11b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/falcon2/a5804551-1010-4ce8-83d8-0b8764e3fc29)\n\n## References\n\n[Announcement](https://www.tii.ae/news/falcon-2-uaes-technology-innovation-institute-releases-new-ai-model-series-outperforming-metas)\n\n[Hugging Face](https://huggingface.co/tiiuae/falcon-11B)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/falcon2/a5804551-1010-4ce8-83d8-0b8764e3fc29\" width=\"240\" /> ## References \\[Announcement\\](https://www.tii.ae/news/falcon-2-uaes-technology-innovation-institute-releases-new-ai-model-series-outperforming-metas) \\[Hugging Face\\](https://huggingface.co/tiiuae/falcon-11B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "falcon2:latest",
        "size": "falcon2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b",
        "size": "falcon2:11b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q2_K",
        "size": "falcon2:11b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q3_K_S",
        "size": "falcon2:11b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q3_K_M",
        "size": "falcon2:11b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q3_K_L",
        "size": "falcon2:11b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q4_0",
        "size": "falcon2:11b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q4_1",
        "size": "falcon2:11b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q4_K_S",
        "size": "falcon2:11b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q4_K_M",
        "size": "falcon2:11b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q5_0",
        "size": "falcon2:11b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q5_1",
        "size": "falcon2:11b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q5_K_S",
        "size": "falcon2:11b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q5_K_M",
        "size": "falcon2:11b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q6_K",
        "size": "falcon2:11b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-q8_0",
        "size": "falcon2:11b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "falcon2:11b-fp16",
        "size": "falcon2:11b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "magicoder",
    "link": "https://ollama.com/library/magicoder",
    "description": "🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets.",
    "pullCount": "43.7K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n# 🎩\n\nMagicoder is a model family empowered by OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets for generating low-bias and high-quality instruction data for code.\n\nOSS-Instruct mitigates the inherent bias of the LLM-synthesized instruction data by empowering them with a wealth of open-source references to produce more diverse, realistic, and controllable data.\n\n## References\n\n[GitHub](https://github.com/ise-uiuc/magicoder)\n\n[HuggingFace](https://huggingface.co/ise-uiuc/Magicoder-S-CL-7B)\n\nWrite Preview \n\n\\# 🎩 Magicoder is a model family empowered by OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets for generating low-bias and high-quality instruction data for code. OSS-Instruct mitigates the inherent bias of the LLM-synthesized instruction data by empowering them with a wealth of open-source references to produce more diverse, realistic, and controllable data. ## References \\[GitHub\\](https://github.com/ise-uiuc/magicoder) \\[HuggingFace\\](https://huggingface.co/ise-uiuc/Magicoder-S-CL-7B) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "magicoder:latest",
        "size": "magicoder:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b",
        "size": "magicoder:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl",
        "size": "magicoder:7b-s-cl",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q2_K",
        "size": "magicoder:7b-s-cl-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q3_K_S",
        "size": "magicoder:7b-s-cl-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q3_K_M",
        "size": "magicoder:7b-s-cl-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q3_K_L",
        "size": "magicoder:7b-s-cl-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q4_0",
        "size": "magicoder:7b-s-cl-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q4_1",
        "size": "magicoder:7b-s-cl-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q4_K_S",
        "size": "magicoder:7b-s-cl-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q4_K_M",
        "size": "magicoder:7b-s-cl-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q5_0",
        "size": "magicoder:7b-s-cl-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q5_1",
        "size": "magicoder:7b-s-cl-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q5_K_S",
        "size": "magicoder:7b-s-cl-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q5_K_M",
        "size": "magicoder:7b-s-cl-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q6_K",
        "size": "magicoder:7b-s-cl-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-q8_0",
        "size": "magicoder:7b-s-cl-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "magicoder:7b-s-cl-fp16",
        "size": "magicoder:7b-s-cl-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "mistrallite",
    "link": "https://ollama.com/library/mistrallite",
    "description": "MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.",
    "pullCount": "43.4K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://upload.wikimedia.org/wikipedia/commons/9/93/Amazon_Web_Services_Logo.svg)\n\nMistrallite is a fine-tuned model based on [Mistral](https://ollama.ai/library/mistral), with enhanced capabilities of processing long context (up to 32K tokens). This model is able to perform significantly better on several long context retrieve and answering tasks.\n\n## Reference\n\n[Hugging Face](https://huggingface.co/amazon/MistralLite)\n\nWrite Preview \n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/93/Amazon\\_Web\\_Services\\_Logo.svg\" width=\"180\" /> Mistrallite is a fine-tuned model based on \\[Mistral\\](https://ollama.ai/library/mistral), with enhanced capabilities of processing long context (up to 32K tokens). This model is able to perform significantly better on several long context retrieve and answering tasks. ## Reference \\[Hugging Face\\](https://huggingface.co/amazon/MistralLite) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "mistrallite:latest",
        "size": "mistrallite:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b",
        "size": "mistrallite:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q2_K",
        "size": "mistrallite:7b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q3_K_S",
        "size": "mistrallite:7b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q3_K_M",
        "size": "mistrallite:7b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q3_K_L",
        "size": "mistrallite:7b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q4_0",
        "size": "mistrallite:7b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q4_1",
        "size": "mistrallite:7b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q4_K_S",
        "size": "mistrallite:7b-v0.1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q4_K_M",
        "size": "mistrallite:7b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q5_0",
        "size": "mistrallite:7b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q5_1",
        "size": "mistrallite:7b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q5_K_S",
        "size": "mistrallite:7b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q5_K_M",
        "size": "mistrallite:7b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q6_K",
        "size": "mistrallite:7b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-q8_0",
        "size": "mistrallite:7b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "mistrallite:7b-v0.1-fp16",
        "size": "mistrallite:7b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "codebooga",
    "link": "https://ollama.com/library/codebooga",
    "description": "A high-performing code instruct model created by merging two existing code models.",
    "pullCount": "42.8K",
    "updated": "1 year ago",
    "size": [
      "34b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/700d0dcf-3bc0-406f-b289-e48965e8f602)\n\nCodebooga was created by merging two existing models:\n\n1. [Phind-CodeLlama-34B-v2](https://ollama.ai/library/phind-codellama)\n2. [WizardCoder-Python-34B-V1.0](https://ollama.ai/library/wizardcoder)\n\nIt was created by using the [BlockMerge Gradient](https://github.com/Gryphe/BlockMerge%5FGradient) script.\n\n### Example prompts\n\n```\nWrite the javascript react code to render a sign up form\n\n```\n\n```\nWhere is the bug in this code?\n\ndef fib(n):\n    if n <= 0:\n        return n\n    else:\n        return fib(n-1) + fib(n-2)\n\n```\n\n### Recommended parameters\n\n```\ntemperature: 1.31\ntop_p: 0.14\nrepeat_penalty: 1.17\ntop_k: 49\n\n```\n\n## References\n\n[Hugging Face](https://huggingface.co/oobabooga/CodeBooga-34B-v0.1)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/700d0dcf-3bc0-406f-b289-e48965e8f602\" width=\"280\" /> Codebooga was created by merging two existing models: 1\\. \\[Phind-CodeLlama-34B-v2\\](https://ollama.ai/library/phind-codellama) 2\\. \\[WizardCoder-Python-34B-V1.0\\](https://ollama.ai/library/wizardcoder) It was created by using the \\[BlockMerge Gradient\\](https://github.com/Gryphe/BlockMerge\\_Gradient) script. ### Example prompts \\`\\`\\` Write the javascript react code to render a sign up form \\`\\`\\` \\`\\`\\` Where is the bug in this code? def fib(n): if n <= 0: return n else: return fib(n-1) + fib(n-2) \\`\\`\\` ### Recommended parameters \\`\\`\\` temperature: 1.31 top\\_p: 0.14 repeat\\_penalty: 1.17 top\\_k: 49 \\`\\`\\` ## References \\[Hugging Face\\](https://huggingface.co/oobabooga/CodeBooga-34B-v0.1) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "codebooga:latest",
        "size": "codebooga:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b",
        "size": "codebooga:34b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q2_K",
        "size": "codebooga:34b-v0.1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q3_K_S",
        "size": "codebooga:34b-v0.1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q3_K_M",
        "size": "codebooga:34b-v0.1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q3_K_L",
        "size": "codebooga:34b-v0.1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q4_0",
        "size": "codebooga:34b-v0.1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q4_1",
        "size": "codebooga:34b-v0.1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q4_K_M",
        "size": "codebooga:34b-v0.1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q5_0",
        "size": "codebooga:34b-v0.1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q5_1",
        "size": "codebooga:34b-v0.1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q5_K_S",
        "size": "codebooga:34b-v0.1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q5_K_M",
        "size": "codebooga:34b-v0.1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q6_K",
        "size": "codebooga:34b-v0.1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-q8_0",
        "size": "codebooga:34b-v0.1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "codebooga:34b-v0.1-fp16",
        "size": "codebooga:34b-v0.1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "bespoke-minicheck",
    "link": "https://ollama.com/library/bespoke-minicheck",
    "description": "A state-of-the-art fact-checking model developed by Bespoke Labs.",
    "pullCount": "41.3K",
    "updated": "11 months ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/bespoke-minicheck/640ec552-feac-4a35-8651-a85ba3f1f9bd)\n\nThis is a grounded factuality checking model developed by [Bespoke Labs](https://bespokelabs.ai).\n\nThe model takes as input a document (text) and a sentence and determines whether the sentence is supported by the document. In order to fact-check a multi-sentence claim, the claim should first be broken up into sentences. The document does not need to be chunked unless it exceeds 32K tokens.\n\n![bespoke-minicheck-howitworks.png](https://ollama.com/assets/library/bespoke-minicheck/4a1f8cce-a9b2-41e1-8d0a-cb4f1c6b5793)\n\nBespoke-MiniCheck is the SOTA fact-checking model despite its small size.\n\n## Usage\n\nThe prompt template is as follows:\n\n```\nDocument: {document}\nClaim: {claim}\n\n```\n\nThe response will either be `Yes` or `No`.\n\n## Examples\n\nPrompt\n\n```\nDocument: A group of students gather in the school library to study for their upcoming final exams.\nClaim: The students are preparing for an examination.\n\n```\n\nResponse\n\n```\nYes\n\n```\n\nPrompt\n\n```\nDocument: A group of students gather in the school library to study for their upcoming final exams.\nClaim: The students are on vacation.\n\n```\n\nResponse\n\n```\nNo\n\n```\n\n## Model performance\n\n![performance.png](https://ollama.com/assets/jmorgan/bespoke-minicheck/5a757ad2-5eff-4440-a2e7-9efc0bad9703)\n\nThe performance of these models is evaluated on our new collected benchmark (unseen by our models during training), [LLM-AggreFact](https://huggingface.co/datasets/lytang/LLM-AggreFact), from 11 recent human annotated datasets on fact-checking and grounding LLM generations. **Bespoke-MiniCheck-7B is the SOTA fact-checking model despite its small size.**\n\n## References\n\n[Website](https://bespokelabs.ai/bespoke-minicheck)\n\n[Paper](https://arxiv.org/pdf/2404.10774)\n\n[LLM-AggreFact Leaderboard](https://llm-aggrefact.github.io/)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/bespoke-minicheck/640ec552-feac-4a35-8651-a85ba3f1f9bd\" width=\"480\" /> This is a grounded factuality checking model developed by \\[Bespoke Labs\\](https://bespokelabs.ai). The model takes as input a document (text) and a sentence and determines whether the sentence is supported by the document. In order to fact-check a multi-sentence claim, the claim should first be broken up into sentences. The document does not need to be chunked unless it exceeds 32K tokens. !\\[bespoke-minicheck-howitworks.png\\](https://ollama.com/assets/library/bespoke-minicheck/4a1f8cce-a9b2-41e1-8d0a-cb4f1c6b5793) Bespoke-MiniCheck is the SOTA fact-checking model despite its small size. ## Usage The prompt template is as follows: \\`\\`\\` Document: {document} Claim: {claim} \\`\\`\\` The response will either be \\`Yes\\` or \\`No\\`. ## Examples <sub>Prompt</sub> \\`\\`\\` Document: A group of students gather in the school library to study for their upcoming final exams. Claim: The students are preparing for an examination. \\`\\`\\` <sub>Response</sub> \\`\\`\\` Yes \\`\\`\\` <sub>Prompt</sub> \\`\\`\\` Document: A group of students gather in the school library to study for their upcoming final exams. Claim: The students are on vacation. \\`\\`\\` <sub>Response</sub> \\`\\`\\` No \\`\\`\\` ## Model performance !\\[performance.png\\](https://ollama.com/assets/jmorgan/bespoke-minicheck/5a757ad2-5eff-4440-a2e7-9efc0bad9703) The performance of these models is evaluated on our new collected benchmark (unseen by our models during training), \\[LLM-AggreFact\\](https://huggingface.co/datasets/lytang/LLM-AggreFact), from 11 recent human annotated datasets on fact-checking and grounding LLM generations. \\*\\*Bespoke-MiniCheck-7B is the SOTA fact-checking model despite its small size.\\*\\* ## References \\[Website\\](https://bespokelabs.ai/bespoke-minicheck) \\[Paper\\](https://arxiv.org/pdf/2404.10774) \\[LLM-AggreFact Leaderboard\\](https://llm-aggrefact.github.io/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "bespoke-minicheck:latest",
        "size": "bespoke-minicheck:latest",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b",
        "size": "bespoke-minicheck:7b",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q2_K",
        "size": "bespoke-minicheck:7b-q2_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q3_K_S",
        "size": "bespoke-minicheck:7b-q3_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q3_K_M",
        "size": "bespoke-minicheck:7b-q3_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q3_K_L",
        "size": "bespoke-minicheck:7b-q3_K_L",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q4_0",
        "size": "bespoke-minicheck:7b-q4_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q4_1",
        "size": "bespoke-minicheck:7b-q4_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q4_K_S",
        "size": "bespoke-minicheck:7b-q4_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q4_K_M",
        "size": "bespoke-minicheck:7b-q4_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q5_0",
        "size": "bespoke-minicheck:7b-q5_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q5_1",
        "size": "bespoke-minicheck:7b-q5_1",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q5_K_S",
        "size": "bespoke-minicheck:7b-q5_K_S",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q5_K_M",
        "size": "bespoke-minicheck:7b-q5_K_M",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q6_K",
        "size": "bespoke-minicheck:7b-q6_K",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-q8_0",
        "size": "bespoke-minicheck:7b-q8_0",
        "updated": "Text input • \n                    11 months ago"
      },
      {
        "name": "bespoke-minicheck:7b-fp16",
        "size": "bespoke-minicheck:7b-fp16",
        "updated": "Text input • \n                    11 months ago"
      }
    ]
  },
  {
    "name": "wizard-vicuna",
    "link": "https://ollama.com/library/wizard-vicuna",
    "description": "Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.",
    "pullCount": "40.3K",
    "updated": "1 year ago",
    "size": [
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/263123848-e99cc861-483d-4b53-a8ce-5d9c372d343b.png)\n\nWizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.\n\n### CLI\n\nOpen the terminal and run `ollama run wizard-vicuna`\n\n### API\n\nExample:\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"wizard-vicuna\",\n  \"prompt\":\"Why is the sky blue?\"\n }'\n\n```\n\n## Memory requirements\n\n* 13b models generally require at least 16GB of RAM\n\n## Reference\n\n[The Bloke](https://huggingface.co/TheBloke/wizard-vicuna-13B-GGML)\n\n[MelodysDreamj](https://huggingface.co/junelee/wizard-vicuna-13b)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/263123848-e99cc861-483d-4b53-a8ce-5d9c372d343b.png\" width=\"500\" /> Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj. ### CLI Open the terminal and run \\`ollama run wizard-vicuna\\` ### API Example: \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"wizard-vicuna\", \"prompt\":\"Why is the sky blue?\" }' \\`\\`\\` ## Memory requirements - 13b models generally require at least 16GB of RAM ## Reference \\[The Bloke\\](https://huggingface.co/TheBloke/wizard-vicuna-13B-GGML) \\[MelodysDreamj\\](https://huggingface.co/junelee/wizard-vicuna-13b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "wizard-vicuna:latest",
        "size": "wizard-vicuna:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b",
        "size": "wizard-vicuna:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q2_K",
        "size": "wizard-vicuna:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q3_K_S",
        "size": "wizard-vicuna:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q3_K_M",
        "size": "wizard-vicuna:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q3_K_L",
        "size": "wizard-vicuna:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q4_0",
        "size": "wizard-vicuna:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q4_1",
        "size": "wizard-vicuna:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q4_K_S",
        "size": "wizard-vicuna:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q4_K_M",
        "size": "wizard-vicuna:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q5_0",
        "size": "wizard-vicuna:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q5_1",
        "size": "wizard-vicuna:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q5_K_S",
        "size": "wizard-vicuna:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q5_K_M",
        "size": "wizard-vicuna:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q6_K",
        "size": "wizard-vicuna:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-q8_0",
        "size": "wizard-vicuna:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "wizard-vicuna:13b-fp16",
        "size": "wizard-vicuna:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "nuextract",
    "link": "https://ollama.com/library/nuextract",
    "description": "A 3.8B model fine-tuned on a private high-quality synthetic dataset for information extraction, based on Phi-3.",
    "pullCount": "39.9K",
    "updated": "1 year ago",
    "size": [
      "3.8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n### Structure Extraction Model by NuMind 🔥\n\nNuExtract is a version of phi-3-mini, fine-tuned on a private high-quality synthetic dataset for information extraction. To use the model, provide an input text (less than 2000 tokens) and a JSON template describing the information you need to extract.\n\nNote: This model is purely extractive, so all text output by the model is present as is in the original text. You can also provide an example of output formatting to help the model understand your task more precisely.\n\n## Usage\n\n### Prompt Format\n\nThis model works best when using a specific prompt format to extract text:\n\n```\n### Template:\n{\n    \"Model\": {\n        \"Name\": \"\",\n        \"Number of parameters\": \"\",\n    },\n    \"Usage\": {\n        \"Use case\": [],\n        \"Licence\": \"\"\n    }\n}\n### Example:\n{\n    \"Model\": {\n        \"Name\": \"Llama3\",\n        \"Number of parameters\": \"8 billion\",\n    },\n    \"Usage\": {\n        \"Use case\":[\n\t\t\t\"chat\",\n\t\t\t\"code completion\"\n\t\t],\n        \"Licence\": \"Meta Llama3\"\n    }\n}\n### Text:\nWe introduce Mistral 7B, a 7–billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms the best open 13B model (Llama 2) across all evaluated benchmarks, and the best released 34B model (Llama 1) in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license. \n\nCode: https://github.com/mistralai/mistral-src \nWebpage: https://mistral.ai/news/announcing-mistral-7b/\n\n```\n\n### References\n\n[Hugging Face](https://huggingface.co/numind/NuExtract)\n\nWrite Preview \n\n\\### Structure Extraction Model by NuMind 🔥 NuExtract is a version of phi-3-mini, fine-tuned on a private high-quality synthetic dataset for information extraction. To use the model, provide an input text (less than 2000 tokens) and a JSON template describing the information you need to extract. Note: This model is purely extractive, so all text output by the model is present as is in the original text. You can also provide an example of output formatting to help the model understand your task more precisely. ## Usage ### Prompt Format This model works best when using a specific prompt format to extract text: \\`\\`\\`sh ### Template: { \"Model\": { \"Name\": \"\", \"Number of parameters\": \"\", }, \"Usage\": { \"Use case\": \\[\\], \"Licence\": \"\" } } ### Example: { \"Model\": { \"Name\": \"Llama3\", \"Number of parameters\": \"8 billion\", }, \"Usage\": { \"Use case\":\\[ \"chat\", \"code completion\" \\], \"Licence\": \"Meta Llama3\" } } ### Text: We introduce Mistral 7B, a 7–billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms the best open 13B model (Llama 2) across all evaluated benchmarks, and the best released 34B model (Llama 1) in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license. Code: https://github.com/mistralai/mistral-src Webpage: https://mistral.ai/news/announcing-mistral-7b/ \\`\\`\\` ### References \\[Hugging Face\\](https://huggingface.co/numind/NuExtract) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "nuextract:latest",
        "size": "nuextract:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b",
        "size": "nuextract:3.8b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q2_K",
        "size": "nuextract:3.8b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q3_K_S",
        "size": "nuextract:3.8b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q3_K_M",
        "size": "nuextract:3.8b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q3_K_L",
        "size": "nuextract:3.8b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q4_0",
        "size": "nuextract:3.8b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q4_1",
        "size": "nuextract:3.8b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q4_K_S",
        "size": "nuextract:3.8b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q4_K_M",
        "size": "nuextract:3.8b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q5_0",
        "size": "nuextract:3.8b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q5_1",
        "size": "nuextract:3.8b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q5_K_S",
        "size": "nuextract:3.8b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q5_K_M",
        "size": "nuextract:3.8b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q6_K",
        "size": "nuextract:3.8b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-q8_0",
        "size": "nuextract:3.8b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "nuextract:3.8b-fp16",
        "size": "nuextract:3.8b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "granite3-guardian",
    "link": "https://ollama.com/library/granite3-guardian",
    "description": "The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks in prompts and/or responses.",
    "pullCount": "35.8K",
    "updated": "9 months ago",
    "size": [
      "2b",
      "8b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n## Granite guardian models\n\nThe IBM Granite Guardian 3.0 **2B and 8B models** are designed to detect risks in prompts and/or responses. They can help with risk detection along many key dimensions catalogued in the [IBM AI Risk Atlas](https://www.ibm.com/docs/en/watsonx/saas?topic=ai-risk-atlas). They are trained on unique data comprising human annotations and synthetic data informed by internal red-teaming, and they outperform other open-source models in the same space on standard benchmarks.\n\n### Parameter Sizes\n\nThe model will produce a single output token, either `Yes` or `No`. By default, the general-purpose `harm` category is used, but other categories can be selected by setting the system prompt.\n\n**2B:**\n\n```\nollama run granite3-guardian:2b\n>>> /set system profanity\n\n```\n\n**8B:**\n\n```\nollama run granite3-guardian:8b\n>>> /set system violence\n\n```\n\n### Supported Uses\n\n* Risk detection in prompt text or model response (i.e. as guardrails), such as:  \n   * Harm (`harm`): content considered generally harmful  \n   * Social Bias (`social_bias`): prejudice based on identity or characteristics  \n   * Jailbreaking (`jailbreak`): deliberate instances of manipulating AI to generate harmful, undesired, or inappropriate content  \n   * Violence (`violence`): content promoting physical, mental, or sexual harm  \n   * Profanity (`profanity`): use of offensive language or insults  \n   * Sexual Content (`sexual_content`): explicit or suggestive material of a sexual nature  \n   * Unethical Behavior (`unethical_behavior`): actions that violate moral or legal standards\n* RAG (retrieval-augmented generation) to assess:  \n   * Context relevance (`relevance`): whether the retrieved context is relevant to the query  \n   * Groundedness (`groundedness`): whether the response is accurate and faithful to the provided context  \n   * Answer relevance (`answer_relevance`): whether the response directly addresses the user’s query\n\n## Granite dense models\n\nThe Granite dense models are available in **2B and 8B** parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.\n\n[See model page](https://ollama.com/library/granite3-dense)\n\n## Granite mixture of experts models\n\nThe Granite MoE models are available in **1B and 3B** parameter sizes designed for low latency usage and to support deployment in on-device applications or situations requiring instantaneous inference.\n\n[See model page](https://ollama.com/library/granite3-moe)\n\n## Learn more\n\n* **Developers:** IBM Research\n* **GitHub Repository:** [ibm-granite/granite-guardian](https://github.com/ibm-granite/granite-guardian)\n* **Website**: [Granite Guardian Docs](https://www.ibm.com/granite/docs/models/guardian/)\n* **Cookbook**: [Granite Guardian Snack](https://github.com/ibm-granite-community/granite-snack-cookbook/blob/main/recipes/Granite%5FGuardian/Granite%5FGuardian%5FDetailed%5FGuide.ipynb)\n* **Release Date**: October 21st, 2024\n* **License:** [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\nWrite Preview \n\n\\## Granite guardian models The IBM Granite Guardian 3.0 \\*\\*2B and 8B models\\*\\* are designed to detect risks in prompts and/or responses. They can help with risk detection along many key dimensions catalogued in the \\[IBM AI Risk Atlas\\](https://www.ibm.com/docs/en/watsonx/saas?topic=ai-risk-atlas). They are trained on unique data comprising human annotations and synthetic data informed by internal red-teaming, and they outperform other open-source models in the same space on standard benchmarks. ### Parameter Sizes The model will produce a single output token, either \\`Yes\\` or \\`No\\`. By default, the general-purpose \\`harm\\` category is used, but other categories can be selected by setting the system prompt. \\*\\*2B:\\*\\* \\`\\`\\` ollama run granite3-guardian:2b >>> /set system profanity \\`\\`\\` \\*\\*8B:\\*\\* \\`\\`\\` ollama run granite3-guardian:8b >>> /set system violence \\`\\`\\` ### Supported Uses \\* Risk detection in prompt text or model response (i.e. as guardrails), such as: \\* Harm (\\`harm\\`): content considered generally harmful \\* Social Bias (\\`social\\_bias\\`): prejudice based on identity or characteristics \\* Jailbreaking (\\`jailbreak\\`): deliberate instances of manipulating AI to generate harmful, undesired, or inappropriate content \\* Violence (\\`violence\\`): content promoting physical, mental, or sexual harm \\* Profanity (\\`profanity\\`): use of offensive language or insults \\* Sexual Content (\\`sexual\\_content\\`): explicit or suggestive material of a sexual nature \\* Unethical Behavior (\\`unethical\\_behavior\\`): actions that violate moral or legal standards \\* RAG (retrieval-augmented generation) to assess: \\* Context relevance (\\`relevance\\`): whether the retrieved context is relevant to the query \\* Groundedness (\\`groundedness\\`): whether the response is accurate and faithful to the provided context \\* Answer relevance (\\`answer\\_relevance\\`): whether the response directly addresses the user's query ## Granite dense models The Granite dense models are available in \\*\\*2B and 8B\\*\\* parameter sizes designed to support tool-based use cases and for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing. \\[See model page\\](https://ollama.com/library/granite3-dense) ## Granite mixture of experts models The Granite MoE models are available in \\*\\*1B and 3B\\*\\* parameter sizes designed for low latency usage and to support deployment in on-device applications or situations requiring instantaneous inference. \\[See model page\\](https://ollama.com/library/granite3-moe) ## Learn more - \\*\\*Developers:\\*\\* IBM Research - \\*\\*GitHub Repository:\\*\\* \\[ibm-granite/granite-guardian\\](https://github.com/ibm-granite/granite-guardian) - \\*\\*Website\\*\\*: \\[Granite Guardian Docs\\](https://www.ibm.com/granite/docs/models/guardian/) - \\*\\*Cookbook\\*\\*: \\[Granite Guardian Snack\\](https://github.com/ibm-granite-community/granite-snack-cookbook/blob/main/recipes/Granite\\_Guardian/Granite\\_Guardian\\_Detailed\\_Guide.ipynb) - \\*\\*Release Date\\*\\*: October 21st, 2024 - \\*\\*License:\\*\\* \\[Apache 2.0\\](https://www.apache.org/licenses/LICENSE-2.0). \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "granite3-guardian:latest",
        "size": "granite3-guardian:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:2b",
        "size": "granite3-guardian:2b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:8b",
        "size": "granite3-guardian:8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:2b-q8_0",
        "size": "granite3-guardian:2b-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:2b-fp16",
        "size": "granite3-guardian:2b-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:8b-q5_K_S",
        "size": "granite3-guardian:8b-q5_K_S",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:8b-q5_K_M",
        "size": "granite3-guardian:8b-q5_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:8b-q6_K",
        "size": "granite3-guardian:8b-q6_K",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:8b-q8_0",
        "size": "granite3-guardian:8b-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "granite3-guardian:8b-fp16",
        "size": "granite3-guardian:8b-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "megadolphin",
    "link": "https://ollama.com/library/megadolphin",
    "description": "MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself.",
    "pullCount": "35.1K",
    "updated": "1 year ago",
    "size": [
      "120b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/374b4598-4777-44ce-b848-8591a4e0a576)\n\nMegaDolphin-120b was inspired by the amazing [Goliath](https://ollama.ai/library/goliath) and Venus models. This model was created using a method of interleaving a model with itself.\n\n## References\n\n[Hugging Face](https://huggingface.co/cognitivecomputations/MegaDolphin-120b)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/374b4598-4777-44ce-b848-8591a4e0a576\" width=\"320\"/> MegaDolphin-120b was inspired by the amazing \\[Goliath\\](https://ollama.ai/library/goliath) and Venus models. This model was created using a method of interleaving a model with itself. ## References \\[Hugging Face\\](https://huggingface.co/cognitivecomputations/MegaDolphin-120b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "megadolphin:latest",
        "size": "megadolphin:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:v2.2",
        "size": "megadolphin:v2.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b",
        "size": "megadolphin:120b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2",
        "size": "megadolphin:120b-v2.2",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q2_K",
        "size": "megadolphin:120b-v2.2-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q3_K_S",
        "size": "megadolphin:120b-v2.2-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q3_K_M",
        "size": "megadolphin:120b-v2.2-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q3_K_L",
        "size": "megadolphin:120b-v2.2-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q4_0",
        "size": "megadolphin:120b-v2.2-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q4_1",
        "size": "megadolphin:120b-v2.2-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q4_K_S",
        "size": "megadolphin:120b-v2.2-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q4_K_M",
        "size": "megadolphin:120b-v2.2-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q5_0",
        "size": "megadolphin:120b-v2.2-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q5_1",
        "size": "megadolphin:120b-v2.2-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q5_K_S",
        "size": "megadolphin:120b-v2.2-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q5_K_M",
        "size": "megadolphin:120b-v2.2-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q6_K",
        "size": "megadolphin:120b-v2.2-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-q8_0",
        "size": "megadolphin:120b-v2.2-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "megadolphin:120b-v2.2-fp16",
        "size": "megadolphin:120b-v2.2-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "notux",
    "link": "https://ollama.com/library/notux",
    "description": "A top-performing mixture of experts model, fine-tuned with high-quality data.",
    "pullCount": "34.5K",
    "updated": "1 year ago",
    "size": [
      "8x7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/4d57573b-8a00-46ea-8d62-e1e6f0bd1411)\n\nThis model is a fine-tuned version of [Mixtral](https://ollama.ai/library/mixtral) using a high-quality, curated dataset. As of Dec 26th 2023, this model is the top ranked MoE (Mixture of Experts) model on the [Hugging Face Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open%5Fllm%5Fleaderboard).\n\n## References\n\n[HuggingFace](https://huggingface.co/argilla/notux-8x7b-v1)\n\n[Argilla](https://argilla.io/)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/4d57573b-8a00-46ea-8d62-e1e6f0bd1411\" width=\"280\" /> This model is a fine-tuned version of \\[Mixtral\\](https://ollama.ai/library/mixtral) using a high-quality, curated dataset. As of Dec 26th 2023, this model is the top ranked MoE (Mixture of Experts) model on the \\[Hugging Face Open LLM Leaderboard\\](https://huggingface.co/spaces/HuggingFaceH4/open\\_llm\\_leaderboard). ## References \\[HuggingFace\\](https://huggingface.co/argilla/notux-8x7b-v1) \\[Argilla\\](https://argilla.io/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "notux:latest",
        "size": "notux:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b",
        "size": "notux:8x7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1",
        "size": "notux:8x7b-v1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q2_K",
        "size": "notux:8x7b-v1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q3_K_S",
        "size": "notux:8x7b-v1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q3_K_M",
        "size": "notux:8x7b-v1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q3_K_L",
        "size": "notux:8x7b-v1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q4_0",
        "size": "notux:8x7b-v1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q4_1",
        "size": "notux:8x7b-v1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q4_K_S",
        "size": "notux:8x7b-v1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q4_K_M",
        "size": "notux:8x7b-v1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q5_0",
        "size": "notux:8x7b-v1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q5_1",
        "size": "notux:8x7b-v1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q5_K_S",
        "size": "notux:8x7b-v1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q5_K_M",
        "size": "notux:8x7b-v1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q6_K",
        "size": "notux:8x7b-v1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-q8_0",
        "size": "notux:8x7b-v1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notux:8x7b-v1-fp16",
        "size": "notux:8x7b-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "open-orca-platypus2",
    "link": "https://ollama.com/library/open-orca-platypus2",
    "description": "Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation.",
    "pullCount": "34.1K",
    "updated": "1 year ago",
    "size": [
      "13b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://user-images.githubusercontent.com/633681/262757252-66e5d8a6-40d8-4cd8-b4b9-30d3f7dc1466.png)\n\nThe OpenOrca Platypus2 model is a 13 billion parameter model which is a merge of the OpenOrca OpenChat model and the Garage-bAInd Platypus2-13B model which are both fine tunings of the Llama 2 model. It is designed to be a general-use model that can be used for chat, text generation, and code generation.\n\n## Get started with OpenOrca Platypus 2\n\nThe model used in the example below is the OpenOrca Platypus 2 model, with 13b parameters, which is a general-use model.\n\n### API\n\n1. Start Ollama server (Run `ollama serve`)\n2. Run the model\n\n```\ncurl -X POST http://localhost:11434/api/generate -d '{\n  \"model\": \"open-orca-platypus2\",\n  \"prompt\":\"Tell me a joke about ropes.\"\n }'\n\n```\n\n### CLI\n\n1. Install Ollama\n2. Open the terminal and run `ollama run open-orca-platypus2`\n\nNote: The `ollama run` command performs an `ollama pull` if the model is not already downloaded. To download the model without running it, use `ollama pull open-orca-platypus2`\n\n## Memory requirements\n\n* 13b models generally require at least 16GB of RAM\n\nIf you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory.\n\n## Model variants\n\nBy default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires.\n\n| **Aliases**            |\n| ---------------------- |\n| latest, 13b, 13b-q4\\_0 |\n\n## Model source\n\n**OpenOrca Platypus 2 source on Ollama**\n\n13b parameters source:[OpenOrca](https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B)\n\n## References\n\n[Platypus: Quick, Cheap, and Powerful Refinement of LLMs](https://arxiv.org/abs/2308.07317)\n\nWrite Preview \n\n<img src=\"https://user-images.githubusercontent.com/633681/262757252-66e5d8a6-40d8-4cd8-b4b9-30d3f7dc1466.png\" style=\"max-width:60%\" /> The OpenOrca Platypus2 model is a 13 billion parameter model which is a merge of the OpenOrca OpenChat model and the Garage-bAInd Platypus2-13B model which are both fine tunings of the Llama 2 model. It is designed to be a general-use model that can be used for chat, text generation, and code generation. ## Get started with OpenOrca Platypus 2 The model used in the example below is the OpenOrca Platypus 2 model, with 13b parameters, which is a general-use model. ### API 1\\. Start Ollama server (Run \\`ollama serve\\`) 2\\. Run the model \\`\\`\\`bash curl -X POST http://localhost:11434/api/generate -d '{ \"model\": \"open-orca-platypus2\", \"prompt\":\"Tell me a joke about ropes.\" }' \\`\\`\\` ### CLI 1\\. Install Ollama 2\\. Open the terminal and run \\`ollama run open-orca-platypus2\\` Note: The \\`ollama run\\` command performs an \\`ollama pull\\` if the model is not already downloaded. To download the model without running it, use \\`ollama pull open-orca-platypus2\\` ## Memory requirements - 13b models generally require at least 16GB of RAM If you run into issues with higher quantization levels, try using the q4 model or shut down any other programs that are using a lot of memory. ## Model variants By default, Ollama uses 4-bit quantization. To try other quantization levels, please try the other tags. The number after the q represents the number of bits used for quantization (i.e. q4 means 4-bit quantization). The higher the number, the more accurate the model is, but the slower it runs, and the more memory it requires. | \\*\\*Aliases\\*\\* | | --- | | latest, 13b, 13b-q4\\_0 | ## Model source \\*\\*OpenOrca Platypus 2 source on Ollama\\*\\* 13b parameters source: \\[OpenOrca\\](https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B) ## References \\[Platypus: Quick, Cheap, and Powerful Refinement of LLMs\\](https://arxiv.org/abs/2308.07317 ) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "open-orca-platypus2:latest",
        "size": "open-orca-platypus2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b",
        "size": "open-orca-platypus2:13b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q2_K",
        "size": "open-orca-platypus2:13b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q3_K_S",
        "size": "open-orca-platypus2:13b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q3_K_M",
        "size": "open-orca-platypus2:13b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q3_K_L",
        "size": "open-orca-platypus2:13b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q4_0",
        "size": "open-orca-platypus2:13b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q4_1",
        "size": "open-orca-platypus2:13b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q4_K_S",
        "size": "open-orca-platypus2:13b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q4_K_M",
        "size": "open-orca-platypus2:13b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q5_0",
        "size": "open-orca-platypus2:13b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q5_1",
        "size": "open-orca-platypus2:13b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q5_K_S",
        "size": "open-orca-platypus2:13b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q5_K_M",
        "size": "open-orca-platypus2:13b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q6_K",
        "size": "open-orca-platypus2:13b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-q8_0",
        "size": "open-orca-platypus2:13b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "open-orca-platypus2:13b-fp16",
        "size": "open-orca-platypus2:13b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "notus",
    "link": "https://ollama.com/library/notus",
    "description": "A 7B chat model fine-tuned with high-quality data and based on Zephyr.",
    "pullCount": "33.6K",
    "updated": "1 year ago",
    "size": [
      "7b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/4d57573b-8a00-46ea-8d62-e1e6f0bd1411)\n\nNotus is a model by [Argilla](https://argilla.io/), fine-tuned from [Zephyr](https://ollama.ai/library/zephyr) using a high-quality dataset.\n\n## References\n\n[HuggingFace](https://huggingface.co/argilla/notus-7b-v1)\n\n[Argilla](https://argilla.io/)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/4d57573b-8a00-46ea-8d62-e1e6f0bd1411\" width=\"280\" /> Notus is a model by \\[Argilla\\](https://argilla.io/), fine-tuned from \\[Zephyr\\](https://ollama.ai/library/zephyr) using a high-quality dataset. ## References \\[HuggingFace\\](https://huggingface.co/argilla/notus-7b-v1) \\[Argilla\\](https://argilla.io/) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "notus:latest",
        "size": "notus:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b",
        "size": "notus:7b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1",
        "size": "notus:7b-v1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q2_K",
        "size": "notus:7b-v1-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q3_K_S",
        "size": "notus:7b-v1-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q3_K_M",
        "size": "notus:7b-v1-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q3_K_L",
        "size": "notus:7b-v1-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q4_0",
        "size": "notus:7b-v1-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q4_1",
        "size": "notus:7b-v1-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q4_K_S",
        "size": "notus:7b-v1-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q4_K_M",
        "size": "notus:7b-v1-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q5_0",
        "size": "notus:7b-v1-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q5_1",
        "size": "notus:7b-v1-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q5_K_S",
        "size": "notus:7b-v1-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q5_K_M",
        "size": "notus:7b-v1-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q6_K",
        "size": "notus:7b-v1-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-q8_0",
        "size": "notus:7b-v1-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "notus:7b-v1-fp16",
        "size": "notus:7b-v1-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "sailor2",
    "link": "https://ollama.com/library/sailor2",
    "description": "Sailor2 are multilingual language models made for South-East Asia. Available in 1B, 8B, and 20B parameter sizes.",
    "pullCount": "32.4K",
    "updated": "9 months ago",
    "size": [
      "1b",
      "8b",
      "20b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![logo](/assets/mchiang0610/sailor2/a76a9182-cc11-47e1-bb50-478ad4ccb157)\n\nSailor2 is a community-driven initiative that brings cutting-edge multilingual language models to South-East Asia (SEA). Our research highlights a strong demand for models in the **8B and 20B** parameter range for production use, alongside **1B models** for specialized applications, such as speculative decoding and research purposes. These models, released under the **Apache 2.0 license**, provide enhanced accessibility to advanced language technologies across the region.\n\nSailor2 builds upon the foundation of the awesome multilingual model Qwen 2.5 and is continuously pre-trained on 500B tokens to support 15 languages better with a unified model. These languages include English, Chinese, Burmese, Cebuano, Ilocano, Indonesian, Javanese, Khmer, Lao, Malay, Sundanese, Tagalog, Thai, Vietnamese, and Waray. By addressing the growing demand for diverse, robust, and accessible language models, Sailor2 seeks to serve the underserved in SEA areas with open, inclusive, and accessible multilingual LLMs. The Sailor2 model comes in three sizes, 1B, 8B, and 20B, which are expanded from the Qwen2.5 base models of 0.5B, 7B, and 14B, respectively.\n\nWrite Preview \n\n!\\[logo\\](/assets/mchiang0610/sailor2/a76a9182-cc11-47e1-bb50-478ad4ccb157) Sailor2 is a community-driven initiative that brings cutting-edge multilingual language models to South-East Asia (SEA). Our research highlights a strong demand for models in the \\*\\*8B and 20B\\*\\* parameter range for production use, alongside \\*\\*1B models\\*\\* for specialized applications, such as speculative decoding and research purposes. These models, released under the \\*\\*Apache 2.0 license\\*\\*, provide enhanced accessibility to advanced language technologies across the region. Sailor2 builds upon the foundation of the awesome multilingual model Qwen 2.5 and is continuously pre-trained on 500B tokens to support 15 languages better with a unified model. These languages include English, Chinese, Burmese, Cebuano, Ilocano, Indonesian, Javanese, Khmer, Lao, Malay, Sundanese, Tagalog, Thai, Vietnamese, and Waray. By addressing the growing demand for diverse, robust, and accessible language models, Sailor2 seeks to serve the underserved in SEA areas with open, inclusive, and accessible multilingual LLMs. The Sailor2 model comes in three sizes, 1B, 8B, and 20B, which are expanded from the Qwen2.5 base models of 0.5B, 7B, and 14B, respectively. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "sailor2:latest",
        "size": "sailor2:latest",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:1b",
        "size": "sailor2:1b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:8b",
        "size": "sailor2:8b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:20b",
        "size": "sailor2:20b",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:1b-chat-q4_K_M",
        "size": "sailor2:1b-chat-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:1b-chat-q8_0",
        "size": "sailor2:1b-chat-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:1b-chat-fp16",
        "size": "sailor2:1b-chat-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:8b-chat-q4_K_M",
        "size": "sailor2:8b-chat-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:8b-chat-q8_0",
        "size": "sailor2:8b-chat-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:8b-chat-fp16",
        "size": "sailor2:8b-chat-fp16",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:20b-chat-q4_K_M",
        "size": "sailor2:20b-chat-q4_K_M",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:20b-chat-q8_0",
        "size": "sailor2:20b-chat-q8_0",
        "updated": "Text input • \n                    9 months ago"
      },
      {
        "name": "sailor2:20b-chat-fp16",
        "size": "sailor2:20b-chat-fp16",
        "updated": "Text input • \n                    9 months ago"
      }
    ]
  },
  {
    "name": "goliath",
    "link": "https://ollama.com/library/goliath",
    "description": "A language model created by combining two fine-tuned Llama 2 70B models into one.",
    "pullCount": "32.3K",
    "updated": "1 year ago",
    "size": null,
    "capabilities": "",
    "readme": "## Readme\n\nA large model used by merging the layers of two models: [Xwin](https://ollama.ai/library/xwinlm) and Euryale.\n\n## References\n\n[HuggingFace](https://huggingface.co/alpindale/goliath-120b)\n\nWrite Preview \n\nA large model used by merging the layers of two models: \\[Xwin\\](https://ollama.ai/library/xwinlm) and Euryale. ## References \\[HuggingFace\\](https://huggingface.co/alpindale/goliath-120b) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "goliath:latest",
        "size": "goliath:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q2_K",
        "size": "goliath:120b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q3_K_S",
        "size": "goliath:120b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q3_K_M",
        "size": "goliath:120b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q3_K_L",
        "size": "goliath:120b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q4_0",
        "size": "goliath:120b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q4_1",
        "size": "goliath:120b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q4_K_S",
        "size": "goliath:120b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q4_K_M",
        "size": "goliath:120b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q5_0",
        "size": "goliath:120b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q5_1",
        "size": "goliath:120b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q5_K_S",
        "size": "goliath:120b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q5_K_M",
        "size": "goliath:120b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q6_K",
        "size": "goliath:120b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-q8_0",
        "size": "goliath:120b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "goliath:120b-fp16",
        "size": "goliath:120b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "firefunction-v2",
    "link": "https://ollama.com/library/firefunction-v2",
    "description": "An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities.",
    "pullCount": "32.2K",
    "updated": "1 year ago",
    "size": [
      "70b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](https://ollama.com/assets/library/firefunction-v2/a2b66a3e-ff43-4eae-b95c-d71b669384a5)\n\nFirefunction-v2 is competitive with GPT-4o function calling capabilities, scoring 0.81 on a medley public benchmarks vs 0.80 for GPT-4o.\n\nFirefunction-v2 is optimized for real world scenarios including multi-turn conversation, instruction following and parallel function calling. It retains Llama 3’s multi-turn instruction capability (0.84 vs 0.89 on MT bench) while consistently outscoring Llama 3 on function calling tasks (0.51 vs 0.30 on Nexus parallel multi function eval)\n\n## References\n\n[Blog Post](https://fireworks.ai/blog/firefunction-v2-launch-post)\n\n[Hugging Face](https://huggingface.co/fireworks-ai/llama-3-firefunction-v2)\n\nWrite Preview \n\n<img src=\"https://ollama.com/assets/library/firefunction-v2/a2b66a3e-ff43-4eae-b95c-d71b669384a5\" width=\"280\" /> Firefunction-v2 is competitive with GPT-4o function calling capabilities, scoring 0.81 on a medley public benchmarks vs 0.80 for GPT-4o. Firefunction-v2 is optimized for real world scenarios including multi-turn conversation, instruction following and parallel function calling. It retains Llama 3’s multi-turn instruction capability (0.84 vs 0.89 on MT bench) while consistently outscoring Llama 3 on function calling tasks (0.51 vs 0.30 on Nexus parallel multi function eval) ## References \\[Blog Post\\](https://fireworks.ai/blog/firefunction-v2-launch-post) \\[Hugging Face\\](https://huggingface.co/fireworks-ai/llama-3-firefunction-v2) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "firefunction-v2:latest",
        "size": "firefunction-v2:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b",
        "size": "firefunction-v2:70b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q2_K",
        "size": "firefunction-v2:70b-q2_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q3_K_S",
        "size": "firefunction-v2:70b-q3_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q3_K_M",
        "size": "firefunction-v2:70b-q3_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q3_K_L",
        "size": "firefunction-v2:70b-q3_K_L",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q4_0",
        "size": "firefunction-v2:70b-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q4_1",
        "size": "firefunction-v2:70b-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q4_K_S",
        "size": "firefunction-v2:70b-q4_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q4_K_M",
        "size": "firefunction-v2:70b-q4_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q5_0",
        "size": "firefunction-v2:70b-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q5_1",
        "size": "firefunction-v2:70b-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q5_K_S",
        "size": "firefunction-v2:70b-q5_K_S",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q5_K_M",
        "size": "firefunction-v2:70b-q5_K_M",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q6_K",
        "size": "firefunction-v2:70b-q6_K",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-q8_0",
        "size": "firefunction-v2:70b-q8_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "firefunction-v2:70b-fp16",
        "size": "firefunction-v2:70b-fp16",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "deepseek-v3.1",
    "link": "https://ollama.com/library/deepseek-v3.1",
    "description": "DeepSeek-V3.1 is a hybrid model that supports both thinking mode and non-thinking mode.",
    "pullCount": "29.5K",
    "updated": "6 days ago",
    "size": [
      "671b"
    ],
    "capabilities": "toolsthinking",
    "readme": "## Readme\n\n![logo.svg](/assets/library/deepseek-v3.1/c3f72402-1dce-4c07-a2a1-eebabd4f4b4b)\n\n> This model requires Ollama v0.11.7 which is currently in [pre-release](https://github.com/ollama/ollama/releases/tag/v0.11.7).\n\nDeepSeek-V3.1 is a hybrid model that supports both thinking mode and non-thinking mode. Compared to the previous version, this upgrade brings improvements in multiple aspects:\n\n**Hybrid thinking mode**: One model supports both thinking mode and non-thinking mode by changing the chat template.\n\n**Smarter tool calling**: Through post-training optimization, the model’s performance in tool usage and agent tasks has significantly improved.\n\n**Higher thinking efficiency**: DeepSeek-V3.1-Think achieves comparable answer quality to DeepSeek-R1-0528, while responding more quickly.\n\nWrite Preview \n\n!\\[logo.svg\\](/assets/library/deepseek-v3.1/c3f72402-1dce-4c07-a2a1-eebabd4f4b4b) > This model requires Ollama v0.11.7 which is currently in \\[pre-release\\](https://github.com/ollama/ollama/releases/tag/v0.11.7). DeepSeek-V3.1 is a hybrid model that supports both thinking mode and non-thinking mode. Compared to the previous version, this upgrade brings improvements in multiple aspects: \\*\\*Hybrid thinking mode\\*\\*: One model supports both thinking mode and non-thinking mode by changing the chat template. \\*\\*Smarter tool calling\\*\\*: Through post-training optimization, the model's performance in tool usage and agent tasks has significantly improved. \\*\\*Higher thinking efficiency\\*\\*: DeepSeek-V3.1-Think achieves comparable answer quality to DeepSeek-R1-0528, while responding more quickly. \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "deepseek-v3.1:latest",
        "size": "deepseek-v3.1:latest",
        "updated": "Text input • \n                    6 days ago"
      },
      {
        "name": "deepseek-v3.1:671b",
        "size": "deepseek-v3.1:671b",
        "updated": "Text input • \n                    2 weeks ago"
      },
      {
        "name": "deepseek-v3.1:671b-q8_0",
        "size": "deepseek-v3.1:671b-q8_0",
        "updated": "Text input • \n                    2 weeks ago"
      },
      {
        "name": "deepseek-v3.1:671b-fp16",
        "size": "deepseek-v3.1:671b-fp16",
        "updated": "Text input • \n                    1 week ago"
      }
    ]
  },
  {
    "name": "alfred",
    "link": "https://ollama.com/library/alfred",
    "description": "A robust conversational model designed to be used for both chat and instruct use cases.",
    "pullCount": "26.5K",
    "updated": "1 year ago",
    "size": [
      "40b"
    ],
    "capabilities": "",
    "readme": "## Readme\n\n![](https://github.com/jmorganca/ollama/assets/251292/a689335b-a2a1-4be9-a132-aaaf7171e6b8)\n\nAlfred is a robust conversational model created by LightOn, based on the [Falcon](https://ollama.ai/library/falcon) 40B model. It’s designed to be used for both chat and instruct use cases.\n\nSome of its features include:\n\n* Reduced Hallucinations: ability to minimize hallucinations, ensuring more accurate and reliable outputs.\n* Enhanced Self-Awareness: In situations where the model lacks a definitive answer, Alfred-40B-1023 is now programmed to state, “I don’t know”, enhancing its transparency and trustworthiness.\n* Superior ‘Chat with Docs’ Capability: Alfred-40B-1023 is trained to perform ‘Chat with Docs’ tasks like no other, streamlining document interaction and information retrieval.\n* Expanded Context: With an increased context of 8K tokens, Alfred-40B-1023 can comprehend and generate longer and more intricate content, ensuring detailed and comprehensive responses.\n\n## References\n\n[HuggingFace](https://huggingface.co/lightonai/alfred-40b-1023)\n\n[Blog Post](https://www.lighton.ai/blog/lighton-s-blog-4/alfred-40b-1023-44)\n\nWrite Preview \n\n<img src=\"https://github.com/jmorganca/ollama/assets/251292/a689335b-a2a1-4be9-a132-aaaf7171e6b8\" width=\"300\"> Alfred is a robust conversational model created by LightOn, based on the \\[Falcon\\](https://ollama.ai/library/falcon) 40B model. It's designed to be used for both chat and instruct use cases. Some of its features include: \\* Reduced Hallucinations: ability to minimize hallucinations, ensuring more accurate and reliable outputs. \\* Enhanced Self-Awareness: In situations where the model lacks a definitive answer, Alfred-40B-1023 is now programmed to state, \"I don't know\", enhancing its transparency and trustworthiness. \\* Superior 'Chat with Docs' Capability: Alfred-40B-1023 is trained to perform 'Chat with Docs' tasks like no other, streamlining document interaction and information retrieval. \\* Expanded Context: With an increased context of 8K tokens, Alfred-40B-1023 can comprehend and generate longer and more intricate content, ensuring detailed and comprehensive responses. ## References \\[HuggingFace\\](https://huggingface.co/lightonai/alfred-40b-1023) \\[Blog Post\\](https://www.lighton.ai/blog/lighton-s-blog-4/alfred-40b-1023-44) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "alfred:latest",
        "size": "alfred:latest",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "alfred:40b",
        "size": "alfred:40b",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "alfred:40b-1023-q4_0",
        "size": "alfred:40b-1023-q4_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "alfred:40b-1023-q4_1",
        "size": "alfred:40b-1023-q4_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "alfred:40b-1023-q5_0",
        "size": "alfred:40b-1023-q5_0",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "alfred:40b-1023-q5_1",
        "size": "alfred:40b-1023-q5_1",
        "updated": "Text input • \n                    1 year ago"
      },
      {
        "name": "alfred:40b-1023-q8_0",
        "size": "alfred:40b-1023-q8_0",
        "updated": "Text input • \n                    1 year ago"
      }
    ]
  },
  {
    "name": "command-r7b-arabic",
    "link": "https://ollama.com/library/command-r7b-arabic",
    "description": "A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.",
    "pullCount": "17.3K",
    "updated": "6 months ago",
    "size": [
      "7b"
    ],
    "capabilities": "tools",
    "readme": "## Readme\n\n![](/assets/library/command-r7b-arabic/e96310ca-5a9a-4e86-8eda-5a0a68513fc6)\n\nCommand R7B Arabic is a fast and highly efficient model that can be served on low-end GPUs, a MacBook, or even CPUs. Similar to other models in the R series, it offers a context length of 128k and industry-leading performance in its class across capabilities that matter most to businesses like regional language understanding and strong accuracy with citations using retrieval-augmented generation (RAG). Its compact size enables businesses to more easily scale Arabic language AI applications to production.\n\n## References\n\n[Blog Post](https://cohere.com/blog/command-r7b-arabic)\n\n[Hugging Face](https://huggingface.co/CohereForAI/c4ai-command-r7b-arabic-02-2025)\n\nWrite Preview \n\n!\\[Hero--1-.webp\\](/assets/library/command-r7b-arabic/e96310ca-5a9a-4e86-8eda-5a0a68513fc6) Command R7B Arabic is a fast and highly efficient model that can be served on low-end GPUs, a MacBook, or even CPUs. Similar to other models in the R series, it offers a context length of 128k and industry-leading performance in its class across capabilities that matter most to businesses like regional language understanding and strong accuracy with citations using retrieval-augmented generation (RAG). Its compact size enables businesses to more easily scale Arabic language AI applications to production. ## References \\[Blog Post\\](https://cohere.com/blog/command-r7b-arabic) \\[Hugging Face\\](https://huggingface.co/CohereForAI/c4ai-command-r7b-arabic-02-2025) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "command-r7b-arabic:latest",
        "size": "command-r7b-arabic:latest",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "command-r7b-arabic:7b",
        "size": "command-r7b-arabic:7b",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "command-r7b-arabic:7b-02-2025-q4_K_M",
        "size": "command-r7b-arabic:7b-02-2025-q4_K_M",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "command-r7b-arabic:7b-02-2025-q8_0",
        "size": "command-r7b-arabic:7b-02-2025-q8_0",
        "updated": "Text input • \n                    6 months ago"
      },
      {
        "name": "command-r7b-arabic:7b-02-2025-fp16",
        "size": "command-r7b-arabic:7b-02-2025-fp16",
        "updated": "Text input • \n                    6 months ago"
      }
    ]
  },
  {
    "name": "embeddinggemma",
    "link": "https://ollama.com/library/embeddinggemma",
    "description": "EmbeddingGemma is a 300M parameter embedding model from Google.",
    "pullCount": "6,274",
    "updated": "yesterday",
    "size": null,
    "capabilities": "",
    "readme": "## Readme\n\n![image.png](/assets/library/embeddinggemma/9a20d963-4bf1-4177-9568-ca5d53a2d14e)\n\n> This model requires [Ollama v0.11.10](https://github.com/ollama/ollama/releases/tag/v0.11.10) or later\n\n**EmbeddingGemma** is a 300M parameter, state-of-the-art for its size, open embedding model from Google, built from Gemma 3 (with T5Gemma initialization) and the same research and technology used to create Gemini models. EmbeddingGemma produces vector representations of text, making it well-suited for search and retrieval tasks, including classification, clustering, and semantic similarity search. This model was trained with data in 100+ spoken languages.\n\nThe small size and on-device focus makes it possible to deploy in environments with limited resources such as mobile phones, laptops, or desktops, democratizing access to state of the art AI models and helping foster innovation for everyone.\n\n### Benchmark\n\n![image.png](/assets/library/embeddinggemma/59a205f6-1711-4db4-8026-96d23fa2c9da)\n\n#### Training Dataset\n\nThis model was trained on a dataset of text data that includes a wide variety of sources totaling approximately 320 billion tokens. Here are the key components:\n\n* **Web Documents**: A diverse collection of web text ensures the model is exposed to a broad range of linguistic styles, topics, and vocabulary. The training dataset includes content in over 100 languages.\n* **Code and Technical Documents**: Exposing the model to code and technical documentation helps it learn the structure and patterns of programming languages and specialized scientific content, which improves its understanding of code and technical questions.\n* **Synthetic and Task-Specific Data**: Synthetically training data helps to teach the model specific skills. This includes curated data for tasks like information retrieval, classification, and sentiment analysis, which helps to fine-tune its performance for common embedding applications.\n\nThe combination of these diverse data sources is crucial for training a powerful multilingual embedding model that can handle a wide variety of different tasks and data formats.\n\n### Reference\n\n[Documentation](https://ai.google.dev/gemma/docs/embeddinggemma)\n\nWrite Preview \n\n!\\[image.png\\](/assets/library/embeddinggemma/9a20d963-4bf1-4177-9568-ca5d53a2d14e) > This model requires \\[Ollama v0.11.10\\](https://github.com/ollama/ollama/releases/tag/v0.11.10) or later \\*\\*EmbeddingGemma\\*\\* is a 300M parameter, state-of-the-art for its size, open embedding model from Google, built from Gemma 3 (with T5Gemma initialization) and the same research and technology used to create Gemini models. EmbeddingGemma produces vector representations of text, making it well-suited for search and retrieval tasks, including classification, clustering, and semantic similarity search. This model was trained with data in 100+ spoken languages. The small size and on-device focus makes it possible to deploy in environments with limited resources such as mobile phones, laptops, or desktops, democratizing access to state of the art AI models and helping foster innovation for everyone. ### Benchmark !\\[image.png\\](/assets/library/embeddinggemma/59a205f6-1711-4db4-8026-96d23fa2c9da) #### Training Dataset This model was trained on a dataset of text data that includes a wide variety of sources totaling approximately 320 billion tokens. Here are the key components: - \\*\\*Web Documents\\*\\*: A diverse collection of web text ensures the model is exposed to a broad range of linguistic styles, topics, and vocabulary. The training dataset includes content in over 100 languages. - \\*\\*Code and Technical Documents\\*\\*: Exposing the model to code and technical documentation helps it learn the structure and patterns of programming languages and specialized scientific content, which improves its understanding of code and technical questions. - \\*\\*Synthetic and Task-Specific Data\\*\\*: Synthetically training data helps to teach the model specific skills. This includes curated data for tasks like information retrieval, classification, and sentiment analysis, which helps to fine-tune its performance for common embedding applications. The combination of these diverse data sources is crucial for training a powerful multilingual embedding model that can handle a wide variety of different tasks and data formats. ### Reference \\[Documentation\\](https://ai.google.dev/gemma/docs/embeddinggemma) \n\n Paste, drop or click to upload images (.png, .jpeg, .jpg, .svg, .gif) ",
    "tags": [
      {
        "name": "embeddinggemma:latest",
        "size": "embeddinggemma:latest",
        "updated": "Text input • \n                    yesterday"
      },
      {
        "name": "embeddinggemma:300m",
        "size": "embeddinggemma:300m",
        "updated": "Text input • \n                    yesterday"
      },
      {
        "name": "embeddinggemma:300m-qat-q4_0",
        "size": "embeddinggemma:300m-qat-q4_0",
        "updated": "Text input • \n                    yesterday"
      },
      {
        "name": "embeddinggemma:300m-qat-q8_0",
        "size": "embeddinggemma:300m-qat-q8_0",
        "updated": "Text input • \n                    yesterday"
      },
      {
        "name": "embeddinggemma:300m-bf16",
        "size": "embeddinggemma:300m-bf16",
        "updated": "Text input • \n                    yesterday"
      }
    ]
  }
]